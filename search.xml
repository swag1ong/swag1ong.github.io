<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>DDQN</title>
    <url>/2021/05/07/DDQN/</url>
    <content><![CDATA[<h1 id="deep-reinforcement-learning-with-double-q-learning"><a href="https://arxiv.org/abs/1509.06461">Deep Reinforcement Learning with Double Q-Learning</a></h1>
<h2 id="introduction">Introduction</h2>
<p>The authors show that the double Q-learning algorithm which was first proposed in a tabular setting, can be generalized to arbitrary function approximation, including DNN. They use this to construct a new algorithm called double DQN to solve the overestimation problem in DQN.</p>
<h2 id="notations">Notations</h2>
<p>Define:</p>
<p><span class="math display">\[Q_{\pi} (s, a) = E[R_1 + \gamma R_2 + ... | S_0=s, A_0=a, \pi]\]</span></p>
<p><span class="math display">\[Q_{*} (s, a) = max_{\pi} Q_{\pi} (s, a)\]</span></p>
<p><span class="math display">\[\pi_{*} (s) = argmax_{a \in A} Q_{*} (s, a)\]</span></p>
<p>The Target:</p>
<p><span class="math display">\[Y_t^{Q} = R_{t+1} + \gamma max_{a} Q(S_{t+1}, a; \theta_{t})\]</span></p>
<p>A standard Q update using stochastic gradient decent is (Semi-gradient Q):</p>
<p><span class="math display">\[\theta_{t+1} = \theta_t + \alpha (Y_{t}^{Q} - Q(S_t, A_t; \theta_t)) \nabla_{\theta_t} Q(S_t, A_t; \theta_t)\]</span></p>
<p>Where <span class="math inline">\(\alpha\)</span> is a scalar step size.</p>
<span id="more"></span>
<h2 id="background">Background</h2>
<h3 id="double-q-learning">Double Q-learning</h3>
<p>The max operator in standard Q-learning and DQN uses the same values both to select and to evaluate an action (ie. same Q is used to select the max action and use the value of this max action to update the Value of the state action pair). This makes it more likely to select overestimated values, resulting in overoptimistic value estimates.</p>
<p>In Double Q-learning, two value functions are learned by assigning experiences randomly to update one of the two value functions, resulting in two sets of weights, <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\theta^{\prime}\)</span>. For each update, one set of weights is used to determine the greedy action, and the other to determine its value.</p>
<p>Previous Q target:</p>
<p><span class="math display">\[Y_t^{Q} = R_{t+1} + \gamma Q(S_{t+1}, argmax_{a \in A} Q(S_{t+1}, a; \boldsymbol{\theta_t}); \boldsymbol{\theta_{t}})\]</span></p>
<p>The double Q-learning target:</p>
<p><span class="math display">\[Y_t^{\text{DoubleQ}} = R_{t+1} + \gamma Q(S_{t+1}, argmax_{a \in A} Q(S_{t+1}, a; \boldsymbol{\theta_t}); \boldsymbol{\theta^{\prime}_{t}})\]</span></p>
<h3 id="maximization-problem">Maximization Problem</h3>
<p><img src='/images/RL/papers/DDQN_1.png'></p>
<p>This theorem shows that even if the value estimates are on average correct, estimation errors of any source can drive the estimates up and away from the true optimal values.</p>
<p>The lower bound in Theorem 1 decreases with the number of actions. This is an artifact of considering the lower bound, which requires very specific values to be attained. More typically, the overoptimism increases with the number of actions.</p>
<p><img src='/images/RL/papers/DDQN_2.png'></p>
<p><span class="math display">\[E[Q(s, a) - V_{*}(s)] = E[V_{*}(s) - V_{*}(s) + \epsilon ] = 0\]</span></p>
<p>But, Q-learning updates have large bias due to max operation, the phenomena is severer as number of actions increases.</p>
<p>In function approximation setting:</p>
<p><img src='/images/RL/papers/DDQN_3.png'></p>
<h2 id="algorithm">Algorithm</h2>
<p>The target network in the DQN architecture provides a natural candidate for the second value function, without having to introduce additional networks. Thus, we can evaluate the greedy policy according to the online network, but using the target network to estimate its value. The resulting update:</p>
<p><span class="math display">\[Y_t^{\text{DoubleDQN}} = R_{t+1} + \gamma Q(S_{t+1}, argmax_{a} Q(S_{t+1}, a; \theta_{t}), \theta_{t}^{-})\]</span></p>
<h2 id="implementation">Implementation</h2>
<p>This is an implementation of DDQN in PARL. This implementation is written using PaddlePaddle.</p>
<p>https://github.com/PaddlePaddle/PARL</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> parl</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DQN</span>(<span class="params">parl.Algorithm</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, model, gamma=<span class="literal">None</span>, lr=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; DQN algorithm</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model (parl.Model): forward neural network representing the Q function.</span></span><br><span class="line"><span class="string">            gamma (float): discounted factor for `accumulative` reward computation</span></span><br><span class="line"><span class="string">            lr (float): learning rate.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.target_model = copy.deepcopy(model)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(gamma, <span class="built_in">float</span>)</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(lr, <span class="built_in">float</span>)</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.lr = lr</span><br><span class="line"></span><br><span class="line">        self.mse_loss = paddle.nn.MSELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">        self.optimizer = paddle.optimizer.Adam(</span><br><span class="line">            learning_rate=lr, parameters=self.model.parameters())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; use self.model (Q function) to predict the action values</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.model.value(obs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">learn</span>(<span class="params">self, obs, action, reward, next_obs, terminal</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; update the Q function (self.model) with DQN algorithm</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Q</span></span><br><span class="line">        pred_values = self.model.value(obs)</span><br><span class="line">        action_dim = pred_values.shape[-<span class="number">1</span>]</span><br><span class="line">        action = paddle.squeeze(action, axis=-<span class="number">1</span>)</span><br><span class="line">        action_onehot = paddle.nn.functional.one_hot(</span><br><span class="line">            action, num_classes=action_dim)</span><br><span class="line">        pred_value = paddle.multiply(pred_values, action_onehot)</span><br><span class="line">        pred_value = paddle.<span class="built_in">sum</span>(pred_value, axis=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># target Q</span></span><br><span class="line">        <span class="keyword">with</span> paddle.no_grad():</span><br><span class="line">            greedy_actions = self.model.value(next_obs).argmax(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            max_v = self.target_model.value(next_obs).gather(index=greedy_actions, axis=<span class="number">1</span>)</span><br><span class="line">            target = reward + (<span class="number">1</span> - terminal) * self.gamma * max_v</span><br><span class="line"></span><br><span class="line">        loss = self.mse_loss(pred_value, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># optimize</span></span><br><span class="line">        self.optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sync_target</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.model.sync_weights_to(self.target_model)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>RL</category>
        <category>VFA</category>
      </categories>
      <tags>
        <tag>Function Approximation</tag>
        <tag>Continuous State Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Deterministic Policy Gradient</title>
    <url>/2021/06/09/DDPG/</url>
    <content><![CDATA[<h1 id="continuous-control-with-deep-reinforcement-learning">Continuous Control with Deep Reinforcement Learning</h1>
<h2 id="notations">Notations</h2>
<p>A trajectory is defined as <span class="math inline">\((s_1, a_1, r_1, ...)\)</span></p>
<p>The initial state distribution: <span class="math inline">\(\rho (s_1)\)</span></p>
<p>Transition dynamics <span class="math inline">\(p(s_{t+1} | s_t, a_t)\)</span></p>
<p>Reward function <span class="math inline">\(r(s_t, a_t)\)</span></p>
<p>The return from a state is defined as the sum of discounted future reward:</p>
<p><span class="math display">\[R_t = \sum_{i=t}^{T} \gamma^{i - t} r(s_i, a_i)\]</span></p>
<p>The discounted state distribution following <span class="math inline">\(\pi\)</span> is denoted as <span class="math inline">\(\rho^{\pi}\)</span></p>
<p>The action-value function:</p>
<p><span class="math display">\[Q^{\pi} (s_t, a_t) = E_{r_{i \geq t}, s_{i &gt; t} \sim P, a_{i &gt;t} \sim \pi} [R_t | s_t, a_t]\]</span></p>
<p>And the action-value function can be expanded using bellman equation:</p>
<p><span class="math display">\[Q^{\pi} (s_t, a_t) = E_{r_{t}, s_{t+1} \sim P} [r(s_t, a_t) + \gamma E_{a_{t+1} \sim \pi (\cdot | s_{t+1})}[Q^{\pi} (s_{t+1}, a_{t+1})] | s_t, a_t]\]</span></p>
<p>If we have deterministic policy <span class="math inline">\(\mu: S \rightarrow A\)</span>, we can remove the integral over next actions and have:</p>
<p><span class="math display">\[Q^{\mu} (s_t, a_t) = E_{r_{t}, s_{t+1} \sim P} [r(s_t, a_t) + \gamma Q^{\mu} (s_{t+1}, \mu(s_{t + 1})) | s_t, a_t]\]</span></p>
<p>This implies that we can learn <span class="math inline">\(Q^{\mu}\)</span> off policy using state samples from another behavior policy <span class="math inline">\(\beta\)</span>.</p>
<p>The off policy loss for parameterized function approximators <span class="math inline">\(\theta^Q\)</span> Bellman Residual Minimization is:</p>
<p><span class="math display">\[L(\theta^{Q}) = E_{s_t \sim \rho^\beta. a_t \sim \beta, r_t} [(Q(s_t, a_t | \theta^{Q}) - y_t)^2]\]</span></p>
<p>where:</p>
<p><span class="math display">\[y_t = r(s_t, a_t) + \gamma Q(s_{t+1}, \mu(s_{t+1}) | \theta^{Q})\]</span></p>
<p>The use of large, non-linear function approximators for learning value or action-value functions has often been avoided in the past since theoretical performance guarantees are impossible, and practically learning tends to be unstable.</p>
<p>The off policy deterministic policy gradient:</p>
<p><span class="math display">\[\nabla_{\theta^{\mu}} J \approx E_{s_{t} \sim \rho^{\beta}} [\nabla_{a} Q(s, a | \theta^Q) |_{s=s_t, a=\mu(s_t)}\nabla_{\theta_{\mu}} \mu(s | \theta^\mu) |_{s=s_t}]\]</span></p>
<p>As with Q learning, introducing non-linear function approximators means that convergence is no longer guaranteed for off-policy deterministic policy gradient.</p>
<span id="more"></span>
<h2 id="algorithm">Algorithm</h2>
<p><img src="/images/RL/pg/ddpg_1" width="600"></p>
<ol type="1">
<li>Initialize:
<ol type="a">
<li>the weights <span class="math inline">\(\theta^Q\)</span> for critic network <span class="math inline">\(Q\)</span> and <span class="math inline">\(\theta^\mu\)</span> for actor network <span class="math inline">\(\mu\)</span></li>
<li>the weights <span class="math inline">\(\theta^{Q^{\prime}} \leftarrow \theta^{Q}\)</span> for target critic <span class="math inline">\(Q^{\prime}\)</span> and <span class="math inline">\(\theta^{\mu^{\prime}} \leftarrow \theta^{\mu}\)</span> for target actor <span class="math inline">\(\mu^{\prime}\)</span></li>
<li>the replay buffer <span class="math inline">\(R\)</span></li>
</ol></li>
<li>For each episode:
<ol type="a">
<li><p>Initialize a random process <span class="math inline">\(\mathcal{N}_1, ....,\)</span> for exploration</p></li>
<li><p>Observe initial state <span class="math inline">\(s_1 \sim \rho^{\mu^{\beta}} \;\;\;\;\;\;\;\;\;\;\;\)</span> (remember we are learning off-policy)</p></li>
<li><p>For each timestep <span class="math inline">\(t = 1, ..., T\)</span> in the episode:</p>
<p><span style="color:red"><em>Data generation</em></span></p>
<ul>
<li><span class="math inline">\(a_t = \mu^{\beta} (s_t) = \mu (s_t | \theta^{\mu}) + \mathcal{N}_t \;\;\;\;\;\;\;\;\;\;\;\)</span> (actions is selected with some noise)</li>
<li>Observe <span class="math inline">\(s_{t+1}, r_t\)</span> by following <span class="math inline">\(a_t\)</span></li>
<li>Store <span class="math inline">\((s_t, a_t, r_t, s_{t+1})\)</span> in <span class="math inline">\(R \;\;\;\;\;\;\;\;\;\;\;\)</span> (for batch learning)</li>
</ul>
<p><span style="color:red"><em>Now we evaluate <span class="math inline">\(Q^{\mu_{\theta}}\)</span> and update <span class="math inline">\(\theta^{\mu}, \theta^{Q}\)</span></em></span></p>
<ul>
<li><p>Sample a random minibatch of <span class="math inline">\(N\)</span> transitions <span class="math inline">\((s_i, a_i, r_i, s_{i+1}) \;\;\;\;\;\;\;\;\;\;\;\)</span> (for batch learning)</p></li>
<li><p>Calculate <span class="math inline">\(y_i = r_i + \gamma Q^{\prime} (s_{i+1}, \mu^{\prime} (s_{i+1}))\;\;\;\;\;\;\;\;\;\;\;\)</span> (<span class="math inline">\(\hat{T}^{\mu^{\prime}} Q^{\prime}\)</span>)</p></li>
<li><p>Update critic by minimizing the loss <span class="math inline">\(L = \frac{1}{N} \sum_{i} (Q(s_i, a_i) - y_i)^2 \;\;\;\;\;\;\;\;\;\;\;\)</span> (update for several times, to have a better estimate of <span class="math inline">\(\hat{T}^{\mu^{\prime}} Q^{\prime}\)</span>)</p></li>
<li><p>Update the actor policy using the sampled policy gradient:</p>
<p><span class="math display">\[\frac{1}{N} \sum_i \nabla_{a} Q(s, a) |_{s=s_i, a=\mu(s_i)} \nabla_{\theta^{\mu}} \mu(s_i)\]</span></p></li>
<li><p>Update the target critic and target actor:</p>
<p><span class="math display">\[\theta^{Q^{\prime}} \leftarrow \tau \theta^{Q} + (1 - \tau) \theta^{Q^{\prime}}\]</span> <span class="math display">\[\theta^{\mu^{\prime}} \leftarrow \tau \theta^{\mu} + (1 - \tau) \theta^{\mu^{\prime}}\]</span></p></li>
</ul></li>
</ol></li>
</ol>
<p>Features:</p>
<ol type="1">
<li><p>Use replay buffer to address correlated samples. Because DDPG is an off-policy algorithm, the replay buffer can be large, allowing the algorithm to benefit from learning across a set of uncorrelated transitions.</p></li>
<li><p>Similar to target network in DQN, a soft target updates rather than directly copying the weights is used. We create a copy of the actor and critic networks, <span class="math inline">\(Q^{\prime} (s, a | \theta^{Q^{\prime}})\)</span> and <span class="math inline">\(\mu^{\prime} (s | \theta^{\mu^{\prime}})\)</span>. Notice here, the target is calculated using these delayed parameters. One problem with this is that:</p>
<p><span class="math display">\[E[r(s_t, a_t) + \gamma Q^{\prime} (s, \mu^{\prime} (s_{t+1} | \theta^{\mu^{\prime}}) | \theta^{Q^{\prime}})] = E[\hat{T}^{\mu^{\prime}} Q^{\prime} (s, a)] = T^{\mu^{\prime}} Q^{\prime} (s, a)\]</span></p>
<p>So, if we minimize the square loss of the critic w.r.t this target for some iterations, then follow the approximate value iteration, we end up evaluating <span class="math inline">\(Q^{\mu^{\prime}} (s, a)\)</span>.</p>
<p>The weights of these target networks are then updated by having them slowly track the learned networks: <span class="math inline">\(\theta^{\prime} \leftarrow (1 - \tau) \theta^{\prime} + \theta\)</span> (stochastic approximation of mean of <span class="math inline">\(\theta\)</span>) with <span class="math inline">\(\tau &lt;&lt; 1\)</span>. This means that the target values are constrained to change slowly, greatly improving the stability of learning. The authors found that having both a delayed <span class="math inline">\(\mu^{\prime}\)</span> and a delayed <span class="math inline">\(Q^{\prime}\)</span> was required to have stable <span class="math inline">\(y_t\)</span> in order to consistently train the critic without divergence.</p></li>
<li><p>In low dimensional feature vector observation space, Batch Normalization is used to normalize each dimension across the samples in a mini-batch to have unit mean and variance. A running average of mean and variance is maintained in training time and used in test time in this case evaluation or exploration. This technique is applied on the state input and all layers of the <span class="math inline">\(\mu\)</span> network and all layers of the <span class="math inline">\(Q\)</span> network prior to the action input. This help with the learning speed and scalability across different envs and units.</p></li>
<li><p>Exploration problem is resolved by having a separate exploration policy <span class="math inline">\(\mu^{\prime}\)</span> (different from target network <span class="math inline">\(\mu^{\prime} (s | \theta^{\mu^{\prime}})\)</span>) by adding noise sampled from a noise process <span class="math inline">\(N\)</span> to our current actor policy:</p>
<p><span class="math display">\[\mu^{\prime} (s_t) = \mu (s_t | \theta_t^{\mu}) + \mathcal{N}\]</span></p>
<p>This <span class="math inline">\(N\)</span> can be chosen to suit the environment.</p></li>
</ol>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Continuous Action Space</tag>
        <tag>Policy Search</tag>
      </tags>
  </entry>
  <entry>
    <title>Deterministic Policy Gradient</title>
    <url>/2021/05/06/DPG/</url>
    <content><![CDATA[<h1 id="deterministic-policy-gradient-algorithms">Deterministic Policy Gradient Algorithms</h1>
<h2 id="introduction">Introduction</h2>
<p>In traditional policy gradient algorithms, policy is parametrized by a probability distribution <span class="math inline">\(\pi_{\theta} (a | s) = P[a | s; \theta]\)</span> that stochastically selects action <span class="math inline">\(a\)</span> in state <span class="math inline">\(s\)</span> according to parameter vector <span class="math inline">\(\theta\)</span>. In this paper, the authors consider deterministic policies <span class="math inline">\(a = \mu_{\theta} (s)\)</span>.</p>
<p>From a practical viewpoint, there is a crucial difference between the stochastic and deterministic policy gradients. In the stochastic case, the policy gradient integrates over both state and action spaces, whereas in the deterministic case it only integrates over the state space:</p>
<p><span class="math display">\[E_{X\sim \rho^{\pi_\theta}A \sim \pi_{\theta}} [\nabla log \pi(A | X) Q^{\pi_{\theta}} (X, A)]\]</span></p>
<p>Thus, <strong>computing deterministic policies may require less samples</strong>.</p>
<p>An off-policy learning scheme is introduced here to ensure adequate exploration (i.e The basic idea is to choose actions according to a stochastic behaviour policy).</p>
<span id="more"></span>
<h2 id="notations">Notations</h2>
<p><strong>Notations are simplified so that the random variables in the conditional density are dropped, and <span class="math inline">\(\pi_{\theta} = \pi\)</span>, the subscripts are dropped for simplicity</strong></p>
<p>Initial state distribution <span class="math inline">\(p_1(s_1)\)</span>, stationary transition dynamics distribution <span class="math inline">\(p(s_{t+1} | s_{t}, a_{t})\)</span>, deterministic reward function <span class="math inline">\(r(x, a)\)</span>. Stochastic policy is represented as <span class="math inline">\(\pi_{\theta} (a_t | s_t)\)</span>. A trajectory of the process is represented as <span class="math inline">\(h_{1:T} = s_1, a_1, r_1, ...., s_T, a_T\)</span>.</p>
<p>The return is the total discounted reward</p>
<p><span class="math display">\[r_t^{\gamma} = \sum^{\infty}_{k = t} \gamma^{k-t} r(s_k, a_k)\]</span></p>
<p>Value functions:</p>
<p><span class="math display">\[V^{\pi} (s) = E[r_1^{\gamma} | S_1=s; \pi]\]</span></p>
<p><span class="math display">\[Q^{\pi} (s, a) = E[r_1^{\gamma} | S_1=s, A_1=a; \pi]\]</span></p>
<p>The objective is to find a policy <span class="math inline">\(\pi\)</span> that maximize <span class="math inline">\(J(\pi)\)</span></p>
<p><span class="math display">\[J(\pi) = E_{s_1 \sim p_1}[r_1^{\gamma} | \pi]\]</span></p>
<p>Define t step transition probability following <span class="math inline">\(\pi\)</span> starting from <span class="math inline">\(s\)</span> as <span class="math inline">\(p^{\pi}(s \rightarrow s^{\prime}; t)\)</span></p>
<p>The un-normalized discounted future state distribution:</p>
<p><span class="math display">\[\rho^{\pi} (s^{\prime}) \triangleq \int_s \sum^{\infty}_{t=1} \gamma^{t-1} p(s) p^{\pi}(s \rightarrow s^{\prime}; t) ds\]</span></p>
<p>The performance objective as expectation:</p>
<p><span class="math display">\[J(\pi) = E_{s \sim \rho^{\pi} (\cdot), a \sim \pi(\cdot | s)} [r(s, a)]\]</span></p>
<p>Where this expectation is over the un-normalized discounted future state distribution. By replacing discounted future state distribution with stationary state distribution, we have average reward performance measure.</p>
<p>The policy gradient can be written as:</p>
<span class="math display">\[\begin{aligned}
\nabla_{\theta} J(\pi_\theta) &amp;= \int_S \rho^{\pi} (s) \int_A \nabla_{\theta} \pi_\theta (a | s) Q^{\pi} (s, a) da ds\\
&amp;= E_{s\sim \rho^{\pi} (\cdot), a \sim \pi_{\theta}}[\nabla_{\theta} \log \pi_\theta (a | s) Q^{\pi} (s, a)]
\end{aligned}\]</span>
<h2 id="off-policy-actor-critic">Off-Policy Actor-Critic</h2>
<p>It is often useful to estimate the policy gradient off-policy from trajectories sampled from a distinct behaviour policy <span class="math inline">\(\beta(a | s) \neq \pi_{\theta} (a | s)\)</span>. In an off-policy setting, the performance objective is typically modified to be the value function of the target policy averaged over the state distribution of the behaviour policy as initial state.</p>
<span class="math display">\[\begin{aligned}
J_{\beta} (\pi_{\theta}) &amp;= \int_s \rho^{\beta} (s) V^{\pi} (s) ds\\
&amp;= \int_s \int_a \rho^{\beta} (s) \pi_{\theta} (a | s) Q^{\pi}(s, a) dads\\
\end{aligned}\]</span>
<p>Differentiating the performacne objective and applying an approximation gives the off-policy policy gradient:</p>
<span class="math display">\[\begin{aligned}
\nabla_{\theta} J_{\beta} (\pi_{\theta}) &amp;\approx \int_s \int_a \rho^{\beta} (s) \nabla_{\theta} \pi_{\theta} (a | s) Q^{\pi}(s, a) dads\\
&amp;= E_{s \sim \rho^\beta, a \sim \beta_{\theta}}[\frac{\pi_{\theta} (a | s)}{\beta (a | s)} \nabla_{\theta} \log \pi_{\theta} (a | s) Q^{\pi} (s, a)]\\
\end{aligned}\]</span>
<h2 id="gradients-of-deterministic-policies">Gradients of Deterministic Policies</h2>
<h3 id="deterministic-policy-gradient-theorem">Deterministic Policy Gradient Theorem</h3>
<p>Let:</p>
<p><span class="math display">\[J(\mu_{\theta}) = E_{s \sim \rho^{\mu_{\theta}} (\cdot)} [r(s, \mu_{\theta}(s))]\]</span></p>
<p>Note here that <span class="math inline">\(\mu_{\theta}\)</span> is the deterministic policy. It is deterministic function of state, and it outputs action (does not represent a probability distribution anymore)</p>
<p><img src="/images/RL/pg/dpg_1.png" width="600"></p>
<h4 id="proof">Proof</h4>
<span class="math display">\[\begin{aligned}
\nabla_{\theta} V^{\mu_{\theta}} (s) &amp;= \nabla_{\theta} Q^{\mu_{\theta}} (s, \mu_{\theta} (s))\\
&amp;= \nabla_{\theta} (r(s, \mu_{\theta} (s)) + \int_{s^{\prime}} p(s^{\prime} | s, \mu_{\theta} (s)) V^{\mu_{\theta}} (s^{\prime}) ds^{\prime})\\
&amp;= \nabla_{\theta} \mu_{\theta} (s) \nabla_{a} r(s, a) + \int_{s^{\prime}} \nabla_{\theta}  \mu_{\theta} (s) \nabla_{a} p(s^{\prime} | s, a) V^{\mu_{\theta}} (s^{\prime}) ds^{\prime} + \int_{s^{\prime}} p(s^{\prime} | s, \mu_{\theta} (s)) \nabla_{\theta}  V^{\mu_{\theta}} (s^{\prime}) ds^{\prime}\\
&amp;= \nabla_{\theta} \mu_{\theta} (s) \nabla_{a} (r(s, a) + \int_{s^{\prime}} p(s^{\prime} | s, a) V^{\mu_{\theta}} (s^{\prime})ds^{\prime}) + \int_{s^{\prime}} p(s^{\prime} | s, \mu_{\theta} (s)) \nabla_{\theta}  V^{\mu_{\theta}} (s^{\prime}) ds^{\prime} \\
&amp;= \nabla_{\theta} \mu_{\theta} (s) \nabla_{a} Q^{\mu_{\theta}} (s, a) + \int_{s^{\prime}} p(s^{\prime} | s, \mu_{\theta} (s)) \nabla_{\theta}  V^{\mu_{\theta}} (s^{\prime}) ds^{\prime}
\end{aligned}\]</span>
<p><br/></p>
<p>Just like Stochastic Policy Gradient Theorem proof, if we keep expanding <span class="math inline">\(V^{\mu_{\theta}}\)</span>, we will end up with:</p>
<p><span class="math display">\[\nabla_{\theta} V^{\mu_{\theta}} (s) = \int_{s^{\prime}} \sum^{\infty}_{t=0} \gamma^{t} p^{\mu_{\theta}}(s \rightarrow s^{\prime}; t) \nabla_{\theta} \mu_{\theta} (s^{\prime}) \nabla_{a} Q^{\mu_{\theta}} (s^{\prime}, a) ds^{\prime}\]</span> <br/></p>
<p>Then our objective can be written as:</p>
<span class="math display">\[\begin{aligned}
\nabla_{\theta} J(\mu_{\theta}) &amp;= \int_{s_1} p_1(s_1) \nabla_{\theta} V^{\mu_{\theta}} (s_1) ds_1\\
&amp;= \int_{s_1} p_1(s_1) \int_{s^{\prime}} \sum^{\infty}_{t=0} \gamma^{t} p^{\mu_{\theta}}(s_1 \rightarrow s^{\prime}; t) \nabla_{\theta} \mu_{\theta} (s^{\prime}) \nabla_{a} Q^{\mu_{\theta}} (s^{\prime}, a) ds^{\prime} ds_1\\
&amp;= \int_{s^{\prime}} \rho^{\mu_{\theta}} (s^{\prime}) \nabla_{\theta} \mu_{\theta} (s^{\prime}) \nabla_{a} Q^{\mu_{\theta}} (s^{\prime}, a) ds^{\prime}\\
&amp;= E_{s \sim \rho^{\mu_{\theta}} (\cdot)} [\nabla_{\theta} \mu_{\theta} (s) \nabla_{a} Q^{\mu_{\theta}} (s, a) |_{a = \mu_\theta(s)}]
\end{aligned}\]</span>
<p><br/></p>
<h3 id="theorem-2">Theorem 2</h3>
<p><img src="/images/RL/pg/dpg_2.png" width="600"></p>
<p>This theorem shows that the familiar machinery of policy gradient. All PG methods are applicable to deterministic policy gradient.</p>
<h2 id="off-policy-deterministic-actor-critic">Off Policy Deterministic Actor-Critic</h2>
<p>The performance objective is:</p>
<p><span class="math display">\[J_{\beta}(\mu_{\theta}) = E_{s \sim \rho^{\beta} (\cdot)} [r(s, \mu_{\theta}(s))]\]</span></p>
<p>The gradient:</p>
<span class="math display">\[\begin{aligned}
\nabla_{\theta} J_{\beta} (\pi_{\theta}) &amp;\approx \int_s \rho^{\beta} (s) \nabla_{\theta} \mu_{\theta} (s) \nabla_{a} Q^{\mu_{\theta}} (s, a) |_{a = \mu_\theta(s)} ds\\
&amp;= E_{s \sim \rho^\beta}[\nabla_{\theta} \mu_{\theta} (s) \nabla_{a} Q^{\mu_{\theta}} (s, a) |_{a = \mu_\theta(s)} ]\\
\end{aligned}\]</span>
<p>This equation gives the off-policy deterministic policy gradient. We now develop an actor-critic algorithm that updates the policy in the direction of the off-policy deterministic policy gradient. We can see that the integral over <span class="math inline">\(a\)</span> is removed because we are using the deterministic policy, that is, we can avoid importance sampling in the critic.</p>
<p>We substitute a differentiable action-value function <span class="math inline">\(Q^{w} (s, a)\)</span> in place of the true action-value function <span class="math inline">\(Q^{\mu} (s, a)\)</span>. A critic estimates the action-value function <span class="math inline">\(Q^{w} (s, a) \approx Q^{\mu} (s, a)\)</span>. In the below off-policy deterministic actor critic algorithm, the critic estimates the action-value function using the samples from <span class="math inline">\(\rho^\beta\)</span></p>
<p><img src="/images/RL/pg/dpg_3.png" width="600"></p>
<h3 id="compatible-function-approximation">Compatible Function Approximation</h3>
<h4 id="compatible-function-approximator-in-stochastic-case">Compatible Function Approximator in Stochastic Case</h4>
<p>In general, substituting an approximate <span class="math inline">\(Q^{w} (s, a)\)</span> will not necessarily follow the true gradient. Similar to the stochastic ase, only compatible function approximators are guaranteed to be unbiased. Recall that a function approximator <span class="math inline">\(f_w\)</span> is <strong>compatiable</strong> if:</p>
<ol type="1">
<li><span class="math inline">\(f_w\)</span> is found by minimizing the square loss <span class="math inline">\(E_{s \sim \rho^{\pi_{\theta}}, a \sim \pi_{\theta}} [(Q^{\pi} (s, a) - f_{w} (s, a))^2]\)</span></li>
<li><span class="math inline">\(\nabla_{w} f_w (s, a) = \nabla_{\theta} \pi_{\theta}(s, a) \frac{1}{\pi(s, a)}\)</span>, this is satisfied only when <span class="math inline">\(f_w (s, a) = \nabla_{\theta} \log \pi_{\theta}(s, a) w^T\)</span></li>
</ol>
<p><br/></p>
<p>These conditions imply:</p>
<p><span class="math display">\[\nabla_{\theta} J(\pi_\theta) = E_{s\sim \rho^{\pi} (\cdot), a \sim \pi_{\theta}}[\nabla_{\theta} \log \pi_\theta (a | s) f_w(s, a)]\]</span></p>
<h4 id="proof-1">Proof</h4>
<p>Notice that, at the fixed point, we will have:</p>
<p><span class="math display">\[Q^{\pi} (s, a) - f_w (s, a) = 0\]</span></p>
<p>and the gradient of the loss:</p>
<p><span class="math display">\[\nabla_{w} E_{s \sim \rho^{\pi_{\theta}}, a \sim \pi_{\theta}} [(Q^{\pi} (s, a) - f_{w} (s, a))^2] = E_{s \sim \rho^{\pi_{\theta}}, a \sim \pi_{\theta}} [(Q^{\pi} (s, a) - f_{w} (s, a)) \nabla_{w} f_{w} (s, a)] = 0\]</span></p>
<p>By substitute condition 2 into the above equation, we have:</p>
<p><span class="math display">\[E_{s \sim \rho^{\pi_{\theta}}, a \sim \pi_{\theta}} [(Q^{\pi} (s, a) - f_{w} (s, a)) \nabla_{\theta} \log \pi_{\theta}(s, a)] = 0\]</span></p>
<p>Since the gradient of loss is 0, we can subtract it from the policy gradient:</p>
<span class="math display">\[\begin{aligned}
\nabla_{\theta} J(\pi_\theta) &amp;= E_{s \sim \rho^{\pi_{\theta}}, a \sim \pi_{\theta}} [\nabla_{\theta} \log \pi_\theta (a | s) Q^{\pi} (s, a)] - E_{s \sim \rho^{\pi_{\theta}}, a \sim \pi_{\theta}} [(Q^{\pi} (s, a) - f_{w} (s, a)) \nabla_{\theta} \log \pi_{\theta}(s, a)]\\
&amp;= E_{s\sim \rho^{\pi} (\cdot), a \sim \pi_{\theta}}[\nabla_{\theta} \log \pi_\theta (a | s) f_w(s, a)]
\end{aligned}\]</span>
<p><br/></p>
<h4 id="compatible-function-approximator-in-deterministic-case">Compatible Function Approximator in Deterministic Case</h4>
<p>Similar in above stochastic case, we want to find a class of compatible function approximators <span class="math inline">\(Q^{w} (s, a)\)</span> such that the gradient is preserved. In order words:</p>
<p><span class="math display">\[\nabla_a Q^{w} (s, a) = \nabla_a Q^{\mu_{\theta}} (s, a)\]</span></p>
<p>So that we could replace <span class="math inline">\(\nabla_a Q^{\mu_{\theta}} (s, a)\)</span> with <span class="math inline">\(\nabla_a Q^{w} (s, a)\)</span> and still have the true gradient preserved.</p>
<p><img src="/images/RL/pg/dpg_4.png" width="600"></p>
<p><strong>This theorem applies to both on-policy and off-policy cases</strong></p>
<h4 id="proof-2">Proof</h4>
<p>The proof basically follows the stochastic case:</p>
<p><img src="/images/RL/pg/dpg_5.png" width="600"></p>
<p>So for any deterministic policy <span class="math inline">\(\mu_\theta (s)\)</span>, there always exists a compatible function approximator of the form:</p>
<p><span class="math display">\[f_{w} (s, a) = \phi(s, a)^T \nabla_{\theta} \mu_{\theta} (s)^Tw + V^{v} (s)\]</span></p>
<p>Where <span class="math inline">\(V^{v} (s)\)</span> can be any baseline function that is independent of the action <span class="math inline">\(a\)</span> and <span class="math inline">\(\nabla_{a} \phi(s, a)^T = 1\)</span>. This function satisfies condition 1. However, in order to satisfy condition 2, we need to find the parameters <span class="math inline">\(w\)</span> that minimize the mse between th gradient of <span class="math inline">\(Q^w\)</span> and the true gradient. Since, acquiring unbiased samples of the true gradient is difficult, in practice, we learn <span class="math inline">\(w\)</span> using a standard policy evaluation method that does not exactly satisfy condition 2 (ie. using SARSA, Q-learning through semi-gradient TD).</p>
<p>We denote the reasonable solution to the policy evaluation problem by <span class="math inline">\(Q^{w} (s, a) \approx Q^{\mu} (s, a)\)</span> and will therefore approximately satisfy</p>
<p><span class="math display">\[\nabla_a Q^{w} (s, a) \approx \nabla_a Q^{\mu_{\theta}} (s, a)\]</span></p>
<h2 id="compatible-off-policy-deterministic-actor-critic-algorithm-copdac">Compatible Off-Policy Deterministic Actor-Critic Algorithm (COPDAC)</h2>
<p>The Compatible off-policy deterministic actor-critic algorithm consists of two compoenents:</p>
<ol type="1">
<li><p>The critic is a linear function approximator that estimates the action-value from features:</p>
<p><span class="math display">\[a \nabla_{\theta}\mu_{\theta} (s)^Tw + V^{v} (s)\]</span></p>
<p>This can be learnt off-policy using samples of a behaviour policy <span class="math inline">\(\beta(a | s)\)</span>, for example using Q-learning or gradient Q-learning. <span class="math inline">\(V^{v} (s)\)</span> is parametrized linearly as <span class="math inline">\({\phi(s)}^T v\)</span>.</p></li>
<li><p>The actor then updates its parameters in the direction of the critic's action-value gradient.</p></li>
</ol>
<p><br/></p>
<p>The following COPDAC-Q algorithm uses a simple Q-learning critic:</p>
<ol type="1">
<li><p>Calculate the TD error for semi gradient TD update</p>
<p><span class="math display">\[\delta_t = r_t + \gamma Q^{w} (s_{t+1}, \mu_{\theta}(s_{t+1})) - Q^{w} (s_t, a_t)\]</span></p></li>
<li><p>Update <span class="math inline">\(V^{v} (s)\)</span></p>
<p><span class="math display">\[v_{t + 1} = v_t + \alpha_v \delta_t \phi(s_t)\]</span></p></li>
<li><p>Update <span class="math inline">\(Q^{w} (s, a)\)</span></p>
<p><span class="math display">\[w_{t + 1} = w_t + \alpha_w \delta_t a_t^T \nabla_{\theta}\mu_{\theta} (s_t)\]</span></p></li>
<li><p>Update the actor <span class="math inline">\(\mu_{\theta} (s)\)</span>:</p>
<p><span class="math display">\[\theta_{t + 1} = \theta_{t} + \alpha_{\theta}  \nabla_{\theta}\mu_{\theta} (s_t) (\nabla_{\theta}\mu_{\theta}^T (s_t) w_t)\]</span></p></li>
</ol>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Continuous Action Space</tag>
        <tag>Policy Search</tag>
      </tags>
  </entry>
  <entry>
    <title>Double Q Learning</title>
    <url>/2021/05/07/FA-issues/</url>
    <content><![CDATA[<h1 id="double-q-learning">Double Q-learning</h1>
<h2 id="the-overestimation-phenomenon">The Overestimation Phenomenon</h2>
<p>Assume the agent observes during learning that action <span class="math inline">\(a\)</span> and executed at state <span class="math inline">\(s\)</span> resulting in the state <span class="math inline">\(s^{\prime}\)</span> and some immediate reward <span class="math inline">\(r^{a}_{s}\)</span>. The Q-learning update can be written as:</p>
<p><span class="math display">\[Q(s, a) \leftarrow r^{a}_{s} + \gamma \max_{\hat{a}} Q(s^{\prime}, \hat{a})\]</span></p>
<p>It has been shown that repeated application of this update equation eventually yields <span class="math inline">\(Q\)</span>-values that give rise to a policy which maximizes the expected cumulative discounted reward. However, these results only apply when <span class="math inline">\(Q-\)</span>values are stored precisely. (e.g by a look up table)</p>
<p>Assume, instead, let <span class="math inline">\(Q\)</span> be represented as a function approximator that induces some noise on the estimates of <span class="math inline">\(Q\)</span>. More specifically, let us assume that the current stored <span class="math inline">\(Q-\)</span>values, denoted by <span class="math inline">\(Q^{approx}\)</span>, represent some implicit target values <span class="math inline">\(Q^{target}\)</span>, corrupted by a noise term <span class="math inline">\(Y^{\hat{a}}_{s^{\prime}}\)</span>, which is due to the function approximator:</p>
<p><span class="math display">\[Q^{approx} (s^{\prime}, \hat{a}) = Q^{target} (s^{\prime}, \hat{a}) + Y^{\hat{a}}_{s^{\prime}}\]</span></p>
<p>Here the noise is modeled by the family of random variable <span class="math inline">\(Y^{\hat{a}}_{s^{\prime}}\)</span> with zero mean:</p>
<span class="math display">\[\begin{aligned}
Z_s &amp;\triangleq r^{a}_{s} + \gamma \max_{\hat{a}}Q^{approx} (s^{\prime}, \hat{a}) -  (r^{a}_{s} + \gamma \max_{\hat{a}}Q^{target} (s^{\prime}, \hat{a})) \\
&amp;= \gamma (\max_{\hat{a}}Q^{approx} (s^{\prime}, \hat{a}) - \max_{\hat{a}}Q^{target} (s^{\prime}, \hat{a}))\\
\end{aligned}\]</span>
<p>Clearly, the noise causes some error on the left-hand side.</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>VFA</category>
      </categories>
      <tags>
        <tag>Function Approximation</tag>
        <tag>Discussions</tag>
      </tags>
  </entry>
  <entry>
    <title>LReLU</title>
    <url>/2021/07/05/LReLU/</url>
    <content><![CDATA[<h1 id="rectifier-nonlinearities-improve-neural-network-acoustic-models">Rectifier Nonlinearities Improve Neural Network Acoustic Models</h1>
<h2 id="background">Background</h2>
<p>A single hidden unit's activation <span class="math inline">\(h^{i}\)</span> is given by:</p>
<p><span class="math display">\[h^{(i)} = \sigma ({\mathbf{w}^i}^T \mathbf{x})\]</span></p>
<p>Where <span class="math inline">\(\sigma (\cdot)\)</span> is the tanh function.</p>
<p>Some drawbacks of tanh:</p>
<ol type="1">
<li>Vanishing gradient problem when lower layers of a DNN have gradients of nearly 0 because higher layer units are nearly saturated at <span class="math inline">\(-1\)</span> or <span class="math inline">\(1\)</span>.</li>
<li>Does not produce a sparse representation in the sense of hard zero sparsity when using tanh.</li>
</ol>
<p>ReLU addresses the vanishing gradient problem because activate units will constantly have gradient of 1. It also provides sparse representation which is useful in classification. <strong>However, an inactivate unit may never activate because gradient-based optimization algorithm will not adjust the weights of a unit that never activates initially.</strong> Thus, we might expect the learning to be slow.</p>
<h2 id="leaky-relu">Leaky ReLU</h2>
<p>LReLU allows for a small, non-zero gradient when the unit is saturated and not active:</p>
<p><span class="math display">\[
h_i = \max({\mathbf{w}^i}^T \mathbf{x}, 0) = 
\begin{cases}
{\mathbf{w}^i}^T \mathbf{x}, \quad &amp; {\mathbf{w}^i}^T \mathbf{x} &gt; 0\\
0.01{\mathbf{w}^i}^T \mathbf{x}, \quad &amp; {\mathbf{w}^i}^T \mathbf{x} \leq 0\\
\end{cases}
\]</span></p>
]]></content>
  </entry>
  <entry>
    <title>Dueling Network Architectures for DRL</title>
    <url>/2021/05/13/Dueling/</url>
    <content><![CDATA[<h1 id="dueling-network-architectures-for-deep-reinforcement-learning">Dueling Network Architectures for Deep Reinforcement Learning</h1>
<h2 id="introduction">Introduction</h2>
<p>The authors introduce an innovating neural network architecture that is better suited for model-free RL. This paper advances a new network but uses already published algorithms.</p>
<p>The proposed architecture is called dueling architecture, explicitly separates the representation of state values and state-dependent action advantages. The architecture consists of two streams that represent the value and advantage functions, while sharing a common convolutional feature learning module. The two streams are combined via a special aggregating layer to produce an estimate of the state-action value function <span class="math inline">\(Q\)</span>. This dueling network should be understood as a single Q network with two streams that replaces the popular single-stream Q-network in existing algorithms such as DQN. The dueling network automatically produces separate estimates of the state value function and advantage function, without any extra supervision.</p>
<p><img src="/images/RL/papers/dueling_1.png"></p>
<p>Intuitively, the dueling architecture can learn which states are (or are not) valuable, without having to learn the effect of each action for each state. (by taking the gradient wrt to the input) It can more quickly identify the correct action during policy evaluation as redundant or similar actions are added to the learning problem.</p>
<span id="more"></span>
<h2 id="background">Background</h2>
<p><strong>random variables have subscript <span class="math inline">\(t\)</span>, <span class="math inline">\(E[ g(x_t, a_t) | x_t=x, a_t] = f(x, a)\)</span> is shorthanded as <span class="math inline">\(f(x, a) = E[g(x, a)]\)</span></strong></p>
<p>In Atari domain, the agent perceives a video <span class="math inline">\(s_t\)</span> consisting of M image frames <span class="math inline">\(s_t = (x_{t-M+1}, ..., x_t) \in S\)</span> at time step <span class="math inline">\(t\)</span>. Then agent chooses an action from a discrete set <span class="math inline">\(a_t \in A\)</span> and observes a reward signal <span class="math inline">\(r_t\)</span> produced by the game emulator.</p>
<p>The agent seeks to maximize the expected discounted return where we define the discounted return as <span class="math inline">\(R_t = \sum_{\tau=t}^{\infty} \gamma^{\tau - t} r_{\tau}\)</span> with <span class="math inline">\(\gamma \in [0, 1]\)</span>.</p>
<p>For an agent behaving to a stochastic policy <span class="math inline">\(\pi\)</span>, the values of the state-action pair <span class="math inline">\((s, a)\)</span> and the state <span class="math inline">\(s\)</span> are defined as:</p>
<p><span class="math display">\[Q^{\pi} (s, a) = E[R_t | s_t=s, a_t=a, \pi]\]</span></p>
<p><span class="math display">\[V^{\pi} (s) = E_{a_t \sim \pi(\cdot | s)}[R_t | s_t=s, \pi] = E_{a_t \sim \pi(\cdot | s)}[E[R_t | s_t, a_t, \pi] | s_t=s] = E_{a_t \sim \pi(\cdot | s)}[ Q^{\pi}(s, a_t)]\]</span></p>
<p>We know that we can rewrite <span class="math inline">\(Q^{\pi}\)</span> as:</p>
<p><span class="math display">\[Q^{\pi} (s, a) = E_s^{\prime} [r + \gamma E_{a^{\prime}}[Q(s^{\prime}, a^{s^{\prime}}) | s^{\prime}] | s, a, \pi]\]</span></p>
<p>We also define:</p>
<p><span class="math display">\[Q^{*} (s, a) = max_{\pi} Q^{\pi} (s, a), \forall (s, a) \in S X A\]</span></p>
<p>Then:</p>
<p><span class="math display">\[V^{*} (s) = max_{a} Q^{*} (s, a)\]</span></p>
<p>And,</p>
<p><span class="math display">\[Q^{*}(s, a) = E_{s^{\prime}} [r + \gamma max_{a^{\prime}} Q^{*} (s^{\prime}, a^{\prime}) | s, a]\]</span></p>
<p>The advantage function is denoted as:</p>
<p><span class="math display">\[A^{\pi} (s, a) = Q^{\pi} (s, a) - V^{\pi} (s)\]</span></p>
<p><span class="math display">\[E_{a}[A^{\pi} (s, a) | s] = E_{a}[Q^{\pi} (s, a) | s] - V^{\pi} (s) = 0\]</span></p>
<p>This means that the advantage at state <span class="math inline">\(s\)</span> weighted by policy <span class="math inline">\(\pi\)</span> is 0. Intuitively, the advantage function measures the relative importance for each action.</p>
<h2 id="dueling-network-architecture">Dueling Network Architecture</h2>
<p>Instead of following the convolutional layers with a single sequence of fully connected layers, they instead use two sequences (streams) of fully connected layers. The streams are constructed such that they have the capability of providing separate estimates of the value and advantage functions. Finally , the two streams are combined to produce a single output <span class="math inline">\(Q\)</span> function.</p>
<p>From the advantage expression, we know that</p>
<p><span class="math display">\[Q^{\pi} (s, a) = V^{\pi} (s) + A^{\pi} (s, a)\]</span></p>
<p>If the policy is the deterministic policy, <span class="math inline">\(a^{*} = argmax_{a^{\prime} \in A} Q(s, a^{\prime})\)</span>, then:</p>
<p><span class="math display">\[E_{a}[Q^{\pi} (s, a)] = Q^{\pi} (s, a^{*}) = V^{\pi} (s)\]</span> and hence <span class="math display">\[A^{\pi}(s, a^{*}) = 0\]</span></p>
<p>Let <span class="math inline">\(V(s; \theta, \beta), A(s, a; \theta, \alpha), Q(s, a; \theta, \alpha, \beta)\)</span> be parametrized version of <span class="math inline">\(V, A, Q\)</span> respectively. <span class="math inline">\(\theta\)</span> are the shared parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are the stream parameters for <span class="math inline">\(V, A\)</span>. We can calculate <span class="math inline">\(Q\)</span> directly using the formula:</p>
<p><span class="math display">\[Q(s, a; \theta, \alpha, \beta) = V(s; \theta, \beta) + A(s, a; \theta, \alpha)\]</span></p>
<p>However, these functions are just estimates of the true values, therefore are unidentifiable in the sense that given <span class="math inline">\(Q\)</span> we can not recover <span class="math inline">\(V, A\)</span> uniquely. (ie. given <span class="math inline">\(Q(s, a)\)</span> what is <span class="math inline">\(V(s), A(s, a)\)</span>?)</p>
<p>To solve the problem, we can force the advantage function to have zero advantage at some chosen action, in this case the greedy action:</p>
<p><span class="math display">\[Q(s, a; \theta, \alpha, \beta) = V(s; \theta, \beta) + A(s, a; \theta, \alpha) - max_{a^{\prime}} A(s, a^{\prime}; \theta, \alpha)\]</span></p>
<p>Thus, if <span class="math inline">\(a^{*} = argmax_{a^{\prime} \in A} Q(s, a^{\prime})\)</span>, then</p>
<p><span class="math display">\[Q(s, a^{*}; \theta, \alpha, \beta) = V(s; \theta, \beta)\]</span></p>
<p>We can determine the <span class="math inline">\(V\)</span> given <span class="math inline">\(Q\)</span>.</p>
<p>Or, we can have:</p>
<p><span class="math display">\[Q(s, a; \theta, \alpha, \beta) = V(s; \theta, \beta) + A(s, a; \theta, \alpha) - \frac{1}{|A|} \sum_{a^{\prime}} A(s, a^{\prime}; \theta, \alpha)\]</span></p>
<p>Take the expectation or average of <span class="math inline">\(Q\)</span>:</p>
<p><span class="math display">\[E[Q(s, a; \theta, \alpha, \beta)] = V(s; \theta, \theta)\]</span></p>
<p>On the one hand this loses the original semantics of <span class="math inline">\(V\)</span> and <span class="math inline">\(A\)</span> because they are now off-target by a constant, but on the other hand it increases the stability of the optimization. Note that while subtracting the mean or max helps with the identifiability, it does not change the relative rank of <span class="math inline">\(A, Q\)</span>, so the greedy action.</p>
<h2 id="discussion">Discussion</h2>
<p>The advantage of the dueling architecture lies partly in its ability to learn the state-value function efficiently. With every update of the <span class="math inline">\(Q\)</span> values in the dueling architecture, the value stream <span class="math inline">\(V\)</span> is updated – this contrasts with the updates in a single-stream architecture where only the value of one of actions is updated, the values of other actions are untouched. The advantage of the dueling architecture over single-stream <span class="math inline">\(Q\)</span> networks grows when the number of actions is large.</p>
<h2 id="implementation">Implementation</h2>
<p><em>One implementation of Dueling Architecture in PARL using PaddlPaddle for Atari Games</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> parl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AtariModel</span>(<span class="params">parl.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, act_dim, dueling=<span class="literal">False</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2D(</span><br><span class="line">            in_channels=<span class="number">4</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>, weight_attr=nn.initializer.KaimingNormal())</span><br><span class="line">        self.conv2 = nn.Conv2D(</span><br><span class="line">            in_channels=<span class="number">32</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>, weight_attr=nn.initializer.KaimingNormal())</span><br><span class="line">        self.conv3 = nn.Conv2D(</span><br><span class="line">            in_channels=<span class="number">32</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, weight_attr=nn.initializer.KaimingNormal())</span><br><span class="line">        self.conv4 = nn.Conv2D(</span><br><span class="line">            in_channels=<span class="number">64</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, weight_attr=nn.initializer.KaimingNormal())</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.max_pool = nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line"></span><br><span class="line">        self.dueling = dueling</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> dueling:</span><br><span class="line">            self.linear_1_adv = nn.Linear(in_features=<span class="number">6400</span>, out_features=<span class="number">512</span>, weight_attr=nn.initializer.KaimingNormal())</span><br><span class="line">            self.linear_2_adv = nn.Linear(in_features=<span class="number">512</span>, out_features=act_dim)</span><br><span class="line">            self.linear_1_val = nn.Linear(in_features=<span class="number">6400</span>, out_features=<span class="number">512</span>, weight_attr=nn.initializer.KaimingNormal())</span><br><span class="line">            self.linear_2_val = nn.Linear(in_features=<span class="number">512</span>, out_features=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.linear_1 = nn.Linear(in_features=<span class="number">6400</span>, out_features=act_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">value</span>(<span class="params">self, obs</span>):</span></span><br><span class="line"></span><br><span class="line">        obs = obs / <span class="number">255.0</span></span><br><span class="line">        out = self.max_pool(self.relu(self.conv1(obs)))</span><br><span class="line">        out = self.max_pool(self.relu(self.conv2(out)))</span><br><span class="line">        out = self.max_pool(self.relu(self.conv3(out)))</span><br><span class="line">        out = self.relu(self.conv4(out))</span><br><span class="line">        out = self.flatten(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.dueling:</span><br><span class="line">            As = self.relu(self.linear_1_adv(out))</span><br><span class="line">            As = self.linear_2_adv(As)</span><br><span class="line">            V = self.relu(self.linear_1_val(out))</span><br><span class="line">            V = self.linear_2_val(V)</span><br><span class="line">            Q = As + (V - As.mean(axis=<span class="number">1</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            Q = self.linear_1(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Q</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>RL</category>
        <category>VFA</category>
      </categories>
      <tags>
        <tag>Function Approximation</tag>
        <tag>Continuous State Space</tag>
      </tags>
  </entry>
  <entry>
    <title>MDP</title>
    <url>/2021/05/03/MDP/</url>
    <content><![CDATA[<h1 id="mdp">MDP</h1>
<p><span style="color:red"><em>Based on Prof Amir-massoud Farahmand's Lecture on RL</em> </span></p>
<p>Define our MDP different from Introduction to RL book:</p>
<p><img src='/images/RL/bellman_equation/mdp.png'></p>
<p>Where <span class="math inline">\(M(X)\)</span> is the space of all probability distributions defined over the state space X <span id="more"></span></p>
<p>So a sample of the process can be described as a rollout or trajectory:</p>
<p><span class="math display">\[\tau = X_1, A_1, R_1, X_2, A_2, R_2, ...\]</span></p>
<p>A deterministic dynamical system always behave exactly the same given the same starting state and action, that is, they can be described as a transition function <span class="math inline">\(f\)</span> instead of transition distribution <span class="math inline">\(P\)</span></p>
<p><span class="math display">\[x_{t+1} = f(x, a)\]</span></p>
<h2 id="policy">Policy</h2>
<p><img src='/images/RL/bellman_equation/policy_1.png'></p>
<p><img src='/images/RL/bellman_equation/policy.png'></p>
<h2 id="policy-induced-transition-kernels">Policy induced Transition Kernels</h2>
<p><img src='/images/RL/bellman_equation/transition_kernel.png'></p>
<h2 id="rewards-and-returns">Rewards and Returns</h2>
<p>Let's define expected reward as:</p>
<p><span class="math display">\[r(x, a) = E[R | X=x, A=a]\]</span></p>
<p>then the expected reward following policy pi is defined as</p>
<p><span class="math display">\[r^{\pi} (x) = E_{a \sim \pi(a | x)} [R | X=x]\]</span></p>
<p>Define return following policy <span class="math inline">\(\pi\)</span> as discounted sum of rewards starting from <span class="math inline">\(X_1\)</span>:</p>
<p><span class="math display">\[G^{\pi} = R_1 + \gamma R_2 + ... + \gamma^{T-1} R_{T} = \sum^{\infty}_{k=t} \gamma^{k - t}R_{t}\]</span></p>
<p>or any starting at any step <span class="math inline">\(X_{t}\)</span>:</p>
<p><span class="math display">\[G^{\pi}_{t} = \sum^{\infty}_{k=t} \gamma^{k - t}R_{t}\]</span></p>
<p>Note that <span class="math inline">\(\gamma\)</span> is a part of the problem setting, it is usually not a hyperparameter. <strong>One way to think about is as a constant probability of termination of <span class="math inline">\(1 - \gamma\)</span>. Or we can set <span class="math inline">\(\gamma = 1\)</span> when we have episodic tasks.</strong>.</p>
<h2 id="example">Example</h2>
<p>Finite horizon example:</p>
<ul>
<li>Start at <span class="math inline">\(X_1 \sim \rho\)</span></li>
<li>Select <span class="math inline">\(A_1 \sim \pi(\cdot | X_1)\)</span></li>
<li>Get <span class="math inline">\(R_1 \sim R(\cdot | A_1, X_1)\)</span></li>
<li>Get <span class="math inline">\(X_2 \sim P(\cdot | A_1, X_1)\)</span></li>
<li>...</li>
<li>...</li>
<li>Get <span class="math inline">\(R_{T} \sim R(\cdot | X_{T}, A_{T})\)</span></li>
<li>Get <span class="math inline">\(X_{T+1} \sim P(\cdot | X_{T}, A_{T})\)</span> (This is the terminal state, which is often dropped because it has value of 0)</li>
</ul>
<p>The process stops!</p>
<h2 id="value-functions">Value functions</h2>
<p>Next we can define value functions as:</p>
<p>State value function (alias: Value function, V, v) starting from state x and following policy <span class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[V^{\pi}(x) = E[G_1^{\pi} | X_{1} = x] = E[G^{\pi}_{t} | X_{t} = x] \text{    (Markov Property)}\]</span></p>
<p>Action value function following policy <span class="math inline">\(\pi\)</span> starting from state x and taking action a:</p>
<p><span class="math display">\[Q^{\pi} (x, a) = E[G_1^{\pi} | X_{1} = x, A_{1} = a] = E[G^{\pi}_{t} | X_{t} = x, A_{t} = a] \text{    (Markov Property)}\]</span></p>
<p>in the <code>terminal formulation</code>, the value function <span class="math inline">\(V_{term}^{\pi}\)</span> can be written as:</p>
<p><span class="math display">\[V_{term}^{\pi} = E[R_{1} + R_2 + .... + R_{t + T} | X_1 = x] \;\;\;\;\;\; \forall x \in X\]</span></p>
<p>The process terminates at time <span class="math inline">\(t + T\)</span> according to <span class="math inline">\(\gamma\)</span>. In this case the termination should be assumed to always occur in a finite number of steps (ie. if we have episodic task we can set <span class="math inline">\(\gamma = 1\)</span>).</p>
<h2 id="another-formulation">Another formulation</h2>
<p>We can also define the T-step rollout or trajectory distribution <span class="math inline">\(P(\tau | \pi)\)</span> following policy <span class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[P(\tau | \pi) = \rho(X_1)\prod_{t=1}^{T} P(X_{t+1}| X_{t}, A_{t}) \pi(A_t | X_{t}) R(R_t | X_{t}, A_{t})\]</span></p>
<p>Then:</p>
<p><span class="math display">\[R(\tau) = G^{\pi}_{1} = \sum^{T}_{k=1} \gamma^{k - t}R_{t}\]</span></p>
<p><span class="math display">\[J(\pi) = E_{\tau \sim P(\tau | \pi) }[R(\tau)] = \int R(\tau) P(d\tau | \pi)\]</span></p>
<p><span class="math display">\[V^{\pi} (x) = E_{\tau \sim P(\tau | \pi, X_1=x)}[R(\tau) | X_1 = x]\]</span></p>
<p>And:</p>
<p><span class="math display">\[J(\pi) = \int V^{\pi} (x) d\rho(x)\]</span></p>
]]></content>
      <categories>
        <category>RL</category>
        <category>Basics</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>TRPO</title>
    <url>/2021/06/11/TRPO/</url>
    <content><![CDATA[<h1 id="trust-region-policy-optimization">Trust Region Policy Optimization</h1>
<h2 id="notations">Notations</h2>
<p><strong><span class="math inline">\(A_{\pi}, A^{\pi}\)</span></strong> are the same, just some mismatch in the notations during writing, same for <span class="math inline">\(V, Q\)</span> :&lt;</p>
<p>Consider an infinite-horizon discounted MDP, defined by the tuple <span class="math inline">\((S, A, P, r, \rho_0, \gamma)\)</span>. <span class="math inline">\(S\)</span> is finite set of states and <span class="math inline">\(A\)</span> is finite set of actions $r: S $.</p>
<p>The expected discounted return over initial state distribution <span class="math inline">\(\rho_0\)</span> (performance measure):</p>
<p><span class="math display">\[\eta (\pi) = E_{s_0, a_0, ...} [\sum^{\infty}_{t=0} \gamma^t r(s_t)]\]</span></p>
<p>Where <span class="math inline">\(s_0 \sim \rho_0, a_t \sim \pi (\cdot | s_t), s_{t+1} \sim P(\cdot | s_t, a_t)\)</span></p>
<p>Value functions:</p>
<p><span class="math display">\[Q_{\pi} (s_t, a_t) = E_{s_{t+1}, a_{t+1}, ..}[\sum^{\infty}_{l=0} \gamma^{l} r(s_{t+l}) | S_t=s_t, A_t=a_t]\]</span></p>
<p><span class="math display">\[V_{\pi} (s_t) = E_{a_{t}, s_{t+1}, a_{t+1}, ..}[\sum^{\infty}_{l=0} \gamma^{l} r(s_{t+l}) | S_t=s_t]\]</span></p>
<p>The advantage:</p>
<p><span class="math display">\[A(s, a) = Q_{\pi} (s, a) - V_{\pi} (s)\]</span></p>
<p>The discounted future state distribution (unormalized):</p>
<p><span class="math display">\[\rho_{\pi} (s) = \lim_{t \rightarrow \infty} \sum_{t} \rho(s_0) \gamma^t P(s_0 \rightarrow s; t, \pi)\]</span></p>
<span id="more"></span>
<h2 id="the-difference-in-policy-performance-as-expected-advantages-over-states-and-actions">The difference in policy performance as expected advantages over states and actions</h2>
<p>Given two policies <span class="math inline">\(\pi, \tilde{\pi}\)</span>, the performance of <span class="math inline">\(\tilde{\pi}\)</span>:</p>
<p><span class="math display">\[\eta (\tilde{\pi}) = \eta(\pi) + E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t = 0} \gamma^t A_{\pi} (s_t, a_t)]\]</span></p>
<h3 id="proof">Proof</h3>
<p>First:</p>
<span class="math display">\[\begin{aligned}
E_{s^{\prime}} [r(s) + \gamma V^{\pi} (s^{\prime}) - V^{\pi} (s) | s, a] &amp;= E_{s^{\prime}} [r(s) + \gamma V^{\pi} (s^{\prime}) | s, a] - V^{\pi} (s)\\
&amp;= r(s) + \gamma \int_{s^{\prime}, a^{\prime}} P(ds^{\prime} | s, a)\pi(da^{\prime} | s^{\prime}) Q^{\pi} (s^{\prime}, a^{\prime}) - V^{\pi} (s)\\
&amp;= Q^{\pi}(s, a) - V^{\prime} (s)\\
&amp;= A_{\pi}(s, a)
\end{aligned}\]</span>
<p>Thus:</p>
<span class="math display">\[\begin{aligned}
E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t=0} \gamma^t A_{\pi} (s_t, a_t)] &amp;= E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t=0} \gamma^t E_{s_{t+1}} [r(s_t) + \gamma V^{\pi} (s_{t+1}) - V^{\pi} (s_t) | s_t, a_t]]\\
&amp;= E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t=0} \gamma^t (r(s_t) + V^{\pi} (s_{t+1}) - V^{\pi} (s_t))]\\
&amp;= E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t=0} \gamma^t(\gamma V^{\pi}(s_{t+1}) - V^{\pi}(s_{t})) + \sum^{\infty}_{t=0} \gamma^t r(s_t)]\\
&amp;= E_{\tau \sim \tilde{\pi}} [ - V^{\pi}(s_{0}) + \sum^{\infty}_{t=0} \gamma^t r(s_t)]\\
&amp;= E_{s_0} [- V^{\pi}(s_{0})] + E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t=0} \gamma^t r(s_t)]\\
&amp;= - \eta (\pi) + \eta (\tilde{\pi})
\end{aligned}\]</span>
<p>The improvement can be written as per timestep advantage.</p>
<p>At the same time, the improvement can rewrite using discounted future state distribution (unormalized):</p>
<span class="math display">\[\begin{aligned}
\eta (\tilde{\pi}) &amp;= \eta (\pi) + E_{\tau \sim \tilde{\pi}} [\sum^{\infty}_{t=0} \gamma^t A_{\pi} (s_t, a_t)]\\
&amp;= \eta (\pi) + \sum^{\infty}_{t=0} \gamma^t E_{\tau \sim \tilde{\pi}} [A_{\pi} (s_t, a_t)]\\
&amp;= \eta (\pi) + \sum^{\infty}_{t=0} \gamma^t E_{s_t, a_t} [A_{\pi} (s_t, a_t)]\\
&amp;= \eta (\pi) + \sum^{\infty}_{t=0} \gamma^t \sum_{s_{t}, a_{t}, s_0} \rho(s_0) P(s_0 \rightarrow s_t; t, \tilde{\pi}) \tilde{\pi}(a_t|s_t) A_{\pi} (s_t, a_t) \\
&amp;= \eta (\pi) + \sum_{s_{t}, a_{t}, s_{0}} \sum^{\infty}_{t=0} \gamma^t \rho(s_0) P(s_0 \rightarrow s_t; t, \tilde{\pi}) \tilde{\pi}(a_t|s_t) A_{\pi} (s_t, a_t) \\
&amp;= \eta (\pi) + \sum_{s_{t}} \rho_{\tilde{\pi}} (s_t) \sum_{a_{t}} \tilde{\pi}(a_t|s_t) A_{\pi}(s_t, a_t)
\end{aligned}\]</span>
<p><strong>This equation implies that any policy update <span class="math inline">\(\pi \rightarrow \tilde{\pi}\)</span> that has non-negative expected advantage over actions at every state <span class="math inline">\(s_t\)</span> is guaranteed to increase the policy performance measure <span class="math inline">\(\eta\)</span> or leave it constant</strong></p>
<h2 id="local-approximation-to-eta">Local Approximation to <span class="math inline">\(\eta\)</span></h2>
<p>In the approximate setting, it will typically be unavoidable, due to estimation error and approximation error that there will be some states with expected advantage over actions less than 0:</p>
<p><span class="math display">\[E_{a \sim \tilde{\pi} (\cdot | s)}[A_{\pi} (s, a) | s] &lt; 0\]</span></p>
<p>At the same time, the expectation also depends on <span class="math inline">\(\rho^{\tilde{\pi}}\)</span> which makes it difficult to optimize directly (the future state distribution is unknown, we cannot sample from unknown distribution), instead, we can use following local approximation to <span class="math inline">\(\eta\)</span>:</p>
<span class="math display">\[\begin{aligned}
L_{\pi} (\tilde{\pi}) &amp;= \eta (\pi) + \underbrace{\sum_{s_t} \rho_{\pi} (s_t)}_{\text{we replace unnormalized state distribution}} \sum_{a_t} \tilde{\pi}(a_t|s_t) [A_{\pi}(s_t, a_t)]\\
&amp;= \eta (\pi) + \frac{1}{1 - \gamma}E_{s_t \sim \rho^{\pi} (\cdot), a_t \sim \tilde{\pi}(\cdot | s_t)} [A^{\pi}(s_t, a_t)]\\
&amp;= \eta (\pi) + \frac{1}{1 - \gamma}\mathbb{A}_{\pi} (\tilde{\pi})
\end{aligned}\]</span>
<p>We now ignore the change in state distribution due to the changes in the policy. If <span class="math inline">\(\pi\)</span> is parametrized by <span class="math inline">\(\theta\)</span>, then:</p>
<p><span class="math display">\[L_{\pi_\theta} (\pi_{\theta}) = \eta (\pi_{\theta}) + \underbrace{ \sum_{s_t} \rho_{\pi_{\theta}} (s_t) \sum_{a_t} \pi(a_t|s_t) [A_{\pi_{\theta}}(s_t, a_t)]}_{E_{a \sim \pi}[A_{\pi_{\theta}} (s, a) | s] = 0} = \eta (\pi_{\theta})\]</span></p>
<p>Consider a small update on <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(\pi_{\theta_{new}} = (1 - \alpha) \pi_{\theta} + \alpha \pi_{\theta^{\prime}}\)</span>, then:</p>
<span class="math display">\[\begin{aligned}
\nabla_{\alpha} \eta (\pi_{\theta_{new}}) |_{\alpha = 0} &amp;= \nabla_{\pi_{\theta_{new}}} \eta (\pi_{\theta_{new}}) \nabla_{\alpha} \pi_{\theta_{new}} |_{\pi_{\theta_{new}} = \pi_{\theta}}\\
&amp;= \sum_{s_t, a_t} \rho^{\pi_{\theta_{new}}} (s_t) \nabla_{\pi_{\theta_{new}}} \pi_{\theta_{new}} (a_t | s_t) (\pi_{\theta^{\prime}} (a_t | s_t) - \pi_{\theta} (a_t | s_t)) A^{\pi_{\theta_{new}}}(s_t, a_t)|_{\pi_{\theta_{new}} = \pi_{\theta}}\\
&amp;= \sum_{s_t, a_t} \rho^{\pi_{\theta}} (s_t) \pi_{\theta^{\prime}} (a_t | s_t) A^{\pi_{\theta}}(s_t, a_t) - \sum_{s_t, a_t} \rho^{\pi_{\theta}} (s_t) \pi_{\theta} (a_t | s_t) A(s_t, a_t)\\
&amp;= \sum_{s_t, a_t} \rho^{\pi_{\theta}} (s_t) \pi_{\theta^{\prime}} (a_t | s_t) A^{\pi_{\theta}}(s_t, a_t) - \sum_{s_t} \rho^{\pi_{\theta}} (s_t) \sum_{a_t} \pi_{\theta} (a_t | s_t) Q^{\pi_{\theta}}(s_t, a_t) - V^{\pi_{\theta}} (s_t)\\
&amp;= \sum_{s_t, a_t} \rho^{\pi_{\theta}} (s_t) \pi_{\theta^{\prime}} (a_t | s_t) A^{\pi_{\theta}}(s_t, a_t)\\
&amp;= \frac{1}{1 - \gamma}\sum_{s_t, a_t} (1 - \gamma)\rho^{\pi_{\theta}} (s_t) \pi_{\theta^{\prime}} (a_t | s_t) A^{\pi_{\theta}}(s_t, a_t)\\
&amp;= \frac{1}{1 - \gamma} E_{s_t \sim \rho^{\pi_{\theta}} (\cdot), a_t \sim \pi_{\theta^{\prime}}(\cdot | s_t)} [A^{\pi_{\theta}}(s_t, a_t)]\\
&amp;=  \frac{1}{1 - \gamma}\mathbb{A}_{\pi_{\theta}} (\pi_{\theta^{\prime}})
\end{aligned}\]</span>
<p></br></p>
<p>By the same insight, we can conclude that <span class="math inline">\(\alpha A_{\pi_{\theta}} (\pi_{\theta^\prime}) = A_{\pi_{\theta}} (\pi_{\theta_{new}})\)</span>. Using Talyor's expansion and above first order results, we can see that the change in <span class="math inline">\(\Delta \eta\)</span>:</p>
<p><span class="math display">\[\eta (\pi_{\theta_{new}}) - \eta (\pi_{\theta}) \geq \frac{1}{1 - \gamma}\mathbb{A}_{\pi_{\theta}} (\pi_{\theta_{new}}) - O(\alpha^2)\]</span></p>
<p><span class="math display">\[\implies \eta (\pi_{\theta_{new}}) \geq L_{\pi_{\theta}} (\pi_{\theta_{new}}) - O(\alpha^2)\]</span></br></p>
<p>These results imply that a sufficiently small step <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\pi_{\theta} \rightarrow \tilde{\pi}\)</span> that improves <span class="math inline">\(L_{\pi_{\theta}}\)</span> will also improve <span class="math inline">\(\eta\)</span>. However, it does not tell us how big of the step to take. To address this issue, some previous works proposed:</p>
<p><span class="math display">\[\pi_{new} (a | s) = (1 - \alpha) \pi_{old} (a | s) + \alpha \pi^{\prime} (a | s)\]</span></p>
<p>Where <span class="math inline">\(\pi^{\prime} = \arg\max_{\pi^{\prime}} L_{\pi_{old}} (\pi^{\prime})\)</span></p>
<p>They also derive the lower bound:</p>
<p><span class="math display">\[\eta (\pi_{new}) \geq L_{\pi_{old}} (\pi_{new}) - \frac{2 \epsilon \gamma}{(1 - \gamma)^2} \alpha^2\]</span></p>
<p>Where <span class="math inline">\(\epsilon = \max_{s} | E_{a \sim \pi^{\prime}} [A_{\pi} (s, a)]|\)</span></p>
<p><strong>However, this bound only applies to the above policy update rule and is restrictive in practice.</strong></p>
<h2 id="monotonic-improvement-guarantee-for-general-stochastic-policies">Monotonic Improvement Guarantee for General Stochastic Policies</h2>
<p>We can extend the above lower bound to more general case stochastic policies by replacing <span class="math inline">\(\alpha\)</span> with some distance measurement between <span class="math inline">\(\pi\)</span> and <span class="math inline">\(\tilde{\pi}\)</span> and change <span class="math inline">\(\epsilon\)</span> accordingly. The particular distance measure in this case is total variation divergence, for discrete probability distributions <span class="math inline">\(p, q\)</span></p>
<p><span class="math display">\[D_{TV} (p || q) = \frac{1}{2} \sum_{i} |p_i - q_i|\]</span></p>
<p>Define the maximum distance to be the maximum total variation divergence over states:</p>
<p><span class="math display">\[D^{\max}_{TV} (\pi, \tilde{\pi}) = \max_{s} D_{TV} (\pi(\cdot | s) || \tilde{\pi} (\cdot | s))\]</span> </br></p>
<p><img src="/images/RL/pg/trpo_1.png" width="600"></p>
<p>Notice that the relationship between KL divergence and total variation divergence:</p>
<p><span class="math display">\[D_{TV} (p || q)^2 \leq D_{KL} (p || q)\]</span></p>
<p>Let:</p>
<p><span class="math display">\[D^{\max}_{KL} (\pi, \tilde{\pi}) = \max_{s} D_{KL} (\pi(\cdot | s) || \tilde{\pi} (\cdot | s)) \geq D^{\max}_{TV} (\pi, \tilde{\pi})\]</span></p>
<p>Then, the lower bound becomes:</p>
<p><span class="math display">\[\eta (\tilde{\pi}) \geq L_{\pi} (\tilde{\pi}) - C D^{\max}_{TV} (\pi, \tilde{\pi})^2 \geq L_{\pi} (\tilde{\pi}) - C D^{\max}_{KL} (\pi, \tilde{\pi})\]</span></p>
<p>Where <span class="math inline">\(C = \frac{4\epsilon \gamma}{(1 - \gamma)^2}\)</span>, <span class="math inline">\(\epsilon = \max_{s, a} |A_{\pi} (s, a)|\)</span></p>
<h2 id="population-version-of-the-algorithm">Population Version of the Algorithm</h2>
<p><strong>The population version of the algorithm assumes exact evaluation of the advantage function:</strong></p>
<p><img src="/images/RL/pg/trpo_2.png" width="600"></p>
<p>We can see that the algorithm generate monotonically improved sequence of performance measure <span class="math inline">\(\eta (\pi_0) \leq \eta (\pi_1) \leq \eta (\pi_2) \leq ...\)</span>. To see this, let <span class="math inline">\(M_i (\pi) = L_{\pi_i} (\pi) - CD^{\max}_{KL} (\pi, \tilde{\pi})\)</span>:</p>
<span class="math display">\[\begin{aligned}
\eta (\pi_{i + 1}) &amp;\geq M_i (\pi_{i + 1})\\
\eta (\pi_{i}) &amp;= M_i (\pi_i)\\
\eta (\pi_{i + 1}) - \eta (\pi_{i}) &amp;\geq M_i (\pi_{i + 1}) - M_i (\pi_i)
\end{aligned}\]</span>
<p></br></p>
<p>Since we are maximizing <span class="math inline">\(M_i (\pi_i)\)</span> at each iteration <span class="math inline">\(\implies M_i (\pi_i) \geq M_i (\pi_i)\)</span>. The improvement is non-decreasing.</p>
<h3 id="optimization-of-parameterized-policies">Optimization of Parameterized Policies</h3>
<p>Since we are parameterizing policy by <span class="math inline">\(\theta\)</span>, some additional notations are used in place of the <span class="math inline">\(\pi\)</span></p>
<p><span class="math display">\[\eta (\theta) := \eta(\pi_\theta) \;\;\;\;\; L_{\theta}(\tilde{\theta}) := L_{\pi_{\theta}} (\pi_{\tilde{\theta}})  \;\;\;\;\; D_{KL} (\theta || \tilde{\theta}) := D_{KL} (\pi_{\theta} || \tilde{\pi}_{\theta})\]</span></p>
<p><span class="math inline">\(\theta_{old}\)</span> is used to denote the previous policy parameters that we want to improve upon.</p>
<p>The previous theorem suggest that, if we maximize:</p>
<p><span class="math display">\[\max_{\theta} \quad [L_{\theta_{old}} (\theta) - CD^{\max}_{KL} (\theta_{old}, \theta)]\]</span> </br></p>
<p>Then we are guaranteed to improve our policy with equality when <span class="math inline">\(\theta_{old} = \theta\)</span>.</p>
<p>However, since the penalty term is <span class="math inline">\(CD^{\max}_{KL} (\theta_{old}, \theta)\)</span> which means smaller change in policy distribution is preferred. If we maximize this objective with penalty coefficient <span class="math inline">\(C\)</span>, we will end up with very small step-size. One way to take larger step size is to use a constraint on the KL divergence between the new policy and the old policy (Trust Region Constraint):</p>
<span class="math display">\[\begin{aligned}
\max_{\theta} \quad &amp; L_{\theta_{old}} (\theta)\\
\textrm{s.t.} \quad &amp; D^{\max}_{KL} (\theta_{old}, \theta) \leq \delta
\end{aligned}\]</span>
<p></br></p>
<p>This optimization problem is impractical to solve due to large number of constraints, but we can use a heuristic approximation which considers the average KL divergence:</p>
<p><span class="math display">\[\bar{D}^\rho_{KL} (\theta_1, \theta_2) := E_{s \sim \rho}[D_{KL} (\pi_{\theta_1} (\cdot | s) || \pi_{\theta_2} (\cdot | s))]\]</span></p>
<p>Then the optimization problem can be rewritten as:</p>
<span class="math display">\[\begin{aligned}
\max_{\theta} \quad &amp; L_{\theta_{old}} (\theta)\\
\textrm{s.t.} \quad &amp; \bar{D}^{\rho_{\theta_{old}}}_{KL} (\theta_1, \theta_2) \leq \delta
\end{aligned}\]</span>
<p></br></p>
<h2 id="sample-based-algorithm">Sample-Based Algorithm</h2>
<p>The above population version optimization problem can be approximated using MC simulation:</p>
<span class="math display">\[\begin{aligned}
\max_{\theta} \quad &amp; E_{s \sim \rho_{\theta_{old}} (\cdot), \; a \sim q (\cdot | s)} [\frac{\pi_{\theta} (a | s)}{q (a | s)} \hat{Q}_{\theta_{old}} (s, a)]\\
\textrm{s.t.} \quad &amp; E_{s \sim \rho_{\theta_{old}} (\cdot)}[D_{KL} (\pi_{\theta_{old}} (\cdot | s) || \pi_{\theta} (\cdot | s))] \leq \delta
\end{aligned}\]</span>
<p></br></p>
<ol type="1">
<li>Drop constant <span class="math inline">\(\eta (\theta_{old})\)</span> from the objective</li>
<li>Replace advantage <span class="math inline">\(A_{\theta_{old}}\)</span> with <span class="math inline">\(Q_{\theta_{old}}\)</span>, because <span class="math inline">\(V_{\pi_{old}} (s)\)</span> only affects the value at each state by a constant (does not depend on policy).</li>
<li>Place sampling of action <span class="math inline">\(a\)</span> by an importance sampling, we can use one trajectory to sample both actions and states if <span class="math inline">\(q = \pi_{\theta_{old}}\)</span>.</li>
<li>Substitute an estimate <span class="math inline">\(\hat{Q}_{\theta_{old}}\)</span> for <span class="math inline">\(Q_{\theta_{old}}\)</span></li>
</ol>
<h3 id="collecting-samples-single-path">Collecting Samples (Single Path)</h3>
<p>In this estimation procedure, we collect a sequence of states by sampling <span class="math inline">\(s_0 \sim \rho_0\)</span>, then simulating the trajectory <span class="math inline">\(\tau = (s_0, a_1, s_1, a_2, ..., s_T)\)</span> by following <span class="math inline">\(\pi_{old}\)</span>, and discount each estimate of the expectation by <span class="math inline">\(\gamma^t\)</span>, then the samples of <span class="math inline">\(s_i\)</span> would be from the discounted state distribution. Then, we use discounted return <span class="math inline">\(G\)</span> to be the unbiased estimator of <span class="math inline">\(Q_{\theta_{old}}\)</span>, that is, <span class="math inline">\(\hat{Q}_{\theta_{old}} = G\)</span></p>
<h3 id="collecting-samples-vine">Collecting Samples (Vine)</h3>
<p>Ignored Here</p>
<h2 id="conclusions">Conclusions</h2>
<ol type="1">
<li><p>The theory justifies optimizing a surrogate objective with a penalty on step size (KL divergence) would guarantee policy improvement. However, the large penalty coefficient C leads to prohibitively small steps, so we relax the penalty by converting the problem to a constraint optimization problem with hard threshold on the step size <span class="math inline">\(\alpha\)</span> which is defined as the average DL divergence. This divergence is easier for numerical optimization and estimation than max KL divergence.</p></li>
<li><p>The theory in this paper ignores estimation error for the advantage function.</p></li>
</ol>
<h2 id="reference">Reference</h2>
<p>https://ieor8100.github.io/rl/docs/Lecture%207%20-Approximate%20RL.pdf</p>
<p>https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Search</tag>
      </tags>
  </entry>
  <entry>
    <title>PPO</title>
    <url>/2021/06/11/PPO/</url>
    <content><![CDATA[<h1 id="proximal-policy-optimization-algorithms">Proximal Policy Optimization Algorithms</h1>
<h2 id="notations-and-backgrounds">Notations and Backgrounds</h2>
<h3 id="policy-gradient-estimator">Policy gradient estimator</h3>
<p><span class="math display">\[\hat{g} = \hat{E}_t [\nabla_{\theta} \log \pi_{\theta} (a_t | s_t) \hat{A_t}]\]</span></p>
<p>Where, <span class="math inline">\(\pi_{\theta}\)</span> is the stochastic policy and <span class="math inline">\(\hat{A_t}\)</span> is an estimate of advantage function at timestep <span class="math inline">\(t\)</span>. The expectation here <span class="math inline">\(\hat{E}_t\)</span> indicates the empirical average over a finite batch of samples, in an algorithm that alternates between sampling and optimization.</p>
<p><span class="math inline">\(\hat{g}\)</span> is obtained by differentiating the objective</p>
<p><span class="math display">\[L^{PG} (\theta) = \hat{E}_t [\log \pi_{\theta} (a_t | s_t) \hat{A_t}]\]</span></p>
<p>While it is appealing to perform multiple steps of optimization on this loss <span class="math inline">\(L^{PG} (\theta)\)</span> (reuse the same samples to update <span class="math inline">\(\theta\)</span>), using the same trajectory, doing so is not well-justi ed, and empirically it often leads to destructively large policy updates.</p>
<h3 id="trust-region-methods">Trust Region Methods</h3>
<p>The optimization problem is defined as:</p>
<span class="math display">\[\begin{aligned}
\max_{\theta} \quad &amp; \hat{E}_{s \sim \rho_{\theta_{old}} (\cdot), \; a \sim \pi_{\theta_{old}}(\cdot | s)} [\frac{\pi_{\theta} (a | s)}{\pi_{\theta_{old}} (a | s)} \hat{A}_{\theta_{old}} (s, a)]\\
\textrm{s.t.} \quad &amp; \hat{E}_{s \sim \rho_{\theta_{old}} (\cdot)}[D_{KL} (\pi_{\theta_{old}} (\cdot | s) || \pi_{\theta} (\cdot | s))] \leq \delta
\end{aligned}\]</span>
<p></br></p>
<p>It is also possible to remove the hard constraint and convert the problem to an unconstrained objective:</p>
<span class="math display">\[\begin{aligned}
\max_{\theta} \quad &amp; \hat{E}_{s \sim \rho_{\theta_{old}} (\cdot), \; a \sim \pi_{\theta_{old}}(\cdot | s)} [\frac{\pi_{\theta} (a | s)}{\pi_{\theta_{old}} (a | s)} \hat{A}_{\theta_{old}} (s, a) - \beta D_{KL}[\pi_{\theta_{old}} (\cdot | s) || \pi_{\theta} (\cdot | s))]]\\
\end{aligned}\]</span>
<p></br></p>
<p>The problem with this objective is that, the penalty prefers small steps, so it is very hard to choose an appropriate <span class="math inline">\(\beta\)</span> that performs well across different problems or even within a single problem where the characteristics change over the course of learning.</p>
<span id="more"></span>
<h2 id="clipped-surrogate-objective">Clipped Surrogate Objective</h2>
<p>Let <span class="math inline">\(r_t (\theta)\)</span> denotes the probability ratio <span class="math inline">\(r_t (\theta) = \frac{\pi_{\theta} (a_t | s_t)}{\pi_{\theta_{old}} (a_t | s_t)}\)</span>, so <span class="math inline">\(r (\theta_{old}) = 1\)</span>. The above unconstrained TRPO objective without penalty becomes:</p>
<p><span class="math display">\[L^{CPI} (\theta) = \hat{E}_{s \sim \rho_{\theta_{old}} (\cdot), \; a \sim \pi_{\theta_{old}} (\cdot | s)} [r_{t} (\theta) \hat{A}_{\theta_{old}} (s, a)]\]</span></p>
<p>Without the penalty, the step size can be super big maximizing <span class="math inline">\(L^{CPI}\)</span>, thus, we can add penalty to the changes to the policy that move <span class="math inline">\(r_t (\theta)\)</span> away from 1 (make big updates or take big step)</p>
<p>The main objective is then:</p>
<p><span class="math display">\[L^{CLIP} (\theta) = \hat{E}_{s \sim \rho_{\theta_{old}} (\cdot), \; a \sim \pi_{\theta_{old}} (\cdot | s)} [\min (r_{t} (\theta) \hat{A}_{\theta_{old}} (s, a), \text{clip}(r_t(\theta), 1 - \epsilon, 1 + \epsilon)\hat{A}_{\theta_{old}} (s, a))]\]</span> </br></p>
<p>Notice here, the clipped objective gives a lower bound of the unclipped objective, to see this:</p>
<ol type="1">
<li>If <span class="math inline">\(A_t &lt; 0\)</span>, then one way to maximize the objective is to make <span class="math inline">\(r_t\)</span> very small, then we will have a really large step size, However, with clipped objective, the largest change is clipped to <span class="math inline">\(1 - \epsilon\)</span></li>
<li>If <span class="math inline">\(A_t &gt; 0\)</span>, then one way to maximize the objective is to make <span class="math inline">\(r_t\)</span> very large, then we will have a really large step size. However, with clipped objective, the largest change is clipped to <span class="math inline">\(1 + \epsilon\)</span></li>
</ol>
<p>At the same time, the minimum gives the above behavior to account for <span class="math inline">\(A_t &gt; 0, A_t &lt; 0\)</span> situation.</p>
<p><img src="/images/RL/pg/ppo_1.png" width="600"></p>
<p><img src="/images/RL/pg/ppo_2.png" width="600"></p>
<h2 id="adaptive-kl-penalty-coefficient">Adaptive KL Penalty Coefficient</h2>
<p>Another approach, which can be used as an alternative to the clipped surrogate objective, or in additional to it is to use a penalty on KL divergence <span class="math inline">\(d_{targ}\)</span> each policy update. In practice, KL performs worse than the clipped surrogate objective.</p>
<p>In the simplest instantiation of this algorithm, the following steps are used in each policy update:</p>
<ul>
<li><p>Using several epochs of mini-batch SGD, optimizing the KL-penalized objective:</p>
<p><span class="math display">\[L^{KLPEN} (\theta) = \hat{E}_t [\frac{\pi_\theta (a_t | s_t)}{\pi_{\theta_{old}} (a_t | s_t)} \hat{A}_t - \beta_t D_{KL} (\pi_{\theta_{old}} (\cdot | s) || \pi_{\theta} (\cdot | s))]\]</span></p></li>
<li><p>Compute and update <span class="math inline">\(\theta_{t+1}\)</span>:</p>
<p><span class="math display">\[d = \hat{E}_t [\beta_t D_{KL} (\pi_{\theta_{old}} (\cdot | s) || \pi_{\theta} (\cdot | s))]\]</span></p>
<ul>
<li>If <span class="math inline">\(d &lt; d_{targ} \;/\; 1.5, \quad \beta_{t + 1} \leftarrow \beta_{t} \;/\; 2\)</span></li>
<li>If <span class="math inline">\(d &gt; d_{targ} * 1.5, \quad \beta_{t + 1} \leftarrow \beta_{t} * 2\)</span></li>
</ul></li>
</ul>
<p><span class="math inline">\(\beta_{t + 1}\)</span> is used in the next policy update. The algorithm is not very sensitive to the choice of <span class="math inline">\(2\)</span> and <span class="math inline">\(1.5\)</span> above. The initial value of <span class="math inline">\(\beta\)</span> is another hyperparameter but is not important in practice.</p>
<h2 id="algorithm">Algorithm</h2>
<p>The advantage function can be estimated using a separate value function <span class="math inline">\(V(x)\)</span>, or a shared parameter value and policy network can be used. If the parameters are shared between policy network and value network, we need to modify the objective by adding the value loss negative value function loss <span class="math inline">\(- L^{VF} (\theta)\)</span> and maybe an entropy term to promote exploration:</p>
<p><span class="math display">\[L^{CLIP + VF + S} (\theta) = \hat{E} [L_t^{CLIP} (\theta) - c_1 L_t^{VF} (\theta) + c_2 S[\pi_{\theta}] (s_t)]\]</span> </br></p>
<p>Where, <span class="math inline">\(c_1, c_2\)</span> are two coefficients, <span class="math inline">\(S[\pi_{\theta}] (s_t)\)</span> is the entropy bonus on <span class="math inline">\(s_t\)</span> and <span class="math inline">\(L_t^{VF} = \|V_{\theta} - V_t^{targ}\|^2\)</span> is the square loss.</p>
<p>One style of advantage estimate is n-step TD estimate:</p>
<p><span class="math display">\[\hat{A}_t = r_t + \gamma r_{t+1} + .... + \gamma^{T-t+1} r_{T-1} + \gamma^{T-t} V(s_T) - V(s_t)\]</span></p>
<p>Where <span class="math inline">\(t\)</span> specifies the time index in <span class="math inline">\([0, T]\)</span>, within a given length-<span class="math inline">\(T\)</span> trajectory segment. Using this idea, we can use a truncated version of generalized advantage estimation:</p>
<p><span class="math display">\[\hat{A}_t = \delta_t + \gamma \lambda \delta_{t+1} + .... + \lambda \gamma^{T-t+1}\delta_{T-1}\]</span></p>
<p><span class="math display">\[\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)\]</span> </br></p>
<p><img src="/images/RL/pg/ppo_3.png" width="600"> </br></p>
<p>A PPO algorithm that uses fixed-length trajectory segments is shown above. Each iteration, each <span class="math inline">\(N\)</span> parallel actors collect <span class="math inline">\(T\)</span> timesteps of data. Then we construct the surrogate loss on these <span class="math inline">\(NT\)</span> timesteps of data and optimize it with mini-batch SGD for <span class="math inline">\(K\)</span> epochs.</p>
<h2 id="implementation">Implementation</h2>
<p>One implementation from parl</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#   Copyright (c) 2021 PaddlePaddle Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> parl</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.optimizer <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle.distribution <span class="keyword">import</span> Normal</span><br><span class="line"></span><br><span class="line">__all__ = [<span class="string">&#x27;PPO&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PPO</span>(<span class="params">parl.Algorithm</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="function"><span class="params">                 model,</span></span></span><br><span class="line"><span class="function"><span class="params">                 clip_param,</span></span></span><br><span class="line"><span class="function"><span class="params">                 value_loss_coef,</span></span></span><br><span class="line"><span class="function"><span class="params">                 entropy_coef,</span></span></span><br><span class="line"><span class="function"><span class="params">                 initial_lr,</span></span></span><br><span class="line"><span class="function"><span class="params">                 eps=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 max_grad_norm=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 use_clipped_value_loss=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; PPO algorithm</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model (parl.Model): model that contains both value network and policy network</span></span><br><span class="line"><span class="string">            clip_param (float): the clipping strength for value loss clipping</span></span><br><span class="line"><span class="string">            value_loss_coef (float): the coefficient for value loss (c_1)</span></span><br><span class="line"><span class="string">            entropy_coef (float): the coefficient for entropy (c_2)</span></span><br><span class="line"><span class="string">            initial_lr (float): initial learning rate.</span></span><br><span class="line"><span class="string">            eps (None or float): epsilon for Adam optimizer</span></span><br><span class="line"><span class="string">            max_grad_norm (float): threshold for grad norm clipping</span></span><br><span class="line"><span class="string">            use_clipped_value_loss (bool): whether use value loss clipping</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(model)</span><br><span class="line">        self.clip_param = clip_param</span><br><span class="line"></span><br><span class="line">        self.value_loss_coef = value_loss_coef</span><br><span class="line">        self.entropy_coef = entropy_coef</span><br><span class="line">        self.use_clipped_value_loss = use_clipped_value_loss</span><br><span class="line">        clip = nn.ClipGradByNorm(max_grad_norm)</span><br><span class="line"></span><br><span class="line">        self.optimizer = optim.Adam(parameters=model.parameters(),</span><br><span class="line">                                    learning_rate=initial_lr,</span><br><span class="line">                                    epsilon=eps,</span><br><span class="line">                                    grad_clip=clip)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">learn</span>(<span class="params">self, obs_batch, actions_batch, value_preds_batch, return_batch,</span></span></span><br><span class="line"><span class="function"><span class="params">              old_action_log_probs_batch, adv_targ</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; update the value network and policy network parameters.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        values = self.model.value(obs_batch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># log std so the std is always positive after e^&#123;log_std&#125;</span></span><br><span class="line">        mean, log_std = self.model.policy(obs_batch)</span><br><span class="line">        dist = Normal(mean, log_std.exp())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Continuous actions are usually considered to be independent,</span></span><br><span class="line">        <span class="comment"># so we can sum components of the ``log_prob`` or the entropy.</span></span><br><span class="line">        action_log_probs = dist.log_prob(actions_batch).<span class="built_in">sum</span>(axis=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        dist_entropy = dist.entropy().<span class="built_in">sum</span>(axis=-<span class="number">1</span>).mean()</span><br><span class="line"></span><br><span class="line">        ratio = paddle.exp(action_log_probs - old_action_log_probs_batch)</span><br><span class="line">        surr1 = ratio * adv_targ</span><br><span class="line">        surr2 = paddle.clip(ratio, <span class="number">1.0</span> - self.clip_param, <span class="number">1.0</span> + self.clip_param) * adv_targ</span><br><span class="line">        action_loss = -paddle.minimum(surr1, surr2).mean()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate value loss using semi gradient TD</span></span><br><span class="line">        <span class="keyword">if</span> self.use_clipped_value_loss:</span><br><span class="line">            value_pred_clipped = value_preds_batch + \</span><br><span class="line">                (values - value_preds_batch).clip(-self.clip_param, self.clip_param)</span><br><span class="line">            value_losses = (values - return_batch).<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line">            value_losses_clipped = (value_pred_clipped - return_batch).<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line">            value_loss = <span class="number">0.5</span> * paddle.maximum(value_losses, value_losses_clipped).mean()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            value_loss = <span class="number">0.5</span> * (return_batch - values).<span class="built_in">pow</span>(<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line">        (value_loss * self.value_loss_coef + action_loss - dist_entropy * self.entropy_coef).backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        self.optimizer.clear_grad()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> value_loss.numpy(), action_loss.numpy(), dist_entropy.numpy()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Sample action from parameterized policy</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        value = self.model.value(obs)</span><br><span class="line">        mean, log_std = self.model.policy(obs)</span><br><span class="line">        dist = Normal(mean, log_std.exp())</span><br><span class="line">        action = dist.sample([<span class="number">1</span>])</span><br><span class="line">        action_log_probs = dist.log_prob(action).<span class="built_in">sum</span>(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> value, action, action_log_probs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Predict action from parameterized policy, action with maximum probability is selected as greedy action</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        mean, _ = self.model.policy(obs)</span><br><span class="line">        <span class="keyword">return</span> mean</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">value</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Predict value from parameterized value function</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.model.value(obs)</span><br></pre></td></tr></table></figure>
<h2 id="reference">Reference</h2>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Policy Search</tag>
      </tags>
  </entry>
  <entry>
    <title>Welcome</title>
    <url>/2030/05/30/aa_welcome/</url>
    <content><![CDATA[<h1 id="welcome">Welcome</h1>
<p><img src="../about/mingren.gif"/></p>
<p><strong>Welcome to my website, hope you enjoy it, most of the notes are listed below</strong>:</p>
<p><br></p>
<p><strong>Some backgrounds</strong>:</p>
<ol type="1">
<li><a href="/2021/05/11/probability/" title="Probability (1)">Probability (1)</a></li>
<li><a href="/2021/05/11/probability-2/" title="Probability (2)">Probability (2)</a></li>
<li><a href="/2021/07/15/probability-3/" title="Probability (3)">Probability (3)</a></li>
<li><a href="/2022/03/10/rigorous-probability-1/" title="Advanced Probability (1)">Advanced Probability (1)</a></li>
<li><a href="/2022/05/02/rigorous-probability-2/" title="Advanced Probability (2)">Advanced Probability (2)</a></li>
<li><a href="/2021/05/14/calculus/" title="Calculus (1)">Calculus (1)</a></li>
<li><a href="/2021/07/06/cal-2/" title="Calculus (2)">Calculus (2)</a></li>
<li><a href="/2021/07/18/cnn/" title="Backpropagation in CNN">Backpropagation in CNN</a></li>
<li><a href="/2021/08/02/rnn/" title="RNN">RNN</a></li>
<li><a href="/2021/12/25/real-analysis-1/" title="Real Analysis (1)">Real Analysis (1)</a></li>
<li><a href="/2022/01/01/real-analysis-2/" title="Real Analysis (2)">Real Analysis (2)</a></li>
<li><a href="/2022/01/01/real-analysis-3/" title="Real Analysis (3)">Real Analysis (3)</a></li>
<li><a href="/2022/01/06/real-analysis-4/" title="Real Analysis (4)">Real Analysis (4)</a></li>
<li><a href="/2022/02/13/mira/" title="Measure Integral and Real Analysis (1)">Measure Integral and Real Analysis (1)</a></li>
<li><a href="/2022/02/27/mira-2/" title="Measure Integral and Real Analysis (2)">Measure Integral and Real Analysis (2)</a></li>
<li><a href="/2022/03/14/mira-3/" title="Measure Integral and Real Analysis (3)">Measure Integral and Real Analysis (3)</a></li>
<li><a href="/2022/03/30/mira-4/" title="Measure Integral and Real Analysis (4)">Measure Integral and Real Analysis (4)</a></li>
<li><a href="/2021/11/15/time-series-1/" title="Time Series (1)">Time Series (1)</a></li>
<li><a href="/2021/11/19/time-series-2/" title="Time Series (2)">Time Series (2)</a></li>
<li><a href="/2022/05/28/time-series-3/" title="Time Series (3)">Time Series (3)</a></li>
<li><a href="/2022/01/06/linear-algebra/" title="Linear Algebra (1)">Linear Algebra (1)</a></li>
<li><a href="/2022/01/09/linear-algebra-2/" title="Linear Algebra (2)">Linear Algebra (2)</a></li>
<li><a href="/2022/01/19/linear-algebra-3/" title="Linear Algebra (3)">Linear Algebra (3)</a></li>
<li><a href="/2022/01/25/linear-algebra-4/" title="Linear Algebra (4)">Linear Algebra (4)</a></li>
<li><a href="/2022/02/04/linear-algebra-5/" title="Linear Algebra (5)">Linear Algebra (5)</a></li>
</ol>
<p><strong>Some RL backgrounds</strong>:</p>
<ol type="1">
<li><a href="/2021/05/03/MDP/" title="MDP">MDP</a></li>
<li><a href="/2021/05/03/bellman-equations/" title="Bellman Equations">Bellman Equations</a></li>
<li><a href="/2021/05/03/bellman-optimality-equations/" title="Bellman Optimality Equations">Bellman Optimality Equations</a></li>
<li><a href="/2021/05/03/dp/" title="Dynamic Programming">Dynamic Programming</a></li>
<li><a href="/2021/05/03/value-iteration/" title="Value Iteration">Value Iteration</a></li>
<li><a href="/2021/05/03/policy-iteration/" title="Policy Iteration">Policy Iteration</a></li>
<li><a href="/2021/05/07/value-function-learning/" title="Learning From Stream of Data">Learning From Stream of Data</a></li>
<li><a href="/2021/05/15/mc/" title="Monte Carlo Methods">Monte Carlo Methods</a></li>
<li><a href="/2021/05/15/td/" title="Temporal Difference Learning">Temporal Difference Learning</a></li>
<li><a href="/2021/05/16/sarsa/" title="SARSA">SARSA</a></li>
<li><a href="/2021/05/16/q-learning/" title="Q Learning">Q Learning</a></li>
<li><a href="/2021/06/12/vfa-1/" title="Value Function Approximation (1)">Value Function Approximation (1)</a></li>
<li><a href="/2021/07/13/vfa-2/" title="Value Function Approximation (2)">Value Function Approximation (2)</a></li>
<li><a href="/2021/05/23/policy-gradient/" title="Policy Gradient (1)">Policy Gradient (1)</a></li>
<li><a href="/2021/05/30/policy-gradient-2/" title="Policy Gradient (2)">Policy Gradient (2)</a></li>
<li><a href="/2021/06/05/policy-gradient-3/" title="Policy Gradient (3)">Policy Gradient (3)</a></li>
<li><a href="/2021/05/30/average-reward-setting/" title="Average Reward Setting (Under Construction)">Average Reward Setting (Under Construction)</a></li>
<li><a href="/2021/06/28/semi-mdp/" title="Semi MDP (Under Construction)">Semi MDP (Under Construction)</a></li>
</ol>
<p><strong>Some interesting RL algorithms</strong>:</p>
<ol type="1">
<li><a href="/2021/05/06/DPG/" title="DPG">DPG</a></li>
<li><a href="/2021/06/09/DDPG/" title="DDPG">DDPG</a></li>
<li><a href="/2021/05/07/DDQN/" title="DDQN">DDQN</a></li>
<li><a href="/2021/06/23/td3/" title="TD3">TD3</a></li>
<li><a href="/2021/05/13/Dueling/" title="Dueling DQN">Dueling DQN</a></li>
<li><a href="/2021/06/11/TRPO/" title="TRPO">TRPO</a></li>
<li><a href="/2021/06/11/PPO/" title="PPO">PPO</a></li>
<li><a href="/2021/05/20/prior-exp-replay/" title="Prioritized Experience Replay">Prioritized Experience Replay</a></li>
<li><a href="/2021/06/25/instrinsic-motivation/" title="Intrinsic Motivation">Intrinsic Motivation</a></li>
<li><a href="/2021/06/25/go-explore/" title="Go Explore">Go Explore</a></li>
<li><a href="/2021/06/03/natural-actor-critic/" title="Natural Actor Critic (Under Construction)">Natural Actor Critic (Under Construction)</a></li>
<li><a href="/2021/06/03/off-policy-actor-critic/" title="Off Policy Actor Critic (Under Construction)">Off Policy Actor Critic (Under Construction)</a></li>
<li><a href="/2021/07/22/sac/" title="SAC (Under Construction)">SAC (Under Construction)</a></li>
</ol>
<p><strong>Some Deep Learning algorithms and models</strong>:</p>
<ol type="1">
<li><a href="/2021/05/25/drop-out/" title="Dropout">Dropout</a></li>
<li><a href="/2021/05/26/batch-norm/" title="Batch Normalization">Batch Normalization</a></li>
<li><a href="/2021/06/02/layer-norm/" title="Layer Normalization">Layer Normalization</a></li>
<li><a href="/2021/07/05/xavier/" title="Xavier Initialization">Xavier Initialization</a></li>
<li><a href="/2021/06/23/kaiming-init/" title="Kaiming Initialization">Kaiming Initialization</a></li>
<li><a href="/2021/07/05/LReLU/" title="LReLU">LReLU</a></li>
<li><a href="/2021/06/22/alex-net/" title="Alex Net">Alex Net</a></li>
<li><a href="/2021/06/25/overfeat/" title="Overfeat (Under Construction)">Overfeat (Under Construction)</a></li>
<li><a href="/2021/06/24/VGG/" title="VGG (Under Construction)">VGG (Under Construction)</a></li>
<li><a href="/2021/07/29/momentum/" title="Momentum">Momentum</a></li>
<li><a href="/2021/07/29/adaptive-lr/" title="Basic Adaptive LR Methods">Basic Adaptive LR Methods</a></li>
<li><a href="/2021/07/29/adam/" title="Adam">Adam</a></li>
<li><a href="/2021/08/06/attention/" title="Attention">Attention</a></li>
<li><a href="/2021/12/25/tcn/" title="TCN">TCN</a></li>
<li><a href="/2021/12/25/transformer/" title="Transformer">Transformer</a></li>
</ol>
<p><strong>Some old school ML algorithms</strong>:</p>
<ol type="1">
<li><a href="/2021/07/19/pca/" title="PCA">PCA</a></li>
<li><a href="/2021/07/19/logistic-regression/" title="Logistic Regression">Logistic Regression</a></li>
<li><a href="/2021/07/19/naive-bayes/" title="Naive Bayes">Naive Bayes</a></li>
<li><a href="/2021/07/19/decision-trees/" title="Decision Trees">Decision Trees</a></li>
<li><a href="/2021/07/19/random-forests/" title="Random Forest (Under Construction)">Random Forest (Under Construction)</a></li>
<li><a href="/2021/07/19/adaboost/" title="AdaBoost">AdaBoost</a></li>
<li><a href="/2021/07/19/gbdt/" title="GBDT">GBDT</a></li>
<li><a href="/2021/07/19/k-means/" title="K-means">K-means</a></li>
<li><a href="/2021/07/19/knn/" title="KNN (Under Construction)">KNN (Under Construction)</a></li>
<li><a href="/2021/07/19/svm/" title="SVM (Under Construction)">SVM (Under Construction)</a></li>
<li><a href="/2021/07/21/em/" title="EM Algorithm">EM Algorithm</a></li>
<li><a href="/2021/08/09/roc/" title="ROC">ROC</a></li>
<li><a href="/2021/09/06/lgb/" title="LGBM">LGBM</a></li>
<li><a href="/2021/09/09/graphical-models/" title="Graphical Models (Under Construction)">Graphical Models (Under Construction)</a></li>
<li><a href="/2021/09/16/hmm/" title="Sequential Data Modeling (Under Construction)">Sequential Data Modeling (Under Construction)</a></li>
</ol>
<p><strong>Some CS</strong>:</p>
<ol type="1">
<li><a href="/2021/05/18/leet-code-1/" title="LeetCode (1)">LeetCode (1)</a></li>
<li><a href="/2021/06/05/leet-code-2/" title="LeetCode (2)">LeetCode (2)</a></li>
<li><a href="/2021/06/16/leet-code-3/" title="LeetCode (3)">LeetCode (3)</a></li>
<li><a href="/2021/07/13/leet-code-4/" title="LeetCode (4)">LeetCode (4)</a></li>
<li><a href="/2021/07/19/heaps/" title="Heaps">Heaps</a></li>
<li><a href="/2021/06/06/sort/" title="Sorts">Sorts</a></li>
<li><a href="/2021/06/14/tree/" title="Trees">Trees</a></li>
</ol>
<p><br></p>
]]></content>
  </entry>
  <entry>
    <title>actor_critic</title>
    <url>/2021/06/14/actor-critic/</url>
    <content><![CDATA[<h1 id="actor-critic-algorithms">Actor-Critic Algorithms</h1>
<p><a href="https://papers.nips.cc/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf">Original Paper</a></p>
]]></content>
  </entry>
  <entry>
    <title>VGG (Under Construction)</title>
    <url>/2021/06/24/VGG/</url>
    <content><![CDATA[<h1 id="very-deep-convolutional-networks-for-large-scale-image-recognition">Very Deep Convolutional Networks For Large-Scale Image Recognition</h1>
<h2 id="generic-architecture">Generic Architecture</h2>
<ol type="1">
<li>Inputs are <span class="math inline">\(224 \times 224\)</span> RGB images with zero mean for each pixel.</li>
<li>The convolutional layers have small filter sizes (<span class="math inline">\(3 \times 3\)</span>), one architecture with <span class="math inline">\(1 \times 1\)</span> filters (Network C).</li>
<li>Padding 1 and stride 1 to maintain the original image size.</li>
<li>5 max pooling layers with <span class="math inline">\(2 \times 2\)</span> window and stride 2.</li>
<li>2 fully connected layers each with 4096 units, and the final fc output layer with 1000 units.</li>
<li>ReLU activation function.</li>
</ol>
<h2 id="configurations">Configurations</h2>
<ol type="1">
<li><p>the shallowest network has 11 weight layers (8 conv layers and 3 FC layers), the deepest network has 19 weight layers (16 conv layers and 3 FC layers)</p></li>
<li><p>The width of conv layers are relative small, starting from 64 in the first layer and then increasing by a factor of 2 each max-pooling layer, until it reaches 512.</p></li>
</ol>
<p><img src="/images/ML/vgg_1.png" width="600"></p>
<span id="more"></span>
<h2 id="discussion">Discussion</h2>
<p>Instead of large filter size, we use small <span class="math inline">\(3 \times 3\)</span> filters. We can see that after 2 consecutive layers, the effective receptive field is <span class="math inline">\(5 \times 5\)</span>, after three consective layers, the effective receptive field is <span class="math inline">\(7 \times 7\)</span>. Comparing to a conv layer with <span class="math inline">\(7 \times 7\)</span> filter, 3 consecutive <span class="math inline">\(3 \times 3\)</span> filter conv layers have less parameters. To see this, assume each layer has input C channel and output C channel, then total parameters:</p>
<ol type="1">
<li>Single conv layer with <span class="math inline">\(7 \times 7\)</span> filter: <span class="math inline">\(7 * 7 * C * C = 49 C^2\)</span></li>
<li>Three conv layer each with <span class="math inline">\(3 \times 3\)</span> filter: <span class="math inline">\(3 (3 * 3 * C * C) = 27 C^2\)</span></li>
</ol>
<p>This can be seen as imposing a regularisation on the <span class="math inline">\(7 \times 7\)</span> conv filters forcing them to have a decomposition through the <span class="math inline">\(3 \times 3\)</span> filters. This structure also have more discriminative power (3 non-linear functions compare to one).</p>
<p>The <span class="math inline">\(1 \times 1\)</span> is one way to increase the non-linearity of the decision function without affecting the receptive fields of the conv layers.</p>
<h2 id="classification-framework">Classification Framework</h2>
<h3 id="training">Training</h3>
<ol type="1">
<li>Batch size 256, momentum 0.9, weight decay 0.0005</li>
<li>Dropout is applied to the first two fully connected layers with rate of 0.5</li>
</ol>
<h4 id="initialization">Initialization</h4>
<ol type="1">
<li>Net <span class="math inline">\(A\)</span> is first trained with random initialization</li>
<li>When training deeper architectures, we initialize the first four conv layers and last three fully connected layers with the layer of <span class="math inline">\(A\)</span></li>
<li>The conv layers in the middle are initialized randomly with normal(0, 0.01)</li>
</ol>
<p>In spite of the larger number of parameters and the greater depth of our nets compare to AlexNet, the nets required less epochs to converge due to</p>
<ol type="1">
<li>implicit regularization imposed by greater depth and smaller filter size</li>
<li>pre-initialization of certain layers</li>
</ol>
<h4 id="training-image-size-rescale">Training Image Size Rescale</h4>
<p>Let <span class="math inline">\(S\)</span> (training scale) be the smallest side of an isotropically-rescaled training image from which the input image is cropped (The training input is first rescaled to smallest side = <span class="math inline">\(S\)</span> before cropping). For a fixed crop size <span class="math inline">\(224 \times 224\)</span>, if <span class="math inline">\(S=224\)</span>, the cropped image will span the smallest side of the training image. If <span class="math inline">\(S &gt;&gt; 224\)</span>, the crop will correspond to a small part of the image. There are two approaches setting up <span class="math inline">\(S\)</span></p>
<ol type="1">
<li>Single scale training: fix <span class="math inline">\(S=256, 384\)</span></li>
<li>Multi-scale training: Each image is individually rescaled by randomly sampling <span class="math inline">\(S\)</span> from a certain range <span class="math inline">\([S_{min}, S_{max}] = [256, 512]\)</span>.</li>
</ol>
<p>Then the rescaled images is:</p>
<ol type="1">
<li>randomly cropped from rescaled training images (one crop per image per SGD iteration)</li>
<li>the crops underwent random horizontal filpping and random RGB colour shift</li>
</ol>
<h3 id="testing">Testing</h3>
<p>During Testing given a trained Conv Net and an input image:</p>
<ol type="1">
<li>It is first isotropically rescaled to a predefined smallest image side <span class="math inline">\(Q\)</span> (test scale, where <span class="math inline">\(S\)</span> is the training scale). <span class="math inline">\(Q\)</span> is not necessarily equal to the training scale <span class="math inline">\(S\)</span></li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>DL</category>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Network Architectures</tag>
      </tags>
  </entry>
  <entry>
    <title>Adaboost</title>
    <url>/2021/07/19/adaboost/</url>
    <content><![CDATA[<h1 id="adaboost-discrete">AdaBoost (Discrete)</h1>
<p>Consider a two-class problem, with the output variable coded as <span class="math inline">\(Y \in \{-1, 1\}\)</span>. Given a vector of input variables <span class="math inline">\(\mathbf{X}\)</span>, a classifier <span class="math inline">\(G(\mathbf{X})\)</span> produces a prediction taking one of the two values <span class="math inline">\(\{-1, 1\}\)</span>.</p>
<p>Suppose we have samples <span class="math inline">\(D = \{(\mathbf{x}_1, y_1), ...., (\mathbf{x}_N, y_N); \; \mathbf{x} \in \mathbb{R}^d\}\)</span>. The error rate (misclassification) on the training sample is defined as:</p>
<p><span class="math display">\[\bar{err} = \frac{1}{N} \sum^{N}_{i=1} I[y_i \neq G(\mathbf{x}_i)]\]</span></p>
<p>The expected error rate is defined as:</p>
<p><span class="math display">\[E_{X, Y} [I[Y \neq G(\mathbf{X})]]\]</span></p>
<p>A weak classifier is one whose error rate is only slightly better than random guessing. The purpose of boosting is to sequentially apply the weak classification algorithm to repeatedly modified versions of the data, thereby producing a sequence of weak classifiers <span class="math inline">\(G_{m} (\mathbf{x}), \; m = 1, ...., M\)</span></p>
<p>The predictions from all of them are then combined through a weighted majority vote to produce the final prediction:</p>
<p><span class="math display">\[G(x) = sign (\sum^{M}_{m=1} \alpha_m G_m (\mathbf{x}))\]</span></p>
<p>Here, <span class="math inline">\(\alpha_1, ...., \alpha_M\)</span> are parameters that weight the contribution of each corresponding classifier <span class="math inline">\(G(\mathbf{x})\)</span> and they are learned by the algorithm. They are here to give higher influence to the more accurate classifiers in the sequence.</p>
<p>The data modifications at each boosting step consist of applying weights <span class="math inline">\(w_1, ...., w_N\)</span> to each of the training observations <span class="math inline">\((\mathbf{x}_i, y_i), \; i=1, ....., N\)</span>:</p>
<ol type="1">
<li>Initially all of the weights are set to <span class="math inline">\(w_i = \frac{1}{N}\)</span>, so the first step simply trains the classifier on the data in usual manner.</li>
<li>For each successive iteration <span class="math inline">\(m = 2, 3, .... , M\)</span>, the observation weights are individually modified:
<ul>
<li>Observations that were misclassified by the classifier <span class="math inline">\(G_{m-1} (\mathbf{x})\)</span> induced at the previous step have their weights increased.</li>
<li>Observations that were classified correctly by the previous classifier have their weights decreased.</li>
</ul></li>
<li>Then the classification algorithm is reapplied to the weighted observations</li>
</ol>
<p>So misclassified samples have their weights increased so that each successive classifier is thereby forced to concentrate on those samples.</p>
<p><img src='/images/ML/adaboost_1.png' width="600"></p>
<p>At each iteration <span class="math inline">\(m\)</span>:</p>
<ol type="1">
<li>A normalized weighted error rate (high penalty for misclassifying high weight samples)<span class="math inline">\(err_m\)</span> is calculated.</li>
<li>The error rate is transformed by <span class="math inline">\(\log (\frac{1 - error_m}{error_m})\)</span>:
<ul>
<li>This function goes to positive infinity as <span class="math inline">\(error_m\)</span> goes to 0</li>
<li>This function goes to negative infinity as <span class="math inline">\(error_m\)</span> goes to 1 (<strong>we should just predict class inversely</strong>)</li>
<li>This function is 0 when error rate is 0.5</li>
</ul></li>
<li>The new weight update:
<ul>
<li>If <strong>correctly classified</strong>, then we simply keep the original weight for the sample (It will be smaller because we are weighting it by sum of error rate in the next classifier).</li>
<li>If <strong>incorrectly classified</strong>:
<ul>
<li>If error rate is small, then <span class="math inline">\(\alpha\)</span> is positively large so each misclassified sample's weight is <strong>increased</strong></li>
<li>If error rate is high, then <span class="math inline">\(\alpha\)</span> goes to negative infinity, so each misclassified sample's weight is <strong>decreased</strong> because this sample is correctly classified inversely so we decrease its weight.</li>
<li>If error rate is 0.5, then <span class="math inline">\(\alpha\)</span> is 0, so each misclassified sample's weight is <strong>maintained</strong></li>
</ul></li>
</ul></li>
</ol>
<p><img src='/images/ML/adaboost_3.png' width="600"></p>
<h2 id="boosting-fits-an-additive-model">Boosting Fits an Additive Model</h2>
<p>Boosting is a way of fitting an additive expansion in a set of elementary basis functions. Here the basis functions are the individual classifiers <span class="math inline">\(G_m(\mathbf{x}) \in \{-1, 1\}\)</span>. More generally, basis function expansions take the form:</p>
<p><span class="math display">\[f(\mathbf{x}) = \sum^{M}_{m=1} \beta_m b(\mathbf{x}; \boldsymbol{\gamma}_m)\]</span></p>
<p>Where <span class="math inline">\(\beta_m, \; m=1, 2, ...., M\)</span> are the expansion coefficients, and <span class="math inline">\(b(\mathbf{x}; \gamma) \in \mathbb{R}\)</span> are usually simple functions of multivariate argument <span class="math inline">\(\mathbf{x}\)</span> characterized by a set of parameters <span class="math inline">\(\{\boldsymbol{\gamma}_1, ...., \boldsymbol{\gamma}_M\}\)</span>.</p>
<p>Typically these models are fit and the parameters are found by minimizing a loss function averaged over the training data:</p>
<p><span class="math display">\[\min_{ \{\beta_m, \boldsymbol{\gamma}_m\}^{M}_1 }\sum^{N}_{i=1} L(y_i, \sum^{M}_{m=1} \beta_m b(\mathbf{x}_i; \boldsymbol{\gamma}_m))\]</span></p>
<h2 id="forward-stagewise-additive-modeling">Forward Stagewise Additive Modeling</h2>
<p>How to solve the above optimization problem? We can use forward stagewise modeling (greedy) to approximate the solution to above equation by sequentially adding new basis functions to the expansion without adjusting the parameters and coefficients of those that have already been added.</p>
<p><img src='/images/ML/adaboost_2.png' width="600"></p>
<p>The loss function of optimization problem at each step <span class="math inline">\(m\)</span> can be rewritten as:</p>
<p><span class="math display">\[L(y_i, f_m(\mathbf{x}_i)) = L(y_i, f_{m-1} (\mathbf{x}_i) + \beta b(\mathbf{x}_i; \boldsymbol{\gamma}))\]</span></p>
<p>Using the square loss, we have:</p>
<p><span class="math display">\[L(y_i, f_m(\mathbf{x}_i)) = (y_i - f_{m-1} (\mathbf{x}_i) - \beta b(\mathbf{x}_i; \boldsymbol{\gamma}))^2\]</span></p>
<p><span class="math display">\[\implies L(y_i, f_m(\mathbf{x}_i)) = (\epsilon_{im-1} -  \beta b(\mathbf{x}_i; \boldsymbol{\gamma}))^2\]</span></p>
<p>This implies that we are fitting a basis function at each step to minimizing the residual from the current model <span class="math inline">\(f_{m-1} (\mathbf{x})\)</span>.</p>
<h2 id="adaboost-as-forward-stagewise-additive-modeling">AdaBoost as Forward Stagewise Additive Modeling</h2>
<p>Let the loss function be the exponential function:</p>
<p><span class="math display">\[L(y_i, f(\mathbf{x}_i)) = e^{-y_i f(\mathbf{x}_i)}\]</span></p>
<p>For adaboost, the basis functions are individual weak classifier <span class="math inline">\(G_m(x) \in \{-1, 1\}\)</span>. Using the exponential loss for additive stagewise modeling, we must minimize the objective:</p>
<p><span class="math display">\[(\beta_m, G_m) = \underset{\beta, G}{\arg\min} \sum^{N}_{i=1} e^{-y_i(f_{m-1} (\mathbf{x}_i) + \beta G(\mathbf{x}_i))}\]</span></p>
<p>Let <span class="math inline">\(w^{(m)}_i = e^{-y_i \mathbf{x}_i}\)</span>, then the above optimization can be expressed as:</p>
<p><span class="math display">\[(\beta_m, G_m) = \underset{\beta, G}{\arg\min} \sum^{N}_{i=1} w^{(m)}_i e^{-y_i\beta G(\mathbf{x}_i)}\]</span></p>
<p>Since, <span class="math inline">\(w^{(m)}_i\)</span> does not depend on <span class="math inline">\(\beta, G(\mathbf{x})\)</span>, so it is just some constant and can be regard it as weight. Since this weight depends on previous prediction and current label, it is changing at each iteration <span class="math inline">\(m\)</span>.</p>
<h3 id="solve-for-beta">Solve for <span class="math inline">\(\beta\)</span></h3>
<p>In order to solve for <span class="math inline">\(\beta\)</span>, we can rewrite the objective as:</p>
<span class="math display">\[\begin{aligned}
\sum^{N}_{i=1} w^{(m)}_i e^{-y_i\beta G(\mathbf{x}_i)} &amp;= \sum^{N}_{i=1} w^{(m)}_i e^{-\beta} I[y_i = G(\mathbf{x}_i)] + w^{(m)}_i e^{\beta} I[y_i \neq G(\mathbf{x}_i)] \\
&amp;= \sum^{N}_{i=1} w^{(m)}_i e^{-\beta} (1 - I[y_i \neq G(\mathbf{x}_i)]) + w^{(m)}_i e^{\beta} I[y_i \neq G(\mathbf{x}_i)]\\
&amp;= (e^{\beta} - e^{-\beta})\sum^{N}_{i=1} w^{m}_i I[y_i \neq G(\mathbf{x}_i)] + e^{-\beta} \sum^{N}_{i=1} w^{(m)}_i
\end{aligned}\]</span>
<p>by taking the partial derivative w.r.t <span class="math inline">\(\beta\)</span> and set it to 0:</p>
<p><span class="math display">\[\implies(e^\beta + e^{-\beta}) \sum_{i=1}^{N} w_i^{(m)}I(y_i \neq G(\mathbf{x}_i)) - e^{-\beta} \sum_{i=1}^{N} w_i^{(m)} = 0\]</span></p>
<p><span class="math display">\[\implies \frac{e^\beta + e^{-\beta}}{e^{-\beta}} = \frac{\sum_{i=1}^{N} w_i^{(m)}}{\sum_{i=1}^{N} w_i^{(m)}I(y_i \neq G(\mathbf{x}_i))}\]</span></p>
<p><span class="math display">\[\implies \frac{e^\beta}{e^{-\beta}} = \frac{\sum_{i=1}^{N} w_i^{(m)}}{\sum_{i=1}^{N} w_i^{(m)}I(y_i \neq G(\mathbf{x}_i))} - 1\]</span></p>
<p><span class="math display">\[\implies 2\beta = \log(\frac{1}{error_m} - 1)\]</span></p>
<p><span class="math display">\[\implies \beta_m = \frac{1}{2} \log (\frac{1 - error_m}{error_m})\]</span></p>
<p>Where <span class="math inline">\(error_m = \frac{\sum_{i=1}^{N} w_i^{(m)}I(y_i \neq G(\mathbf{x}_i))}{\sum_{i=1}^{N} w_i^{(m)}}\)</span></p>
<p>That is, for any classifier <span class="math inline">\(G\)</span>:</p>
<ul>
<li><span class="math inline">\(\beta_m &gt; 0\)</span>, if <span class="math inline">\(error_m &lt; 0.5\)</span></li>
<li><span class="math inline">\(\beta_m &lt; 0\)</span>, if <span class="math inline">\(error_m &gt; 0.5\)</span></li>
</ul>
<h3 id="solve-for-g">Solve for <span class="math inline">\(G\)</span></h3>
<p>We want our basis function (weak classifier) to have better misclassification rate than random classifier, so we want <span class="math inline">\(error_m &lt; 0.5\)</span> which implies that we want <span class="math inline">\(\beta &gt; 0\)</span>. Thus, for any value <span class="math inline">\(\beta &gt; 0\)</span>, we can see that if we let <span class="math inline">\(G(\mathbf{x}_i) = y_i\)</span> for all samples, we have minimum objective. Thus, we can transform the minimization problem to minimize the error rate:</p>
<span class="math display">\[\begin{aligned}
G_m = \underset{G}{\arg\min} \sum^{N}_{i=1} w^{(m)}_i I[y_i \neq G(\mathbf{x}_i)]
\end{aligned}\]</span>
<p><br></p>
<p>By substitute <span class="math inline">\(G_m\)</span> back to the solution of <span class="math inline">\(\beta\)</span>, we have:</p>
<p><span class="math display">\[\beta_m = \frac{1}{2} \log (\frac{1 - error_m}{error_m})\]</span></p>
<p>Where <span class="math inline">\(error_m = \frac{\sum_{i=1}^{N} w_i^{(m)}I(y_i \neq G_m(\mathbf{x}_i))}{\sum_{i=1}^{N} w_i^{(m)}}\)</span></p>
<p>The approximation is then updated:</p>
<p><span class="math display">\[f_m (\mathbf{x}_i) = f_{m-1} (\mathbf{x}_i) + \beta_m G_m (\mathbf{x}_i)\]</span></p>
<p>Which causes the weights for the next iteration to be:</p>
<span class="math display">\[\begin{aligned}
w^{(m + 1)}_i &amp;= e^{-y_i f_{m} (\mathbf{x}_i)}\\
&amp;= e^{-y_i (f_{m - 1} (\mathbf{x}_i) + \beta_m G_m (\mathbf{x}_i))}\\
&amp;= e^{-y_i f_{m-1}(\mathbf{x}_i)} e^{-y_i \beta_m G_m (\mathbf{x}_i)}\\
&amp;= w^{(m)}_{i} e^{-y_i \beta_m G_m (\mathbf{x}_i)}
\end{aligned}\]</span>
<p>Notice here, <span class="math inline">\(-y_i G_m (x_i) = 2 I[y_i \neq G_m (\mathbf{x}_i)] - 1\)</span>:</p>
<p><span class="math display">\[\implies w^{(m + 1)}_i = w^{(m)}_{i} e^{\alpha_m I[y_i \neq G_m(\mathbf{x}_i)]} e^{-\beta_m }\]</span></p>
<p>Where, <span class="math inline">\(\alpha_m = 2 \beta_m\)</span> is the <span class="math inline">\(\alpha_m\)</span> in Adaboost algorithm, and <span class="math inline">\(e^{-\beta_m}\)</span> has no effect on weights because it is just a constant multiplying every sample.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Thus, we can think of Adaboost algorithm as stagewise additive modeling with basis function as a weak classifier (Minimizing the misclassification rate to have slightly better misclassification rate than random classifier) and exponential loss function.</p>
<h1 id="ref">Ref</h1>
<p>ESLII Chapter 10</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Adam</title>
    <url>/2021/07/29/adam/</url>
    <content><![CDATA[<h1 id="adam-a-method-for-stochastic-optimization">ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION</h1>
<p><img src='/images/ML/adam_1.png' width="600"></p>
<p>Let <span class="math inline">\(F\)</span> be a noisy objective function (stochastic function) defined as <span class="math inline">\(F(\boldsymbol{\theta})\)</span> that is differentiable w.r.t <span class="math inline">\(\boldsymbol{\theta}\)</span>, we are interested in minimizing the expected value of this random function:</p>
<p><span class="math display">\[\min_{\boldsymbol{\theta}} E_{F}[F(\boldsymbol{\theta})]\]</span></p>
<p>Let <span class="math inline">\(F_1(\boldsymbol{\theta}), ...., F_{T} (\boldsymbol{\theta})\)</span> be a random sample of <span class="math inline">\(F(\boldsymbol{\theta})\)</span> and let <span class="math inline">\(f_1 (\boldsymbol{\theta}), ..., f_T(\boldsymbol{\theta})\)</span> be the realization of random sample. <strong>This random sample can be forms of mini-batches of data which the distribution does not depend on the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>.</strong></p>
<p>Then:</p>
<p><span class="math display">\[\nabla_{\boldsymbol{\theta}} E_F[F (\boldsymbol{\theta})] = E_F[\nabla_{\boldsymbol{\theta}} F (\boldsymbol{\theta})]\]</span></p>
<p><br></p>
<p>Given the individual sample gradient <span class="math inline">\(\nabla_{\boldsymbol{\theta}} f_1 (\boldsymbol{\theta}), ...., \nabla_{\boldsymbol{\theta}} f_T(\boldsymbol{\theta})\)</span>, one way to estimate the expectation of gradient, <span class="math inline">\(E_{F} [\nabla_{\boldsymbol{\theta}} F_t(\boldsymbol{\theta})]\)</span>, is to use stochastic approximation (similar to Momentum):</p>
<p><span class="math display">\[m_t \leftarrow \beta_1 {m}_{t} + (1 - \beta_1) \nabla_{\boldsymbol{\theta}} f_t(\boldsymbol{\theta})\]</span></p>
<p>Where <span class="math inline">\(m_t\)</span> is the average up to sample <span class="math inline">\(t\)</span>, and <span class="math inline">\(\beta_1 \in [0, 1)\)</span> is the decay rates.</p>
<p>At the same time, we can use SA to estimate the second moment of the gradient which is the un-centered variance (This is similar to RMSProp):</p>
<p><span class="math display">\[v_t \leftarrow \beta_2 {v}_{t} + (1 - \beta_2) \nabla_{\boldsymbol{\theta}} f_t(\boldsymbol{\theta})^2\]</span></p>
<p>However, these estimates are biased toward 0 if we initialize them to be 0 especially during initial timesteps and especially when the decay rates are small (<span class="math inline">\(\beta_1, \beta_2\)</span> close to 1). Thus, we need to apply bias correction.</p>
<h2 id="initial-bias-correction">Initial Bias Correction</h2>
<p>Let <span class="math inline">\(\mathbf{G} = \nabla_{\boldsymbol{\theta}} F\)</span> be the gradient of the stochastic objective <span class="math inline">\(F\)</span>, we wish to estimate its second raw moment using SA of the squared gradient with decay rate <span class="math inline">\(\beta_2\)</span>. Let <span class="math inline">\(\mathbf{G}_1, ...., \mathbf{G}_T\)</span> be random sample of <span class="math inline">\(\mathbf{G}\)</span> that draws from the gradient distribution <span class="math inline">\(P(\mathbf{G})\)</span>. Suppose we initialize our SA procedure at <span class="math inline">\({v}_0 = 0\)</span>, then after <span class="math inline">\(t\)</span> steps, we have:</p>
<p><span class="math display">\[v_1 = (1 - \beta_2) \mathbf{G}^2_1\]</span></p>
<p><span class="math display">\[v_2 = \beta_2(1 - \beta_2) \mathbf{G}^2_1 + (1 - \beta_2) \cdot \mathbf{G}^2_2 = \beta_2 (1 - \beta_2) (\mathbf{G}^2_1 + \mathbf{G}^2_2)\]</span></p>
<p><span class="math display">\[\implies {v}_t = (1 - \beta_2) \sum^{t}_{i=1} \beta^{t - i}_2 \mathbf{G}^2_{i}\]</span></p>
<p>Where <span class="math inline">\(\mathbf{G}^2 = \|\mathbf{G}\|^2_2\)</span>. We want the SA estimator to be unbiased estimator of second moment of gradient but we know that there is initialization bias (discrepancy) of SA estimator, we denote this discrepancy <span class="math inline">\(\eta\)</span>. Since additive discrepancy can be keep small by assigning less weight to history, we want two sides to be equal:</p>
<p><span class="math display">\[E_{\mathbf{G}} [\mathbf{G}^2] = E_\mathbf{G}[\mathbf{v}^2_t] + \eta = E_\mathbf{G} [(1 - \beta_2) \sum^{t}_{i=1} \beta_2^{t - i} \mathbf{G}^2_{i}] + \eta\]</span></p>
<p>However, since <span class="math inline">\(t &lt; \infty\)</span>, we have a proportion bias:</p>
<span class="math display">\[\begin{aligned}
E_\mathbf{G}[\mathbf{v}^2_t] + \eta &amp;= E_{\mathbf{G}} [\mathbf{G}^2] (1 - \beta_2)  \sum^{t}_{i=1} \beta_2^{t - i} + \eta\\
&amp;= E_{\mathbf{G}} [\mathbf{G}^2] (1 - \beta_2)  \sum^{t}_{i=1} \beta_2^{t}(\frac{1}{\beta_2})^i + \eta\\
&amp;= E_{\mathbf{G}} [\mathbf{G}^2] (1 - \beta_2)  \frac{1}{\beta_2} \sum^{t}_{i=0}\beta_2^{t}(\frac{1}{\beta_2})^i + \eta\\
&amp;= E_{\mathbf{G}} [\mathbf{G}^2] (1 - \beta_2)  \frac{1}{\beta_2} \beta_2^{t} \frac{\beta^t_2 - 1}{\beta^t_2} \frac{\beta_2}{\beta_2 - 1}+ \eta\\
&amp;= E_{\mathbf{G}} [\mathbf{G}^2] \underbrace{(1 - \beta^t_2)}_{\text{This term we do not want}} + \eta 
\end{aligned}\]</span>
<p>Thus, we can apply a bias correction term on the estimator to correct for this proportion bias <span class="math inline">\(\frac{1}{1 - \beta^t_2}\)</span>.</p>
<p>The same correction <span class="math inline">\(\frac{1}{1 - \beta^t_1}\)</span>is applied on first moment estimator of the gradient.</p>
<h2 id="adamax">AdaMax</h2>
<p>In Adam, the current average gradient estimate <span class="math inline">\(\hat{m}_t\)</span> is scaled inversely to history proportional to the scaled <span class="math inline">\(L^2\)</span> norm of their individual current and past gradients (i.e <span class="math inline">\(\frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon}\)</span>). We can generalize <span class="math inline">\(L^2\)</span> norm to a <span class="math inline">\(L^\infty\)</span> norm based update rule. This leads to a surprisingly simple and stable algorithm:</p>
<p><img src='/images/ML/adam_2.png' width="600"></p>
<p><br></p>
<p>In case of <span class="math inline">\(L^p\)</span> norm, <span class="math inline">\(\mathbf{v}_t\)</span> is defined to be:</p>
<span class="math display">\[\begin{aligned}
{v}_t &amp;\leftarrow \beta^p_2  + {v}_t (1 - \beta^p_2) \|\mathbf{G}_i\|^p_p\\
&amp;\leftarrow (1 - \beta_2^p) \sum^{t}_{i=1} \beta^{p(t - i)}_2 \|\mathbf{G}_i\|^p_p\\
\end{aligned}\]</span>
<p>Note define:</p>
<p><span class="math display">\[u_t = \lim_{p \rightarrow \infty} (v_t)^{\frac{1}{p}}\]</span></p>
<p>Then:</p>
<span class="math display">\[\begin{aligned}
u_t &amp;= \lim_{p \rightarrow \infty} (v_t)^{\frac{1}{p}}\\
&amp;= \lim_{p \rightarrow \infty} ((1 - \beta_2^p) \sum^{t}_{i=1} \beta^{p(t - i)}_2 \|\mathbf{G}_i\|^p_p)^\frac{1}{p}\\
&amp;= \lim_{p \rightarrow \infty} (1 - \beta_2^p)^\frac{1}{p} (\sum^{t}_{i=1} \beta^{p(t - i)}_2 \|\mathbf{G}_i\|^p_p)^\frac{1}{p}\\
&amp;= \lim_{p \rightarrow \infty} (\sum^{t}_{i=1}(\beta^{(t - i)}_2 \|\mathbf{G}_i\|_p)^p)^\frac{1}{p}\\
&amp;= \| \beta^{(t - i)}_2 \|\mathbf{G}_i\|_{\infty}\|_{\infty}\\
&amp;= \max(\beta^{(t - 1)}_2 \|\mathbf{G}_1\|_{\infty}, .... , \|\mathbf{G}_t\|_{\infty}) 
\end{aligned}\]</span>
<p>Which corresponding to:</p>
<p><span class="math display">\[u_t \leftarrow \max(\beta_2 u_{t}, \|\mathbf{G}_t\|_{\infty})\]</span></p>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
  </entry>
  <entry>
    <title>Alex Net</title>
    <url>/2021/06/22/alex-net/</url>
    <content><![CDATA[<h1 id="imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks</h1>
<h2 id="the-dataset-image-preprocessing">The dataset, Image preprocessing</h2>
<p>ImageNet is a dataset of over 15 million labeled high-resolutoin images. It consists of variable-resolution images, while the network requires a constant input dimensionality. Therefore, we down-sampled the images to a fixed resolution of <span class="math inline">\(256 \times 256\)</span>. Given a rectangular image, we first rescaled the image such that the shorter side was of length 256, and then cropped out the central <span class="math inline">\(256 \times 256\)</span> patch from the resulting image. We did not pre-process the images in any other way, except for subtracting the mean activity over the training set for each pixel (normalize each input pixel). So we trained our network on the centered raw RGB values of the pixels.</p>
<span id="more"></span>
<h2 id="the-architecture">The Architecture</h2>
<h3 id="relu-nonlinearity">ReLU Nonlinearity</h3>
<p>tanh and other saturating nonlinearities are much slower than the non-saturating nonlinearity <span class="math inline">\(f(x) = max(0, x)\)</span>. DNN with ReLUs train several times faster than their equivalents with tanh units.</p>
<h3 id="training-on-multiple-gpus">Training on Multiple GPUs</h3>
<p>We split half of the kernels (neurons) on each GPU, with one additional trick: the GPUs communicate only in certain layers. This means that, for examples, the kernels of layer 3 take input form all kernel maps in layer 2. However, kernels in layer 4 take input only from those kernel maps in layer 3 which reside on the same GPU. This allows us to precisely tune the amount of communication until it is an acceptable fraction of the amount of computation.</p>
<h3 id="local-response-normalization">Local Response Normalization</h3>
<p>Denoting by <span class="math inline">\(a^{i}_{x, y}\)</span> the activity of a neuron computed by applying kernel <span class="math inline">\(i\)</span> at position <span class="math inline">\((x, y)\)</span> and then applying the ReLU nonlinearity, the response-normalized activity <span class="math inline">\(b^i_{x,y}\)</span> is given by the expression:</p>
<p><span class="math display">\[b^{i}_{x, y} = \frac{a^{i}_{(x, y)}}{(k + \alpha \sum_{j=\max(0 , \frac{i - n}{2})}^{\min(N - 1, \frac{i + n}{2})}(a^{i}_{(x, y)})^2)^\beta}\]</span></p>
<p>Where the sum runs over <span class="math inline">\(N\)</span> adjacent kernel maps at the same spatial position, and <span class="math inline">\(N\)</span> is the total number of kernels in the layer. This normalization is applied after applying the ReLU nonlinearity in certain layers.</p>
<h3 id="overlapping-pooling">Overlapping Pooling</h3>
<p>Pooling layers in CNNs summarize the outputs of neurons in the same kernel map. Traditionally, the pooling units do not overlap. To be more precise, a pooling layer can be though of as consisting of a grid of pooling units spaced <span class="math inline">\(s\)</span> pixels apart, each summarizing a neighborhood of size <span class="math inline">\(z \times z\)</span> centered at the location of the pooling unit. If we set <span class="math inline">\(s = z\)</span>, we obtain traditional local pooling. If <span class="math inline">\(s &lt; z\)</span>, we obtain overlapping pooling. This is used in the network. We generally observe during training that models with overlapping pooling find it slightly more difficult to overfit.</p>
<h2 id="reduce-overfitting">Reduce Overfitting</h2>
<h3 id="data-augmentation">Data Augmentation</h3>
<p>Two distinct forms of data augmentation:</p>
<ol type="1">
<li><p>Generating image translations and horizontal reflections. We do this by extracting random <span class="math inline">\(227 \times 227\)</span> patches, and their horizontal reflections from the <span class="math inline">\(256 \times 256\)</span> images and training our network on these extracted patches. At the test time, the network makes a prediction by extracting 5 <span class="math inline">\(227 \times 227\)</span> patches (4 corner patches and 1 center patch) as well as their horizontal reflections and average the predictions made by the network's softmax layer on the ten patches.</p></li>
<li><p>Altering the intensities of the RGB channels in training images. Specifically, we perform PCA on the set of RGB pixel values throughout the imageNet training set. For each training image, we add multiples of the found principal components with magnitudes proportional to the corresponding eigenvalues times a random variable drawn from a Gaussian with mean zero and std 0.1.</p></li>
</ol>
<h3 id="dropout">Dropout</h3>
<p>Model aggregation using dropout. Attest time, we use all the neurons but multiply their outputs by 0.5, which is a reasonable approximation to taking the geometric mean of the predictive distributions produced by the exponentially-many dropout networks.</p>
<p>We use dropout in the first two fully-connected layers. Without dropout, our network exhibits substantial overfitting. Dropout roughly doubles the number of iterations required to converge.</p>
<p><br></p>
<h2 id="overall-architecture">Overall Architecture</h2>
<p>The net contains eight layers with weights, the first five are convolutional and the remaining three are full-connected. The output of the last fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels. The network maximizes the multinomial logistic regression objective (-cross entropy), which is equaivalent to maximizing the average across training cases of the log-probability of the correct label under the prediction distribution.</p>
<p>The kernels of the second, fourth and fifth convolutional layers are connected only to those kernel maps in the previous layer which reside on the same GPU. The kernels of the third convolutional layer are connected to all kernel maps in the second layer. The neurons in the fully connected layers are connected to all neurons in the previous layer. Normalization layers follow the first and second convolutional layers. Max-pooling layers, of the kind with overlapping, follow both normalization layers and the fifth convolutional layer.</p>
<p>The first convolutional layer filters the <span class="math inline">\(227 \times 227 \times 3\)</span> (random crop from <span class="math inline">\(256 \times 256 \times 3\)</span>) input images with 96 kernels of size <span class="math inline">\(11 \times 11 \times 3 = 363\)</span> weights in each kernel with a stride of 4 pixels.</p>
<p>The second convolutional layer takes as input (normalized and max pooled) output of the first convolutional layer and filters it with <span class="math inline">\(256\)</span> kernels of size <span class="math inline">\(5 \times 5 \times 48\)</span>.</p>
<p>The third convolutional layer has 384 kernels of size <span class="math inline">\(3 \times 3 \times 256\)</span> connected to the (normalized and max pooled) outputs of the second convolutional layer.</p>
<p>The fourth convolutional layer has 384 kernels of size <span class="math inline">\(3 \times 3 \times 192\)</span>.</p>
<p>The fifth convolutional layer has 256 kernels of size <span class="math inline">\(3 \times 3 \times 192\)</span>.</p>
<p>The fully connected layers have 4096 neurons each.</p>
<p><br></p>
<p>Number of weights in each layer:</p>
<ol type="1">
<li><span class="math inline">\(11 * 11 * 3 * 96 = 34848\)</span></li>
<li><span class="math inline">\(5 * 5 * 48 * 256 = 307200\)</span> (connected only to the Neurons reside in the same GPU)</li>
<li><span class="math inline">\(3 * 3 * 256 * 384= 884736\)</span></li>
<li><span class="math inline">\(3 * 3 * 192 * 384 = 663552\)</span> (connected only to the Neurons reside in the same GPU)</li>
<li><span class="math inline">\(3 * 3 * 192 * 256 = 442368\)</span> (connected only to the Neurons reside in the same GPU)</li>
</ol>
<p>Number of Neurons (output):</p>
<ol type="1">
<li><span class="math inline">\(55 * 55 * 96 = 290400\)</span></li>
<li><span class="math inline">\(27 * 27 * 256 = 186624\)</span></li>
<li><span class="math inline">\(13 * 13 * 384 = 64896\)</span></li>
<li><span class="math inline">\(13 * 13 * 384 = 64896\)</span></li>
<li><span class="math inline">\(13 * 13 * 256 = 43264\)</span></li>
</ol>
<p><br></p>
<p><img src='/images/ML/Alex_1.png' width="600"></p>
<p><br></p>
<h2 id="training-details">Training Details</h2>
<p>Model is trained using SGD with:</p>
<ol type="1">
<li>batch size: 128</li>
<li>momentum: 0.9</li>
<li>weight decay: 0.0005</li>
<li>epochs: 90</li>
<li>lr start: 0.01. It is divided by 10 when the validation error rate stopped improving with the current learning rate and three times prior to termination.</li>
</ol>
<p>All weights initialized using a 0-mean and 0.01 std Gaussian distribution. Biases in the second, fourth and fifth convolutional layers are initialized to 1 as well as the bias in fully connected layers. Biases in remaining layers are initialized to 0. This initialization accelerates the early states of learning by providing the ReLUs with positive inputs.</p>
<h1 id="reference">Reference</h1>
<p>https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/tutorials/tut6_slides.pdf</p>
<p>https://learnopencv.com/understanding-alexnet/#:~:text=The%20input%20to%20AlexNet%20is,of%20size%20256%C3%97256</p>
]]></content>
      <categories>
        <category>DL</category>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Network Architectures</tag>
      </tags>
  </entry>
  <entry>
    <title>Basic Adaptive LR Algorithms</title>
    <url>/2021/07/29/adaptive-lr/</url>
    <content><![CDATA[<h1 id="algorithms-with-adaptive-learning-rates">Algorithms with Adaptive Learning Rates</h1>
<p>Learning rate is reliably one of the hyperparameters that is the most difficult to set because it has a significant impact on model performance. At each iteration, the cost is often highly sensitive to some directions in parameter space and insensitive to others. Momentum solves some of the problems in the cost of introducing another hyperparameter. Thus, it is natural to consider algorithms that have separate learning rate for each parameter and automatically adapt learning rates for each of the parameter.</p>
<p>The <code>delta-bar-delta</code> algorithm (base on full-batch) is an early heuristic approach to adapting individual learning rates for model parameters during training, it is based on intuitive idea similar to momentum:</p>
<blockquote>
<p>If the partial derivative of the loss, with respect to a given model parameter, remains the same sign, then the learning rate should increase, if the partial derivative with respect to the parameter changes sign, then the learning rate should decrease.</p>
</blockquote>
<p>We would like to extend the idea to mini-batch scenario.</p>
<h2 id="adagrad">AdaGrad</h2>
<p><img src='/images/ML/adagrad_1.png' width="600"></p>
<p>The <code>AdaGrad</code> algorithm, individually adapts the learning rates of all model parameters by scaling them inversely proportional to square root of the sum of all of their historical squared values:</p>
<ol type="1">
<li><p>If <span class="math inline">\(g_1\)</span> is large constantly larger than <span class="math inline">\(g_2\)</span>, then:</p>
<p><span class="math display">\[\sqrt{r_1} &gt; \sqrt{r_2} \implies \epsilon_1 &lt; \epsilon_2\]</span></p>
<p>This makes sense because we want to take a small step in the gradient direction when the magnitude of gradient is large, especially when we have noisy gradient. Conversely, we would like to take slightly larger step than large gradient case when we have smaller gradient.</p></li>
<li><p>If <span class="math inline">\(r_i\)</span> is less than 1, we have increasing learning rate compare to base learning rate:</p>
<p><span class="math display">\[r_i &lt; 1 \implies \epsilon_i &gt; \epsilon\]</span></p>
<p>This helps us to get out of the local minimum or flat region of the surface by taking larger steps.</p></li>
</ol>
<p>AdaGrad is designed to converge rapidly when applied to a convex optimization problem, so when it finds a convex structure, it can converge rapidly.</p>
<p>However, in non-convex optimization problem (training neural networks) the accumulated gradient <span class="math inline">\(\mathbf{r}\)</span> starts accumulating at the beginning, <strong>this will introduce excessive decrease in the effective learning in later training steps (at end, we will have large <span class="math inline">\(\mathbf{r}\)</span>, so the learning rates will be small to prevent effective learning in later stages or early large gradients will prevent learning in early stages)</strong>.</p>
<h2 id="rmsprop">RMSProp</h2>
<p>The <code>RMSProp</code> algorithm modifies AdaGrad so that it can perform better in non-convex setting by changing the gradient accumulation into an exponentially weighted moving average, so the early accumulation becomes less and less important. This structure helps in non-convex problem by discarding the history from extreme past so when we arrive at a convex bowl, we have sufficiently large learning rate to converge rapidly.</p>
<p><img src='/images/ML/rmsprop_1.png' width="600"></p>
<p>The algorithm introduces a new parameter <span class="math inline">\(\rho\)</span> that controls for the weight of accumulated gradient.</p>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>approximate_infer</title>
    <url>/2021/09/16/approximate-infer/</url>
    <content><![CDATA[<h1 id="variational-inference">Variational Inference</h1>
]]></content>
  </entry>
  <entry>
    <title>Attention</title>
    <url>/2021/08/06/attention/</url>
    <content><![CDATA[<h1 id="neural-machine-translation-by-jointly-learning-to-align-and-translate">Neural Machine Translation By Jointly Learning to Align and Translate</h1>
<p>One problem with traditional encoder-decoder structure is that a neural network needs to be able to compress all the necessary information of a source sentence into a <strong>fixed-length</strong> vector <span class="math inline">\(\mathbf{c}\)</span>. <code>Attention</code> does not attempt to encode a whole input sentence into a single fixed-length vector. Instead, it encodes the input sentence into a sequence of vectors and chooses a subset of these vectors adaptively while decoding the translation.</p>
<h2 id="background-rnn-encoder-decoder">Background: RNN Encoder-Decoder</h2>
<p>In the Encoder-Decoder framework, an encoder reads the input sentence, a sequence of vectors <span class="math inline">\(\mathbf{x} = (\mathbf{x}_1, ...., \mathbf{x}_{T_x})\)</span>, into a fixed length context vector <span class="math inline">\(\mathbf{c}\)</span>:</p>
<p><span class="math display">\[\mathbf{h}_t = f(\mathbf{x}_t, \mathbf{h}_{t-1})\]</span> <span class="math display">\[\mathbf{c} = q(\mathbf{h}_{1}, ...., \mathbf{h}_{T_x})\]</span></p>
<p>Where <span class="math inline">\(f\)</span> and <span class="math inline">\(q\)</span> are non-linear functions. Typically, <span class="math inline">\(q\)</span> is the identity function defined as <span class="math inline">\(q(\mathbf{h}_{1}, ...., \mathbf{h}_{T_x}) = \mathbf{h}_{T_x}\)</span>.</p>
<p>The decoder is often trained to predict the next word <span class="math inline">\(\mathbf{y}_{t^{\prime}}\)</span> given all the previous predicted words <span class="math inline">\(\{\hat{\mathbf{y}}_1, ..., \hat{\mathbf{y}}_{t^{\prime} - 1}\}\)</span>. In training step <span class="math inline">\(t\)</span>, we can use feed the true target value <span class="math inline">\(\mathbf{y}_{t-1}\)</span>. Then, in training of decoder, we are maximizing the log joint conditional probability (minimize the sum of per time step cross entropy):</p>
<p><span class="math display">\[L = \sum^{T_y}_{t=1} L^{t}\]</span> <span class="math display">\[-L = P_{\mathbf{Y}}(\mathbf{y}) = \sum^{T_y}_{t=1} P_{\mathbf{Y_t} | \mathbf{Y_1} ,...., \mathbf{Y_{t-1}}, \mathbf{c}}(\mathbf{y}_t | \{\mathbf{y}_{1}, ...., \mathbf{y}_{t-1}, \mathbf{c}\})\]</span></p>
<p>Where in RNN, each conditional probability distribution <span class="math inline">\(P_{\mathbf{Y_t} | \mathbf{Y_1} ,...., \mathbf{Y_{t-1}}, \mathbf{c}}\)</span> is model as <span class="math inline">\(g(\mathbf{y}_{t-1}, \mathbf{s}_t, \mathbf{c})\)</span>.</p>
<h2 id="learning-to-align-and-translate">Learning to Align and Translate</h2>
<p><code>Attention</code> contains bidirectional RNN as an encoder and a decoder that emulates searching through a source sentence during decoding a tranlation.</p>
<h3 id="decoder-general-description">Decoder: General Description</h3>
<p>In the new model, we define each conditional distribution as:</p>
<p><span class="math display">\[\hat{P}_{\mathbf{Y_t} | \mathbf{Y_1} ,...., \mathbf{Y_{t-1}}, \mathbf{c}} \triangleq g(\mathbf{y}_{t-1}, \mathbf{s}_t, \mathbf{c}_t)\]</span></p>
<p>Notice here, we have different <span class="math inline">\(\mathbf{c}_t\)</span> for each time step <span class="math inline">\(t\)</span>.</p>
<p>The context vector <span class="math inline">\(\mathbf{c}_i\)</span> depends on a sequence of <code>annotations</code> <span class="math inline">\((\mathbf{h}_1, ....., \mathbf{h}_{T_x})\)</span> which contains information about the whole input sequence (similar to hidden units in encoder) with a strong focus on the parts surrounding the <span class="math inline">\(i\)</span>th word of the input sequence.</p>
<p>The context vector <span class="math inline">\(\mathbf{c}_i\)</span> is, then computed as a weighted sum of these annotations <span class="math inline">\(\mathbf{h}_{i}\)</span>:</p>
<p><span class="math display">\[\mathbf{c}_i = \sum^{T_x}_{j=1} \alpha_{ij} \mathbf{h}_j\]</span></p>
<p><span class="math display">\[\alpha_{ij} = \frac{\exp^{e_{ij}}}{\sum^{T_x}_{k=1} \exp^{e_{ik}}}\]</span></p>
<p>Where</p>
<p><span class="math display">\[e_{ij} = a(\mathbf{s}_{i-1}, \mathbf{h}_j)\]</span></p>
<p>is an <code>alignment model</code> which scores how well the inputs around position <span class="math inline">\(j\)</span> and the output at position <span class="math inline">\(i\)</span> match. This model <span class="math inline">\(a\)</span> is parameterized by a MLP which is jointly trained with all the other components of the proposed system. The score is based on the RNN decoder's hidden state <span class="math inline">\(\mathbf{s}_{i-1}\)</span> and the <span class="math inline">\(j\)</span>th annotation <span class="math inline">\(\mathbf{h}_j\)</span> of the input sentence. <strong>It reflects the importance of each annotation vector <span class="math inline">\(\mathbf{h}_j\)</span> with respect to the previous hidden state <span class="math inline">\(\mathbf{s}_{i-1}\)</span> in deciding the current state <span class="math inline">\(\mathbf{s}_i\)</span> and generating prediction <span class="math inline">\(\hat{\mathbf{y}}_i\)</span></strong>.</p>
<p>We can think the approach of taking a weighted sum of all the annotations as computing an expected annotation, where the expectation is over possible alignments (<span class="math inline">\(\alpha_{ij}\)</span>). In other words, let <span class="math inline">\(\alpha_{ij}\)</span> be a probability that the target word <span class="math inline">\(\mathbf{y}_i\)</span> is aligned to, or translated from a source input word <span class="math inline">\(\mathbf{x}_{j}\)</span>. <strong>Then, the <span class="math inline">\(i\)</span>th context vector <span class="math inline">\(\mathbf{c}_i\)</span> is the expected value of annotations (input sequence) distributed according to probability distribution defined by <span class="math inline">\(\alpha_{ij}\)</span>.</strong></p>
<p>Intuitively, this implements a mechanism of <strong>attention</strong> in the decoder. The decoder decides parts of the source sentence to pay attention to. By letting the decoder have an attention mechanism, we relieve the encoder from the burden of having to encode all information in the source sentence into a fixed length vector.</p>
<h3 id="encoder-bidirectional-rnn-for-annotating-sequences">Encoder: Bidirectional RNN for Annotating Sequences</h3>
<p>A bidirectional RNN consists of forward and backward RNNs. The forward RNN <span class="math inline">\(\overset{\rightarrow}{f}\)</span> reads the input sequence from the front and has <strong>forward hidden units <span class="math inline">\(\{\overset{\rightarrow}{\mathbf{h}}_1, ...., \overset{\rightarrow}{\mathbf{h}}_{T_x}\}\)</span></strong>. <span class="math inline">\(\overset{\leftarrow}{f}\)</span> reads the sequence in the reverse order (from <span class="math inline">\(\mathbf{x}_{T_x}\)</span> to <span class="math inline">\(\mathbf{x}_1\)</span>), resulting in a sequence of <strong>backward hidden units <span class="math inline">\(\{\overset{\leftarrow}{\mathbf{h}}_1, ...., \overset{\leftarrow}{\mathbf{h}}_{T_x}\}\)</span></strong>.</p>
<p>The <strong>annotation</strong> vector <span class="math inline">\(\mathbf{h}_j\)</span> is then calculated by concatenating the forward hidden state <span class="math inline">\(\overset{\rightarrow}{\mathbf{h}}_j\)</span> and the backward hidden state <span class="math inline">\(\overset{\leftarrow}{\mathbf{h}}_j\)</span>:</p>
<p><span class="math display">\[\mathbf{h}_j = [\overset{\rightarrow}{\mathbf{h}}_j, \overset{\leftarrow}{\mathbf{h}}_j]\]</span></p>
<p>This sequence of annotations is used by the decoder and the alignment model later to compute the context vector <span class="math inline">\(\mathbf{c}_{i}\)</span>.</p>
<h1 id="effective-approaches-to-attention-based-neural-machine-translation">Effective Approaches to Attention-based Neural Machine Translation</h1>
<h1 id="long-short-term-memory-networks-for-machine-reading">Long Short-Term Memory-Networks for Machine Reading</h1>
<h1 id="ref">Ref</h1>
<p>https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#self-attention</p>
]]></content>
      <categories>
        <category>DL</category>
        <category>RNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Network Architectures</tag>
      </tags>
  </entry>
  <entry>
    <title>average_reward_setting</title>
    <url>/2021/05/30/average-reward-setting/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Batch Normalization</title>
    <url>/2021/05/26/batch-norm/</url>
    <content><![CDATA[<h1 id="batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</h1>
<p><strong>Internal covariate shift</strong> describes the phenomenon in training DNN that the distribution of each layer's inputs changes during training, as the parameters of the previous layer change. This slow down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating non-linearities (tanh, sigmoid). This problem can be addressed by normalizing the layer inputs.</p>
<h2 id="introduction">Introduction</h2>
<p>To see the input distribution shift in terms of sub-network or a layer. Consider a network computing:</p>
<p><span class="math display">\[l = F_2(F_1(\textbf{u}, \Theta_1), \Theta_2)\]</span></p>
<p>Where <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span> are arbitrary transformations, and the parameters <span class="math inline">\(\Theta_1, \Theta_2\)</span> are to be learned to minimize the loss <span class="math inline">\(l\)</span>. Learning <span class="math inline">\(\Theta_2\)</span> can be viewed as if inputs <span class="math inline">\(\textbf{x} = F_1(\textbf{u}, \Theta_1)\)</span> and fed into the sub-network:</p>
<p><span class="math display">\[l = F_2(\textbf{x}, \Theta_2)\]</span></p>
<p>Thus, a fixed input distribution (ie. the distribution of <span class="math inline">\(\textbf{x}\)</span>) would make the training more effective, because <span class="math inline">\(\Theta_2\)</span> does not need to adapt to the new distribution. At the same time, if the mapping <span class="math inline">\(F_2\)</span> is saturating non-linearity, a fixed-distribution will help to prevent the gradient of parameters from vanishing.</p>
<span id="more"></span>
<h2 id="towards-reducing-internal-covariate-shift">Towards Reducing Internal Covariate Shift</h2>
<p>Consider a layer with the input <span class="math inline">\(u\)</span> that adds the learned bias <span class="math inline">\(b\)</span>, and normalizes the result by subtracting the mean of the activation computed over the training data <span class="math inline">\(\hat{x} = x - \bar{x}\)</span>, where <span class="math inline">\(\bar{x} = \frac{1}{N} \sum_{i=1}^{N} x_i\)</span>. If we <strong>ignore the dependence of <span class="math inline">\(b\)</span> in <span class="math inline">\(\bar{x}\)</span></strong> (ie. <span class="math inline">\(\hat{x} = x - \mu\)</span> we just center the input by some constant <span class="math inline">\(\mu\)</span>, does not take into account <span class="math inline">\(b\)</span>), then</p>
<p><span class="math display">\[\frac{\partial L}{\partial b} = -\frac{\partial L}{\partial \hat{x}} \frac{\partial \hat{x}}{\partial b} = -\frac{\partial L}{\partial \hat{x}}\]</span></p>
<p>Then, the update rule is:</p>
<p><span class="math display">\[b \leftarrow b - \frac{1}{N}\sum_{i}\frac{\partial L}{\partial \hat{x}}\]</span></p>
<p>Let, <span class="math inline">\(\nabla b = - \frac{1}{N}\sum_{i}\frac{\partial L}{\partial \hat{x}}\)</span> Then, new <span class="math inline">\(\hat{x}\)</span> after update <span class="math inline">\(b\)</span> is:</p>
<p><span class="math display">\[u + (b + \nabla b) + \frac{1}{N} \sum_i [u + (b + \nabla b)] = u + b - E[u + b]\]</span></p>
<p>Thus, the combination of the update to <span class="math inline">\(b\)</span> and subsequent change in normalization led to no change in the output of the layer nor, consequently, the loss (ie. center the input without taking account of <span class="math inline">\(b\)</span> will result useless update to <span class="math inline">\(b\)</span> that has no effect on the loss). However, as the training continues, <span class="math inline">\(b\)</span> will grow indefinitely while the loss remains the same.</p>
<p>This is caused because the gradient descent optimization does not take into account that the normalization takes place.</p>
<h2 id="normalization-via-mini-batch-statistics">Normalization via Mini-Batch Statistics</h2>
<p>Normalize the layer inputs are expensive, as it requires computing the covariance matrix, the inverse square root, the expectation over all training samples, as well as the derivative of these transformations. Several simplifications are proposed to deal with these.</p>
<ol type="1">
<li><p>Instead normalize the features in layer inputs and outputs jointly, we will normalize each scalar feature independently by making it have the mean of zero and the variance of 1. For a layer with <span class="math inline">\(d\)</span>-dimensional input <span class="math inline">\(x = (x^{1}, ..., x^{d})\)</span>, we will normalize each individual feature:</p>
<p><span class="math display">\[\hat{x}^{k} = \frac{x^k - E[x^k]}{\sqrt{Var[x^k]}}\]</span></p></li>
</ol>
<p>Where the expectation and variance are computed over the training dataset (i.e first input feature is normalized by first features of all input samples). However, this approach may decrease the expressive power of the activation function, for instance, if we scale the input of sigmoid activation to have mean 0 and variance 1, then we will be limited at the middle region of the sigmoid function (<strong>In this paper, batch norm is applied right after activation and before activation function</strong>)</p>
<p><img src="/images/ML/batch_norm_1.png"></p>
<p>To address this, we make sure that the transformation inserted in the network can represent the identity transformation, that is for each activation <span class="math inline">\(x^k\)</span>, a pair of parameters <span class="math inline">\(\gamma^k, \beta^k\)</span>, which scales and shift the normalized value:</p>
<p><span class="math display">\[y^k = \gamma^k \hat{x}^k + \beta^k\]</span></p>
<p>These parameters are learned through back propagation, and by setting <span class="math inline">\(\gamma^k = \sqrt{Var[x^k]}, \beta^k = E[x^k]\)</span>, we could recover the original activation, if that were the optimal thing to do.</p>
<ol start="2" type="1">
<li>Instead of using whole batch of data for estimating mean and variance which is impractical in practice. We only use mini-batches to estimate means and variance, because mini-batches produce unbiased estimates of the mean and variance. Note that the use of mini-batches is enabled by computation of <strong>per-dimension variances rather than joint covariances</strong> (we do not estimate the covariance). In joint case, regularization would be required since the mini-batch size is likely to be smaller than the number of activations, resulting in singular covariance matrices.</li>
</ol>
<p>Together, we can describe the batch norm transformation for each activation <span class="math inline">\(x\)</span> as:</p>
<p><img src="/images/ML/batch_norm_2.png"></p>
<p>Where <span class="math inline">\(\epsilon\)</span> is a constant added to the mini-batch variance for numerical stability, <span class="math inline">\(BN_{\gamma, \beta}: x_{1, ..., m} \rightarrow y_{1, ..., m}\)</span> is the batch norm transformation. Since the normalization is applied to each activation independently, <span class="math inline">\(k\)</span> which indicates the activation or dimension is dropped.</p>
<p>The backward pass can be write as:</p>
<p><img src="/images/ML/batch_norm_3.png"></p>
<p>Notice that, <span class="math inline">\(\gamma, \beta\)</span> have superscript <span class="math inline">\(k\)</span>, they bind to each activation.</p>
<h2 id="training-and-inference-with-batch-normalized-network">Training and Inference with Batch Normalized Network</h2>
<p>To <strong>Batch-Normalize</strong> a network, any layer that previously received <span class="math inline">\(x\)</span> as input now receive <span class="math inline">\(BN(x)\)</span>.</p>
<h3 id="training">Training</h3>
<p>A model employing Batch Normalization can be trained using batch gradient descent, or Stochastic Gradient Descent with a mini-batch size <span class="math inline">\(m &gt; 1\)</span> or any variant such as Adam. The normalization of activations that depends on the mini-batch allows efficient training. Using moving averages instead, we can track the accuracy of a model as it trains.</p>
<h3 id="testing">Testing</h3>
<p>During testing, it is neither necessary nor desirable to estimate mean and variance using mini-batches, thus, once the network has been trained, we use the normalization:</p>
<p><span class="math display">\[\hat{x} = \frac{x - E[x]}{\sqrt{Var[x] - \epsilon}}\]</span></p>
<p><span class="math display">\[Var[x] = \frac{m}{m - 1} E_{B}[\sigma^2_{B}]\]</span></p>
<p>where <span class="math inline">\(E[x]\)</span> is the mean for the whole dataset. The variance is a bias-corrected version of mini-batch sample variance over all training mini-batches weighted by their occurrence during training.</p>
<p><img src="/images/ML/batch_norm_4.png"></p>
<h2 id="batch-norm-in-cov-net">Batch Norm in Cov Net</h2>
<p>For convolutional layers, we additionally want the normalization to obey the convolutional property ----- so that different elements of the same feature map, at different locations, are normalized in the same way (ie. features in the same feature are normalized in same way). So in the <span class="math inline">\(BN(x)\)</span>, we replace <span class="math inline">\(B\)</span>: mini-batch by <span class="math inline">\(B\)</span>: the set of all values in a feature map across both the elements of a mini-batch and spatial locations, for a mini-batch of size <span class="math inline">\(m\)</span> and feature map of size <span class="math inline">\(p * q\)</span> <span class="math inline">\(|B| = m * p * q\)</span>. We learn <span class="math inline">\(\gamma^k, \beta^k\)</span> per feature map. So in total, we have <span class="math inline">\(C\)</span> different means and variances, where <span class="math inline">\(C\)</span> is number of input channels.</p>
<h2 id="side-effects-of-batch-norm">Side Effects of Batch Norm</h2>
<ol type="1">
<li><p>With Batch Norm, back-propagation through a layer is unaffected by the scale of its parameters. <span class="math display">\[ BN(\alpha W u) = BN(Wu) \]</span> <span class="math display">\[ \frac{\partial BN(\alpha Wu)}{\partial u} = \frac{\partial BN(Wu)}{\partial u}\]</span> <span class="math display">\[ \frac{\partial BN(\alpha Wu)}{\partial \alpha W} = \frac{1}{\alpha} \frac{\partial BN(Wu)}{\partial u}\]</span></p></li>
<li><p>Larger weights leads to smaller gradients, Batch Normalization stabilize the parameter growth:</p>
<p><span class="math display">\[\alpha = 100, \implies \frac{\partial BN(100 Wu)}{\partial 100 W} = \frac{1}{100} \frac{\partial BN(Wu)}{\partial u}\]</span></p></li>
<li><p>Use sample statistics from mini-batches introduce random noise, which helps with the overfitting.</p></li>
</ol>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>Bellman Equations</title>
    <url>/2021/05/03/bellman-equations/</url>
    <content><![CDATA[<p><em>Please read post on <a href="/2021/05/03/MDP/" title="MDP">MDP</a> prior this post</em></p>
<h1 id="bellman-equations">Bellman Equations</h1>
<p>By expanding value functions, we reveal the recursive property of return:</p>
<p><span class="math display">\[
\begin{aligned}
V^{\pi} (x) &amp;= E[G^{\pi}_{t} | X_{t} = x]\\
&amp; = E[R_{t} + \gamma G^{\pi}_{t+1} | X_{t} = x]\\
&amp; = E_{a \sim \pi(a | s)}[R_{t} | X_{t} = x] + \gamma E[G^{\pi}_{t+1} | X_{t} = x]\\
&amp; = r^{\pi} (x) + \gamma E[V^{\pi} (X_{t+1}) | X_{t} = x]\\
\end{aligned}
\]</span> <span id="more"></span></p>
<p>Where: <span class="math display">\[V^{\pi} (X_{t+1}) = E[G^{\pi}_{t+1} | X_{t+1}] \]</span></p>
<p><span class="math display">\[\implies E_{X_{t+1} \sim P(\cdot | x_t, A_t)}[V^{\pi} (X_{t+1}) | X_t=x_t] = E_{X_{t+1} \sim P(\cdot | x_t, A_t)}[E[G^{\pi}_{t+1} | X_{t+1}] | X_{t}=x_t] = E[G^{\pi}_{t+1} | X_{t} = x_t]\]</span></p>
<p>This implies that neither side is random, by expanding:</p>
<p><span class="math display">\[E[V^{\pi} (X_{t+1}) | X_{t} = x]\]</span></p>
<p>we get:</p>
<p><span class="math display">\[E[V^{\pi} (X_{t+1}) | X_{t} = x] = \int P(dx^\prime | x, a) \pi (da | x) V^{\pi} (x^\prime)\]</span></p>
<p>Thus, the value function can be expressed as:</p>
<p><span class="math display">\[V^{\pi} (x) = r^{\pi} (x) + \gamma \int P(dx^\prime | x, a) \pi (da | x) V^{\pi} (x^\prime)\]</span></p>
<p>This is the <span style="color:red"><strong>bellman equation</strong> </span> for a policy <span class="math inline">\(\pi\)</span>, this can be interpreted as: The value of following a policy <span class="math inline">\(\pi\)</span> is the expected immediate reward that the <span class="math inline">\(\pi\)</span>-following agent receives at that state plus the discounted average(expected) value that the agent receives at the next-state.</p>
<p>Same for action-value function, we have bellman equation:</p>
<p><span class="math display">\[Q^{\pi} (x, a) = r(x, a) + \gamma \int P(dx^\prime | x, a) V^{\pi}(x^\prime) = r(x, a) + \gamma \int P(dx^\prime | x, a) \pi (da^\prime | x^\prime) Q^{\pi} (x^\prime, a^\prime)\]</span></p>
<p>Compare with value function, we have expected reward base on action <span class="math inline">\(a\)</span> plus discounted average(expected) value that the agent receives at the next-state following <span class="math inline">\(\pi\)</span> (the choice of action is given at state <span class="math inline">\(s\)</span> in action value function)</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>Basics</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Bellman Equations for Optimal Value Functions</title>
    <url>/2021/05/03/bellman-optimality-equations/</url>
    <content><![CDATA[<p><em>Please read posts on <a href="/2021/05/03/MDP/" title="MDP">MDP</a> and <a href="/2021/05/03/bellman-equations/" title="Bellman Equations">Bellman Equations</a> prior this post.</em></p>
<h1 id="bellman-equations-for-optimal-value-functions">Bellman Equations for Optimal Value Functions</h1>
<p><img src='/images/RL/bellman_equation/optimal_policy_value_func.png'></p>
<p>So it is natural to ask, does the optimal value function of optimal policy <span class="math inline">\(V^{\pi^*}\)</span> have similar recursive structure? the answer is yes, however, we need to prove this. The proof goes with 3 claims which we will prove later: <span id="more"></span></p>
<ol type="1">
<li><ol type="a">
<li><p><span class="math inline">\(\exists\)</span> a value function <span class="math inline">\(V^*\)</span> s.t <span class="math inline">\(\forall x \in X\)</span>, we have:</p>
<p><span class="math display">\[V^{*}(x) = max_{a} \{Q^{*}(x, a)\} = max_{a} \{r(x, a) + \gamma \int P(dx^\prime | x, a) V^{*}(x^\prime)\}\]</span></p></li>
<li><p><span class="math inline">\(\exists\)</span> a value function <span class="math inline">\(Q^*\)</span> s.t <span class="math inline">\(\forall x, a \in X, A\)</span>, we have:</p>
<p><span class="math display">\[Q^{*}(x, a) = r(x, a) + \gamma \int P(dx^\prime | x, a) max_{a^\prime} \{Q^{*} (x^\prime, a^\prime)\}\]</span></p></li>
</ol>
<p>These equations are called <span style="color:red"><strong>bellman optimality equations for the value functions</strong></span></p></li>
<li><p><span class="math inline">\(V^{*}\)</span> is the same as <span class="math inline">\(V^{\pi^*}\)</span>, the optimal value function when <span class="math inline">\(\pi\)</span> is restricted to be within the space of all stationary and non-stationary policies.</p></li>
<li><p>For discounted continuing MDPs, we can always find a stationary policy that is optimal within the space of all stationary and non-stationary policies.</p></li>
</ol>
<p>In summary, we claim that:</p>
<p><strong><span class="math inline">\(V^{*}\)</span> exists and it is unique, <span class="math inline">\(V^{*} = V^{\pi^{*}}\)</span>. Same for <span class="math inline">\(Q^{*}\)</span></strong></p>
<h2 id="bellman-operators">Bellman Operators</h2>
<p>In order to prove the claims, we need several concepts:</p>
<p><img src='/images/RL/bellman_equation/bellman-operator.png'> <img src='/images/RL/bellman_equation/bell-opt-operator.png'></p>
<p>These operators are linear and recall that:</p>
<p><span class="math display">\[Q^{\pi} (x, a) = r(x, a) + \gamma \int P(dx^\prime | x, a) V^{\pi}(x^\prime) = r(x, a) + \gamma \int P(dx^\prime | x, a) \pi (a^\prime | x^\prime) Q^{\pi} (x^\prime, a^\prime)\]</span></p>
<p>This implies <span class="math inline">\(T^{\pi} Q^{\pi} = Q^{\pi}\)</span>, same for state-value function and bellman optimality operators. Thus, we can conclude that:</p>
<p><span class="math display">\[V^{\pi} = T^{\pi} V^{\pi}\]</span> <span class="math display">\[Q^{\pi} = T^{\pi} Q^{\pi}\]</span> <span class="math display">\[V^{*} = T^{*} V^{*}\]</span> <span class="math display">\[Q^{*} = T^{*} Q^{*}\]</span></p>
<h3 id="properties-of-bellman-operators">Properties of Bellman Operators</h3>
<p>Bellman operators have several important properties. The properties that matters for us the most are:</p>
<ol type="1">
<li>Monotonicity</li>
<li>Contraction</li>
</ol>
<h4 id="monotonicity">Monotonicity</h4>
<p><img src='/images/RL/bellman_equation/monotonicity.png'></p>
<p>we can easily prove this (only prove <span class="math inline">\(T^{\pi}\)</span>, <span class="math inline">\(T^{*}\)</span> is the same):</p>
<p>Assume:</p>
<p><span class="math display">\[V_1(x^{\prime}) \geq V_2(x^{\prime}), \forall x^{\prime} \in X\]</span></p>
<p>we get that for any <span class="math inline">\(x \in X\)</span>:</p>
<p><span class="math display">\[T^{\pi}V_{1} (x) = r^{\pi} (x) + \gamma \int P^{\pi}(dx^{\prime} | x) V_{1} (x^\prime) \geq r^{\pi} (x) + \gamma \int P^{\pi}(dx^{\prime} | x) V_{2} (x^\prime) = T^{\pi}V_2(x)\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[T^{\pi}V_{1} (x) \geq T^{\pi}V_{2} (x)\]</span></p>
<h4 id="contraction">Contraction</h4>
<p><img src='/images/RL/bellman_equation/contraction_mapping.png'></p>
<p>we can also easily prove that <span class="math inline">\(T^{*}, T^{\pi}\)</span> are contraction mappings (only prove <span class="math inline">\(T^{\pi}\)</span>, <span class="math inline">\(T^{*}\)</span> is the same):</p>
<p>Consider two action-value functions:</p>
<p><span class="math display">\[Q_1, Q_2 \in B(X\times A)\]</span></p>
<p>Consider the metric:</p>
<p><span class="math display">\[d(Q_1, Q_2) = \| Q_1 - Q_2 \|_{\infty}\]</span></p>
<p>We show the contraction w.r.t <span class="math inline">\(l-\infty\)</span> norm.</p>
<p>For any <span class="math inline">\((x, a) \in X \times A\)</span>, we have:</p>
<span class="math display">\[\begin{aligned}
\lvert T^{\pi} Q_1 (x, a) - T^{\pi} Q_2 (x, a) \rvert &amp;= \lvert r (x, a) + \gamma \int P(dx^{\prime} | x, a) \pi(da^\prime | x^\prime) Q_{1} (x^\prime, a^{\prime}) - r (x, a) - \gamma \int P(dx^{\prime} | x, a) \pi(da^\prime | x^\prime) Q_{2} (x^\prime, a^{\prime}) \rvert\\
&amp; = \gamma \lvert \int P(dx^{\prime} | x, a) \pi(da^\prime | x^\prime) [Q_{1} (x^\prime, a^{\prime}) -  Q_{2} (x^\prime, a^{\prime})] \rvert\\
&amp; \leq \gamma \int \underbrace{P(dx^{\prime} | x, a) \pi(da^\prime | x^\prime)}_{\text{these are probabilities which $ \geq $ 0}} \lvert [Q_{1} (x^\prime, a^{\prime}) -  Q_{2} (x^\prime, a^{\prime})] \rvert\\
&amp; \leq \gamma \int P(dx^{\prime} | x, a) \pi(da^\prime | x^\prime) \sup_{x, a}\lvert [Q_{1} (x, a) -  Q_{2} (x, a)] \rvert\\
&amp; = \gamma \sup_{x, a}\lvert Q_{1} (x, a) -  Q_{2} (x, a) \rvert \underbrace{\int P(dx^{\prime} | x, a) \pi(da^\prime | x^\prime)}_{\text{this is a probability distribution which sums to 1}}\\
&amp; = \gamma \sup_{x, a}\lvert Q_{1} (x, a) -  Q_{2} (x, a) \rvert = \gamma \|Q_{1} -  Q_{2}\|_{\infty}
\end{aligned}\]</span>
<p>This inequality holds for all state action pair, thus, we have showed that bellman operators are contraction mappings.</p>
<p><img src='/images/RL/bellman_equation/gamma_contraction.png'></p>
<h3 id="consequences-of-monotonicity-and-contraction">Consequences of Monotonicity and Contraction</h3>
<h4 id="uniqueness-of-fixed-points">Uniqueness of fixed points</h4>
<p><img src='/images/RL/bellman_equation/fixed_point.png'> <img src='/images/RL/bellman_equation/bfpt.png'> <img src='/images/RL/bellman_equation/unique_fixed_points.png'></p>
<p>Proof of the proposition is also simple (Same for <span class="math inline">\(Q^{\pi}, Q^{*}\)</span>):</p>
<p>For any <span class="math inline">\(\pi\)</span>, <span class="math inline">\(T^{\pi}\)</span> is a <span class="math inline">\(\gamma-\)</span>contraction mapping (same for <span class="math inline">\(T^{*}\)</span>), thus, by the Banach fixed point theorem, they have unique fixed point</p>
<p><span class="math display">\[T^{*} V^{*} = V^{*}, T^{\pi} V^{\pi} = V^{\pi}\]</span></p>
<p>Moreover, the update rule <span class="math inline">\(V_{k+1} \leftarrow T^{\pi} V_{k}\)</span> converges, which means:</p>
<p><span class="math display">\[lim_{k \rightarrow \infty} \| V_{k} - V^{\pi}\|_{\infty} = 0\]</span></p>
<h4 id="value-of-the-greedy-policy-of-v-is-v">Value of the greedy policy of <span class="math inline">\(V^{*}\)</span> is <span class="math inline">\(V^{*}\)</span></h4>
<p>We know if:</p>
<p><span class="math display">\[T^{\pi} V^{*} = T^{*}V^{*} \implies T^{\pi} V^{*} = V^{*}\]</span></p>
<p>This is also the fix point of <span class="math inline">\(T^{\pi}\)</span>, this implies <span class="math inline">\(V^{\pi} = V^{*}\)</span>.</p>
<p>On the other hand, if we know <span class="math inline">\(V^\pi = V^{*}\)</span>, the by applying <span class="math inline">\(T^{\pi}\)</span> to both side we have</p>
<p><span class="math display">\[T^{\pi} V^{\pi} = T^{\pi} V^{*} \implies T^{\pi} V^{\pi} = T^{*} V^{*} = T^{\pi} V^{*}\]</span></p>
<p>Thus, we can conclude that:</p>
<p><span class="math display">\[T^{\pi} V^{*} = T^{*}V^{*} \text{ iff } V^\pi = V^{*}\]</span></p>
<p><strong>The Connection To Greedy Policy</strong></p>
<p>Given <span class="math inline">\(V^{*}\)</span>, the greedy policy of <span class="math inline">\(V^{*}\)</span> is defined as:</p>
<p><span class="math display">\[\pi_{g} (x; V^{*}) = argmax_{a \in A} Q^{*}(x, a) = argmax_{a \in A} r(x, a) + \gamma \int P(dx^{\prime} | x, a) V^{*}(x^{\prime})\]</span></p>
<p>So:</p>
<p><span class="math display">\[T^{\pi_{g} (x; V^{*})} V^{*} = r(x, \pi_{g} (x; V^{*})) + \gamma \int P(dx^{\prime} | x, \pi_{g} (x; V^{*})) V^{*}(x^{\prime}) = max_{a \in A} r(x, a) + \gamma \int P(dx^{\prime} | x, a) V^{*}(x^{\prime})\]</span></p>
<p>Compare with <span class="math inline">\(T^{*} V^{*}\)</span>:</p>
<p><span class="math display">\[T^{*} V^{*} =  max_{a \in A} r(x, a) + \gamma \int P(dx^{\prime} | x, a) V^{*}(x^{\prime})\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[T^{*} V^{*} = T^{\pi_{g} (x; V^{*})} V^{*}\]</span></p>
<p>Since:</p>
<p><span class="math display">\[T^{\pi} V^{*} = T^{*}V^{*} \text{ iff } V^\pi = V^{*} \implies V^{*} = V^{\pi_{g} (x; V^{*})}\]</span></p>
<p>That is, the value of following <span class="math inline">\(\pi_{g} (x; V^{*})\)</span> is the same as <span class="math inline">\(V^{*}\)</span>. This means that if we find <span class="math inline">\(V^{*}\)</span> and its greedy policy, the value of following the greedy policy is <span class="math inline">\(V^{*}\)</span>.</p>
<p><span style="color:red"><strong>To find an optimal policy, we can find <span class="math inline">\(V^{*}\)</span> first, then find its greedy policy</strong></span></p>
<p>following this conclusion: Although we have not yet prove that <span class="math inline">\(V^{*}\)</span> is the optimal value function (<span class="math inline">\(\pi^{*} = argmax_{\pi \in \prod} V^{\pi} (x)\)</span>, <span class="math inline">\(V^{*} = V^{\pi^{*}}\)</span> (claim 2)), this is indeed true. (prove later)</p>
<h4 id="an-error-bound-based-on-the-bellman-error">An error bound based on the bellman error</h4>
<p>If we find a V s.t <span class="math inline">\(V = T^{*} V\)</span>, we know that <span class="math inline">\(V = V^{*}\)</span> (same for <span class="math inline">\(T^{\pi} and Q\)</span>), what if <span class="math inline">\(V \approx T^{*} V\)</span>, what can we say about the closeness of <span class="math inline">\(V\)</span> to <span class="math inline">\(V^{*}\)</span>?</p>
<p><img src='/images/RL/bellman_equation/br_1.png'> <img src='/images/RL/bellman_equation/br_2.png'></p>
<p><strong>Proof:</strong></p>
<span class="math display">\[\begin{aligned}
V - V^{*} &amp;= V - T^{*} V + T^{*} V - V^{*}\\
\implies \| V - V^{*} \|_{\infty} &amp;= \| V - T^{*} V + T^{*} V - V^{*} \|_{\infty}\\
&amp;\leq   \|V - T^{*} V \|_{\infty} + \|T^{*} V - T^{*}V^{*} \|_{\infty} \\
&amp;\leq   \|V - T^{*} V \|_{\infty} + \gamma \|V - V^{*} \|_{\infty} (i.e. \|T^{*} V - T^{*}V^{*} \|_{\infty} \leq \gamma \|V - V^{*} \|_{\infty}, \text{contraction property} )\\
\implies \| V - V^{*} \|_{\infty} &amp;\leq \frac{\|V - T^{*} V \|_{\infty}}{(1 - \gamma)}\\
\implies \| V - V^{*} \|_{\infty} &amp;\leq \frac{BE^{*}}{(1 - \gamma)}
\end{aligned}\]</span>
<h4 id="proof-of-claim-2-v-t-v-is-the-same-as-vpi">Proof of claim 2: <span class="math inline">\(V^{*} = T^{*} V^{*}\)</span> is the same as <span class="math inline">\(V^{\pi^{*}}\)</span></h4>
<p><img src='/images/RL/bellman_equation/claim_2.png'></p>
<p>The proof has three parts:</p>
<ol type="1">
<li><p>Prove that <span class="math inline">\(V^{*} (x) \leq sup_{\pi \in \prod} V^{\pi} (x)\)</span></p></li>
<li><p>Prove that <span class="math inline">\(V^{*} (x) \geq sup_{\pi \in \prod} V^{\pi} (x)\)</span></p></li>
<li><p>Combine 1 and 2, we show that claim 2 is true, that is, <span class="math inline">\(V^{*} = T^{*} V^{*}\)</span> is the same as <span class="math inline">\(V^{\pi^{*}}\)</span></p></li>
</ol>
<h5 id="proof-v-x-leq-sup_pi-in-prod-vpi-x">Proof <span class="math inline">\(V^{*} (x) \leq sup_{\pi \in \prod} V^{\pi} (x)\)</span></h5>
<p>From the error bound with the choice of <span class="math inline">\(V = V^{*}\)</span>, we have for any <span class="math inline">\(\pi \in \prod\)</span>,</p>
<p><span class="math display">\[\| V^{*} - V^{\pi} \|_{\infty} \leq \frac{\| V^{*} - T^{\pi}V^{*} \|_{\infty}}{1 - \gamma}\]</span></p>
<p>Let <span class="math inline">\(\epsilon &gt; 0\)</span>. Choose a policy <span class="math inline">\(\pi_{\epsilon}\)</span> s.t:</p>
<p><span class="math display">\[\| V^{*} - T^{\pi_{\epsilon}} V^{*} \|_{\infty} \leq (1 - \gamma) \epsilon\]</span></p>
<p>We know that this <span class="math inline">\(\pi_{\epsilon}\)</span> exists because we can always pick a <span class="math inline">\(\pi_{\epsilon}\)</span> s.t it is the maximizer of <span class="math inline">\(T^{*}V^{*}\)</span> (ie. pick <span class="math inline">\(\pi_{\epsilon}\)</span> to be <span class="math inline">\(\pi_{g} (x; V^{*})\)</span>, from above proof we know that <span class="math inline">\(T^{\pi_{g} (x; V^{*})} V^{*} = T^{*} V^{*}\)</span>), then:</p>
<p><span class="math display">\[\| V^{*} - T^{\pi_{\epsilon}} V^{*} \|_{\infty} = 0 \leq (1 - \gamma) * \epsilon, \forall \epsilon &gt; 0\]</span></p>
<p>For any policy <span class="math inline">\(\pi_{\epsilon}\)</span> that satisfies above equation:</p>
<p><span class="math display">\[\| V^{*} - V^{\pi_{\epsilon}} \|_{\infty} \leq \epsilon\]</span></p>
<p>This means that:</p>
<p><span class="math display">\[sup_{x_i} \{|V^{*} (x_i) - V^{\pi_{\epsilon}} (x_i)|\} \leq \epsilon\]</span></p>
<p><span class="math display">\[\implies |V^{*} (x_i) - V^{\pi_{\epsilon}} (x_i)| \leq sup_{x_i} \{|V^{*} (x_i) - V^{\pi_{\epsilon}} (x_i)|\} \leq \epsilon, \forall x_i \in X\]</span></p>
<p><span class="math display">\[\implies V^{*} (x_i) - V^{\pi_{\epsilon}} (x_i) \leq  |V^{*} (x_i) - V^{\pi_{\epsilon}} (x_i)| \leq \epsilon\]</span></p>
<p><span class="math display">\[\implies V^{*} (x_i) \leq \epsilon + V^{\pi_{\epsilon}} (x_i)\]</span></p>
<p>Since:</p>
<p><span class="math display">\[V^{\pi_{\epsilon}} (x) \leq sup_{\pi \in \prod} V^{\pi} (x)\]</span></p>
<p>As we take <span class="math inline">\(\epsilon \rightarrow 0\)</span>, we have:</p>
<p><span class="math display">\[V^{*} (x) \leq lim_{\epsilon \rightarrow 0} (\epsilon + V^{\pi_{\epsilon}} (x)) \leq lim_{\epsilon \rightarrow 0} (\epsilon + sup_{\pi \in \prod} V^{\pi}  (x)) = sup_{\pi \in \prod} V^{\pi} (x)\]</span></p>
<p><strong>This shows that <span class="math inline">\(V^{*} = T^{*} V^{*}\)</span> is upper bounded by the optimal value function within the space of stationary policies</strong></p>
<h5 id="proof-v-x-geq-sup_pi-in-prod-vpi-x">Proof <span class="math inline">\(V^{*} (x) \geq sup_{\pi \in \prod} V^{\pi} (x)\)</span></h5>
<p>Consider any <span class="math inline">\(\pi \in \prod\)</span>. By the definition of <span class="math inline">\(T^{\pi}\)</span> and <span class="math inline">\(T^{*}\)</span>, for any <span class="math inline">\(V \in B(X)\)</span>, we have that for any <span class="math inline">\(x \in X\)</span>:</p>
<span class="math display">\[\begin{aligned}
T^{\pi} V &amp;= r^{\pi}(x) + \int P(dx^{\prime} | x, a) \pi(da | x) V(x^{\prime})\\
&amp;= \int  \pi(da | x) [P(dx^{\prime} | x, a) V(x^{\prime}) + r(x, a)]\\
&amp;\leq sup_{a \in A} \{r(x, a) + \int P(dx^{\prime} | x, a) V(x^{\prime})\} = T^{*} V
\end{aligned}\]</span>
<p>In particular, with the choice of <span class="math inline">\(V = V^{*}\)</span>, we have:</p>
<span class="math display">\[\begin{aligned}
T^{\pi} V^{*} &amp;\leq T^{*} V^{*} = V^{*}\\
\implies T^{\pi}T^{\pi} V^{*} &amp;\leq T^{\pi}V^{*} \leq V^{*} \text{(Monotonicity)}\\
\implies (T^{\pi})^{k} V^{*} &amp;\leq V^{*} \text{(apply bellman operator k times)}
\end{aligned}\]</span>
<p>as <span class="math inline">\(k \rightarrow \infty\)</span>, by fix point theorem, we know that <span class="math inline">\((T^{\pi})^k V^{*} = V^{\pi}\)</span>:</p>
<span class="math display">\[\begin{aligned}
\implies V^{\pi} &amp;= lim_{k \rightarrow \infty} (T^{\pi})^k V^{*} \leq V^{*}, \forall \pi \in \prod\\
\implies V^{*} (x) &amp;\geq sup_{\pi \in \prod} V^{\pi} (x)
\end{aligned}\]</span>
<p><strong>Thus, we can conclude that <span class="math inline">\(V^{*} (x) \geq sup_{\pi \in \prod} V^{\pi} (x)\)</span></strong></p>
<p><span style="color:red"><strong>Together, we showed that <span class="math inline">\(V^{*}\)</span> is the same as <span class="math inline">\(V^{\pi^{*}}\)</span>, the solution of bellman optimality equation is the optimal value function</strong></span></p>
]]></content>
      <categories>
        <category>RL</category>
        <category>Basics</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Calculus (1)</title>
    <url>/2021/05/14/calculus/</url>
    <content><![CDATA[<h1 id="multivariate-calculus-1">Multivariate Calculus (1)</h1>
<h2 id="fundamental-theorem-of-calculus">Fundamental Theorem of Calculus</h2>
<p>If <span class="math inline">\(f\)</span> is continuous and <span class="math inline">\(F\)</span> is indefinite integral of <span class="math inline">\(f\)</span> (i.e <span class="math inline">\(F^{\prime} = f\)</span> or <span class="math inline">\(\int f(x) dx = F(x) + c\)</span>, without bounds) on closed interval <span class="math inline">\([a, b]\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(\int^{b}_{a} f(x) dx = F(b) - F(a)\)</span></li>
<li><span class="math inline">\(\frac{d}{dx}\int^{x}_{a} f(t)dt = F^{\prime}(x) - F^{\prime}(a) = F^{\prime} (x) = f(x)\)</span></li>
</ol>
<h2 id="definition-of-integral">Definition of Integral</h2>
<p>If <span class="math inline">\(f(x)\)</span> is defined for <span class="math inline">\(a \leq x \leq b\)</span>, we start by dividing the interval <span class="math inline">\([a, b]\)</span> into <span class="math inline">\(n\)</span> sub-intervals <span class="math inline">\([x_{i - 1}, x_{i}]\)</span> of equal width <span class="math inline">\(\Delta x = \frac{b - a}{n}\)</span> and we choose sample points <span class="math inline">\(x^{*}_i\)</span> in these subintervals. Then we form the <code>Riemann sum</code>:</p>
<p><span class="math display">\[\sum^{n}_{i=1} f(x^{*}_n) \Delta x\]</span></p>
<p>Then by taking the limit <span class="math inline">\(n \rightarrow \infty\)</span>, we have the definite integral of <span class="math inline">\(f\)</span> from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>:</p>
<p><span class="math display">\[\int^{b}_{a} f(x) dx = \lim_{n \rightarrow \infty} \sum^{n}_{i=1} f(x^{*}_n) \Delta x\]</span></p>
<p>In the special case where <span class="math inline">\(f(x) \leq 0\)</span>, we can interpret the <code>Riemann sum</code> as the sum of the areas of the approximating rectangles, and <span class="math inline">\(\int^{b}_{a} f(x) dx\)</span> represents the area under the curve <span class="math inline">\(y = f(x)\)</span> from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>.</p>
<p><img src='/images/cal/15_1_1.png' width="600"></p>
<h2 id="vectors-and-the-geometric-of-space">Vectors and the Geometric of Space</h2>
<h3 id="equation-of-a-sphere">Equation of a sphere</h3>
<p>By definition, a sphere is the set of all points <span class="math inline">\(P(x, y, z)\)</span> whose distance from <span class="math inline">\(C\)</span> is <span class="math inline">\(r\)</span>, where <span class="math inline">\(C\)</span> is the center <span class="math inline">\(C(h, k, l)\)</span>. Thus, <span class="math inline">\(P\)</span> is on the sphere if and only if</p>
<p><span class="math display">\[|PC| = r \implies |PC|^2 = r^2\]</span></p>
<p><span class="math display">\[(x - h)^2 + (y - k)^2 + (z - l)^2 = r^2\]</span></p>
<p><img src='/images/cal/12_1_1.png' width="600"></p>
<span id="more"></span>
<h3 id="vectors">Vectors</h3>
<p>The term vector is used by scientists to indicate a quantity that has both magnitude and direction.</p>
<p><img src='/images/cal/12_2_1.png' width="600"></p>
<p>In three dimensions, the vector <span class="math inline">\(a = \vec{OP}\)</span> is the <strong>position vector</strong> of the point <span class="math inline">\(P\)</span>. We can think of all geometric vectors as representation of the position vector of the point <span class="math inline">\(P\)</span>.</p>
<h3 id="dot-product">Dot product</h3>
<p><img src='/images/cal/12_3_1.png' width="600"></p>
<h4 id="proof">Proof</h4>
<p>Recall the law of cosines for vector <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> and their difference <span class="math inline">\(a - b\)</span>:</p>
<p><span class="math display">\[|a - b|^2 = |a|^2 + |b|^2 - 2|a||b|\cos\theta\]</span></p>
<p>If we expand left side:</p>
<p><span class="math display">\[|a - b|^2 = (a - b) \cdot (a - b) = |a|^2 + |b|^2 - 2 a \cdot b\]</span></p>
<p>Then we have:</p>
<p><span class="math display">\[|a|^2 + |b|^2 - 2 a \cdot b = |a|^2 + |b|^2 - 2|a||b|\cos\theta \implies a \cdot b = |a||b|\cos \theta\]</span> </br></p>
<p>If two vectors are <strong>perpendicular</strong> or <strong>orthogonal</strong> <span class="math inline">\(\Longleftrightarrow\)</span> the angle between them is <span class="math inline">\(\theta = 90^\circ\)</span> and <span class="math inline">\(a \cdot b = 0\)</span></p>
<h3 id="projections">Projections</h3>
<p><img src='/images/cal/12_3_2.png' width="600"></p>
<p>The vector projection of <span class="math inline">\(b\)</span> onto <span class="math inline">\(a\)</span> is denoted as <span class="math inline">\(proj_a b\)</span>. The <span class="math inline">\(comp_a b\)</span> is defined to be the signed magnitude of the vector projection.</p>
<p><span class="math inline">\(\cos \theta = \frac{adjacent}{hypotenuse} \implies\)</span> the magnitude of the project vector is <span class="math inline">\(comp_{a} b = |b| \cos \theta\)</span>.</p>
<p>Recall that the dot product:</p>
<p><span class="math display">\[a \cdot b = |a|(|b|\cos \theta)\]</span></p>
<p>So:</p>
<p><span class="math display">\[com_{a} b = \frac{a \cdot b }{|a|}\]</span></p>
<p>Remember that <span class="math inline">\(proj_a b\)</span> is a vector, we need to add direction of <span class="math inline">\(a\)</span> which is <span class="math inline">\(\frac{a}{|a|}\)</span> to the magnitude <span class="math inline">\(comp_a b\)</span>:</p>
<p><span class="math display">\[proj_a b = \frac{a \cdot b }{|a|} \frac{a}{|a|} = \frac{a \cdot b}{|a|^2} a\]</span></p>
<p><img src='/images/cal/12_3_3.png' width="600"></p>
<h3 id="cross-product">Cross Product</h3>
<p><img src='/images/cal/12_4_1.png' width="600"></p>
<p>The cross product of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> is a vector. Note that <span class="math inline">\(a \times b\)</span> is only defined when <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are three-dimensional vectors.</p>
<p><img src='/images/cal/12_4_2.png' width="600"></p>
<p><img src='/images/cal/12_4_3.png' width="600"></p>
<p><img src='/images/cal/12_4_4.png' width="600"></p>
<p><br></p>
<p><strong>Two non-zero vectors <span class="math inline">\(a, b\)</span> are parallel if and only if <span class="math inline">\(a \times b = 0\)</span></strong></p>
<h2 id="equations-of-lines-and-planes">Equations of Lines and Planes</h2>
<p>A line on xy-plane is determined when a point on the line and the direction of the line. Likewise, a line <span class="math inline">\(L\)</span> in 3 dimensional space is determined when we know a point <span class="math inline">\(P_0 (x_0, y_0, z_0)\)</span> on <span class="math inline">\(L\)</span> and the direction of <span class="math inline">\(L\)</span>.</p>
<p>In 3 d space the direction of the line is described as a vector, so we let <span class="math inline">\(v = \vec{OV}\)</span> be a vector parallel to <span class="math inline">\(L\)</span>. Let <span class="math inline">\(P(x, y, z)\)</span> be an arbitrary point on <span class="math inline">\(L\)</span> and let <span class="math inline">\(r_0 = \vec{OP_0}\)</span> and <span class="math inline">\(r= \vec{OP}\)</span> be the position vectors of Let <span class="math inline">\(a = \vec{P_0P}\)</span>, then</p>
<p><span class="math display">\[\vec{P_0P} = \vec{OP} - \vec{OP_0} \implies r = r_0 + a\]</span></p>
<p>Since <span class="math inline">\(a, v\)</span> are parallel vectors, there is a scalar such that <span class="math inline">\(a = tv\)</span>. Thus:</p>
<p><span class="math display">\[r = r_0 + tv\]</span></p>
<p>This is the <strong>vector equation</strong> of <span class="math inline">\(L\)</span> in 3 d. Each value of the parameter <span class="math inline">\(t\)</span> gives the position vector <span class="math inline">\(r\)</span> of a point on <span class="math inline">\(L\)</span>. So the line in 3 d is represented by a position vector on the line and a scalar multiple of direction vector <span class="math inline">\(tv\)</span>.</p>
<p><br></p>
<p>In component form <span class="math inline">\(r = &lt;x, y, z&gt;, r_0 = &lt;x_0, y_0, z_0&gt;, v=&lt;a, b, c&gt;\)</span>, each component is called <strong>parametric equation</strong> of the line <span class="math inline">\(L\)</span> through point <span class="math inline">\(P_0\)</span>:</p>
<p><span class="math display">\[&lt;x, y, z&gt; = &lt;x_0 + ta, y_0 + tb, z_0 + tc&gt;\]</span> </br></p>
<p><img src='/images/cal/12_5_1.png' width="600"></p>
<p><br></p>
<p>In general, we know that the vector equation of a line through the tip of the vector <span class="math inline">\(r_0\)</span> in the direction of a vector <span class="math inline">\(v\)</span> is <span class="math inline">\(r(t) = r_0 + tv\)</span>. If the line also passes through the tip of <span class="math inline">\(r_1\)</span>, then we can take <span class="math inline">\(v = r_1 - r_0\)</span> because <span class="math inline">\(v = r_1 - r_0\)</span> is parallel to the line <span class="math inline">\(L\)</span>, thus satisfies the vector equation of line:</p>
<p><span class="math display">\[r(t) = r_0 + tv = r_0 + t(r_1 - r_0)\]</span></p>
<p>If <span class="math inline">\(t = 1 \implies r = r_1\)</span>, if <span class="math inline">\(t = 0 \implies r = r_0\)</span>, the line segment from $r_0 $ to <span class="math inline">\(r_1\)</span> is ten given by the parameter interval <span class="math inline">\(0 \leq t \leq 1\)</span>:</p>
<p><img src='/images/cal/12_5_2.png' width="600"></p>
<h3 id="planes">Planes</h3>
<p>Although a line in space is determined by a point and a direction, a plane in space is more difficult to describe.</p>
<p>A plane in the space is determined by a point <span class="math inline">\(P_0\)</span> in the plane and a vector <span class="math inline">\(n\)</span> that is orthogonal to the plane. This orthogonal vector <span class="math inline">\(n\)</span> is called a <strong>normal vector</strong>.</p>
<p>Let <span class="math inline">\(P(x, y, z), P_0 (x_0, y_0, z_0)\)</span> be an arbitrary point in the plane, and let <span class="math inline">\(r_0\)</span> and <span class="math inline">\(r\)</span> be the position vectors of <span class="math inline">\(P_0\)</span> and <span class="math inline">\(P\)</span>. Then the vector <span class="math inline">\(r - r_0 = \vec{P_0 P}\)</span> is on the plane. The normal vector <span class="math inline">\(n = &lt;a, b, c&gt;\)</span> is orthogonal to every vector on the plane, that is:</p>
<p><span class="math display">\[n \cdot (r - r_0) = 0\]</span></p>
<p>We can rewrite this as:</p>
<p><span class="math display">\[n \cdot r = n \cdot r_0\]</span></p>
<p>Either of these equations are called a <strong>vector equation of the plane</strong>.</p>
<p>The <strong>scalar equation of the plane through <span class="math inline">\(P_0\)</span> with normal vector <span class="math inline">\(n\)</span></strong> can be written as:</p>
<p><span class="math display">\[&lt;a, b, c&gt; \cdot &lt;x - x_0, y - y_0, z - z_0&gt; = 0 \implies a (x - x_0) + b (y - y_0) + c (z - z_0) = 0\]</span></p>
<p>By collecting terms, we can have:</p>
<p><span class="math display">\[ax + by + cz + d = 0\]</span></p>
<p>Where <span class="math inline">\(d = -(ax_0 + by_0 + cz_0)\)</span>. If <span class="math inline">\(a, b, c\)</span> are not all zero, this equation can represent the plane.</p>
<p><br></p>
<p>Two planes are parallel if their normal vectors are parallel. If two planes are not parallel, then they intersact in a straight line and the angle between them is defined as the acute angle between their normal vectors.</p>
<h4 id="the-distance-to-plane">The distance to plane</h4>
<p><img src='/images/cal/12_5_3.png' width="600"></p>
<p>We know that the <span class="math inline">\(D = comp_n b = \frac{n \cdot b}{|n|}\)</span>, since the distance is positive, we need to find <span class="math inline">\(|comp_n b|\)</span>:</p>
<p><span class="math display">\[|D| = |comp_n b| = \frac{|n \cdot b|}{|n|}\]</span></p>
<p><img src='/images/cal/12_5_4.png' width="600"></p>
<h2 id="vector-functions">Vector Functions</h2>
<h3 id="vector-functions-and-space-curves">Vector Functions and Space Curves</h3>
<p>In general, a function is a rule that assigns to each element in the domain an element in the range. A <strong>vector-valued function</strong>, is simply a function whose domain is a set of real numbers and whose range is a set of vectors.</p>
<p>We are most interested in vector functions <span class="math inline">\(r\)</span> whose values are three-dimensional vectors. This means that for every number <span class="math inline">\(t\)</span> in the domain of <span class="math inline">\(r\)</span> three is a unique vector in <span class="math inline">\(V_3\)</span> denoted by <span class="math inline">\(r(t)\)</span>. If <span class="math inline">\(f(t), g(t), h(t)\)</span> are the components of the vector <span class="math inline">\(r(t)\)</span>, then <span class="math inline">\(f, g\)</span> and <span class="math inline">\(h\)</span> are real-valued functions called the <strong>component functions</strong> of <span class="math inline">\(r\)</span> and we can write:</p>
<p><span class="math display">\[r(t) = &lt;f(t), \;g(t), \;h(t)&gt;\]</span></p>
<p><br></p>
<p><img src='/images/cal/13_1_1.png' width="600"></p>
<p><br></p>
<p>if <span class="math inline">\(\lim_{t \rightarrow \infty} r(t) = L\)</span>, then this is equivalent to saying that the length and direction of the vector <span class="math inline">\(r(t)\)</span> approach the length and direction of the vector <span class="math inline">\(L\)</span>.</p>
<p>A vector function <span class="math inline">\(r\)</span> is continuous at <span class="math inline">\(a\)</span> if:</p>
<p><span class="math display">\[\lim_{t \rightarrow a} r(t) = r(a)\]</span></p>
<p>That is, <span class="math inline">\(r(t)\)</span> is continuous at <span class="math inline">\(a\)</span> if and only if all the components are continuous at <span class="math inline">\(a\)</span>.</p>
<h2 id="derivatives-and-integrals-of-vector-functions">Derivatives and Integrals of Vector Functions</h2>
<h3 id="derivatives">Derivatives</h3>
<p><img src='/images/cal/13_2_1.png' width="600"></p>
<p>If the limit exists, let <span class="math inline">\(P, Q\)</span> with position vector <span class="math inline">\(r(t), r(t + h)\)</span>, then <span class="math inline">\(r(t + h) - r(t)\)</span> is the vector between them, <span class="math inline">\(\frac{r(t + h) - r(t)}{h}\)</span> has same direction as <span class="math inline">\(r(t + h) - r(t)\)</span>. As <span class="math inline">\(h \rightarrow 0\)</span>, <span class="math inline">\(r(t + h)\)</span> gets closer to <span class="math inline">\(r(t)\)</span> so <span class="math inline">\(\frac{r(t + h) - r(t)}{h}\)</span> becomes the <strong>tangent vector</strong> to the curve defined by <span class="math inline">\(r\)</span> at the point <span class="math inline">\(P\)</span>.</p>
<p><img src='/images/cal/13_2_2.png' width="600"></p>
<p>The <strong>tangent line</strong> at <span class="math inline">\(P\)</span> is defined to be the line through <span class="math inline">\(P\)</span> parallel to the tangent vector <span class="math inline">\(r^{\prime}(t)\)</span></p>
<p><img src='/images/cal/13_2_3.png' width="600"></p>
<h4 id="differentiation-rules">Differentiation Rules</h4>
<p><img src='/images/cal/13_2_4.png' width="600"></p>
<h3 id="integrals">Integrals</h3>
<p><img src='/images/cal/13_2_5.png' width="600"></p>
<h2 id="arc-length-and-curvature">Arc Length and Curvature</h2>
<p>Suppose that the curve has the vector equation <span class="math inline">\(r(t) = &lt;f(t), g(t), h(t)&gt;, \; a\geq t \leq b\)</span>. The length of the space curve as t traverses exactly once from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span> can be shown:</p>
<p><span class="math display">\[L = \int^{b}_{a} \sqrt{[f^{\prime}(t)]^2 + [g^{\prime}(t)]^2 + [h^{\prime}(t)]^2} dt = \int^{b}_{a} |r^{\prime}(t)| dt\]</span></p>
<p>Where <span class="math inline">\(|r^\prime(t)| = \sqrt{[f^{\prime}(t)]^2 + [g^{\prime}(t)]^2 + [h^{\prime}(t)]^2}\)</span> is the length of tangent vector at any point defined by space curve <span class="math inline">\(r(t)\)</span>.</p>
<p><br></p>
<h3 id="reparameterize-a-curve-with-respect-to-arc-length">Reparameterize a curve with respect to arc length</h3>
<p>Let <span class="math inline">\(s(t)\)</span> be the arc length between point <span class="math inline">\(r(a), r(t)\)</span>:</p>
<p><span class="math display">\[s(t) = \int^{t}_{a} |r^{\prime}(u)| du\]</span></p>
<p>Then by the fundamental theorem of calculus, we have:</p>
<p><span class="math display">\[s^{\prime}(t) = |r^{\prime}(t)|\]</span></p>
<p>By calculating <span class="math inline">\(|r^{\prime} (t)|\)</span>, and <span class="math inline">\(s(t)\)</span> with <span class="math inline">\(t\)</span> as function of <span class="math inline">\(s\)</span>, we can reparameterize the space curve by <span class="math inline">\(r(t(s))\)</span>.</p>
<h2 id="curvature">Curvature</h2>
<p>A parameterization <span class="math inline">\(r(t)\)</span> is called <strong>smooth</strong> on an interval <span class="math inline">\(I\)</span> if <span class="math inline">\(r^{\prime}\)</span> is continuous and <span class="math inline">\(r^{\prime} (t) \neq 0\)</span> on <span class="math inline">\(I\)</span>.</p>
<p>A curve is called <strong>smooth</strong> if it has a smooth parametrization. A smooth curve has no sharp corners or cusps when the tangent vector turns, it does so continuously.</p>
<p><img src='/images/cal/13_3_1.png' width="600"></p>
<p>If <span class="math inline">\(C\)</span> is a smooth curve defined by the vector function <span class="math inline">\(r\)</span>, the unit tangent vector <span class="math inline">\(T(t)\)</span> is given by:</p>
<p><span class="math display">\[T(t) = \frac{r^{\prime} (t)}{|r(t)|}\]</span></p>
<p>and this indicates the direction of the curve.</p>
<p>The curvature of <span class="math inline">\(C\)</span> at a given point is a measure of how quickly the curve changes direction at that point. Specifically, we define it to be the magnitude of the rate of change of the unit tangent vector with respect to arc length.</p>
<p><img src='/images/cal/13_3_2.png' width="600"></p>
<p><br></p>
<p><span class="math display">\[\frac{dT}{dt} = \frac{dT}{ds} \frac{ds}{dt} \implies |\frac{dT}{ds}| = |\frac{\frac{dT}{dt}}{\frac{ds}{dt}}|\]</span></p>
<p>Remember <span class="math inline">\(\frac{ds}{dt} = |r^{\prime} (t)|\)</span>:</p>
<p><span class="math display">\[|\frac{dT}{ds}| = \frac{|T^{\prime} (t)|}{|r^{\prime} (t)|}\]</span></p>
<p>In general, the below formula is more convenient to apply:</p>
<p><img src='/images/cal/13_3_3.png' width="600"></p>
<p><br></p>
<p>In 2d case:</p>
<p><img src='/images/cal/13_3_4.png' width="600"></p>
<h2 id="the-normal-and-binormal-vectors">The Normal and Binormal Vectors</h2>
<p>Since <span class="math inline">\(|T(t)| = 1 \implies T(t) \cdot T(t) = 1\)</span>, we have:</p>
<p><span class="math display">\[\frac{T(t) \cdot T(t)}{t} = T^{\prime}(t) \cdot T(t) +  T^{\prime}(t) \cdot T(t) = 2 T^{\prime}(t)  \cdot T(t) = 0\]</span></p>
<p>Thus, <span class="math inline">\(T^{\prime} (t) \cdot T(t) = 0\)</span>. <span class="math inline">\(T^{\prime} (t)\)</span> is orthogonal to <span class="math inline">\(T(t)\)</span>. Note that <span class="math inline">\(T^{\prime} (t)\)</span> is itself not a unit vector. But at any point where <span class="math inline">\(k \neq 0\)</span> we can define the <strong>principal unit normal vector N(t)</strong> as:</p>
<p><span class="math display">\[N(t) = \frac{T^{\prime} (t)}{|T(t)|}\]</span></p>
<p>The vector <span class="math inline">\(B(t) = T(t) \times N(t)\)</span> is called the <strong>binormal vector</strong>. It is perpendicular to both <span class="math inline">\(T\)</span> and <span class="math inline">\(N\)</span> and is also a unit vector at particular point.</p>
<p><img src='/images/cal/13_3_5.png' width="600"></p>
<p><br></p>
<p>The plane determined by the normal and binormal vectors <span class="math inline">\(N\)</span> and <span class="math inline">\(B\)</span> at a point <span class="math inline">\(P\)</span> on a curve <span class="math inline">\(C\)</span> is called the <strong>normal plane</strong> of <span class="math inline">\(C\)</span> at <span class="math inline">\(P\)</span>. It consists of all lines that are orthogonal to the tangent vector <span class="math inline">\(T\)</span>.</p>
<p>The plane determined by the vectors <span class="math inline">\(T\)</span> and <span class="math inline">\(N\)</span> is called the <strong>osculating plane</strong> of <span class="math inline">\(C\)</span> at <span class="math inline">\(P\)</span>. It is the plane that comes closest to containing the part of the curve near <span class="math inline">\(P\)</span>.</p>
<p><img src='/images/cal/13_3_6.png' width="600"></p>
<h2 id="partial-derivatives">Partial Derivatives</h2>
<h3 id="functions-of-several-variables">Functions of Several Variables</h3>
<p><img src='/images/cal/14_1_1.png' width="600"></p>
<p>A function of two variables is just a function whose domain is a subset of <span class="math inline">\(\mathbb{R}^2\)</span> and whose range is subset of <span class="math inline">\(\mathbb{R}\)</span></p>
<p><img src='/images/cal/14_1_2.png' width="600"></p>
<p><img src='/images/cal/14_1_3.png' width="600"></p>
<p><img src='/images/cal/14_1_3.png' width="600"></p>
<p><br></p>
<p>A function of three variables, <span class="math inline">\(f\)</span>, is a rule that assigns to each ordered triple <span class="math inline">\((x, y, z)\)</span> in a domain <span class="math inline">\(D \in \mathbb{R}^3\)</span> a unique real number denoted by <span class="math inline">\(f(x, y, z)\)</span>.</p>
<p>In general, function of any number of variables can be considered. A <strong>function of n variables</strong> is a rule that assigns a number <span class="math inline">\(z = f(x_1, ...., x_n)\)</span> to an <span class="math inline">\(n\)</span>-tuple <span class="math inline">\((x_1, x_2, ..., x_n)\)</span> of real numbers. We denote by <span class="math inline">\(\mathbb{R}^{n}\)</span> the set of all such <span class="math inline">\(n\)</span>-tuples. Sometimes we will use vector notation to write such functions more compactly as <span class="math inline">\(f(\mathbf{x}), \quad \mathbf{x} = &lt;x_1, ....., x_n&gt;\)</span>.</p>
<p>In this view of the one to one correspondence between points <span class="math inline">\((x_1, ......, x_n)\)</span> in <span class="math inline">\(\mathbb{R}^n\)</span> and their position vectors <span class="math inline">\(\mathbf{x} = &lt;x_1, ....., x_n&gt;\)</span>. In general, we have three ways of looking at a function <span class="math inline">\(f\)</span> defined on a subset of <span class="math inline">\(\mathbb{R}^n\)</span>:</p>
<ol type="1">
<li>As a function of <span class="math inline">\(n\)</span> real variables <span class="math inline">\(x_1, ....., x_n\)</span></li>
<li>As a function of a single point variable <span class="math inline">\((x_1, ....., x_n)\)</span></li>
<li>As a single vector variable <span class="math inline">\(\mathbf{x} = &lt;x_1, ....., x_n&gt;\)</span></li>
</ol>
<h3 id="limits-and-continuity">Limits and Continuity</h3>
<p><img src='/images/cal/14_2_2.png' width="600"></p>
<p><img src='/images/cal/14_2_3.png' width="600"></p>
<p><img src='/images/cal/14_2_1.png' width="600"></p>
<h3 id="partial-derivatives-1">Partial Derivatives</h3>
<p>In general if <span class="math inline">\(f\)</span> is a function of two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, suppose we let only <span class="math inline">\(x\)</span> vary while keeping <span class="math inline">\(y=b\)</span> fixed. Then, we are really considering a function of a single variable <span class="math inline">\(x\)</span>, namely, <span class="math inline">\(g(x) = f(x, b)\)</span>. If <span class="math inline">\(g\)</span> has a derivative at <span class="math inline">\(a\)</span>, then we call it the partial derivative of <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(x\)</span> at <span class="math inline">\((a, b)\)</span> and denote it by <span class="math inline">\(f_x (a, b)\)</span>. Thus,</p>
<p><img src='/images/cal/14_3_1.png' width="600"></p>
<h4 id="geometry-view-of-partial-derivatives">Geometry View of Partial Derivatives</h4>
<p>We recall that the equation <span class="math inline">\(z = f(x, y)\)</span> represents a surface <span class="math inline">\(S\)</span> (the graph of <span class="math inline">\(f\)</span>) that maps points on <span class="math inline">\((x, y, 0)\)</span> to <span class="math inline">\((x, y, z)\)</span>. By fixing <span class="math inline">\(y=b\)</span>, we have a curve <span class="math inline">\(C_1\)</span> that is the vertical plane <span class="math inline">\(y=b\)</span> intersecting <span class="math inline">\(S\)</span>. Likewise, the vertical plane <span class="math inline">\(x=a\)</span> intersects <span class="math inline">\(S\)</span> in a curve <span class="math inline">\(C_2\)</span>, both of curves <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span> passes through the point <span class="math inline">\((a, b, z)\)</span>.</p>
<p><img src='/images/cal/14_3_2.png' width="600"></p>
<p>Thus, the partial derivatives <span class="math inline">\(f_x (a, b)\)</span> and <span class="math inline">\(f_y(a, b)\)</span> can be interpreted geometrically as the slopes of the tangent lines at <span class="math inline">\(P(a, b, z)\)</span> to the curves <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span> of <span class="math inline">\(S\)</span> in the planes <span class="math inline">\(y=b\)</span> and <span class="math inline">\(x=a\)</span></p>
<p><img src='/images/cal/14_3_3.png' width="600"></p>
<p>The partial derivatives can also be interpreted as <strong>rate of changes</strong>. If <span class="math inline">\(z = f(x, y)\)</span>, then <span class="math inline">\(f_x\)</span> represents the rate of change of <span class="math inline">\(f\)</span> or <span class="math inline">\(z\)</span> (<span class="math inline">\(z = f(x, y)\)</span>, to emphasize this is a function depends on <span class="math inline">\(x, y\)</span>) with respect to <span class="math inline">\(x\)</span> when <span class="math inline">\(y\)</span> is fixed.</p>
<p><img src='/images/cal/14_3_4.png' width="600"></p>
<h3 id="tangent-planes-and-linear-approximations">Tangent Planes and Linear Approximations</h3>
<h4 id="tangent-planes">Tangent Planes</h4>
<p>Suppose a surface <span class="math inline">\(S\)</span> (the graph of <span class="math inline">\(f(x, y)\)</span>) has equation <span class="math inline">\(z = f(x, y)\)</span>, where <span class="math inline">\(f\)</span> has continuous first partial derivative, and let <span class="math inline">\(P(x_0, y_0, z_0)\)</span> be a point on <span class="math inline">\(S\)</span>. Let <span class="math inline">\(C_1, C_2\)</span> be the curves obtained by intersecting the vertical planes <span class="math inline">\(y=y_0, \; x=x_0\)</span> (The curves are the graphs of <span class="math inline">\(f(x, y_0), \; f(x_0, y)\)</span>). Let <span class="math inline">\(T_1, T_2\)</span> be the tangent lines to the curves <span class="math inline">\(C_1, C_2\)</span> at point <span class="math inline">\(P\)</span>. Then the slopes of these tangent lines are the partial derivatives (<span class="math inline">\(f_x, f_y\)</span>) at point <span class="math inline">\(P\)</span>. Then the <code>tagent plane</code> to the surface <span class="math inline">\(S\)</span> at the point <span class="math inline">\(P\)</span> is defined to be the plane that contains both tangent lines <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span>.</p>
<p>If <span class="math inline">\(C\)</span> is any other curve that lies on the surface <span class="math inline">\(S\)</span> and passes through <span class="math inline">\(P\)</span>, then its tangent line at <span class="math inline">\(P\)</span> also lies in the tangent plane (plane contains of all possible tangent lies at <span class="math inline">\(P\)</span> to curves that lie on <span class="math inline">\(S\)</span> and pass through <span class="math inline">\(P\)</span>). <strong>The tangent plane at <span class="math inline">\(P\)</span> is the plane that most closely approximates the surface <span class="math inline">\(S\)</span> near the point <span class="math inline">\(P\)</span></strong>.</p>
<p>We know that any plane passing through the point <span class="math inline">\(P(x_0, y_0, z_0)\)</span> has an equation of the form:</p>
<p><span class="math display">\[A(x - x_0) + B(y - y_0) + C(z - z_0) = 0\]</span></p>
<p>By dividing this equation by <span class="math inline">\(C\)</span> and letting <span class="math inline">\(a = -\frac{A}{C}, \; b = -\frac{B}{C}\)</span>, we can rewrite:</p>
<p><span class="math display">\[z - z_0 = a(x - x_0) + b(y - y_0)\]</span></p>
<p>Then the intersection between the plane <span class="math inline">\(y = y_0\)</span> and the tangent plane at point <span class="math inline">\(P\)</span> must be the tangent line <span class="math inline">\(T_2\)</span> (<span class="math inline">\(y = y_0\)</span>):</p>
<p><span class="math display">\[z - z_0 = a(x - x_0)\]</span></p>
<p>We know that this is the equation of tangent line <span class="math inline">\(C_2\)</span> with slope <span class="math inline">\(a\)</span>, at the same time, we know that the slopes of this tangent line is the partial derivative at point <span class="math inline">\(P\)</span>:</p>
<p><span class="math display">\[a = f_x(x_0, y_0)\]</span></p>
<p>Similiar for <span class="math inline">\(C_1\)</span>, we have:</p>
<p><span class="math display">\[b = f_y(x_0, y_0)\]</span></p>
<p><img src='/images/cal/14_4_1.png' width="600"></p>
<h4 id="linear-approximation">Linear Approximation</h4>
<p>We know that the equation of the tangent plane to the graph of function <span class="math inline">\(f(x, y)\)</span> at point <span class="math inline">\(P\)</span> is:</p>
<p><span class="math display">\[z - z_0 = f_x(x_0, y_0) (x - x_0) + f_y(x_0, y_0) (y - y_0) \implies z - z_0 = f_x(x_0, y_0) (x - x_0) + f_y(x_0, y_0) (y - y_0) + f(x_0, y_0)\]</span></p>
<p>The linear function whose graph is the tangent plant, namely:</p>
<p><span class="math display">\[L(x, y) = f_x(x_0, y_0) (x - x_0) + f_y(x_0, y_0) (y - y_0) + f(x_0, y_0)\]</span></p>
<p>is called the <code>lineariation</code> of <span class="math inline">\(f\)</span> at <span class="math inline">\((x_0, y_0)\)</span> and the approximation at point <span class="math inline">\((x_0, y_0)\)</span></p>
<p><span class="math display">\[L(x, y) \approx f(x, y)\]</span></p>
<p>is called <code>linear approximation</code> of <span class="math inline">\(f\)</span> at point <span class="math inline">\((x_0, y_0)\)</span>.</p>
<p><br></p>
<p><img src='/images/cal/14_4_2.png' width="600"></p>
<p><img src='/images/cal/14_4_3.png' width="600"></p>
<p><br></p>
<h4 id="differentials">Differentials</h4>
<p>For a differentiable function of one variable <span class="math inline">\(y = f(x)\)</span>, we define the <code>differential</code> <span class="math inline">\(dx\)</span> to be an independent variable, that is, <span class="math inline">\(dx\)</span> can be given the value of any real number. The differential of y is then defined as:</p>
<p><span class="math display">\[dy = f^{\prime} (x)dx\]</span></p>
<p><img src='/images/cal/14_4_4.png' width="600"></p>
<p><br></p>
<p>For a differentiable function of two variables <span class="math inline">\(z = f(x, y)\)</span>, we define the <code>differentials</code> <span class="math inline">\(dx,\; dy\)</span> to be independent variables. Then the differential <span class="math inline">\(dz\)</span> which is also called <code>total differential</code> is defined by:</p>
<p><img src='/images/cal/14_4_5.png' width="600"></p>
<p>We can rewrite the differential of <span class="math inline">\(z\)</span> as the equation of tangent plane at point <span class="math inline">\(P\)</span> to the graph of function <span class="math inline">\(f\)</span> with</p>
<p><span class="math display">\[dz = \Delta z = z - z_0\]</span> <span class="math display">\[dy = \Delta y = y - y_0\]</span> <span class="math display">\[dx = \Delta x = x - x_0\]</span></p>
<p>Thus, the <code>linear approximation</code> equation can be rewrite in terms of differentials:</p>
<p><span class="math display">\[f(x, y) \approx z = f(a, b) + dz\]</span></p>
<h4 id="functions-of-three-or-more-variables">Functions of Three or More Variables</h4>
<p>Linear approximations, differentiability, and differentials can be defined in a similar manner for functions of more than two variables.</p>
<h3 id="the-chain-rule">The Chain Rule</h3>
<p><img src='/images/cal/14_5_1.png' width="600"> <img src='/images/cal/14_5_2.png' width="600"> <img src='/images/cal/14_5_3.png' width="600"></p>
<h4 id="implicit-differentiation">Implicit Differentiation</h4>
<p>Suppose we have function of the form <span class="math inline">\(F(x, y) = 0, \forall x \in \mathbb{D}\)</span>, where <span class="math inline">\(y = f(x)\)</span> is a function of <span class="math inline">\(x\)</span>. If <span class="math inline">\(F\)</span> is differentiable, <span class="math inline">\(\frac{\partial F}{\partial y} \neq 0\)</span>, then:</p>
<p><img src='/images/cal/14_5_5.png' width="600"></p>
<p>By <code>Implicit Differentiation Theorem</code>, this is valid only if:</p>
<ol type="1">
<li><span class="math inline">\(F\)</span> is defined on a disk containing <span class="math inline">\((a, b)\)</span>, where <span class="math inline">\(F(a, b) = 0, \; F_y (a, b) \neq 0\)</span></li>
<li><span class="math inline">\(F_x, \; F_y\)</span> is continuous on the disk</li>
</ol>
<p><br></p>
<p>Also, if we have function defined <span class="math inline">\(f (x, y, z) = 0, \; z = f(x, y)\)</span>:</p>
<p><img src='/images/cal/14_5_4.png' width="600"></p>
<h3 id="directional-derivatives-and-the-gradient-vector">Directional Derivatives and the Gradient Vector</h3>
<h4 id="directional-derivatives">Directional Derivatives</h4>
<p>We know that the paritial derivatives represent the rates of change of <span class="math inline">\(z\)</span> in the <span class="math inline">\(x, y\)</span> directions, that is, in the direction of unit vectors <span class="math inline">\(i, j\)</span>. Suppose that we know wish to find the rate of change of <span class="math inline">\(z\)</span> at <span class="math inline">\((x_0, y_0)\)</span> in the direction of an arbitrary unit vector <span class="math inline">\(\mathbf{u} = &lt;a, b&gt;\)</span>.</p>
<p>To do this, we consider a surface <span class="math inline">\(S\)</span> with equation <span class="math inline">\(z = f(x, y)\)</span> (the graph of <span class="math inline">\(f\)</span>) and we let <span class="math inline">\(z_0 = f(x_0, y_0)\)</span>, then the point <span class="math inline">\(P_0 (x_0, y_0, z_0)\)</span> lies on the surface <span class="math inline">\(S\)</span>. The vertical plane that passes through <span class="math inline">\(P\)</span> in the direction of <span class="math inline">\(\mathbf{u}\)</span> intersects <span class="math inline">\(S\)</span> in a curve <span class="math inline">\(C\)</span>. The slope of the tangent line <span class="math inline">\(T\)</span> to <span class="math inline">\(C\)</span> at point <span class="math inline">\(P\)</span> is the rate of change of <span class="math inline">\(z\)</span> in the direction of <span class="math inline">\(\mathbf{u}\)</span></p>
<p><img src='/images/cal/14_6_2.png' width="600"></p>
<p>If <span class="math inline">\(Q(x, y, z)\)</span> is another point on <span class="math inline">\(C\)</span> and <span class="math inline">\(P^{\prime}, Q^{\prime}\)</span> are the projections of <span class="math inline">\(P, Q\)</span> onto the <span class="math inline">\(x, y\)</span>-plane, then the vector <span class="math inline">\(\vec{P^{\prime}Q^{\prime}}\)</span> is parallel to <span class="math inline">\(\mathbf{u}\)</span> and:</p>
<p><span class="math display">\[\vec{P^{\prime}Q^{\prime}} = h \mathbf{u} = &lt;ha, hb&gt;\]</span></p>
<p>for some scalar <span class="math inline">\(h\)</span>. Therefore, <span class="math inline">\(\Delta x = x - x_0 = ha, \; \Delta y = y - y_0 = hb\)</span>:</p>
<p><span class="math display">\[\Delta z = z - z_0 = f(ha + x_0, hb + y_0) - f(x_0, y_0)\]</span></p>
<p><span class="math display">\[\frac{\Delta z}{h} = \frac{f(ha + x_0, hb + y_0) - f(x_0, y_0)}{h}\]</span></p>
<p><br></p>
<p>If we take limit to 0, we have the rate of change of <span class="math inline">\(z\)</span> with respect to distance in the direction of <span class="math inline">\(\mathbf{u}\)</span>, we call this the <code>directional derivative</code> of <span class="math inline">\(f\)</span> in the direction of <span class="math inline">\(\mathbf{u}\)</span>:</p>
<p><img src='/images/cal/14_6_1.png' width="600"></p>
<p><br></p>
<p>If we let <span class="math inline">\(\mathbf{u} = \mathbf{i} = &lt;1, \;0&gt;\)</span>, then we have <span class="math inline">\(D_i f = f_x\)</span>. If we let <span class="math inline">\(\mathbf{u} = \mathbf{j} = &lt;0, \;1&gt;\)</span>, then we have <span class="math inline">\(D_j f = f_y\)</span>. <strong>Partial derivatives are special cases of the directional derivative in the direction of x axis and y axis</strong></p>
<p><br></p>
<p><img src='/images/cal/14_6_3.png' width="600"></p>
<h4 id="the-gradient-vector">The Gradient Vector</h4>
<p>We can write the directional derivative formula as dot product:</p>
<p><span class="math display">\[D_u f(x, y) = f_x(x, y)a + f_y(x, y)b = \; &lt;f_x(x, y), \; f_y(x, y)&gt; \cdot \; \mathbf{u}\]</span></p>
<p>The first vector in the dot product is called the <code>gradient of f</code></p>
<p><img src='/images/cal/14_6_4.png' width="600"></p>
<p>Recall that, the scalar projection <span class="math inline">\(comp_a b = \frac{a \cdot b}{|a|}\)</span>, so the directional derivative can be interpreted as the <strong>scalar projection of gradient vector onto the unit vector <span class="math inline">\(u\)</span></strong>.</p>
<h4 id="functions-of-three-variables">Functions of Three Variables</h4>
<p>For functions of three variables, we can define directional derivatives similarly</p>
<p><img src='/images/cal/14_6_5.png' width="600"> <img src='/images/cal/14_6_6.png' width="600"></p>
<h4 id="maximizing-the-directional-derivative">Maximizing the Directional Derivative</h4>
<p>Suppose that we have a function <span class="math inline">\(f\)</span> of two or three variables, and we consider all possible directional derivatives of <span class="math inline">\(f\)</span> at a given point. These give the rates of change of <span class="math inline">\(f\)</span> in all possible directions. What is the maximum rate of change?</p>
<p>Recall that:</p>
<p><span class="math display">\[D_{\mathbf{u}} f = \nabla f \cdot \; \mathbf{u} = |\nabla f||\mathbf{u}| \cos \theta\]</span></p>
<p>When <span class="math inline">\(\theta = 0\)</span>, <span class="math inline">\(cos \;\theta = 1\)</span> and this is at its maximum. Thus:</p>
<p><span class="math display">\[\max D_{\mathbf{u}} f = |\nabla f|\]</span></p>
<p>The maximum of the directional derivatives is the length of gradient vector at the direction of gradient vector. Since, the slope or rate of change is positive, we have <strong><code>steepest increase</code></strong>.</p>
<p><img src='/images/cal/14_6_7.png' width="600"></p>
<p><br></p>
<h4 id="tangent-planes-to-level-surfaces">Tangent Planes to Level Surfaces</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a surface with equation <span class="math inline">\(F(x, y, z) = k\)</span>, that is, it is a level surface of a function <span class="math inline">\(F\)</span> of three variables, and let <span class="math inline">\(P(x_0, y_0, z_0)\)</span> be a point on <span class="math inline">\(S\)</span>. Let <span class="math inline">\(C\)</span> be any curve that lies on the surface <span class="math inline">\(S\)</span> and passes through the point <span class="math inline">\(P\)</span>. Recall that, the curve is described by a vector function <span class="math inline">\(r(t) = &lt;x(t), y(t), z(t)&gt;\)</span>. Let <span class="math inline">\(t_0\)</span> be the parameter value corresponding to <span class="math inline">\(P\)</span>. That is <span class="math inline">\(r(t_0) = P = &lt;x_0, y_0, z_0&gt;\)</span>. Since <span class="math inline">\(C\)</span> lies on <span class="math inline">\(S\)</span>, any point <span class="math inline">\((x(t), y(t), z(t))\)</span> must satisfy the equation of <span class="math inline">\(S\)</span>, that is:</p>
<p><span class="math display">\[F(x(t), y(t), z(t)) = k\]</span></p>
<p>If <span class="math inline">\(F, x, y, z\)</span> is differentiable w.r.t <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[\frac{dF}{dt} = \frac{\partial F \partial x}{\partial x \partial t} + \frac{\partial F \partial y}{\partial y \partial t} + \frac{\partial F \partial z}{\partial z \partial t} = 0\]</span></p>
<p>But, since <span class="math inline">\(\nabla F = &lt;F_x, F_y, F_z&gt;\)</span> and <span class="math inline">\(r^{\prime} (t) = &lt;x^{\prime} (t), y^{\prime} (t), z^{\prime} (t)&gt;\)</span>, we can rewrite the above equation as:</p>
<p><span class="math display">\[\nabla F \cdot r^{\prime} (t) = 0\]</span></p>
<p>Thus, <span class="math inline">\(\nabla F\)</span> is orthogonal to the tangent vector <span class="math inline">\(r^{\prime} (t)\)</span>, in particular at point <span class="math inline">\(P\)</span>:</p>
<p><span class="math display">\[\nabla F(x_0, y_0, z_0) \cdot r^{\prime} (t_0) = 0\]</span></p>
<p>So, if <span class="math inline">\(\nabla F(x_0, y_0, z_0) \neq 0\)</span>, it is natural to define the <code>tangent plane to the level surface</code> <span class="math inline">\(F(x, y, z) = k\)</span> at <span class="math inline">\(P(x_0, y_0, z_0)\)</span> as the plane that pass through <span class="math inline">\(P\)</span> that has normal vector <span class="math inline">\(\nabla F(x_0, y_0, z_0)\)</span>. Using the standard equation of a plane, we have:</p>
<p><span class="math display">\[F_x(x_0, y_0, z_0) (x - x_0) + F_y (x_0, y_0, z_0) (y - y_0) + F_z (x_0, y_0, z_0) (z - z_0) = 0\]</span></p>
<p>The <code>normal line</code> to <span class="math inline">\(S\)</span> at <span class="math inline">\(P\)</span> is the line passing through <span class="math inline">\(P\)</span> and perpendicular to the tangent plane. The direction of the normal line is therefore given by the gradient vector <span class="math inline">\(\nabla F(x_0, y_0, z_0)\)</span>.</p>
<p><img src='/images/cal/14_6_9.png' width="600"></p>
<p>Note that, the tangent plane equation for function of two variables can be derived from this more general form of equation:</p>
<p><img src='/images/cal/14_6_8.png' width="600"></p>
<p><br></p>
<p><img src='/images/cal/14_6_10.png' width="600"></p>
<p><img src='/images/cal/14_6_11.png' width="600"></p>
<h3 id="maximum-and-minimum-values">Maximum and Minimum Values</h3>
<p><img src='/images/cal/14_7_1.png' width="600"></p>
<p>If the inequalities in definition 1 hold for all points <span class="math inline">\((x, y)\)</span> in the domain of <span class="math inline">\(f\)</span>, then <span class="math inline">\(f\)</span> has an <code>absolute maximum or absolute minimum</code>at <span class="math inline">\((a, b)\)</span>.</p>
<p><br></p>
<p><img src='/images/cal/14_7_2.png' width="600"></p>
<p>If <span class="math inline">\(f_x(a, b) = 0, \; f_y (a, b) = 0\)</span>, then the tangent plane at point <span class="math inline">\((a, b)\)</span> is:</p>
<p><span class="math display">\[f_x(a, b) (x - a) + f_y (a, b) (y - b) - (z - z_0) = 0 \implies z = z_0\]</span></p>
<p>Thus, if <span class="math inline">\(f\)</span> has a local maximum or minimum at point <span class="math inline">\((a, b)\)</span>, then the tangent plane at this point on the graph must be horizontal (<span class="math inline">\(z = z_0\)</span>).</p>
<p>This point <span class="math inline">\((a, b)\)</span> is called <code>critical point or stationary point</code> of <span class="math inline">\(f\)</span> if <span class="math inline">\(f_x(a, b) = 0, \; f_y (a, b) = 0\)</span> (has gradient 0) or <strong>if one of these partial derivatives does not exist.</strong> All local maximum and minimum are critical points, however, not all critical points are local maximum or minimum.</p>
<p>Example:</p>
<blockquote>
<p>Consider the example <span class="math inline">\(f(x, y) = y^2 - x^2\)</span>, then <span class="math inline">\(f_x = -2x, \; f_y = 2y\)</span>. This implies there is only one critical point <span class="math inline">\((0, 0)\)</span> for function <span class="math inline">\(f\)</span>. We compute <span class="math inline">\(x &gt; 0\)</span> for <span class="math inline">\(y = 0\)</span>, we have <span class="math inline">\(f(x, y) &lt; 0\)</span>. If we compute <span class="math inline">\(y &gt; 0\)</span> for <span class="math inline">\(x = 0\)</span>, we have <span class="math inline">\(f(x, y) &gt; 0\)</span>. Thus, we do not have a minimum, or a maximum at this critical point.</p>
</blockquote>
<p><img src='/images/cal/14_7_3.png' width="600"></p>
<p><br></p>
<p>In this case, we have maximum in the direction of <span class="math inline">\(x\)</span> but minimum in the direction of <span class="math inline">\(y\)</span>, thus, we have a <code>saddle point</code> at <span class="math inline">\((0, 0)\)</span>.</p>
<p>In order to distinguish between critical points, we can use <code>second derivative test</code>:</p>
<p><img src='/images/cal/14_7_4.png' width="600"></p>
<p>Notes:</p>
<ol type="1">
<li>In case c, the point <span class="math inline">\((a, b)\)</span> is the saddle point of <span class="math inline">\(f\)</span> and the graph of <span class="math inline">\(f\)</span> crosses its tangent plane at <span class="math inline">\((a, b)\)</span>.</li>
<li>If <span class="math inline">\(D = 0\)</span>, the test is useless.</li>
<li><span class="math inline">\(D\)</span> is actually the determinant of the Hessian matrix</li>
</ol>
<h4 id="absolute-maximum-and-minimum-values">Absolute Maximum and Minimum Values</h4>
<p>A <code>bounded set</code> in <span class="math inline">\(\mathbb{R}^2\)</span> is one that is contained within some disk (less than and greater than some real numbers). In other words, it is finite in extent. A <code>close set</code> in <span class="math inline">\(\mathbb{R}^2\)</span> is one that contains all its boundary points.</p>
<p><img src='/images/cal/14_7_5.png' width="600"></p>
<p><img src='/images/cal/14_7_6.png' width="600"></p>
<h3 id="lagrange-multipliers">Lagrange Multipliers</h3>
<p><code>Lagrange's method</code> is used for maximizing or minimizing a general function <span class="math inline">\(f(x, y, z)\)</span> subject to a constraint of the form <span class="math inline">\(g(x, y, z) = k\)</span>. We start by considering function of two variables, <span class="math inline">\(f(x, y)\)</span> subject to constraint <span class="math inline">\(g(x, y) = k\)</span>. Recall that <span class="math inline">\(g(x, y) = k\)</span> is a level curve, that is we can think of the optimization problem as finding the extreme value of <span class="math inline">\(f(x, y)\)</span> when the points <span class="math inline">\((x, y)\)</span> are restricted on the level curve <span class="math inline">\(g(x, y) = k\)</span>. It is also equivalent to find the largest value of <span class="math inline">\(c\)</span> s.t the level curve <span class="math inline">\(f(x, y)=c\)</span> intersects with the level curve <span class="math inline">\(g(x, y) = k\)</span>. That is, when they have common tangent line and their gradient vectors are parallel:</p>
<p><span class="math display">\[\nabla f(x_0, y_0) = \lambda \nabla g(x_0, y_0)\]</span></p>
<p>This kind of argument also applies to the problem of finding the extreme values of <span class="math inline">\(f(x, y, z)\)</span> subject to <span class="math inline">\(g(x, y, z) = k\)</span>. Thus, the point <span class="math inline">\((x, y, z)\)</span> is restricted to lie on the level surface <span class="math inline">\(S\)</span> with equation <span class="math inline">\(g(x, y, z) = k\)</span>.</p>
<p><img src='/images/cal/14_8_1.png' width="600"></p>
<p>The number <span class="math inline">\(\lambda\)</span> is called <code>lagrange multiplier</code>. We assume that <span class="math inline">\(\nabla g \neq 0\)</span>.</p>
<h4 id="two-constraints">Two Constraints</h4>
<p>Suppose now we want to find the maximum and minimum values of a function <span class="math inline">\(f(x, y, z)\)</span> subject to two constraints <span class="math inline">\(g(x, y, z) = k, h(x, y, z) = c\)</span>. Geometrically, this means that we are looking for the extreme values of <span class="math inline">\(f\)</span> when <span class="math inline">\((x, y, z)\)</span> is restricted to lie on the curve of intersection <span class="math inline">\(C\)</span> of the level surfaces <span class="math inline">\(g(x, y, z) = k\)</span> and <span class="math inline">\(h(x, y, z) = c\)</span>.</p>
<p><img src='/images/cal/14_8_2.png' width="600"></p>
<p><img src='/images/cal/14_8_3.png' width="600"></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Calculus (2)</title>
    <url>/2021/07/06/cal-2/</url>
    <content><![CDATA[<h1 id="multivariate-calculus-2">Multivariate Calculus (2)</h1>
<h2 id="double-integrals">Double Integrals</h2>
<h3 id="double-integrals-over-rectangles">Double Integrals over Rectangles</h3>
<p>In a similar manner as definite integral, we consider a function <span class="math inline">\(f\)</span> of two variables defined on a closed rectangle:</p>
<p><span class="math display">\[R = [a, b] \times [c, d] = \{(x, y, z) \in \mathbb{R}^2 | a \leq x \leq b, c \leq y \leq d\}\]</span></p>
<p>and we first suppose that <span class="math inline">\(f(x, y) \leq 0\)</span>. The graph of <span class="math inline">\(f\)</span> is a surface with equation <span class="math inline">\(z = f(x, y)\)</span>. Let <span class="math inline">\(S\)</span> be the solid that lies above <span class="math inline">\(R\)</span> and under the graph of <span class="math inline">\(f\)</span>:</p>
<p><span class="math display">\[S = \{(x, y, z) \in \mathbb{R}^3 | a \leq x \leq b, c \leq y \leq d, 0 \leq z \leq f(x, y)\}\]</span></p>
<p>We first divide the <span class="math inline">\(R\)</span> into subrectangles. We accomplish this by dividing the interval <span class="math inline">\([a, b]\)</span> into <span class="math inline">\(m\)</span> subintervals <span class="math inline">\([x_{i-1}, x_{i}]\)</span> of equal width <span class="math inline">\(\Delta x = \frac{(b - a)}{m}\)</span> and dividing <span class="math inline">\([c, d]\)</span> into <span class="math inline">\(n\)</span> subintervals <span class="math inline">\([y_{j - 1}, y_j]\)</span> of equal width <span class="math inline">\(\Delta y = \frac{(d - c)}{n}\)</span>. Then the subrectangles are defined as:</p>
<p><span class="math display">\[R_{i, j} = [x_{i - 1}, x_i] \times [y_{j - 1}, y_j] = \{(x, y) | x_{i - 1} \leq x \leq x_i, y_{j - 1} \leq y leq y_j\}\]</span></p>
<p>Then the area of individual subrectangle is:</p>
<p><span class="math display">\[\Delta A = \Delta x \Delta y\]</span></p>
<p>If we choose a sample point <span class="math inline">\((x^{*}_{i, j}, y^{*}_{i, j}) \in R_{i, j}\)</span>, then we can approximate the part of <span class="math inline">\(S\)</span> that lies above each <span class="math inline">\(R_{i, j}\)</span> (The volume) by a column with height <span class="math inline">\(f(x^{*}_{i, j}, y^{*}_{i, j})\)</span> and base area <span class="math inline">\(\Delta A\)</span>. The volume of the column:</p>
<p><span class="math display">\[f(x^{*}_{i, j}, y^{*}_{i, j})\Delta A\]</span></p>
<p><img src='/images/cal/15_1_2.png' width="600"></p>
<p>Then the volume (<strong>only when <span class="math inline">\(f(x, y) \leq 0 \; \forall (x, y) \in S\)</span></strong>) of <span class="math inline">\(S\)</span> can be approximated:</p>
<p><span class="math display">\[V \approx \sum^{m}_{i=1} \sum^{n}_{j=1}f(x^{*}_{i, j}, y^{*}_{i, j})\Delta A\]</span></p>
<p>This sum is called <code>double Riemann sum</code>.</p>
<span id="more"></span>
<p>Then the approximation becomes better as <span class="math inline">\(n, m \rightarrow \infty\)</span>:</p>
<p><span class="math display">\[V = \lim_{n, m \rightarrow \infty} \sum^{m}_{i=1} \sum^{n}_{j=1}f(x^{*}_{i, j}, y^{*}_{i, j})\Delta A\]</span></p>
<p><img src='/images/cal/15_1_3.png' width="600"></p>
<p>A function <span class="math inline">\(f\)</span> is called <code>integrable</code> if the limit above exists, it can be showed that <strong>all continuous functions are integrable.</strong> If <span class="math inline">\(f\)</span> is bounded (<span class="math inline">\(\exists \; M, \; s.t \; |f(x, y)| \leq M, \; \forall (x, y) \in R\)</span>), then if <span class="math inline">\(f\)</span> is continuous there, except on a finite number of smooth curves, then <span class="math inline">\(f\)</span> is integrable over <span class="math inline">\(R\)</span>.</p>
<p><img src='/images/cal/15_1_4.png' width="600"></p>
<h2 id="iterated-integral">Iterated Integral</h2>
<p>Suppose that <span class="math inline">\(f\)</span> is a function of two variables that is integrable on the rectangle <span class="math inline">\(R = [a, b] \times [c, d]\)</span>. Now, <span class="math inline">\(\int^{d}_{c} f(x, y) dy\)</span> is a function that depends on the value of <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[A(x) = \int^{d}_{c} f(x, y) dy\]</span></p>
<p>If we now integrate the function <span class="math inline">\(A\)</span> w.r.t <span class="math inline">\(x\)</span> from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>, we have:</p>
<p><span class="math display">\[\int^{b}_{a} A(x) dx = \int^{b}_{a} \int^{d}_{c} f(x, y) dy dx\]</span></p>
<p>This integral on the right side is called <code>iterated integral</code> means that we first integrate w.r.t <span class="math inline">\(y\)</span> from <span class="math inline">\(c\)</span> to <span class="math inline">\(d\)</span>, then we integral w.r.t <span class="math inline">\(x\)</span> from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>.</p>
<p><img src='/images/cal/15_2_1.png' width="600"></p>
<p><br></p>
<p>If <span class="math inline">\(f(x, y)\)</span> can be factored s.t <span class="math inline">\(f(x, y) = g(x)h(y)\)</span>, then:</p>
<p><span class="math display">\[\int^{b}_{a} \int^{d}_{c} f(x, y) dy dx = \int^{b}_{a} g(x) dx \int^{d}_{c} h(y) dy\]</span></p>
<p><br></p>
<h2 id="double-integrals-over-general-regions">Double Integrals over General Regions</h2>
<p>We want to extend the previous idea from region of rectangle (<span class="math inline">\(R = [a, b] \times [c, d]\)</span>) to a bounded region <span class="math inline">\(D\)</span> (<span class="math inline">\(D\)</span> can be enclosed in a rectangular region <span class="math inline">\(R\)</span>) of more general shape. Then we define a new function <span class="math inline">\(F\)</span> with domain <span class="math inline">\(R\)</span> by:</p>
<p><span class="math display">\[
F(x, y)=
\begin{cases}
f(x, y), &amp; (x, y) \in D\\
0, \quad &amp; (x, y) \notin D \; \text{ but } \in R
\end{cases}
\]</span></p>
<p>If <span class="math inline">\(F\)</span> is integrable over <span class="math inline">\(R\)</span>, then we define the <code>double integral of $f$ over $D$</code> by:</p>
<p><span class="math display">\[\underset{D}{\int\int} f(x, y) dA = \underset{R}{\int\int} F(x, y) dA\]</span></p>
<p><img src='/images/cal/15_2_2.png' width="600"></p>
<p>This makes sense because:</p>
<ol type="1">
<li>The rectangle version has been previously defined.</li>
<li><span class="math inline">\(F(x, y) = 0\)</span> when <span class="math inline">\((x, y) \notin D\)</span>, so it contributes nothing to the integral.</li>
</ol>
<p>Notice here that <span class="math inline">\(D\)</span> might have discontinuities at the boundary points. However, if the boundary curve of <span class="math inline">\(D\)</span> is <code>well-behaved</code> ("Any function for which the mathematical theorem I am about to quote is true, only I don't remember exactly which functions these are"), it can be shown that <span class="math inline">\(\underset{R}{\int\int} F(x, y) dA\)</span> exists and <span class="math inline">\(\underset{D}{\int\int} f(x, y) dA\)</span> exists.</p>
<p>A plane region <span class="math inline">\(D\)</span> is said to be of <code>type I</code> if it lies between the graphs of two continuous function of <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[D = \{(x, y) | a \leq x \leq b, g_1(x) \leq y \leq g_2(x)\}\]</span></p>
<p>Where <span class="math inline">\(g_1\)</span>, <span class="math inline">\(g_2\)</span> are continuous on <span class="math inline">\([a, b]\)</span>.</p>
<p><img src='/images/cal/15_2_3.png' width="600"></p>
<p>Then:</p>
<p><img src='/images/cal/15_2_4.png' width="600"></p>
<p><br></p>
<p>A plane region <span class="math inline">\(D\)</span> is said to be of <code>type II</code> if it is defined as:</p>
<p><span class="math display">\[D = \{(x, y) | c \leq y \leq d, h_1(y) \leq x \leq h_2(y)\}\]</span></p>
<p>Where <span class="math inline">\(h_1, h_2\)</span> are continuous.</p>
<p><img src='/images/cal/15_2_5.png' width="600"></p>
<p>Then:</p>
<p><img src='/images/cal/15_2_6.png' width="600"></p>
<h3 id="properties-of-double-expectation">Properties of Double Expectation</h3>
<p><img src='/images/cal/15_1_5.png' width="600"></p>
<p>If <span class="math inline">\(D = D_1 \cup D_2\)</span> where <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span> don't overlap except perhaps on their boundaries, then:</p>
<p><span class="math display">\[\underset{D}{\int\int} f(x, y) dA = \underset{D_1}{\int\int} f(x, y) dA + \underset{D_2}{\int\int} f(x, y) dA\]</span></p>
<p>This property can be used to evaluate double integrals over regions <span class="math inline">\(D\)</span> that are neither <code>type I</code> nor <code>type II</code> by converting it to regions of type I or type II.</p>
<p><br></p>
<p>If we integrate the constant function <span class="math inline">\(f(x, y) = 1\)</span> over a region <span class="math inline">\(D\)</span>, we end up with the area of <span class="math inline">\(D\)</span>:</p>
<p><span class="math display">\[A(D) = \underset{D}{\int\int} 1 dA\]</span></p>
<p><img src='/images/cal/15_2_7.png' width="600"></p>
<h3 id="surface-area">Surface Area</h3>
<h3 id="triple-integral">Triple Integral</h3>
<h3 id="change-of-variable">Change of Variable</h3>
<h2 id="vector-and-matrix-differentiation">Vector and Matrix Differentiation</h2>
<h3 id="numerator-layout">Numerator Layout</h3>
<p>Let:</p>
<p><span class="math display">\[\mathbf{y} = \psi(\mathbf{x})\]</span></p>
<p>Where, <span class="math inline">\(\mathbf{x}, \mathbf{y}\)</span> are column vectors with size <span class="math inline">\(n, m\)</span> respectively. Then the partial derivative of <span class="math inline">\(\mathbf{y}\)</span> w.r.t <span class="math inline">\(\mathbf{x}\)</span> is a <span class="math inline">\(m \times n\)</span> matrix:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_1}{\partial x_2} &amp; .... &amp; \frac{\partial y_1}{\partial x_n}\\
.\\
.\\
.\\
\frac{\partial y_m}{\partial x_1} &amp; \frac{\partial y_m}{\partial x_2} &amp; .... &amp; \frac{\partial y_m}{\partial x_n}
\end{bmatrix}_{m \times n}
\]</span></p>
<p>This matrix is called the <code>Jacobian Matrix</code>. Notice that, each row of this matrix is a gradient vector <span class="math inline">\(\frac{\partial y_1}{\partial \mathbf{x}}\)</span>, thus, we can rewrite <code>Jacobian Matrix</code> as:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\nabla_{\mathbf{x}} y_1\\
.\\
.\\
.\\
\nabla_{\mathbf{x}} y_m
\end{bmatrix}_{m \times n}
\]</span></p>
<p>Notice that, single gradient vector <span class="math inline">\(\nabla_{\mathbf{x}} y_i\)</span> is a row vector, we can represent it as a column vector by</p>
<p><span class="math display">\[\nabla^T_{\mathbf{x}} y_i = \frac{\partial y_i}{\partial \mathbf{x}^T} = (\frac{\partial y_i}{\partial \mathbf{x}})^T\]</span></p>
<p>At the same time:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\frac{\partial \mathbf{y}}{\partial x_1} &amp; ..... &amp; \frac{\partial \mathbf{y}}{\partial x_n}\\
\end{bmatrix}
\]</span></p>
<p>Where:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial x_i} = 
\begin{bmatrix}
\frac{\partial y_1}{\partial x_i}\\
.\\
.\\
.\\
\frac{\partial y_m}{\partial x_i}
\end{bmatrix}
\]</span></p>
<h3 id="denominator-layout">Denominator Layout</h3>
<p><span class="math display">\[\mathbf{y} = \psi(\mathbf{x})\]</span></p>
<p>Where, <span class="math inline">\(\mathbf{x}, \mathbf{y}\)</span> are <strong>row</strong> vectors with size <span class="math inline">\(n, m\)</span> respectively. Then the partial derivative of <span class="math inline">\(\mathbf{y}\)</span> w.r.t <span class="math inline">\(\mathbf{x}\)</span> is a <span class="math inline">\(n \times m\)</span> matrix:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_2}{\partial x_1} &amp; .... &amp; \frac{\partial y_m}{\partial x_1}\\
.\\
.\\
.\\
\frac{\partial y_1}{\partial x_n} &amp; \frac{\partial y_2}{\partial x_n} &amp; .... &amp; \frac{\partial y_m}{\partial x_n}
\end{bmatrix}_{n \times m}
\]</span></p>
<p>In terms of gradient vectors (<strong>to be consistent with the layout, they are column vectors now. It is possible to represent gradient vectors as row vectors while using denominator layout just by adding transpose to the formula below</strong> ):</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\nabla_{\mathbf{x}} y_1 &amp; .... &amp; \nabla_{\mathbf{x}} y_m\\
\end{bmatrix}_{n \times m}
\]</span></p>
<p>At the same time:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\frac{\partial \mathbf{y}}{\partial x_1} \\
.\\
.\\
.\\
\frac{\partial \mathbf{y}}{\partial x_n}\\
\end{bmatrix}
\]</span></p>
<p>Where <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial x_i}\)</span> is now a row vector:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial x_i} = 
\begin{bmatrix}
\frac{\partial y_1}{\partial x_i} &amp; .... &amp; \frac{\partial y_m}{\partial x_i}\\
\end{bmatrix}_{n \times m}
\]</span></p>
<p><br></p>
<h3 id="derivative-of-function-of-the-form-mathbfy-amathbfx">Derivative of Function of the Form: <span class="math inline">\(\; \mathbf{y} = A\mathbf{x}\)</span></h3>
<p><img src='/images/cal/matrix_5_2_1.png' width="600"></p>
<p><br></p>
<p><strong>Proof</strong>:</p>
<blockquote>
<p>Since <span class="math inline">\(y_i = \sum^{n}_{k=1} a_{ik} x_k \implies \frac{\partial y_i}{\partial x_j} = a_{ij}\)</span></p>
<p>Thus, the <code>Jacobian Matrix</code> is:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = 
\begin{bmatrix}
\nabla_{\mathbf{x}} y_1\\
.\\
.\\
.\\
\nabla_{\mathbf{x}} y_m
\end{bmatrix}_{m \times n}
= A
\]</span></p>
</blockquote>
<p><br></p>
<p>Now, let <span class="math inline">\(\mathbf{x} = f(\mathbf{\alpha})\)</span>, where <span class="math inline">\(\mathbf{\alpha}\)</span> is a <span class="math inline">\(r\)</span> dimensional vector, then the above results can be extended using chain rule:</p>
<p><span class="math display">\[\frac{\partial \mathbf{y}}{\partial \mathbf{r}} = \frac{\partial \mathbf{y}}{\partial \mathbf{x}}\frac{\partial \mathbf{x}}{\partial \mathbf{\alpha}} = [A \frac{\partial \mathbf{x}}{\partial \mathbf{\alpha}}]_{m \times r}\]</span></p>
<p><br></p>
<p><strong>Proof</strong>:</p>
<blockquote>
<p>Since <span class="math inline">\(y_i = \sum^{n}_{k=1} a_{ik} x_k(\alpha_1, ...., \alpha_r) \implies \frac{\partial y_i}{\partial r_j} = \sum^{n}_{k=1} a_{ik} \frac{\partial y_i}{\partial x_k}\frac{\partial x_k}{\partial \alpha_j} = \sum^{n}_{k=1} a_{ik} \frac{\partial x_k}{\partial \alpha_j}\)</span></p>
<p>Thus, the <code>Jacobian Matrix</code> is:</p>
<p><span class="math display">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{\alpha}} = 
\begin{bmatrix}
\sum^{n}_{k=1} a_{1k} \frac{\partial x_k}{\partial \alpha_1} &amp; ... &amp; \sum^{n}_{k=1} a_{1k} \frac{\partial x_k}{\partial \alpha_r}\\
.\\
.\\
.\\
\sum^{n}_{k=1} a_{mk} \frac{\partial x_k}{\partial \alpha_1} &amp; ... &amp; \sum^{n}_{k=1} a_{mk} \frac{\partial x_k}{\partial \alpha_r}
\end{bmatrix}_{m \times n}
= [A \frac{\partial \mathbf{x}}{\partial \mathbf{\alpha}}]_{m \times r}
\]</span></p>
</blockquote>
<p><br></p>
<h1 id="ref">Ref</h1>
]]></content>
  </entry>
  <entry>
    <title>Backpropagation in CNN</title>
    <url>/2021/07/18/cnn/</url>
    <content><![CDATA[<h1 id="backpropagation-in-convolutional-neural-networks">Backpropagation In Convolutional Neural Networks</h1>
<h2 id="cross-correlation">Cross Correlation</h2>
<p>Given an input image <span class="math inline">\(I\)</span> and a filter <span class="math inline">\(K\)</span> of dimensions <span class="math inline">\(k_1 \times k_2\)</span>, then the cross correlation operation is defined as:</p>
<p><span class="math display">\[(I \otimes K)_{ij} = \sum^{k_2 - 1}_{m=0}\sum^{k_1 - 1}_{n=0} I(i + m, j + n)K(m, n)\]</span></p>
<h2 id="convolution">Convolution</h2>
<p><span class="math display">\[(I * K)^{d}_{ij} = \sum^{k_2 - 1}_{m=0}\sum^{k_1 - 1}_{n=0} I(i - m, j - n)K(m, n)\]</span></p>
<p>which is equivalent to <code>cross correlation</code> with flipped kernel (i.e flipped 180 degree)</p>
<p><span class="math display">\[(I * K)_{ij} = \sum^{k_2 - 1}_{m=0}\sum^{k_1 - 1}_{n=0} I(i + m, j + n) \text{ rot}_{180}(K(m, n))\]</span></p>
<span id="more"></span>
<h2 id="cnns">CNNs</h2>
<p>a Convolution layer consists of:</p>
<ol type="1">
<li>An input map <span class="math inline">\(I \in \mathbb{R}^{H \times W \times C}\)</span> with height <span class="math inline">\(H\)</span>, width <span class="math inline">\(W\)</span>, channels <span class="math inline">\(H\)</span>.</li>
<li>A bank of <span class="math inline">\(D\)</span> filters <span class="math inline">\(K \in \mathbb{R}^{k_1 \times k_2 \times D}\)</span>.</li>
<li>Bias <span class="math inline">\(b \in \mathbb{R}^{D}\)</span> (one for each filter).</li>
<li>An activation function <span class="math inline">\(f\)</span> apply element-wise.</li>
</ol>
<p>In general, the forward output of applying filter <span class="math inline">\(d\)</span> on the input map is:</p>
<p><span class="math display">\[(I * K^d)_{ij} = \sum^{k_2 - 1}_{m=0}\sum^{k_1 - 1}_{n=0} \sum^{C}_{n=1}I(i + m, j + n, c) \cdot \text{ rot}_{180}(K^d(m, n, c)) + b\]</span></p>
<p>However, in CNN, we do not care about the arrangement of filters (i.e whether it is flipped or not), because the weights are going to be learned regardless of the arrangement of the filters. Thus, we can safely ignore the flip and treat the convolution operation as cross correlation:</p>
<p><span class="math display">\[(I * K^d)_{ij} = \sum^{k_2 - 1}_{m=0}\sum^{k_1 - 1}_{n=0} \sum^{C}_{n=1}I(i + m, j + n, c) \cdot K^d(m, n, c) + b\]</span></p>
<p>For the simplicity, we focus on <span class="math inline">\(2d\)</span> case first (i.e we focus on gray scale image with <span class="math inline">\(C = 1\)</span>) and only one filter:</p>
<p><span class="math display">\[(I * K)_{ij} = \sum^{k_2 - 1}_{m=0}\sum^{k_1 - 1}_{n=0} I(i + m, j + n)K(m, n)\]</span></p>
<h3 id="notations">Notations</h3>
<ol type="1">
<li><span class="math inline">\(l\)</span> is the <span class="math inline">\(l\)</span>th layer, where <span class="math inline">\(l = 1\)</span> is the first layer, <span class="math inline">\(L\)</span> is the last layer.</li>
<li>Input <span class="math inline">\(\mathbf{x}\)</span> has dimension <span class="math inline">\(H \times W\)</span>.</li>
<li>The filter weight at each layer is denoted as <span class="math inline">\(w^l_{m, n}, \; 0 \leq m &lt; k^l_1, \; 0 \leq n &lt; k^l_2\)</span></li>
<li>The convolved input at each layer is denoted as <span class="math inline">\(y^{l}_{ij}\)</span>: <span class="math display">\[y^{l}_{i, j} = \sum^{k^l_2 - 1}_{m=0}\sum^{k^l_1 - 1}_{n=0} w^{l}_{m, n} x^{l - 1}_{i+m, j+n} + b^l\]</span></li>
<li>The output of each convolution layer after applying the activation function is denoted as: <span class="math display">\[x^{l}_{ij} = f(y^{l}_{i, j})\]</span></li>
</ol>
<h3 id="forward-pass">Forward Pass</h3>
<p>The forward pass is essential characterized above:</p>
<p><img src="/images/ML/cnn.gif" width="600"></p>
<h3 id="backward-pass">Backward Pass</h3>
<p>Let the mean square loss be defined as:</p>
<p><span class="math display">\[L = \frac{1}{N} \sum^{N}_{i=1} (t_i - y^L_i)^2\]</span></p>
<p>Where <span class="math inline">\(y^L_i\)</span> is the prediction from the final layer and <span class="math inline">\(t_i\)</span> is the target value.</p>
<p>In backward propagation, we are seeking to compute the gradient of loss w.r.t the weights <span class="math inline">\(\frac{\partial L}{\partial w^{l}_{m, n}}\)</span> for each layer, and the gradient w.r.t the output map to each layer <span class="math inline">\(\frac{\partial L}{\partial y^l_{i, j}}\)</span>.</p>
<h4 id="gradient-of-the-weights">Gradient of the Weights</h4>
<p>Since, the output map <span class="math inline">\(\mathbf{y}^l\)</span> will have dimension <span class="math inline">\(H^{l} = H^{l - 1} - k^l_{1} + 1\)</span>, <span class="math inline">\(W^{l} = W^{l - 1} - k^{l}_2 + 1\)</span> (<span class="math inline">\(\mathbf{y}^{l}\)</span> is reshaped to be a <span class="math inline">\(H^{l} W^{l} \times 1\)</span> vector)</p>
<span class="math display">\[\begin{aligned}
\frac{\partial L}{\partial  w^{l}_{m^{\prime}, n^{\prime}}} &amp;= \frac{\partial L}{\partial \mathbf{y}^l} \frac{\partial \mathbf{y}^{l}}{\partial  w^{l}_{m^{\prime}, n^{\prime}}}\\
&amp;= \sum^{H^{l} - 1}_{i=0} \sum^{W^{l} - 1}_{j=0}\frac{\partial L}{\partial y^l_{i, j}}\frac{\partial y_{i, j}^{l}}{\partial  w^{l}_{m^{\prime}, n^{\prime}}}\\
\end{aligned}\]</span>
<p>By expanding <span class="math inline">\(\frac{\partial y_{i, j}^{l}}{\partial w^{l}_{m^{\prime}, n^{\prime}}}\)</span> we have:</p>
<span class="math display">\[\begin{aligned}
\frac{\partial y_{i, j}^{l}}{\partial  w^{l}_{m^{\prime}, n^{\prime}}} &amp;=  \frac{\partial}{\partial  w^{l}_{m^{\prime}, n^{\prime}}}\sum^{k^l_2 - 1}_{m=0}\sum^{k^l_1 - 1}_{n=0} w^{l}_{m, n} x^{l - 1}_{i+m, j+n} + b^l\\
&amp;= x^{l - 1}_{i + m^{\prime}, j + n^{\prime}}
\end{aligned}\]</span>
<p>By substituting the above result back to the previous gradient equation we have:</p>
<p><span class="math display">\[\frac{\partial L}{\partial  w^{l}_{m^{\prime}, n^{\prime}}} = \sum^{H^{l} - 1}_{i=0} \sum^{W^{l} - 1}_{j=0}\frac{\partial L}{\partial y^l_{i, j}} x^{l - 1}_{i + m^{\prime}, j + n^{\prime}}\]</span></p>
<p>We can see that this is the convolution (cross correlation) of gradient of activations on the input feature map:</p>
<p><span class="math display">\[\frac{\partial L}{\partial  w^{l}_{m^{\prime}, n^{\prime}}} = (X^{l - 1} \otimes \frac{\partial L}{\partial \mathbf{y}^l})_{m^{\prime}, n^{\prime}}\]</span></p>
<p>Where <span class="math inline">\(\frac{\partial L}{\partial \mathbf{y}^l}\)</span> is reshaped to a <span class="math inline">\(H^l \times W^l\)</span> matrix.</p>
<h4 id="gradients-of-the-inputs">Gradients of the Inputs</h4>
<p>Recall that, <span class="math inline">\(\mathbf{x}^l = f(\mathbf{y}^l)\)</span>, so they have same dimensions.</p>
<span class="math display">\[\begin{aligned}
\frac{\partial L}{\partial y^l_{i, j}} &amp;= \frac{\partial L}{\partial \mathbf{x}^l} \frac{\partial \mathbf{x}^l}{\partial y_{i, j}^l}\\
&amp;= \sum^{H^{l} - 1}_{i=0} \sum^{W^{l} - 1}_{j=0} \frac{\partial L}{\partial x^l_{i, j}} f^{\prime} (y^l_{i, j})\\
\\
\frac{\partial L}{\partial x^l_{i^{\prime}, j^{\prime}}} &amp;= \frac{\partial L}{\partial \mathbf{y}^{l + 1}} \frac{\partial \mathbf{y}^{l + 1}}{\partial x^l_{i^{\prime}, j^{\prime}}}\\
&amp;= \sum^{H^{l + 1} - 1}_{i=0} \sum^{W^{l + 1} - 1}_{j=0} \frac{\partial L}{\partial y^{l + 1}_{i^{\prime} - m, j^{\prime} - n}} w^{l + 1}_{m, n}
\end{aligned}\]</span>
<p>This is exactly as the full convolution (or correlation with flipped kernel, notice here, we have to flip the kernel):</p>
<p><span class="math display">\[\frac{\partial L}{\partial x^l_{i^{\prime}, j^{\prime}}} = (\frac{\partial L}{\partial \mathbf{y}^{l + 1}} * W^{l + 1} )_{i^{\prime}, j^{\prime}}\]</span></p>
<p>Where <span class="math inline">\(W^{l + 1}\)</span> and <span class="math inline">\(\frac{\partial L}{\partial \mathbf{y}^{l + 1}}\)</span> are reshaped into matrices.</p>
<p><img src="/images/ML/cnn_2.gif" width="600"></p>
<h2 id="implementation">Implementation</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params">images, kernel, bias, p, s</span>):</span></span><br><span class="line">    n, c_in, h_in, w_in = images.shape</span><br><span class="line">    c_out, c_in, k, _ = kernel.shape</span><br><span class="line">    h_out = (h_in + <span class="number">2</span> * p - k) // <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">    w_out = (w_in + <span class="number">2</span> * p - k) // <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">    <span class="comment"># add padding</span></span><br><span class="line">    pad_image = np.pad(images, [(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>), (p, p), (p, p)])</span><br><span class="line">    out_images = np.zeros((n, c_out, h_out, w_out))</span><br><span class="line">    _, _, pad_image_h, pad_image_w = pad_image.shape</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(c_out):</span><br><span class="line">            y_idx = out_y = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> y_idx + k &lt;= pad_image_w:</span><br><span class="line">                x_idx = out_x = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> x_idx + k &lt;= pad_image_h:</span><br><span class="line">                    out_images[i, j, out_x, out_y] = \</span><br><span class="line">                        np.<span class="built_in">sum</span>(pad_image[i, :, y_idx:y_idx+k, x_idx:x_idx+k] * kernel[i]) + bias[j]</span><br><span class="line">                    x_idx += s</span><br><span class="line">                    out_x += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                y_idx += s</span><br><span class="line">                out_y += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out_images</span><br></pre></td></tr></table></figure>
<h2 id="ref">Ref</h2>
<p>https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/</p>
<p>https://medium.com/<span class="citation" data-cites="pavisj/convolutions-and-backpropagations-46026a8f5d2c">@pavisj/convolutions-and-backpropagations-46026a8f5d2c</span></p>
]]></content>
      <categories>
        <category>DL</category>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Cheat Sheet</title>
    <url>/2021/05/18/cheat-sheet/</url>
    <content><![CDATA[<h1 id="cheat-sheet">Cheat Sheet</h1>
<h2 id="permutation-and-combination">Permutation and Combination</h2>
<p>Number of permutations for <span class="math inline">\(n\)</span> people and <span class="math inline">\(k\)</span> chairs:</p>
<p><span class="math display">\[nPk = \frac{n!}{(n - k)!}\]</span></p>
<p><span class="math display">\[nCk = \frac{nPk}{k!} = \frac{n!}{k! (n - k)!}\]</span></p>
<h2 id="rl">RL</h2>
<p><span class="math display">\[Q^{\pi} (s, a) = E_s^{\prime} [r + \gamma E_{a^{\prime}}[Q(s^{\prime}, a^{s^{\prime}}) | s^{\prime}] | s, a, \pi]\]</span></p>
<p><span class="math display">\[V^{*} (s) = max_{a} Q^{*} (s, a)\]</span></p>
<p><span class="math display">\[Q^{*} (s, a) = max_{\pi} Q^{\pi} (s, a), \forall (s, a) \in S X A\]</span></p>
<p><span class="math display">\[V^{\pi} (s) = E_{a_t \sim pi(\cdot | s)}[R_t | s_t=s, \pi] = E_{a_t \sim pi(\cdot | s)}[E[R_t | s_t, a_t, \pi] | s_t=s] = E_{a_t \sim pi(\cdot | s)}[ Q^{\pi}(s, a_t)]\]</span></p>
<p><span class="math display">\[A^{\pi} (s, a) = Q^{\pi} (s, a) - V^{\pi} (s)\]</span></p>
<p><span class="math display">\[E_{a}[A^{\pi} (s, a) | s] = E_{a}[Q^{\pi} (s, a) | s] - V^{\pi} (s) = 0\]</span></p>
<p><span class="math display">\[E_{s^{\prime}}[R_t + \gamma V^{\pi}(s^{\prime}) - V^{\pi} (s)] = A^{\pi}(s, a)\]</span></p>
<span class="math display">\[\begin{aligned}
Q (s, a) + \delta (s, a; \pi) &amp;= Q(s, a) + \hat{T}^{\pi} Q(s, a) - Q(s, a)\\
&amp; = R + \gamma Q(s^{\prime}, a^{\prime})
\end{aligned}\]</span>
<h2 id="ml">ML</h2>
<p>True Positive Rate (<strong>Sensitivity</strong> or <strong>Recall</strong>):</p>
<p><span class="math display">\[\frac{TP}{TP + FN}\]</span></p>
<p>Specificity:</p>
<p><span class="math display">\[\frac{TN}{TN + FP}\]</span></p>
<p>False Positive Rate (<strong>1 - specificity</strong>):</p>
<p><span class="math display">\[\frac{FP}{TN + FP}\]</span></p>
<p>Precision:</p>
<p><span class="math display">\[\frac{TP}{TP + FP}\]</span></p>
<p>Accuracy:</p>
<p><span class="math display">\[\frac{TP + TN}{TP + TN + FP + FN}\]</span></p>
<p>F-score:</p>
<p><span class="math display">\[2 * \frac{Precision * Recall}{Precision + Recall}\]</span></p>
]]></content>
      <categories>
        <category>RL</category>
        <category>ML</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>ML Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>convex_opt</title>
    <url>/2021/06/14/convex-opt/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Decision Trees</title>
    <url>/2021/07/19/decision-trees/</url>
    <content><![CDATA[<h1 id="decision-trees-cart">Decision Trees (CART)</h1>
<p>Tree based methods partition the feature space into a set of rectangles, and then fit a simple model (i.e constant) in each one. We focus on CART in this post.</p>
<p>Suppose we have dataset <span class="math inline">\(D = \{(\mathbf{x}_1, y_1) , ...., (\mathbf{x}_N, y_N) ;\; \mathbf{x}_i \in \mathbb{R}^d\}\)</span>. The algorithm needs to automatically decide on the <strong>splitting variables</strong> and <strong>splitting points</strong> and also what shape the tree should have.</p>
<h2 id="regression-trees">Regression Trees</h2>
<p>In this scenario, our response variable <span class="math inline">\(Y\)</span> is continuous. Suppose first that we have a partition into <span class="math inline">\(M\)</span> regions <span class="math inline">\(R_1, ...., R_M\)</span> and we define the <strong>model prediction</strong> as:</p>
<p><span class="math display">\[\hat{y} = \sum^{M}_{m=1} c_m I[\mathbf{x}_i \in R_m]\]</span></p>
<p>By minimizing the mean square loss <span class="math inline">\(\frac{1}{2} \frac{1}{N} \sum^{N}_{i=1} (y_i - \hat{y}_i)^2\)</span>, we have:</p>
<span class="math display">\[\begin{aligned}
\frac{\partial L}{\partial c_m} &amp;= \frac{1}{N}\sum^{N}_{i=1} (y_i -  \sum^{M}_{m=1} c_m I[\mathbf{x}_i \in R_m]) I[\mathbf{x}_i \in R_m]\\
&amp;= \frac{1}{N_m}\sum^{N}_{i=1} (y_i I[\mathbf{x}_i \in R_m]) - c_m\\
\implies \hat{c}_m &amp;= \frac{1}{N_m}\sum^{N}_{i=1} (y_i I[\mathbf{x}_i \in R_m])
\end{aligned}\]</span>
<p>Thus, the best estimate <span class="math inline">\(\hat{c}_m\)</span> in each region is the <strong>average training responses</strong> in that region w.r.t mean square error:</p>
<p><span class="math display">\[\hat{c}_m = \frac{1}{N_m} \sum^{N}_{i=1} y_i I[\mathbf{x}_i \in R_m]\]</span></p>
<p>Where <span class="math inline">\(N_m = \sum^{N}_{i=1} I[\mathbf{x}_i \in R_m]\)</span>, is total training examples in region <span class="math inline">\(R_m\)</span>.</p>
<span id="more"></span>
<h3 id="best-splitting-point">Best Splitting Point</h3>
<p>Now, finding the binary partition in terms of minimum sum of squares is generally computational infeasible. However, we can use a greedy algorithm that starts with all of the data, considering every splitting variable <span class="math inline">\(j\)</span> and splitting point <span class="math inline">\(s\)</span> and find the pair that minimize the particular loss:</p>
<ul>
<li><p>Every pair of splitting point <span class="math inline">\(j\)</span> and split point <span class="math inline">\(s\)</span> define the pair of half-planes:</p>
<ul>
<li><span class="math inline">\(R_1(j, s) = \{\mathbf{x} | x_j \leq s\}\)</span> (all samples that have <span class="math inline">\(j\)</span>th feature less than or equal to <span class="math inline">\(s\)</span>)</li>
<li><span class="math inline">\(R_2(j, s) = \{\mathbf{x} | x_j &gt; s\}\)</span> (all samples that have <span class="math inline">\(j\)</span>th feature greater than <span class="math inline">\(s\)</span>)</li>
</ul></li>
<li><p>For each half-plane, we find the best estimate that will minimize the mean square loss in that region: <span class="math display">\[\hat{c}_1 = \underset{c_1}{\arg\min} \frac{1}{N_{1}}\sum_{x_i \in R_1 (j, s)} (y_i - c_1)^2\]</span> <span class="math display">\[\hat{c}_2 = \underset{c_2}{\arg\min} \frac{1}{N_{2}}\sum_{x_i \in R_2 (j, s)} (y_i - c_2)^2\]</span></p>
<p>From previous results, we know that the minimizers are the average training responses in these regions, that is:</p>
<p><span class="math display">\[\hat{c}_1 = \frac{1}{N_1} \sum_{x_i \in R_1 (j, s)} y_i I[\mathbf{x}_i \in R_1] \quad \quad \hat{c}_2 = \frac{1}{N_2} \sum_{x_2 \in R_2 (j, s)} y_i I[\mathbf{x}_i \in R_2]\]</span></p></li>
<li><p>For any choice of <span class="math inline">\((j, s)\)</span>, we seek to minimize the overall objective:</p>
<p><span class="math display">\[\min_{j, s} [\frac{1}{N_{1}}\sum_{x_i \in R_1 (j, s)} (y_i - \hat{c}_1)^2 + \frac{1}{N_{2}}\sum_{x_i \in R_2 (j, s)} (y_i - \hat{c}_2)^2]\]</span></p></li>
<li><p>This optimization problem can be solved by scanning through all positive pair of <span class="math inline">\((j, s)\)</span> very quickly. Having found the best split, we partition the data into two regions and repeat this finding procedure until stopping signal received.</p></li>
</ul>
<p><br></p>
<h3 id="cost-complexity-pruning">Cost Complexity Pruning</h3>
<p>How large should the tree grow? Clearly, a large tree will overfit the training set while a small tree might not capture the important structure. <strong>Tree size</strong> is a tuning parameter governing the model's complexity, and the optimal tree size should be adaptively chosen from the data.</p>
<p>The preferred strategy is to grow a large tree <span class="math inline">\(T_0\)</span>, stopping the splitting process only until some stopping signals, then pruned the large tree using <code>cost-complexity pruning</code>.</p>
<p>We define a subtree <span class="math inline">\(T \in T_0\)</span> to be any tree that can be obtained by pruning <span class="math inline">\(T_0\)</span>, that is, collapsing any number of its internal (non-leave) nodes (set the nodes as leaves). The idea is to find, for each <span class="math inline">\(\alpha\)</span> the subtree <span class="math inline">\(T_\alpha \subset T_0\)</span> to minimize the objective:</p>
<p><span class="math display">\[C_{\alpha} (T) = \sum^{|T|}_{m=1} \sum_{x_i \in R_m} (y_i - \hat{c}_m)^2 + \alpha |T|\]</span></p>
<p>Where <span class="math inline">\(|T|\)</span> represents current number of leaves, <span class="math inline">\(\alpha |T|\)</span> is the penalty term that trades off tree size and goodness of fit.</p>
<h3 id="hyperparameters">Hyperparameters:</h3>
<ol type="1">
<li><strong>Tree size</strong>: <span class="math inline">\(\;\)</span> Governing the tree's complexity.</li>
<li><strong>Minimum decease in loss from split</strong>: <span class="math inline">\(\;\)</span>Split tree nodes only if the decrease in sum of squares due to the split exceeds some threshold. However, this approach is short-sighted because a seemingly worthless split might lead to a very good split below it.</li>
<li><strong>Minimum or maximum leave size</strong>: <span class="math inline">\(\;\)</span> Minimum or maximum number of leaves.</li>
<li><strong><span class="math inline">\(\alpha\)</span></strong>: Controls for penalty in cost-complexity pruning.</li>
</ol>
<h2 id="classification-trees">Classification Trees</h2>
<p>If <span class="math inline">\(Y\)</span> is a classification outcome taking values <span class="math inline">\(1, 2, 3, ...., K\)</span>, the only change needed in the tree algorithm pertain to the criteria for splitting nodes and pruning the tree. For regression, we used MSE as the splitting criteria and we use average response <span class="math inline">\(\hat{c}\)</span> at each leave as our prediction. In classification case, for each region <span class="math inline">\(m\)</span>, we use proportion to make predictions:</p>
<p><span class="math display">\[\hat{p}_{mk} = \frac{1}{N_m} \sum_{x_1 \in R_m} I[y_i = k]\]</span></p>
<p><span class="math display">\[\hat{y}_m = \underset{k}{\arg\max} \; \hat{p}_{mk} \]</span></p>
<p>Thus, <strong>the prediction at each region is the majority class in that region</strong>.</p>
<h3 id="impurity-measure">Impurity Measure</h3>
<p>In classification case, we call the splitting criteria <code>impurity measure</code>. We have several choices for the impurity measure:</p>
<ol type="1">
<li><p><strong>Misclassification Error</strong>: <span class="math display">\[\frac{1}{N_m} \sum_{i \in R_m} I[y_i \neq \hat{y}_m] = 1 - \hat{p}_{m \hat{y}_m}\]</span></p></li>
<li><p><strong>Gini Index</strong>: <span class="math display">\[\sum_{k \neq k^{\prime}} \hat{p}_{mk} \hat{p}_{mk^{\prime}} = \sum^{K}_{k=1} \hat{p}_{mk} (1 - \hat{p}_{mk})\]</span></p>
<p>Notice here, if there is only one class in the region, then the gini index will be <span class="math inline">\(0\)</span>. That is, gini index prefers purer nodes.</p></li>
<li><p><strong>Cross-entropy</strong>: <span class="math display">\[-\sum^{K}_{k=1} \hat{p}_{mk} \log \hat{p}_{mk}\]</span></p>
<p>Notice here, if there is only one class in the region, then the cross-entropy will be <span class="math inline">\(0\)</span> which is minimum. Thus, cross-entropy prefers purer nodes.</p></li>
</ol>
<p>In general, we should always use cross entropy or gini index over misclassification rate, because misclassification rate does not capture extra purity. <strong>The impurity needs to scale by the instance number in each region</strong></p>
<h2 id="other-issues">Other Issues</h2>
<h3 id="instability-of-trees">Instability of Trees</h3>
<p>One major problem with trees is their high variance, often a small change in the data changes the structure of the tree. The major reason for this instability is the hierarchical nature of the process: the effect of an error in the top split is propagated down to all of the splits below it.</p>
<h3 id="difficulty-in-capturing-additive-structure">Difficulty in Capturing Additive Structure</h3>
<p>Another problem with trees is their difficulty in modeling additive structure. For regression <span class="math inline">\(Y = c_1 I[X_1 &lt; t_1] + c_2 I[X_2 &lt; t_2] + \epsilon\)</span>, a tree has to split based on <span class="math inline">\((X_1, t_1)\)</span>, then split on <span class="math inline">\((X_2, t_2)\)</span>. This might happen with sufficient data, but the model is given no special encouragement to find such structure.</p>
<h3 id="linear-combination-splits">Linear Combination Splits</h3>
<p>To solve the additive structure problem, rather than restricting splits to be of the form <span class="math inline">\(X_j \leq s\)</span>, one can allow splits along linear combinations of features:</p>
<p><span class="math display">\[\sum_{j} a_j X_j \leq s\]</span></p>
<p>While this can improve the predictive power of the tree, it can hurt interpretability.</p>
<h1 id="implementation">Implementation</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecisionTreeNode</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, split_point=<span class="literal">None</span>, split_feature=<span class="literal">None</span>, gini_index=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_instance=<span class="literal">None</span>, left_child=<span class="literal">None</span>, right_child=<span class="literal">None</span>, prediction=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        self.split_point = split_point</span><br><span class="line">        self.split_feature = split_feature</span><br><span class="line">        self.gini_index = gini_index</span><br><span class="line">        self.num_instance = num_instance</span><br><span class="line">        self.left_child = left_child</span><br><span class="line">        self.right_child = right_child</span><br><span class="line">        self.prediction = prediction</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecisionTreeClassifier</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, max_depth=<span class="number">10</span>, criterion=<span class="string">&#x27;gini_index&#x27;</span>, min_sample_leave=<span class="number">1</span></span>):</span></span><br><span class="line">        self.max_depth = max_depth</span><br><span class="line">        self.criterion = criterion</span><br><span class="line">        self.min_sample_splits = min_sample_leave</span><br><span class="line">        self._tree = <span class="literal">None</span></span><br><span class="line">        self._num_features = <span class="literal">None</span></span><br><span class="line">        self.feature_names = <span class="literal">None</span></span><br><span class="line">        self._num_samples = <span class="literal">None</span></span><br><span class="line">        self._classes = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x_train, y_train</span>):</span></span><br><span class="line">        self._num_samples, self._num_features = x_train.shape</span><br><span class="line">        self._classes = np.unique(y_train)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x_train, pd.DataFrame):</span><br><span class="line">            self.feature_names = x_train.columns</span><br><span class="line">            x_train = x_train.values</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.feature_names = <span class="built_in">range</span>(self._num_features)</span><br><span class="line"></span><br><span class="line">        self._tree = self._grow_tree(np.column_stack([x_train, y_train]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_grow_tree</span>(<span class="params">self, train, curr_depth=<span class="number">0</span>, stop=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> stop:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            impurity_dict = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self._num_features):</span><br><span class="line">                curr_feature_col = train[:, j]</span><br><span class="line">                <span class="keyword">for</span> s <span class="keyword">in</span> np.unique(curr_feature_col):</span><br><span class="line">                    impurity = self._cal_impurity(train, j, s)</span><br><span class="line">                    <span class="keyword">if</span> impurity <span class="keyword">in</span> impurity_dict.keys():</span><br><span class="line">                        impurity_dict[impurity].append((j, s))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        impurity_dict[impurity] = [(j, s)]</span><br><span class="line"></span><br><span class="line">            min_impurity = <span class="built_in">min</span>(impurity_dict.keys())</span><br><span class="line">            j_hat, s_hat = impurity_dict[min_impurity][<span class="number">0</span>]</span><br><span class="line">            prediction = Counter(train[:, -<span class="number">1</span>]).most_common()[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">            R_l = train[train[:, j_hat] &lt; s_hat]</span><br><span class="line">            R_r = train[train[:, j_hat] &gt;= s_hat]</span><br><span class="line">            sample_split = [<span class="built_in">len</span>(R_l), <span class="built_in">len</span>(R_r)]</span><br><span class="line"></span><br><span class="line">            if_stop = self._check_stopping_criterion(curr_depth, sample_split)</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(curr_depth, min_impurity, sample_split, (j_hat, s_hat))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> DecisionTreeNode(split_point=s_hat,</span><br><span class="line">                                    split_feature=j_hat,</span><br><span class="line">                                    prediction=prediction,</span><br><span class="line">                                    gini_index=min_impurity,</span><br><span class="line">                                    num_instance=<span class="built_in">len</span>(train),</span><br><span class="line">                                    left_child=self._grow_tree(train=R_l,</span><br><span class="line">                                                               curr_depth=curr_depth+<span class="number">1</span>,</span><br><span class="line">                                                               stop=if_stop),</span><br><span class="line"></span><br><span class="line">                                    right_child=self._grow_tree(train=R_r,</span><br><span class="line">                                                                curr_depth=curr_depth+<span class="number">1</span>,</span><br><span class="line">                                                                stop=if_stop))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_check_stopping_criterion</span>(<span class="params">self, curr_depth, sample_split</span>):</span></span><br><span class="line">        <span class="keyword">if</span> curr_depth &gt; self.max_depth:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">any</span>([sample_split[<span class="number">0</span>] &lt; self.min_sample_splits, sample_split[<span class="number">1</span>] &lt; self.min_sample_splits]):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_cal_impurity</span>(<span class="params">self, train, j, s</span>):</span></span><br><span class="line">        R_l = train[train[:, j] &lt; s]</span><br><span class="line">        R_r = train[train[:, j] &gt;= s]</span><br><span class="line">        R_l_y = R_l[:, -<span class="number">1</span>]</span><br><span class="line">        R_r_y = R_r[:, -<span class="number">1</span>]</span><br><span class="line">        N_l = <span class="built_in">len</span>(R_l) + <span class="number">1e-10</span></span><br><span class="line">        N_r = <span class="built_in">len</span>(R_r) + <span class="number">1e-10</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.criterion == <span class="string">&#x27;gini_index&#x27;</span>:</span><br><span class="line">            gini_l = <span class="number">0</span></span><br><span class="line">            gini_r = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> self._classes:</span><br><span class="line">                p_l = <span class="built_in">len</span>(R_l_y[R_l_y == k]) / N_l</span><br><span class="line">                p_r = <span class="built_in">len</span>(R_r_y[R_r_y == k]) / N_r</span><br><span class="line">                gini_l += p_l * (<span class="number">1</span> - p_l)</span><br><span class="line">                gini_r += p_r * (<span class="number">1</span> - p_r)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> gini_l * N_l + gini_r * N_r</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_test</span>):</span></span><br><span class="line">        output = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> x_test:</span><br><span class="line">            output.append(self._traverse_tree(i))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_traverse_tree</span>(<span class="params">self, x, tree=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tree:</span><br><span class="line">            tree = self._tree</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tree.left_child <span class="keyword">and</span> <span class="keyword">not</span> tree.left_child:</span><br><span class="line">            <span class="keyword">return</span> tree.prediction</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> x[tree.split_feature] &lt; tree.split_point:</span><br><span class="line">                <span class="keyword">return</span> self._traverse_tree(x, tree.left_child)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self._traverse_tree(x, tree.right_child)</span><br></pre></td></tr></table></figure>
<h1 id="ref">Ref</h1>
<p>ESLII Chapter 9</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Dropout</title>
    <url>/2021/05/25/drop-out/</url>
    <content><![CDATA[<h1 id="dropout-a-simple-way-to-prevent-neural-networks-from-overfitting">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</h1>
<p>The key idea of drop out is to randomly drop units along with their connections from the neural network during training to prevent overfitting. It can be interpreted as a way of regularizing a NN by adding noise to its hidden units.</p>
<h2 id="introduction">Introduction</h2>
<p>With unlimited computation, the best way to "regularize" a fixed-sized model is to average the predictions of all possible settings of the parameters, weighting each setting by the posterior probability given the training data (<span class="math inline">\(P(\theta | X)\)</span>). This approach is not feasible in real life especially when there is large computational cost for training neural networks and training data are limited.Dropout prevents overfitting and provides a way of approximately combining exponentially many neural network architectures effectively.</p>
<p>Dropout temporarily removes units from the network along with all their incoming and outgoing connections. The choice of which units to drop is random.</p>
<p><img src="/images/ML/dropout_1.png"></p>
<p><strong>At training time</strong>, for a NN with <span class="math inline">\(n\)</span> units, Dropout can be seen as training a collection of <span class="math inline">\(2^n\)</span> (each unit can be retained or removed by dropout, so <span class="math inline">\(2^n\)</span> different combinations) thinned networks (some units are dropped by dropout) with extensive weight sharing where each thinned network gets trained very rarely.</p>
<p><strong>At test time</strong>, it is not feasible to explicitly average the predictions form exponentially many thinned models. However, we use a single NN without dropout by scaling-down the weights of this network. If an unit is retained with probability <span class="math inline">\(p\)</span> during traning, the outgoing weights of that unit are multiplied by <span class="math inline">\(p\)</span> at the test time. This ensures that the expected output is the same as the actual output at the test time (we use expected output at test time).</p>
<span id="more"></span>
<h3 id="model-description">Model Description</h3>
<p>Consider a NN with <span class="math inline">\(L\)</span> hidden layers. Let <span class="math inline">\(l \in \{1, ..., L\}\)</span> index the hidden layers of the network. Let <span class="math inline">\(\textbf{z}^{l}\)</span> denote the vector of inputs into layer <span class="math inline">\(l\)</span>, <span class="math inline">\(\textbf{y}^{l}\)</span> denote the vector of output from layer <span class="math inline">\(l\)</span> (<span class="math inline">\(\textbf{y}^{0} = \textbf{x}\)</span>). <span class="math inline">\(W^{l}\)</span> and <span class="math inline">\(\textbf{b}^l\)</span> are the weights and biases at layer <span class="math inline">\(l\)</span>. The standard forward operation can be described as:</p>
<p><span class="math display">\[z^{l + 1}_i = \textbf{w}_{i}^{l + 1} \textbf{y}^{l} + b_i^{l + 1}\]</span></p>
<p><span class="math display">\[y_i^{l+1} = f(z^{l + 1}_i)\]</span></p>
<p>Where <span class="math inline">\(W^l = [\textbf{w}_1^{l}, \textbf{w}_2^{l}, ...., \textbf{w}_{|l|}^{l}]\)</span>, <span class="math inline">\(f\)</span> is any activation function.</p>
<p>With dropout, the forward operation becomes:</p>
<p><span class="math display">\[R_j^{l} \sim Bernoulli(p)\]</span></p>
<p><span class="math display">\[\tilde{\textbf{y}} = \textbf{R}^{l} * \textbf{y}^{l}\]</span></p>
<p><span class="math display">\[z^{l + 1}_i = \textbf{w}_{i}^{l + 1} \tilde{\textbf{y}}^{l} + b_i^{l + 1}\]</span></p>
<p><span class="math display">\[y_i^{l+1} = f(z^{l + 1}_i)\]</span></p>
<p>At the test time, the weights are scaled as <span class="math inline">\(W^{l}_{test} = p W^{l}\)</span></p>
<h2 id="backpropagation">Backpropagation</h2>
<p>Dropout NNs are trained using SGD in manner similar to standard NN. The only difference is that for each training case in the mini-batch, we sample a thinned network by dropping out units. Parameters that are dropped have zero gradients:</p>
<p><span class="math display">\[\tilde{\textbf{y}} = 0\]</span></p>
<p><span class="math display">\[\frac{\partial L}{\partial \textbf{w}_{i}^{l + 1}} = \frac{\partial L}{\partial z^{l + 1}_i} \frac{\partial z^{l + 1}_i}{\partial \textbf{w}_{i}^{l + 1}} = 0\]</span></p>
<p>One technique the authors found useful is to impose the max norm constraint on the weights during optimization such that:</p>
<p><span class="math display">\[\|w\|_{2} \leq c\]</span></p>
<h2 id="effect-on-sparsity">Effect on Sparsity</h2>
<p>The authors also found that as a side-effect of doing dropout, the activations of the hidden units become sparse, even when no sparsity inducing regularizes are present. Thus, dropout automatically leads to sparse representations.</p>
<p><img src="/images/ML/dropout_2.png"></p>
<h2 id="practical-guide-for-training-dropout-networks">Practical Guide for Training Dropout Networks</h2>
<h3 id="network-size">Network Size</h3>
<p>It is to be expected that dropping units will reduce the capacity of a NN. At each training step (single training example or a mini-batch of examples), a subset of model parameters are optimized. Therefore, if <span class="math inline">\(n\)</span>-sized layer is optimal for a standard NN on any given task, a good dropout net should have at least <span class="math inline">\(\frac{n}{p}\)</span> units. This is a useful heuristic for setting the number of hidden units for convolutional and fully connected networks.</p>
<h3 id="learning-rate-and-momentum">Learning Rate and Momentum</h3>
<p>Dropout introduces a significant amount of noise in the gradients compared to standard SGD. Thus, a lot of gradients tend to cancel each other. In order ot make up for this, a dropout net should typically use 10-100 times the learning-rate that was optimal for a standard NN. Another way to reduce the effect of the noise is to use a high momentum. Using high learning rate and high momentum significantly speed up learning.</p>
<h3 id="max-norm-regularization">Max-norm Regularization</h3>
<p>Though large momentum and learning rate speed up learning, they sometimes cause the weights to explode, so we need to apply some regularization on the parameter size.</p>
<h3 id="dropout-rate-p">Dropout Rate <span class="math inline">\(p\)</span></h3>
<p>This hyperparameter controls the intensity of dropout. Small value of <span class="math inline">\(p\)</span> requires big hidden unit size <span class="math inline">\(n\)</span> which will slow down the training and leads to underfitting while large <span class="math inline">\(p\)</span> may not produce enough dropout to prevent overfitting.</p>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Regularization</tag>
      </tags>
  </entry>
  <entry>
    <title>EM</title>
    <url>/2021/07/21/em/</url>
    <content><![CDATA[<h1 id="expectation-maximization-algorithm">Expectation-Maximization Algorithm</h1>
<p>Gaussian Mixture distribution can be written as a linear superposition of Gaussians in the form:</p>
<p><span class="math display">\[P(\mathbf{X}) = \sum^K_{k=1} \pi_k N(\mathbf{X} | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)\]</span></p>
<p>Where <span class="math inline">\(\pi_k\)</span> is the mixing coefficient for each normal component that satisfies the conditions:</p>
<p><span class="math display">\[0 \leq \pi_k \leq 1\]</span> <span class="math display">\[\sum^{K}_{k=1} \pi_k = 1\]</span></p>
<p><br></p>
<p>Let us introduce a <span class="math inline">\(K\)</span>-dimensional binary latent random vector <span class="math inline">\(\mathbf{Z}\)</span> having a 1-of-<span class="math inline">\(K\)</span> representation in which a particular element <span class="math inline">\(Z_k \in \{0, 1\}\)</span> is equal to 1 and all other elements are equal to 0 and <span class="math inline">\(\sum^{K}_{k=1} Z_k = 1\)</span>. We define:</p>
<ul>
<li><p>The joint distribution <span class="math inline">\(P(\mathbf{X}, \mathbf{Z}) = P(\mathbf{Z}) P(\mathbf{X} | \mathbf{Z})\)</span> in terms of a marginal distribution <span class="math inline">\(P(\mathbf{Z})\)</span> and a conditional distribution <span class="math inline">\(P(\mathbf{X} | \mathbf{Z})\)</span>.</p></li>
<li><p>The marginal distribution over <span class="math inline">\(\mathbf{Z}\)</span> is specified in terms of the mixing coefficient <span class="math inline">\(\pi_k\)</span>, such that: <span class="math display">\[P(Z_k = 1) = \pi_k\]</span> <span class="math display">\[P(\mathbf{Z}) = \prod^{K}_{k=1} \pi_k^{Z_k}\]</span></p></li>
<li><p>The conditional distribution of <span class="math inline">\(\mathbf{X}\)</span> given a particular value for <span class="math inline">\(\mathbf{Z}\)</span> is a Gaussian: <span class="math display">\[P(\mathbf{X} | Z_k = 1) = N(\mathbf{X} | \mu_k, \Sigma_k)\]</span> <span class="math display">\[P(\mathbf{X} | \mathbf{Z}) = \prod^{K}_{k=1} N(\mathbf{X} | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)^{Z_k}\]</span></p></li>
<li><p>The conditional probability (posterior probability) of particular value of <span class="math inline">\(\mathbf{Z}\)</span> given a particular value for <span class="math inline">\(\mathbf{X}\)</span>, which can be found by Bayes rule: <span class="math display">\[\gamma(Z_k) = P(Z_k = 1 | \mathbf{X}) = \frac{P(\mathbf{X} | Z_k = 1) P(Z_k = 1)}{P(\mathbf{X})} = \frac{\pi_k N(\mathbf{X} | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)}{\sum^K_{j=1} \pi_k N(\mathbf{X} | \boldsymbol{\mu}_j, \boldsymbol{\Sigma}_j)}\]</span></p>
<p>This probability can be viewed as the <strong>responsibility</strong> that component <span class="math inline">\(k\)</span> takes for explaining the observation <span class="math inline">\(\mathbf{X}\)</span></p></li>
</ul>
<p><br></p>
<p>Then the marginal distribution of the gaussian mixture can be written using the distribution of latent random vector <span class="math inline">\(\mathbf{Z}\)</span> as:</p>
<p><span class="math display">\[P(\mathbf{X}) = \sum_{\mathbf{Z}} P(\mathbf{Z}) P(\mathbf{X} | \mathbf{Z}) = \sum^{K}_{k=1} \pi_k N(\mathbf{X} | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)\]</span></p>
<p>It follows that, since we are using a joint distribution, if we have a random sample <span class="math inline">\(\mathbf{X}_1, ..., \mathbf{X}_N\)</span>, for every random vector <span class="math inline">\(\mathbf{X}_n\)</span> there is a corresponding latent variable <span class="math inline">\(\mathbf{Z}_n\)</span>. Therefore, we have found an equivalent formulation of the Gaussian mixture involving an explicit latent variable. Now, we can work with the joint distribution <span class="math inline">\(P(\mathbf{X}, \mathbf{Z})\)</span> instead of the original marginal distribution <span class="math inline">\(P(\mathbf{X})\)</span>.</p>
<p>We can express the joint distribution as Bayesian network:</p>
<p><img src='/images/ML/em_1.png' width="600"></p>
<p>And we can use ancestral sampling to generate random samples distributed according to the Gaussian mixture model:</p>
<ol type="1">
<li>Sample from <span class="math inline">\(\hat{\mathbf{Z}} \sim P(\mathbf{Z})\)</span></li>
<li>Sample from <span class="math inline">\(P(\mathbf{X} | \hat{\mathbf{Z}})\)</span></li>
<li>Coloring them by the <span class="math inline">\(\mathbf{\hat{Z}}\)</span></li>
</ol>
<p><img src='/images/ML/em_2.png' width="600"></p>
<h2 id="em-for-gaussian-mixtures">EM for Gaussian Mixtures</h2>
<p>Suppose we have a dataset of observations <span class="math inline">\(\{\mathbf{x}_1, ...., \mathbf{x}_N; \; \mathbf{x} \in \mathbb{R}^M\}\)</span>, and we wish to model this data using a mixture of Gaussians. We can represent this dataset as an <span class="math inline">\(N \times M\)</span> matrix <span class="math inline">\(\mathbf{D}\)</span> in which the <span class="math inline">\(n\)</span>th row is given by <span class="math inline">\(\mathbf{x}^T_n\)</span>. Similarly, the corresponding latent variables will be denoted by an <span class="math inline">\(N \times K\)</span> matrix <span class="math inline">\(\mathbf{H}\)</span> with rows <span class="math inline">\(\mathbf{Z}^T_n\)</span>. If we assume that the data points are drawn independently from the distribution then we can express the Gaussian mixture model for this i.i.d dataset using the graphical representation:</p>
<p><img src='/images/ML/em_3.png' width="600"></p>
<p>The log-likelihood function is given by:</p>
<p><span class="math display">\[\ln(P(\mathbf{D} | \boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Sigma})) = \sum^{N}_{n=1} \ln (\sum^K_{k=1} \pi_k N(\mathbf{x}_n | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k))\]</span></p>
<p>An elegant and powerful method for finding maximum likelihood solutions for models with latent variables is called the <code>expectation-maximization algorithm</code>.</p>
<p>We know that at a maximum of the likelihood function (by taking the derivative with respect to <span class="math inline">\(\mathbf{\mu}_k\)</span>):</p>
<p><span class="math display">\[0 = - \sum^N_{n=1} \underbrace{\frac{\pi_k N(\mathbf{x}_n | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)}{\sum^K_{j=1} \pi_k N(\mathbf{x}_n | \boldsymbol{\mu}_j, \boldsymbol{\Sigma}_j)}}_{\gamma(Z_{nk})} \boldsymbol{\Sigma}_k (\mathbf{x}_n - \boldsymbol{\mu}_k)\]</span></p>
<p>By assuming that <span class="math inline">\(\boldsymbol{\Sigma}_k\)</span> is invertible and rearranging we have:</p>
<p><span class="math display">\[\boldsymbol{\hat{\mu}}_k = \frac{1}{N_k} \sum^N_{n=1} \gamma(Z_{nk}) \mathbf{x}_n\]</span></p>
<p><span class="math display">\[N_k = \sum^N_{n=1} \gamma(Z_{nk})\]</span></p>
<p>Since <span class="math inline">\(Z_{nk} = P(Z_{nk} = 1 | \mathbf{X} = \mathbf{x}_n)\)</span> is the posterior probability, we can interpret <span class="math inline">\(N_k\)</span> as the total probability of samples assigned to cluster <span class="math inline">\(k\)</span>. We can see that the mean <span class="math inline">\(\boldsymbol{\mu}_k\)</span> for the <span class="math inline">\(k\)</span>th Gaussian component is obtained by taking a mean of all of the points in the dataset weighted by the posterior distribution for cluster <span class="math inline">\(k\)</span>.</p>
<p><br></p>
<p>By taking the derivative w.r.t <span class="math inline">\(\boldsymbol{\Sigma}_k\)</span>, we have:</p>
<p><span class="math display">\[\boldsymbol{\hat{\Sigma}}_k = \frac{1}{N_k} \sum^N_{n=1} \gamma(Z_{nk}) (\mathbf{x}_n - \boldsymbol{\mu}_n)(\mathbf{x}_n - \boldsymbol{\mu}_n)^T\]</span></p>
<p>By taking the derivative w.r.t the miximing coefficients <span class="math inline">\(\pi_k\)</span> and using lagrange multiplier, we have:</p>
<p><span class="math display">\[\hat{\pi}_k = \frac{N_k}{N}\]</span></p>
<p>So that the mixing coefficient for the <span class="math inline">\(k\)</span>th component is given by the average responsibility which that component takes for explaining the data points.</p>
<p>We can see that, <span class="math inline">\(\hat{\pi}_k, N_k, \boldsymbol{\hat{\mu}}_k, \boldsymbol{\hat{\Sigma}}_k\)</span> all depends on the value of <span class="math inline">\(\gamma(Z_{nk})\)</span> and <span class="math inline">\(\gamma(Z_{nk})\)</span> depends on the values of all other variables. Thus, we can do a simple iterative scheme for finding a solution to the maximum likelihood problem, which turns out to be an instance of the EM algorithm for the particular case of Gaussian Mixture Model:</p>
<ol type="1">
<li>We first choose some initial values for the means, covariances and mixing coefficients.</li>
<li>We alternate between E step and M step:
<ul>
<li><strong>Expectation Step</strong>: We use the current values for the parameters to evaluate the posterior probabilities (responsibilities).</li>
<li><strong>Maximization Step</strong>: We then use responsibilities to maximize the log likelihood function for parameters (Mean first, then covariance matrix).</li>
</ul></li>
</ol>
<p>In practice, the algorithm is deemed to have converged when the change in the log likelihood function or alternatively in the parameters falls below some threshold.</p>
<p><img src='/images/ML/em_4.png' width="600"> <img src='/images/ML/em_5.png' width="600"></p>
<h2 id="an-alternative-view-of-em">An Alternative View of EM</h2>
<p>The goal of EM Algorithm is to find maximum likelihood solutions for models having latent variables. We denote sthe set of all observed data by <span class="math inline">\(\mathbf{D}\)</span> in which the <span class="math inline">\(n\)</span>th row represents <span class="math inline">\(\mathbf{x}^T_n\)</span>, and similarily we denote the set of all latent variables by <span class="math inline">\(\mathbf{H}\)</span> with a corresponding row <span class="math inline">\(\mathbf{Z}^T_n\)</span>. The set of all parameters is denoted by <span class="math inline">\(\boldsymbol{\theta}\)</span> and so the log likelihood function is given by:</p>
<p><span class="math display">\[\ln L(\boldsymbol{\theta}; \; \mathbf{D}) = \ln(\sum_{\mathbf{H}} P(\mathbf{D}, \mathbf{H} | \boldsymbol{\theta}))\]</span></p>
<p>If we have continuous latent variable, we can replace the summation by integral.</p>
<p>A key observation is that the summation over the latent variables appears inside the logarithm which provides much complicated expression of log likelihood. Suppose, for each observation in <span class="math inline">\(\mathbf{D}\)</span>, we have observed corresponding random variable <span class="math inline">\(\mathbf{Z}^T_n = \mathbf{z}^T_n\)</span>. We call <span class="math inline">\(\{\mathbf{D}, \mathbf{H}\}\)</span> the <strong>complete dataset</strong> and if we only observed <span class="math inline">\(\mathbf{D}\)</span> we have <strong>incomplete</strong> dataset, the maximization of this complete-data log likelihood function is straightforward and much simpler than incomplete likelihood.</p>
<p>In practice, we are not given the complete dataset but only the incomplete data. Our state of knowledge of the values of the latent variables in <span class="math inline">\(\mathbf{H}\)</span> is given only by the posterior distribution:</p>
<p><span class="math display">\[P(\mathbf{H} | \mathbf{D}, \boldsymbol{\theta}) = \frac{P(\mathbf{H}, \mathbf{D} | \boldsymbol{\theta})}{P(\mathbf{D} | \boldsymbol{\theta})}\]</span></p>
<p>Since we cannot use the complete dataset log likelihood, we can consider using the expectation under the posterior distribution (<strong>E step</strong>). In E step, we use the current parameter values <span class="math inline">\(\boldsymbol{\theta}^{old}\)</span> to find the posterior distribution of the latent variables given by <span class="math inline">\(P(\mathbf{H} | \mathbf{D}, \boldsymbol{\theta})\)</span>. We then use this posterior distribution to find the expectation of the complete-data log likelihood evaluated for some general parameter value <span class="math inline">\(\boldsymbol{\theta}\)</span>. This expectation, denoted as:</p>
<p><span class="math display">\[Q(\boldsymbol{\theta}, \boldsymbol{\theta}^{old}) = E_{\mathbf{H} | \mathbf{D}, \boldsymbol{\theta}^{old}} [\ln P(\mathbf{D}, \mathbf{H} | \boldsymbol{\theta})] = \sum_{\mathbf{H}} P(\mathbf{H} | \mathbf{D}, \boldsymbol{\theta}^{old}) \ln P(\mathbf{D}, \mathbf{H} | \boldsymbol{\theta})\]</span></p>
<p>In the subsequent <strong>M step</strong>, we find parameters that maximize this expectation. If the current estimate for the parameters is denoted <span class="math inline">\(\boldsymbol{\theta}^{old}\)</span>, then a pair of successive E and M steps gives rise to a revised estimate <span class="math inline">\(\boldsymbol{\theta}^{new}\)</span>. The algorithm is initialized by choosing some starting value for the parameters <span class="math inline">\(\boldsymbol{\theta}_0\)</span>.</p>
<p><span class="math display">\[\theta^{new} = \underset{\boldsymbol{\theta}}{\arg\max} \; Q(\boldsymbol{\theta}, \boldsymbol{\theta}^{old})\]</span></p>
<p>Notice here we have complete data log likelihood, compare it with incomplete data log likelihood, the log likelihood function is much easier to compute.</p>
<h3 id="general-em-algorithm">General EM algorithm</h3>
<p><img src='/images/ML/em_6.png' width="600"> <img src='/images/ML/em_7.png' width="600"></p>
<h3 id="general-em-algorithm-for-gaussian-mixture">General EM Algorithm for Gaussian Mixture</h3>
<p>Previously, we used incomplete data log likelihood for Gaussian Mixture together with the EM algorithm, we have summation over <span class="math inline">\(k\)</span> over <span class="math inline">\(k\)</span> that occurs inside the logarithm. Now, we try to use general approach of EM algorithm.</p>
<p>We have the complete data likelihood:</p>
<span class="math display">\[\begin{aligned}
P(\mathbf{D}, \mathbf{H} | \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi}) &amp;= P(\mathbf{D} | \mathbf{H},  \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi}) P(\mathbf{H} | \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi})\\
&amp;= \prod^{N}_{n=1}\prod^{K}_{k=1}\pi_k^{Z_{nk}} N(\mathbf{x}_n | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)^{Z_{nk}}\\
\end{aligned}\]</span>
<p>Where <span class="math inline">\(Z_{nk}\)</span> is the <span class="math inline">\(k\)</span> the component of <span class="math inline">\(\mathbf{Z}_n\)</span>. Taking the logarithm, we have the log likelihood:</p>
<p><span class="math display">\[\ln P(\mathbf{D}, \mathbf{H} | \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi}) = \sum^{N}_{n=1}\sum^{K}_{k=1} Z_{nk} (\ln \pi_k + \ln  N(\mathbf{x}_n | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k))\]</span></p>
<p>Compare with the incomplete data log likelihood, we can see that this form is much easier to solve. In practice, we do not obtain the values of <span class="math inline">\(\mathbf{H}\)</span>, thus, we use expectation instead:</p>
<span class="math display">\[\begin{aligned}
E_{\mathbf{H} | \boldsymbol{\mu}} [\ln P(\mathbf{D}, \mathbf{H} | \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi})] &amp;= \sum^{N}_{n=1}\sum^{K}_{k=1} P(Z_{nk}=1 | \mathbf{D}, \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi}) (\ln \pi_k + \ln  N(\mathbf{x}_n | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k))\\
&amp;= \sum^{N}_{n=1}\sum^{K}_{k=1} \gamma(Z_{nk}) (\ln \pi_k + \ln  N(\mathbf{x}_n | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k))
\end{aligned}\]</span>
<p>We then proceed as follows:</p>
<ol type="1">
<li>First we start at some initial values for parameters.</li>
<li>We use these parameters to evaluate the responsibilities.</li>
<li>We then maximize the expected log likelihood function.</li>
</ol>
<p>Which is the same as the incomplete data log likelihood EM previously, but we have a much easier log likelihood function to maximize over.</p>
<h1 id="ref">Ref</h1>
<p>PRML Chapter 9</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Dynamic Programming</title>
    <url>/2021/05/03/dp/</url>
    <content><![CDATA[<h1 id="dynamic-programming">Dynamic Programming</h1>
<p>We have defined concepts and properties such as value functions, bellman equations, bellman operators and etc. The question is <strong>how we can find the the optimal policy?</strong> Before we start, we assume that the dynamics of the MDP is given, that is, we know our transition distribution <span class="math inline">\(P\)</span> and immediate reward distribution <span class="math inline">\(R\)</span>. The assumption of knowing the dynamics do not hold in the RL setting, but designing methods for finding the optimal policy with known model provides the foundation for developing methods for the RL setting.</p>
<p>DP methods benefit from the structure of the MDP such as the recursive structure encoded in the Bellman equation, in order to compute the value function.</p>
<span id="more"></span>
<h2 id="policy-evaluation">Policy Evaluation</h2>
<p>Policy Evaluation is the problem of computing the value function of a given policy <span class="math inline">\(\pi\)</span> (i.e. find <span class="math inline">\(V^{\pi}\)</span> or <span class="math inline">\(Q^{\pi}\)</span>). This is not the ultimate goal of an RL agent (Finding the optimal policy is the goal), but is often needed as an intermediate step in finding the optimal policy</p>
<p>Given an MDP (<span class="math inline">\(X, A, P, R, \gamma\)</span>) and a policy <span class="math inline">\(\pi\)</span>, we would like to compute <span class="math inline">\(V^{\pi}, Q^{\pi}\)</span>:</p>
<p><span class="math display">\[V^{\pi} (x) = E^{\pi}[\sum_{t=1}^{\infty} \gamma^{t-1} R_{t} | X_0 = x]\]</span></p>
<p><em><img src='/images/RL/dp/tree_structure.png'></em></p>
<h2 id="control">Control</h2>
<p>Control is the problem of finding the optimal value function <span class="math inline">\(V^{*}, Q^{*}\)</span> or <span class="math inline">\(\pi^{*}\)</span></p>
]]></content>
      <categories>
        <category>RL</category>
        <category>DP</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>Dynamic Programming</tag>
      </tags>
  </entry>
  <entry>
    <title>gaussian-process</title>
    <url>/2022/06/12/gaussian-process/</url>
    <content><![CDATA[<h1 id="gaussian-process">Gaussian Process</h1>
<h2 id="notations">Notations</h2>
<p><img src='/images/RL/background/gp_notations_1.png' width="600"> <img src='/images/RL/background/gp_notations_2.png' width="600"></p>
<h2 id="gaussian-identities">Gaussian Identities</h2>
<p>The multivariate Gaussian distribution has a joint probability density (Bayesian):</p>
<p><span class="math display">\[p(\mathbf{x} | \mathbf{m}, \Sigma) = (2\pi)^{-\frac{D}{2}} |\Sigma|^{-\frac{1}{2}} e^{-\frac{1}{2} (\mathbf{x} - \mathbf{m})^T \Sigma^{-1} (\mathbf{x} - \mathbf{m})}\]</span></p>
<p>Where <span class="math inline">\(\mathbf{m}\)</span> is the <strong>mean</strong> vector of length <span class="math inline">\(D\)</span> and <span class="math inline">\(\Sigma\)</span> is the symmetric <span class="math inline">\(D \times D\)</span>, positive definite covariance matrix. As a shorthand, we write <span class="math inline">\(\mathbf{x} \sim N(\mathbf{m}, \Sigma)\)</span></p>
<p><br></p>
<p>Let <span class="math inline">\(\mathbf{x}, \mathbf{y}\)</span> be jointly Gaussian random vectors:</p>
<p>$$$$</p>
<h2 id="regression">Regression</h2>
<h3 id="a-function-space-view">A Function Space View</h3>
<h4 id="definition-2.1-gaussian-process">Definition 2.1: Gaussian Process</h4>
<p>A <strong>Gaussian Process</strong> is a collection of random variables, any finite number of which have joint Gaussian distribution.</p>
<p><br></p>
<p>A Gaussian process is completely specified by its mean function and covariance function. We define mean function <span class="math inline">\(m(\mathbf{x})\)</span> and the covariance function <span class="math inline">\(k(\mathbf{x}, \mathbf{x}^\prime)\)</span> of a real process <span class="math inline">\(f(\mathbf{x})\)</span> as:</p>
<p><span class="math display">\[m(\mathbf{x}) = E[f(\mathbf{x})] \quad \quad k(\mathbf{x}, \mathbf{x}^\prime) = E[(f(\mathbf{x}) - m(\mathbf{x}))(f(\mathbf{x}^\prime) - m(\mathbf{x}^\prime))]\]</span></p>
<p>and given <span class="math inline">\(N\)</span> examples, we write the Gaussian process <span class="math inline">\(f := (f(\mathbf{x}_1) , ...., f(\mathbf{x}_N))\)</span> as:</p>
<p><span class="math display">\[f(\mathbf{x}) \sim GP(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}^\prime))\]</span></p>
<p>where the random variables represent the value of the function <span class="math inline">\(f\)</span> at location <span class="math inline">\(\mathbf{x}\)</span>. Often Gaussian process are defined over time, where the index set of the random variables is time. This is not the case in our use of GPs, here the index set <span class="math inline">\(\mathbb{X}\)</span> is the set of possible inputs. In our case, we identify the random variables s.t <span class="math inline">\(f_i := f(\mathbf{x}_i)\)</span> corresponding to training example <span class="math inline">\((\mathbf{x}_i, y_i)\)</span>.</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Go Explore</title>
    <url>/2021/06/25/go-explore/</url>
    <content><![CDATA[<h1 id="go-explore-a-new-approach-for-hard-exploration-problems">Go-Explore: a New Approach for Hard-Exploration Problems</h1>
<h2 id="definitions">Definitions</h2>
<p><strong>What is hard-exploration problem?</strong></p>
<ol type="1">
<li>Sparse rewards: precise sequences of many actions must be taken between obtaining rewards.</li>
<li>Deceptive rewards: the reward function provides misleading feedback for reaching overall global objective.</li>
</ol>
<p>Both sparse and deceptive reward problems constitute "hard-exploration" problems.</p>
<p><br></p>
<p><strong>What is Derailment?</strong></p>
<p>Typical IM agents have two layers of exploration mechanisms:</p>
<ol type="1">
<li>Higher level IR incentive that rewards when new states are reached, the IM agents rely on this mechanism to return to high IR promising states.</li>
<li>A more basic exploratory mechanism such as epsilon-greedy exploration, action-space noise, or parameter-space noise. The IM agents rely on this mechanism to explore high IR states.</li>
</ol>
<p>However, to return to a previously discovered high IR state, a longer, more complex and more precise sequence of actions is needed. In this case, the lower level exploration mechanism (e.g epsilon greedy) will "derail" the agent from ever returning to that state (The needed precise actions are naively perturbed by the basic exploration mechanism).</p>
<p><br></p>
<p><strong>What is detachment?</strong></p>
<p>Detachment is idea that an agent driven by Intrinsic Motivation could become detached from the frontiers of high intrinsic reward. IM is nearly always a consumable resource: a curious agent is curious about state to the extent that it has not often visited them. If an agent discovers multiple areas of the state space that produce high IR, its policy may in the short term focus on one such area. After exhausting some of the IR offered by that area, the policy may by chance begin consuming IR in another area. Once it has exhausted that IR, it is difficult for it to rediscover the frontier it detached from in the initial area, because it has already consumed the IR that led to that frontier and it likely will not remember how to return to that frontier due to catastrophic forgetting.</p>
<p>In theory, a replay buffer could prevent detachment, but in practicce it would have to be large to prevent data about the abandoned frontier to not be purged before it becomes needed, and large replay buffers introduce their own optimization stability difficulties.</p>
<p><img src="/images/RL/papers/go_explore.png" width="600"></p>
<span id="more"></span>
<h2 id="go-explore-algorithm">Go Explore Algorithm</h2>
<p>Go-Explore is an explicit response to both detachment and derailment that is also designed to achieve robust solutions in stochastic environments. To deal with:</p>
<ol type="1">
<li><strong>Detachment</strong>: The algorithm explicitly stores an archive of promising states visited so taht they can then be revisited and explored from later.</li>
<li><strong>Derailment</strong>: The algorithm decomposes the basic exploration mechanism into first returning to a promising state without intentionally adding any exploration then exploring further from the promising state.</li>
</ol>
<p>The algorithm works in two phases:</p>
<ol type="1">
<li><p><strong>Phase 1</strong>: solve the problem in a way that may be brittle, such as solving a deterministic version of the problem. Phase 1 focuses on exploring infrequently visited states which forms the basis for dealing with sparse-reward and deceptive problems.</p>
<ol type="a">
<li>Add all interestingly different states visited so far into the archive</li>
<li>Each time a state from the archive is selected to explore from, first <strong>GO</strong> back to the state without adding exploration, and then <strong>Explore</strong> further from that state in search of new states.</li>
</ol></li>
</ol>
<p><br></p>
<ol start="2" type="1">
<li><p><strong>Phase 2</strong>: robustify (train to be able to reliably perform the solution in the presence of stochasticity) via imitation learning or learning from demonstrations. The only difference with Go-Explore is that the solution demonstrations are produced automatically by Phase 1 instead of being provided by humans. If in the first phase, we obtain a policy that is robust in stochastic environment, then we do not need this second phase.</p>
<ul>
<li><strong>Input</strong>: One or more high-performing trajectories from phase 1</li>
<li><strong>Output</strong>: A robust policy able to consistently achieve similar performance.</li>
</ul></li>
</ol>
<h3 id="phase-1-explore-until-solved">Phase 1: Explore until solved</h3>
<p>The purpose of Phase 1 is to explore the state space and find one or model high-performing trajectories that can later be turned into a robust policy in Phase 2. To do this, phase 1 builds up an archive of interestingly different game states, which we call <code>cells</code>, and the trajectories that lead to them. It starts with an archive that only contains the starting state. From there, it builds the archive by repeating the following procedure:</p>
<ol type="1">
<li><p>choose a cell from the current archive</p></li>
<li><p>return to that cell without adding any stochastic exploration</p></li>
<li><p>explore from that location stochastically</p></li>
</ol>
<h4 id="cell-representations">Cell representations</h4>
<p>In theory, one can store high-dimensional states as cell with one cell representing one state. However, this is intractable in practice. To be tractable in high-dimensional state spaces, we need to reduce the dimensionality of the state space (although the final policy will still play in the same original state space). Thus, we want the cell representation to conflate similar states while not conflating states that are meaningfully different (aggregating similar frames to one frame).</p>
<p>Since appropriate downscaling parameters can vary across games and even as exploration progresses within a given game, such parameters are optimized <strong>dynamically</strong> at regular intervals by maximizing the objective function over a sample of recently discovered frames.</p>
<p><br></p>
<p><strong>Cell representations without domain knowledge</strong></p>
<p>We found that a very simple dimensionality reduction procedure produces surprisingly good results on Montezuma's Revenge. Specifically:</p>
<ol type="1">
<li>Convert each game frame image to grayscale</li>
<li><strong>Downscale</strong> it to an <span class="math inline">\(w \leq 160, \; h \leq 120\)</span> image with area interpolation (i.e using the average pixel value in the area of the downsampled pixel)</li>
<li>rescale <strong>pixel intensities</strong> <span class="math inline">\(d \leq 255\)</span> using the formula <span class="math inline">\(\lfloor \frac{d\cdot p}{255} \rfloor\)</span>, instead of original 0 to 255.</li>
</ol>
<p>The downscaling dimensions and pixel-intensity range <span class="math inline">\(w, h, d\)</span> are updated <strong>dynamically</strong> by proposing different values for each, calculating how a sample of recent frames would be grouped into cells under these proposed parameters, and then selecting the values that result in the best cell distribution as determined by the objective function:</p>
<p>The objective function for candidate downscaling parameters is calculated based on:</p>
<ol type="1">
<li><p>A target number of cells <span class="math inline">\(T\)</span>, where <span class="math inline">\(T\)</span> is a fixed fraction of the number of cells in the sample (target groups of frames formed from the samples of frames)</p></li>
<li><p>The actual number of cells produced by the parameters currently considered, <span class="math inline">\(n\)</span> (actual groups of frames formed from the samples)</p></li>
<li><p>The distribution of sample frames over cells <span class="math inline">\(\mathbf{p}\)</span></p></li>
</ol>
<p><span class="math display">\[O(\mathbf{p}, n) = \frac{H_n (\mathbf{p})}{L(n, T)}\]</span></p>
<p>Where:</p>
<ol type="1">
<li><p><strong>Cell number control</strong>: <span class="math inline">\(L(n, T)\)</span> measures the discrepancy between the number of cells under the current parameters <span class="math inline">\(n\)</span> and the target number of cells <span class="math inline">\(T\)</span>. It prevents the representation that is discovered from aggregating too many frames together, which would result in low exploration, or from aggregating too few frames together, which would result in an intractable time and memory complexity.</p>
<p><span class="math display">\[L(n, T) = \sqrt{|\frac{n}{T} - 1| + 1}\]</span></p>
<p>If <span class="math inline">\(n &gt;&gt; T \implies L(n, T) \rightarrow \infty\)</span>, if <span class="math inline">\(n &lt;&lt; T \implies L(n, T) \rightarrow \sqrt{2}\)</span>, more penalty on large number of groups.</p></li>
<li><p><strong>Frame distribution control</strong>: <span class="math inline">\(H_n (\mathbf{p})\)</span> is the ratio of the entropy of how frames were distributed across cells to the entropy of the discrete uniform distribution of size <span class="math inline">\(n\)</span>.</p>
<p><span class="math display">\[H_n (\mathbf{p}) = - \sum^{n}_{i=1} \frac{p_i \log(p_i)}{\log(n)}\]</span></p>
<p>Larger entropy gives a uniform distribution, that is, the objective encourages frames to be distributed as uniformly as possible across cells. Normalized entropy is comparable across different number of cells, allowing the number of cells to be controlled solely by <span class="math inline">\(L(n, T)\)</span>.</p></li>
</ol>
<p><br></p>
<p>At each step of the randomized search, new values of each tuple of parameter <span class="math inline">\(w, h, d\)</span> are proposed by sampling from a geometric distribution (close to zero values have higher probability of being selected) whose mean (<span class="math inline">\(\mu = \frac{1}{p}\)</span>) is the current best known value of the given parameter. If the current best known value is lower than a heuristic minimum mean <span class="math inline">\(w=8, h=10.5, d=12\)</span>, then the minimum mean is used as the mean of the geometric distribution. New parameter values are resampled if they fall outside of the valid range for the parameter. Then, the scaled frames are grouped into groups and objective are calculated.</p>
<p>The sample of frames are obtained by maintaining a set of recently seen smaple frames as GO-Explore runs: each time a frame not realy in the set is seen during the explore step, it is added to the running set with a probability of 1%. If the resulting set contains more than 10,000 frames, the oldest frame it contains is removed.</p>
<p><strong>Cell representations with domain knowledge</strong></p>
<p>In <strong>Montezuma's Revenge</strong>, domain knowledge is provided as unique combinations of:</p>
<ol type="1">
<li><p>the <span class="math inline">\(x, y\)</span> position of the agent (descretized into a grid in which each cell is <span class="math inline">\(16 \times 16\)</span> pixels)</p></li>
<li><p>room number</p></li>
<li><p>level number</p></li>
<li><p>rooms that the currently-held keys were found</p></li>
</ol>
<p>In <strong>Pitfall</strong>, only the <span class="math inline">\(x, y\)</span> position of the agent and room number is used.</p>
<p>All of this information was extracted directly from pixels with simple hand-coded classifiers to detect objects such as the main character's location combined with our knowledge of the map structure in the two games.</p>
<p>While Phase 1 provides the opportunity to leverage domain knowledge in the cell representation, the robustified Neural Network produced by Phase 2 still plays directly form pixels only.</p>
<h4 id="selecting-cells">Selecting cells</h4>
<p>In each iteration of Phase 1, a cell is chosen from the archive to explore from. This choice could be made:</p>
<ol type="1">
<li>Uniformly at random</li>
<li>Assign a positive weight to each cell that is higher for cells that are deemed more promising (less often visited cells, have recently contributed to discovering a new cell, expected to be near undiscovered cells and etc..). The weights of all cells are normalized to represent the probability distribution over the current cell space. No cell is ever given a weight of 0.</li>
</ol>
<h6 id="count-subscore">Count Subscore</h6>
<p>The score of a cell is the sum of separate subscores. One important set of such subscores is called the <code>count subscore</code>s. <code>Count subscore</code>s are computed from attributes of cells that represent the number of times a cell was interacted with in different ways. Specifically:</p>
<ol type="1">
<li><p>The number of times the cell has already been chosen (i.e selected as a cell to explore from)</p></li>
<li><p>The number of times the cell was visited at any point during the exploration phase</p></li>
<li><p>the number of times a cell has been chosen since exploration from it last produced the discovery of a new or better cell.</p></li>
</ol>
<p>Lower counts of these attributes indicate a more promising cell to explore from (e.g. a cell that has been chosen more times already is less likely to lead to new cells than a cell that has been chosen fewer times). The <code>count subscore</code> for each of these attribute is given by:</p>
<p><span class="math display">\[CntScore (c, a) = w_a \cdot (\frac{1}{v(c, a) + \epsilon_1})^{p_a} + \epsilon_2\]</span></p>
<p>Here:</p>
<ul>
<li><p><span class="math inline">\(c\)</span> is the cell for which we are calculating the score</p></li>
<li><p><span class="math inline">\(v(c, a)\)</span> is the value of attribute <span class="math inline">\(a\)</span> for cell <span class="math inline">\(c\)</span></p></li>
<li><p><span class="math inline">\(w_a\)</span> is the weight hyperparameter for attribute <span class="math inline">\(a\)</span></p></li>
<li><p><span class="math inline">\(p_a\)</span> is the power hyperparameter for attribute <span class="math inline">\(a\)</span></p></li>
<li><p><span class="math inline">\(\epsilon_1\)</span> is a normalization parameter to prevent zero division</p></li>
<li><p><span class="math inline">\(\epsilon_2\)</span> helps guarantee that no cell ever has a 0 probability of being chosen</p>
<p><span class="math inline">\(\epsilon_1=0.001, \epsilon_2=0.00001\)</span> are the default values.</p></li>
</ul>
<h6 id="neighbor-subscore">Neighbor Subscore</h6>
<p>Given the position of <span class="math inline">\(x, y\)</span>, it is possible to determine the possible neighbors of given cells and whether these neighbors are already present in the archive. For these cases, we define a set of <code>neighbor subscore</code>s. Each neighbor subscore is defined as <span class="math inline">\(w_n\)</span> if neighbor <span class="math inline">\(n\)</span> does not exist in the archive, 0 if the does exist.</p>
<p>The motivation of neighbor subscore is that the cells that are lacking neighbors are likely at the edge of the current frontier of knowledge and are thus more likely to yield new cells. We consider 3 types of neighbors:</p>
<ol type="1">
<li>Vertical (2)</li>
<li>Horizontal (2)</li>
<li>Cells that are in the same level, room, <span class="math inline">\(x, y\)</span> position, but are holding a larger number of keys</li>
</ol>
<p>Neighbors of the same type share the same value for <span class="math inline">\(w_n\)</span>, then the score is calculated by:</p>
<p><span class="math display">\[NeighScore(c, n) = w_n * (1 - HasNeighbor(c, n))\]</span></p>
<p>Where <span class="math inline">\(c\)</span> is current cell and <span class="math inline">\(n \in Vertical \cup Horizontal \cup MoreKeys\)</span> is current neighbor. In cases without domain knowledge, it is unclear what exactly would constitute a cell's neighbor, and so <code>neighbor score</code> is defined as 0.</p>
<h6 id="level-weight-only-montezumas-revenge">Level Weight (Only Montezuma's Revenge)</h6>
<p>In the case of Montezuma's Revenge with domain knowledge, cells are exponentially downweighted based on the distance to the maximum level currently reached, thereby favoring progress in the furthest level reached, while skill keeping open the possibility of improving previous level's trajectories:</p>
<p><span class="math display">\[LevelWeight (c) = 0.1^{MaxLevel - Level(c)}\]</span></p>
<p>In the case of no domain knowledge, <span class="math inline">\(LevelWeight (c) = 1, \quad \forall c\)</span></p>
<h5 id="final-score-and-final-cell-probability">Final Score and Final Cell Probability</h5>
<p>The final score is then:</p>
<p><span class="math display">\[CellScore (c) = LevelWeight (c) \cdot [(\sum_n NeighScore (c, n)) + \sum_a CntScore (c, a) + 1]\]</span></p>
<p>The final probability is then:</p>
<p><span class="math display">\[CellProb (c) = \frac{CellScore (c)}{\sum_{c^{\prime}}CellScore (c^{\prime})}\]</span></p>
<p><br></p>
<h5 id="new-version">New Version</h5>
<p><strong>In the new version (except Montezuma's Revenge with domain knowledge but without a return policy), the selection weight (score) is reduced to:</strong></p>
<p><span class="math display">\[W = \frac{1}{\sqrt{C_{seen} + 1}}\]</span></p>
<p>In case of Montezuma's Revenge with domain knowledge but without a return policy, three addtional domain knowledge features further contribute to the weight:</p>
<ol type="1">
<li><p>The number of horizontal neighbours to the cell present in the archive (<span class="math inline">\(h\)</span>).</p></li>
<li><p>A key bonus: for each location (defined by level, room, and x, y position), the cell with the largest number of keys at that location gets a bonus of <span class="math inline">\(k=1\)</span> (<span class="math inline">\(k=0\)</span> for other cells).</p></li>
<li><p>The current level.</p>
<p><span class="math display">\[W_{location} = \frac{2 - h}{10} + k\]</span> <span class="math display">\[W_{mont_domain} = 0.1^{L-l}(W + W_{location})\]</span></p></li>
</ol>
<p>Where, <span class="math inline">\(l\)</span> is the level given current cell and the maximum level in the archive <span class="math inline">\(L\)</span>.</p>
<p><br></p>
<h4 id="returning-to-cells-and-opportunities-to-exploit-deterministic-simulators">Returning to cells and opportunities to exploit deterministic simulators</h4>
<p>The easiest way to return to a cell is if the world is deterministic and resettable, such that one can reset the state of the simulator to a previous visit to that cell. The ability to harness determinism and perform such resets forces us to recognize that there are two different types of problems we wish to solve with RL algorithms:</p>
<ol type="1">
<li>Require stochasticity at test time only</li>
<li>Require stochasticity during both testing and training time (further research)</li>
<li>Environment that prevents return to cells (further research)</li>
</ol>
<p>We can take advantage of the fact simulators can be made deterministic to improve performance, especially on hard-exploration problems. For many types of problems, we want a reliable final solution (e.g. a robot that reliably finds survivors after a natural disaster) and there is no principled reason to care whether we obtain this solution via initially deterministic training. If we can solve previously unsolvable problems, including ones that are stochastic at evaluation (test) time, via making simulators deterministic, we should take advantage of this opportunity.</p>
<p>There are also cases where a simulator is not available and where learning algorithms must confront stochasticity during training. We can train goal-conditioned policies that reliably return to cells in the archive during the exploration phase. This strategy would result in a fully trained policy at the end of the exploration phase meaning there would be no need for a phase 2 at the end.</p>
<p>For problems in which all we care about is a reliable policy at test time, a key insight behind Go-Explore is that we can first solve the problem (Phase 1), and then (if necessary) deal with making the solution more robust later (Phase 2).</p>
<p>Due to the fact that the present version of Go-Explore operates in a deterministic setting during Phase 1, each cell is associated with an open-loop sequence of instructions that lead to it given the <strong>initial state</strong>, not a proper policy that maps any state to an action. A true policy is produced during robustification in Phase 2.</p>
<p><strong>Sequence of actions and states are stored for each cell</strong></p>
<p><br></p>
<h4 id="exploration-from-cells">Exploration from cells</h4>
<p>Once a cell is reached, any exploration method can be applied to find new cells. In this work, the agent explores by taking random actions <span class="math inline">\(k = 100\)</span> training frames, with a 95% probability of repeating the previous action at each training frame. Besides reaching the <span class="math inline">\(k = 100\)</span> training frame limit for exploration, exploration is also aborted at the episodes' end, and the action that led to the episode ending is ignored because it does not produce a destination cell.</p>
<p>This exploration does not require a neural network or other controller.</p>
<p><br></p>
<h4 id="updating-the-archive">Updating the archive</h4>
<p>While an agent is exploring from a cell, the archive updates in two conditions:</p>
<ol type="1">
<li><p>When the agent visits a cell that was no yet in the archive (which can happen multiple times while exploring from a given cell). In this case, , that cell is added to the archive with four associated pieces of meta data:</p>
<ul>
<li>A full trajectory from the starting state to that cell (states and actions)</li>
<li>The state of the environment at the time of discovering the cell (if the environment supports such an operation)</li>
<li>The cumulative score of that trajectory</li>
<li>The length of that trajectory</li>
</ul></li>
<li><p>The second condition is when a newly-encountered trajectory is "better" than that belonging to a cell already in the archive. We define a new trajectory is "better" than an existing trajectory when the new trajectory either has:</p>
<ul>
<li>A higher cumulative score</li>
<li>A shorter trajectory with the same score</li>
</ul>
<p>In either case, we update the existing cell in the archive with new trajectory, new trajectory length, new environment state and new score. In addition, information regarding the likelihood of this cell being chosen resets including the total number of times the cell has been chosen and the number of times the cell has been chosen since leading to the discovery of another cell. Resetting these values is beneficial when cells conflate many different states because a new way of reaching a cell may actually be a more promising stepping stone to explore from (so we want to encourage its selection).</p></li>
</ol>
<h4 id="batch-implementation">Batch Implementation</h4>
<p>Phase 1 is implemented in parallel to take advantage of multiple CPUs. At each step, a batch of <span class="math inline">\(b\)</span> cells is selected with replacement and exploration from each of these cells proceeds in parallel. A high <span class="math inline">\(b\)</span> saves time of recomputing cell selection probabilities less frequently, which is important as this computation accounts for a significant portion of run time as the archive gets large.</p>
<h3 id="phase-2">Phase 2</h3>
<p>If successful, the result of Phase 1 is one or more high-performing trajectories. However, if Phase 1 of Go-Explore harness ed determinism in a simulator, such trajectories will not be robust to any stochasticity, which is present at test time. Phase 2 addresses this gap by creating a policy robust to noise via imitation learning. Thus, the policy that is trained has to lean how to mimic or perform as well as the trajectory obtained from the Go-Explore exploration phase while simultaneously dealing with circumstances that were not present in the original trajectory.</p>
<p>The <code>Backward Algorithm</code> is used for imitation learning. It works by starting the agent near the last state in the trajectory, and then running an ordinary RL algorithm from there (In this case <code>PPO</code>). Once the algorithm has learned to obtain the same or a higher reward than the example trajectory from that starting place near the end of the trajectory, the algorithm backs the agent's starting point up to a slightly earlier place along the trajectory and repeats the process until eventually the agent has learned to obtain a score greater than or equal to the example trajectory all the way from the initial state.</p>
<p><strong>Advantages</strong>:</p>
<ol type="1">
<li>The policy is only optimized to maximize its own score, and not actually forced to accurately mimic the trajectory, for this reason, this phase is able to further optimize the expert trajectories as well as generalize beyond them.</li>
<li>RL algorithms with discounting factor that prizes near-term rewards more than those gathered later. Thus, if the original trajectory contains unnecessary actions, such behavior could be eliminated during robustification.</li>
</ol>
<h2 id="policy-based-go-explore">Policy-based Go-Explore</h2>
<p>In policy-based Go-Explore, a goal-conditioned (i.e conditioned on the cell to return to) policy <span class="math inline">\(\pi_{\theta} (a | s, g)\)</span> is trained during the exploration phase with <code>PPO</code>. Instead of training the policy to directly reach cells in the archive, the policy is trained to follow the best trajectory of cells that previously led to the selected state (cell). The goal-conditioned policy has the potential to greatly improve exploration effectiveness over random actions. In addition to returning to previously visited cells, the policy can also be queried during the explore step by presenting it with additional goals, including goals not already in the archive. Such goal cells are chosen according to a simple strategy that either:</p>
<ol type="1">
<li><p>Chooses a cell adjacent to the current position of the agent, possibly leading to a new cell.</p></li>
<li><p>Randomly selects a cell from the archive, potentially repositioning the agent within the archive or finding new cells while trying to do so.</p></li>
</ol>
<p><strong>Every time post-return exploration (after reaching the selected cell from archive) is started, the algorithm randomly commits with equal probability to either take random actions or sampling from the policy for the duration of the post-return exploration step.</strong></p>
<p>The total reward <span class="math inline">\(r_t\)</span> is the sum of the trajectory reward <span class="math inline">\(r^{\tau}_t\)</span> and the environment reward <span class="math inline">\(r^e_t\)</span>, where <span class="math inline">\(r^e_t\)</span> is clipped to the <span class="math inline">\([-2, 2]\)</span> range. Policy based Go-Explore also includes self-imitation learning, where self-initation actors follow the same procedure as regular actors, except that they replay the trajectory associated with the cell they select from the archive.</p>
<p><img src="/images/RL/papers/go_explore_3.png" width="600"></p>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Imitation Learning</tag>
        <tag>IM</tag>
      </tags>
  </entry>
  <entry>
    <title>GBDT</title>
    <url>/2021/07/19/gbdt/</url>
    <content><![CDATA[<h1 id="gradient-boosting-decision-trees">Gradient Boosting Decision Trees</h1>
<h2 id="boosting-trees">Boosting Trees</h2>
<p>Regression and classification trees partition the space of all joint predictor variable values into disjoint regions <span class="math inline">\(R_j, \; j=1, 2, ...., J\)</span> as represented by the terminal nodes of the tree. A constant <span class="math inline">\(c_j\)</span> is assigned to each such region and the prediction rule is:</p>
<p><span class="math display">\[\mathbf{x} \in R_j \implies f(\mathbf{x}) = c_j\]</span></p>
<p>Thus, a tree can be formally expressed as:</p>
<p><span class="math display">\[T(\mathbf{x}; \boldsymbol{\theta}) = \sum^{J}_{j=1} c_j I[\mathbf{x} \in R_j]\]</span></p>
<p>with parameters <span class="math inline">\(\theta = \{R_j, c_j\}^J_1\)</span>. The parameters are found by iteratively solving minimizing problem:</p>
<ol type="1">
<li>Given <span class="math inline">\(R_j\)</span>, we solve <span class="math inline">\(\hat{c}_j\)</span> by simply taking the average or majority class.</li>
<li><span class="math inline">\(R_j\)</span> is found by iterating over all possible pairs of feature and splitting point.</li>
</ol>
<p>The boosted tree model is a sum of such trees induced in a forward stagewise manner:</p>
<p><span class="math display">\[f_M (\mathbf{x}) = \sum^{M}_{m=1} T(\mathbf{x}; \; \boldsymbol{\theta}_m)\]</span></p>
<p>At each step, one must solve:</p>
<p><span class="math display">\[\hat{\boldsymbol{\theta}}_m = \underset{\boldsymbol{\theta}_m}{\arg\min} \sum^{N}_{i=1} L(y_i, f_{m-1} (\mathbf{x}_i) + T(\mathbf{x}_i; \; \boldsymbol{\theta}_m))\]</span></p>
<h2 id="gradient-boosting">Gradient Boosting</h2>
<p>In general, it is hard to directly take partial derivatives w.r.t the tree's parameters, thus, we take partial derivatives of tree predictions <span class="math inline">\(f(\mathbf{x}_i)\)</span>.</p>
<p>Fast approximate algorithms for solving the above problem with any differentiable loss criterion can be derived by analogy to numerical optimization. We first start with general case. The loss in using <span class="math inline">\(\mathbf{f}\)</span> to predict <span class="math inline">\(y\)</span> on the training data is:</p>
<p><span class="math display">\[L(\mathbf{f}) = \sum^{N}_{i=1} L(y_i, f(\mathbf{x}_i))\]</span></p>
<p>The goal is to minimize <span class="math inline">\(L(\mathbf{x}_i)\)</span> w.r.t <span class="math inline">\(f\)</span>, where here <span class="math inline">\(f(\mathbf{x})\)</span> is constrained to be a sum of trees <span class="math inline">\(f_M (\mathbf{x})\)</span>.</p>
<p>We first start with general case where <span class="math inline">\(f\)</span> can be any parameters or numbers. In this case, we have <span class="math inline">\(N\)</span> samples, thus, <span class="math inline">\(\mathbf{f} = \{f(\mathbf{x}_1), ...., f(\mathbf{x}_N)\} \in \mathbb{R}^N\)</span>.</p>
<p>Then, the gradient of objective w.r.t <span class="math inline">\(\mathbf{f} = \mathbf{f}_{m-1}\)</span> which is the current model is:</p>
<p><span class="math display">\[\mathbf{g}_m = \nabla_{\mathbf{f}} L(\mathbf{f}) = \; &lt;\frac{\partial L(\mathbf{f})}{\partial f(\mathbf{x}_1)}, ...., \frac{\partial L(\mathbf{f})}{\partial f(\mathbf{x}_N)}&gt;\]</span></p>
<p>Then this gradient points at the direction of <strong>steepest increase</strong>, it tells us how we can change our current predictions to increase our loss. Since we want to minimize the objective, we would like to adjust our current predictions to the direction of <strong>steepest decrease</strong>:</p>
<p><span class="math display">\[\mathbf{h}_m = - \rho_m \mathbf{g}_m\]</span></p>
<p>Where <span class="math inline">\(\rho_m\)</span> is the step size for current model and it is minimizer of:</p>
<p><span class="math display">\[\rho_m = \underset{\rho}{\arg\min} \; L(\mathbf{f}_{m-1} - \rho\mathbf{g}_m)\]</span></p>
<p>The current solution is then updated as</p>
<p><span class="math display">\[\mathbf{f}_{m} = f_{m-1} - \rho_m\mathbf{g}_m\]</span></p>
<p><strong>If fitting the training data (minimizing the loss) is our ultimate goal</strong>, then the above update rule can solve our problem by adding the negative gradient at each iteration. However, our ultimate goal is to generalize to new data, copying and pasting training data exactly is not what we want. One possible solution is to learn the update <span class="math inline">\(- \rho_m\mathbf{g}_m\)</span> by fitting a simple decision tree:</p>
<p><span class="math display">\[\hat{\boldsymbol{\theta}}_m = \underset{\boldsymbol{\theta}}{\arg\min} \sum^{N}_{i=1} (-g_{im} - T(x_i; \; \boldsymbol{\theta}))^2\]</span></p>
<p>That is, we fit a regression tree <span class="math inline">\(T\)</span> to the negative gradient values.</p>
<p><img src='/images/ML/gbdt_1.png' width="600"></p>
<h3 id="algorithm">Algorithm</h3>
<p><img src='/images/ML/gbdt_2.png' width="600"></p>
<ol type="1">
<li>We first start by a constant model (model that predict constants) which is a single terminal node tree.</li>
<li>For all samples new targets are generated to be the negative gradient of the loss function w.r.t the current model prediction <span class="math inline">\(\mathbf{f}_{m-1}\)</span>.</li>
<li>Fit a regression tree to minimize the MSE between new target (negative gradient) and current prediction.</li>
</ol>
<h2 id="discussions">Discussions</h2>
<h3 id="regularization">Regularization</h3>
<p>For numbers of gradient boosting rounds <span class="math inline">\(M\)</span>, the loss can be made arbitrarily small. However, fitting the data too well can lead to overfitting which degrades the risk on future predictions.</p>
<h4 id="shrinkage">Shrinkage</h4>
<p>Controlling the value of <span class="math inline">\(M\)</span> is not the only possible regularization strategy, we can add penalty terms to the loss function that penalize large <span class="math inline">\(M\)</span> or we can weight subsequent trees. The simplest implementation of shrinkage in the context of boosting is to scale the contribution of each tree by a factor of <span class="math inline">\(0 &lt; v &lt; 1\)</span>, when it is added to the current approximation:</p>
<p><span class="math display">\[f_m (\mathbf{x}) = f_{m-1}(\mathbf{x}) + v \sum^{J}_{j=1} c_{jm} I[\mathbf{x} \in R_{jm}]\]</span></p>
<p>The parameter <span class="math inline">\(v\)</span> can be regarded as controlling the <strong>learning rate</strong> of the boosting procedure. Smaller values of <span class="math inline">\(v\)</span> result in larger training error for the same number of iterations <span class="math inline">\(M\)</span> but might have better generalization. Thus, both <span class="math inline">\(v\)</span> and <span class="math inline">\(M\)</span> control prediction risk on the training data. <span class="math inline">\(v\)</span> and <span class="math inline">\(M\)</span> tradeoff each other, therefore in practice, it is best to set <span class="math inline">\(v\)</span> small and control <span class="math inline">\(M\)</span> by early stopping.</p>
<h4 id="subsampling">Subsampling</h4>
<p>We know that bootstrap averaging (bagging) improves the performance of a noisy classifier through averaging (reduce variance). We can exploit the same idea in gradient boosting.</p>
<p>At each iteration, we sample a fraction <span class="math inline">\(\eta\)</span> of the training observations without replacement, and grow the next tree using that subsample. A typical value of <span class="math inline">\(\eta\)</span> is 0.5, although for large sample size <span class="math inline">\(N\)</span>, we can have smaller <span class="math inline">\(\eta\)</span>.</p>
<h1 id="ref">Ref</h1>
<p>https://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Heaps</title>
    <url>/2021/07/19/heaps/</url>
    <content><![CDATA[<h1 id="heaps">Heaps</h1>
<p>The <code>binary heap</code> data structure is an array object that we can view as a nearly complete binary tree. Each node of the tree corresponds to an element of the array. The tree is completely filled on all levels except possibly the lowes, which is filled from the left up to a point that is <strong>the elements in the subarray <span class="math inline">\(A[\lfloor \frac{n}{2} \rfloor + 1 ... n]\)</span></strong> are all leaves.</p>
<p>An array <span class="math inline">\(A\)</span> that represents a heap is an object with two attributes:</p>
<ol type="1">
<li><span class="math inline">\(A.length\)</span>: gives the number of elements in the array. <span class="math inline">\(A[1:A.length]\)</span>.</li>
<li><span class="math inline">\(A.heap\_size\)</span>: gives how many elements in the heap are stored within array <span class="math inline">\(A\)</span>. <span class="math inline">\(A[1:A.heap\_size:A.length]\)</span></li>
</ol>
<p>Given the index <span class="math inline">\(i\)</span> of a node, we can easily compute the indices of its parent, left child and right child by:</p>
<ol type="1">
<li><code>parent</code>: <span class="math inline">\(\lfloor \frac{i}{2} \rfloor\)</span> (by shifting right 1 bit <code>i &gt;&gt; 1</code>)</li>
<li><code>left child</code>: <span class="math inline">\(2i\)</span> (by shifting left 1 bit <code>i &lt;&lt; 1</code>)</li>
<li><code>right child</code>: <span class="math inline">\(2i + 1\)</span> (by shifting left 1 bit and add 1 <code>i &lt;&lt; 1 + 1</code>)</li>
</ol>
<p>There are two types of binary heap:</p>
<ol type="1">
<li><code>Max heap</code>: satisfies the <code>max heap property</code> that for every node <span class="math inline">\(i\)</span> other than the root <span class="math inline">\(A[parent(i)] \geq A[i]\)</span>, that is the maximum value in the array is stored in the root and the subtree rooted at a node contains values no larger than that contained at the node itself (heap sorts).</li>
<li><code>Min heap</code>: satisfies the <code>min heap property</code> that is organized in the opposite way, for every node <span class="math inline">\(i\)</span> other than the root <span class="math inline">\(A[parent(i) \leq A[i]]\)</span> (priority queues)</li>
</ol>
<p><br></p>
<p><img src="/images/algo/heap_1.png" width="600px"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Heap</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, A, heap_size</span>):</span></span><br><span class="line">        <span class="comment"># A may not be a heap, call build_min_heap or build_max_heap to convert this instance to heap</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(A, <span class="built_in">list</span>)</span><br><span class="line">        self.heap_size = heap_size</span><br><span class="line">        self.length = <span class="built_in">len</span>(A)</span><br><span class="line">        self._A = A</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">left</span>(<span class="params">self, i</span>):</span></span><br><span class="line">        <span class="keyword">return</span> i &lt;&lt; <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">right</span>(<span class="params">self, i</span>):</span></span><br><span class="line">        <span class="keyword">return</span> i &lt;&lt; <span class="number">1</span> + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parent</span>(<span class="params">self, i</span>):</span></span><br><span class="line">        <span class="keyword">return</span> i &gt;&gt; <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._A[index]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">append</span>(<span class="params">self, val</span>):</span></span><br><span class="line">        self._A.append(val)</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="maintaining-the-heap-property">Maintaining the Heap Property</h2>
<p><code>max_heapify(A, i)</code>, when it is called, <strong>this function assumes that the binary trees rooted at <span class="math inline">\(left(i)\)</span> and <span class="math inline">\(right(i)\)</span></strong> are max heaps but that <span class="math inline">\(A[i]\)</span> might be smaller than its children:</p>
<ol type="1">
<li>At each step, the largest of the elements <span class="math inline">\(A[i], left(i), right(i)\)</span> is determined, and its index is stored in <code>largest</code>.</li>
<li>If <span class="math inline">\(A[i]\)</span> is largest, then the subtree rooted at node <span class="math inline">\(i\)</span> is already a max-heap, we terminate the function.</li>
<li>Otherwise, we swap <span class="math inline">\(A[i]\)</span> with <span class="math inline">\(A[\arg\max(A[left(i)], A[right(i)])]\)</span></li>
<li>Next, repeat on node <span class="math inline">\(A[\arg\max(A[left(i)], A[right(i)])]\)</span> until the function terminates.</li>
</ol>
<p><img src="/images/algo/heap_2.png" width="600px"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span>(<span class="params">A, i</span>):</span></span><br><span class="line">    <span class="comment"># get left and right index</span></span><br><span class="line">    l = A.left(i)</span><br><span class="line">    r = A.right(i)</span><br><span class="line">    <span class="comment"># if left &gt; A[i], set current largest index to l</span></span><br><span class="line">    <span class="keyword">if</span> l &lt;= A.heap_size <span class="keyword">and</span> A[l] &gt; A[i]:</span><br><span class="line">        largest = l</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        largest = i</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># if right &gt; A[i], set current largest index to r</span></span><br><span class="line">    <span class="keyword">if</span> r &lt;= A.heap_size <span class="keyword">and</span> A[r] &gt; A[largest]:</span><br><span class="line">        largest = r</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># if there largest is A[i], we have base case therefore we dump out the loop, else we repeat on largest</span></span><br><span class="line">    <span class="keyword">if</span> largest != i:</span><br><span class="line">        A[i], A[largest] = A[largest], A[i]</span><br><span class="line">        max_heapify(A, largest)</span><br></pre></td></tr></table></figure>
<p><code>min_heapify</code> can be implemented in similar but opposite way.</p>
<h2 id="building-a-heap">Building a Heap</h2>
<p>We can use the procedure <code>max_heapify</code> in a bottom-up manner to convert an array <span class="math inline">\(A[1 ... A.heap\_size]\)</span> into a max heap. Recall that the elements in the subarray <span class="math inline">\(A[\lfloor \frac{n}{2} \rfloor + 1 ... n]\)</span> are all leaves of the trees, and so each is a 1-element heap to begin with. The function <code>build_max_heap(A)</code> goes through the remaining nodes of the tree and runs <code>max_heapify</code> on each one.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_max_heap</span>(<span class="params">A</span>):</span></span><br><span class="line">    n = A.heap_size</span><br><span class="line">    <span class="comment"># start at first non-leave node which is floor(n / 2)</span></span><br><span class="line">    start = n // <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        max_heapify(A, i)</span><br></pre></td></tr></table></figure>
<p>A min heap can be build in similar way by replace <code>max_heapify</code> with <code>min_heapify</code>.</p>
<h2 id="heap-sort">Heap Sort</h2>
<p>Recall that, a root of the max heap is the maximum item in the array <span class="math inline">\(A[1 ... A.heap\_size]\)</span>. if we do a <code>build_max_heap</code> on entire <span class="math inline">\(A\)</span>, swap <span class="math inline">\(A[1]\)</span> with <span class="math inline">\(A[n]\)</span> and then do a <code>max_heapify(A[1 ... n - 1], i)</code>, we end up with a sorted array.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span>(<span class="params">A</span>):</span></span><br><span class="line">    build_max_heap(A)</span><br><span class="line">    <span class="keyword">while</span> A.heap_size &gt;= <span class="number">2</span>:</span><br><span class="line">        A[<span class="number">0</span>], A[heap_size - <span class="number">1</span>] = A[heap_size - <span class="number">1</span>], A[<span class="number">0</span>]</span><br><span class="line">        A.heap_size = A.heap_size - <span class="number">1</span></span><br><span class="line">        max_heapify(A, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="priority-queues">Priority Queues</h2>
<p>A <code>priority queue</code> is a data structure for maintaining a set <span class="math inline">\(S\)</span> of elements, each with an associated value called a <span class="math inline">\(key\)</span>. A <code>max priority queue</code> is based on <code>max heap</code> and a <code>min prioprity queue</code> is based on <code>min heap</code>.</p>
<p>The <code>max priority queue</code> (used in scheduler such as job scheduling) supports:</p>
<ol type="1">
<li><code>insert(S, x)</code>: inserts the elements <span class="math inline">\(x\)</span> into <span class="math inline">\(S\)</span>.</li>
<li><code>maximum(S)</code>: returns the element of S with the largest key.</li>
<li><code>extract_max(S)</code>: removes and returns the element of <span class="math inline">\(S\)</span> with the largest key.</li>
<li><code>increase_key(S, i, k)</code>: increases the value of index <span class="math inline">\(i\)</span>'s key to the new value <span class="math inline">\(k\)</span>, which is assumed to be at least as large as <span class="math inline">\(x\)</span>'s current key value.</li>
</ol>
<p>The <code>min priority queue</code> (used in event-driven simulator) supports:</p>
<ol type="1">
<li><code>insert(S, x)</code>: inserts the elements <span class="math inline">\(x\)</span> into <span class="math inline">\(S\)</span>.</li>
<li><code>minimum(S)</code>: returns the element of S with the smallest key.</li>
<li><code>extract_min(S)</code>: removes and returns the element of <span class="math inline">\(S\)</span> with the smallest key.</li>
<li><code>decrease_key(S, i, k)</code>: decreases the value with index <span class="math inline">\(i\)</span>'s key to the new value <span class="math inline">\(k\)</span>, which is assumed to be at most as large as <span class="math inline">\(x\)</span>'s current key value.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maximum</span>(<span class="params">A</span>):</span></span><br><span class="line">    <span class="keyword">return</span> A[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_max</span>(<span class="params">A</span>):</span></span><br><span class="line">    <span class="keyword">if</span> A.heap_size &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Heap underflow&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    max_val = maximum(A)</span><br><span class="line">    A[<span class="number">0</span>], A[A.heap_size - <span class="number">1</span>] = A[A.heap_size - <span class="number">1</span>], A[<span class="number">0</span>]</span><br><span class="line">    A.heap_size = A.heap_size - <span class="number">1</span></span><br><span class="line">    max_heapify(A, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> max_val</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increase_key</span>(<span class="params">A, i, k</span>):</span></span><br><span class="line">    n = A.heap_size</span><br><span class="line">    <span class="keyword">if</span> i &gt;= n <span class="keyword">or</span> n &lt; <span class="number">1</span> <span class="keyword">or</span> k &lt; A[i]:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&#x27;invalid key or value&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    A[i] = k</span><br><span class="line">    <span class="keyword">while</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> A[i] &gt; A[A.parent(i)]:</span><br><span class="line">        A[i], A[A.parent(i)], i = A[A.parent(i)], A[i], A.parent(i)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">A, x</span>):</span></span><br><span class="line">    <span class="comment"># add a new leave, then increase key of the leave to x.</span></span><br><span class="line">    A.append(x)</span><br><span class="line">    A.heap_size = A.heap_size + <span class="number">1</span></span><br><span class="line">    A.length = A.length + <span class="number">1</span></span><br><span class="line">    increase_key(A, A.heap_size - <span class="number">1</span>, x)</span><br></pre></td></tr></table></figure>
<h2 id="complexity">Complexity</h2>
<ol type="1">
<li><code>max_heapify</code>: <span class="math inline">\(O(\log (n))\)</span></li>
<li><code>build_max_heap</code>: <span class="math inline">\(O(n)\)</span></li>
<li><code>heap_sort</code>: <span class="math inline">\(O(n \log (n))\)</span></li>
<li><code>maximum</code>: <span class="math inline">\(O(1)\)</span></li>
<li><code>extract_max</code>: <span class="math inline">\(O(\log n)\)</span></li>
<li><code>insert</code>: <span class="math inline">\(O(\log n)\)</span></li>
<li><code>increase_key</code>: <span class="math inline">\(O(\log n)\)</span></li>
</ol>
]]></content>
      <categories>
        <category>CS Basics</category>
      </categories>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>Sequential Data</title>
    <url>/2021/09/16/hmm/</url>
    <content><![CDATA[<h1 id="sequential-data">Sequential Data</h1>
<p>In some cases, we have i.i.d assumptions to allow use to express the likelihood function as the product over all data points of the probability distribution evaluated at each data point. However, in some cases namely sequential data, we may not have i.i.d samples.</p>
<h2 id="markov-models">Markov Models</h2>
<p>To express the sequential dependence of the samples, we can relax the i.i.d assumption and one of the simplest ways to do this is to consider a <code>Markov Model</code>. First of all, without loss of generality, we can use the product rule to express the joint distribution for a sequence of observations in the form:</p>
<p><span class="math display">\[P(X_1, ...., X_n) = \prod^N_{n=1} P(X_n | X_1, ..., X_{n-1})\]</span></p>
<p>If we assume that each of the conditional distributions on the right-hand side is independent of all previous observations except the most recent, we obtain the <code>first-order Markov Chain</code>, which can depicted as graphical model:</p>
<p><img src='/images/ML/hmm_1.png' width="600"></p>
<p>The joint distribution for a sequence of <span class="math inline">\(N\)</span> observations under this model is given by:</p>
<p><span class="math display">\[P(X_1, ..., X_N) = P(X_1) \prod^{N}_{n=2} P(X_n | X_{n-1})\]</span></p>
<p>Thus, if we use such a model to predict the next observation in a sequence, the distribution of predictions will depend only on the value of the immediately preceding observation and will be independent of all earlier observations. In most applications of such models, the conditional distributions <span class="math inline">\(P(X_n | X_{n-1})\)</span> that define the model will be constrained to be equal, corresponding to a assumption of a stationary time series. The model is then known as the <code>homogeneous Markov Chain</code> (All conditional distribution share the same parameters).</p>
<p>However, first-order Markov model is still restrictive. For many sequential observations, we anticipate that the trends in the data over several successive observations will provide important information in predicting the next value. One way to allow earlier observations to have an influence is to move to higher-order Markov chains, the <code>second-order Markov chain</code> is given by:</p>
<p><span class="math display">\[P(X_1, ..., X_N) = P(X_1) P(X_2 | X_1) \prod^{N}_{n=3} P(X_n | X_{n-1}, X_{n-2})\]</span></p>
<p><img src='/images/ML/hmm_2.png' width="600"></p>
<p>Suppose we wish to build a model for sequences that is not limited by the Markov assumption to any order and yet that can be specified using a limited number of free parameters. We can achieve this by introducing additional latent variables to permit a rich class of models to be constructed out of simple components, as we did with mixture distributions.</p>
<p>For each observation <span class="math inline">\(\mathbf{X}_n\)</span>, we introduce a corresponding latent random vector <span class="math inline">\(\mathbf{Z}_n\)</span> which may be of different type or dimensionality to the observed variable. We now assume that it is the <strong>latent variables that form a Markov chain</strong>, giving rise to the graphical structure known as <code>state space model</code>. It satisfies the key conditional independence properties that <span class="math inline">\(\mathbf{Z}_{n-1}, \mathbf{Z}_{n+1}\)</span> are independent given <span class="math inline">\(\mathbf{Z}_n\)</span> so that:</p>
<p><span class="math display">\[\mathbf{Z}_{n+1} \perp \!\!\! \perp \mathbf{Z}_{n-1} \;|\; \mathbf{Z}_n\]</span></p>
<p>The joint distribution of the model is:</p>
<p><span class="math display">\[P(\mathbf{X}_1, ...., \mathbf{X}_{N}, \mathbf{Z}_1, ...., \mathbf{Z}_{N}) = P(\mathbf{Z}_1) \prod^N_{n=1} P(\mathbf{X}_n | \mathbf{Z}_n) \prod^{N}_{n=2} P(\mathbf{Z}_n | \mathbf{Z}_{n-1})\]</span></p>
<p><img src='/images/ML/hmm_3.png' width="600"></p>
<p>Using the d-separation criterion, we see that there is always a path connecting any two observed variables <span class="math inline">\(\mathbf{X}_n\)</span> and <span class="math inline">\(\mathbf{X}_{n+1}\)</span> via the latent variable, so the predictive distribution <span class="math inline">\(P(\mathbf{X}_{n+1} | \mathbf{X}_{1} , ..., \mathbf{X}_{n})\)</span> does not have any conditional dependence properties so it depends on all previous variables.</p>
<p>There are two important models for sequential data:</p>
<ol type="1">
<li><strong>Hidden Markov Model</strong>: If the latent variables are discrete.</li>
<li><strong>Linear Dynamical System</strong>: If the latent variables, observed variables are Gaussian with a linear-Gaussian dependence of the conditional distributions on their parents.</li>
</ol>
<h2 id="hidden-markov-models">Hidden Markov Models</h2>
<p>The hidden markov model can be viewed as specific instance of the state space model with discrete latent variables. It can also be viewed as an extension of a mixture model in which the choice of mixture component for each observation is not selected independently but depends on the choice of component for the previous observation.</p>
<p>It is convenient to use 1-of-<span class="math inline">\(K\)</span> coding scheme for the latent variables <span class="math inline">\(\mathbf{Z}_n\)</span>. We now allow the probability distribution of <span class="math inline">\(\mathbf{Z}_n\)</span> to depend on the state of previous latent variable <span class="math inline">\(\mathbf{Z}_{n-1}\)</span> through a conditional probability distribution <span class="math inline">\(P(\mathbf{Z}_{n} | \mathbf{Z}_{n-1})\)</span>. Since, we want to express the dependency of each element of <span class="math inline">\(\mathbf{Z}_n\)</span> on each element of <span class="math inline">\(\mathbf{Z}_{n-1}\)</span>, we introduce a <span class="math inline">\(K \times K\)</span> matrix of probabilities that we denote by <span class="math inline">\(\mathbf{A}\)</span>, the element of which are known as transition probabilities:</p>
<p><span class="math display">\[A_{jk} = P(Z_{nk} = 1 | Z_{n-1, j}) = 1\]</span></p>
<p>And because they are probabilities:</p>
<p><span class="math display">\[\sum^K_{k=1} A_{jk} = 1\]</span></p>
<p><span class="math display">\[0 \geq A_{jk} \leq 1\]</span></p>
<p><img src='/images/ML/hmm_4.png' width="600"></p>
<p>We can write the conditional distribution explicitly in the form:</p>
<p><span class="math display">\[P(\mathbf{Z}_{n} | \mathbf{Z}_{n-1}, \mathbf{A}) = \prod^K_{k=1}\prod^{K}_{j=1} A_{jk}^{Z_{nk}Z_{n-1, \;j}}\]</span></p>
<p>The initial latent node <span class="math inline">\(\mathbf{Z}_1\)</span> is special in that it does not have a parent node, and so it has a marginal distribution <span class="math inline">\(P(\mathbf{Z}_1)\)</span> represented by a vector of probabilities that represents the initial probabilities <span class="math inline">\(\boldsymbol{\pi}\)</span>:</p>
<p><span class="math display">\[\pi_k = P(Z_{1k} = 1)\]</span> <span class="math display">\[\sum^{K}_{k=1} \pi_k = 1\]</span> <span class="math display">\[P(\mathbf{Z}_1 | \boldsymbol{\pi}) = \prod^K_{k=1} \pi_k^{Z_{1k}}\]</span></p>
<p>Lastly, the specification of the probabilistic model is completed by defining the conditional distribution of observed variables <span class="math inline">\(P(\mathbf{X}_n | \mathbf{Z}_n, \boldsymbol{\phi})\)</span>, where <span class="math inline">\(\boldsymbol{\phi} = \{\boldsymbol{\phi}_1, ...., \boldsymbol{\phi}_K\}\)</span> is a set of parameters governing the distribution. These distributions are called <code>emissino distribution</code> and might be given by Gaussian if the elements of <span class="math inline">\(\mathbf{X}\)</span> are continues random variables or by conditioanl probability tables if <span class="math inline">\(\mathbf{X}\)</span> are discrete. Since the distribution depends on the values of <span class="math inline">\(\mathbf{Z}\)</span> which has <span class="math inline">\(K\)</span> possible states, We can define the emission distribution as:</p>
<p><span class="math display">\[P(\mathbf{X}_n | \mathbf{Z}_n, \boldsymbol{\phi}) = \prod^K_{k=1} P(\mathbf{X}_n | \boldsymbol{\phi}_k)^{Z_{nk}}\]</span></p>
<p>In this case, we focus on <strong>Homogeneous</strong> models for which all the conditional distributions governing the latent variables share the same parameters <span class="math inline">\(\mathbf{A}\)</span> and similarly all of the emission distributions share the same parameters <span class="math inline">\(\boldsymbol{\phi}\)</span>, so the joint distribution is:</p>
<p><span class="math display">\[P(\mathbf{X}_1, ...., \mathbf{X}_{N}, \mathbf{Z}_1, ...., \mathbf{Z}_{N} | \boldsymbol{\theta}) = P(\mathbf{D}, \mathbf{H} | \boldsymbol{\theta}) = P(\mathbf{Z}_1 | \boldsymbol{\pi}) \prod^N_{n=1} P(\mathbf{X}_n | \mathbf{Z}_n, \boldsymbol{\phi}) \prod^{N}_{n=2} P(\mathbf{Z}_n | \mathbf{Z}_{n-1}, \mathbf{A})\]</span></p>
<p>Where <span class="math inline">\(\boldsymbol{\theta} = \{\boldsymbol{\pi}, \boldsymbol{\phi}, \boldsymbol{A}\}\)</span></p>
<h3 id="maximum-likelihood-for-hmm">Maximum Likelihood for HMM</h3>
<p>If we have observed a dataset <span class="math display">\[\mathbf{D} = \{\mathbf{x}_1, ...., \mathbf{x}_N\}\]</span>, we can determine the parameters of an HMM using maximum likelihood method. The likelihood function is obtained from the joint distribution by marginalizing over the latent variables:</p>
<p><span class="math display">\[L(\boldsymbol{\theta} ;\; \mathbf{D}) = \sum_{\mathbf{H}} P(\mathbf{D}, \mathbf{H} | \; \boldsymbol{\theta}) = P(\mathbf{D} | \; \boldsymbol{\theta}) = \prod^N_{n=1} P(\mathbf{x}_n |\; \boldsymbol{\theta})\]</span></p>
<p>This is similar to the mixture distribution with latent variable in EM, we have a summation inside the log for log likelihood which is much difficult to work with, direct maximization of the log likelihood function will therefore lead to complex expressions with no closed-form solutions. Thus, one way to solve the problem is to use <strong>EM algorithm</strong> to find an efficient framework for maximizing the likelihood function in HMM.</p>
<p>The EM algorithm starts with some initial selection for the model parameters, which we denote by <span class="math inline">\(\boldsymbol{\theta}^{old}\)</span>:</p>
<ol type="1">
<li><strong>E step</strong>:
<ul>
<li>We take these parameter values and find the posterior distribution of the latent variables: <span class="math display">\[P(\mathbf{H} | \mathbf{X}, \boldsymbol{\theta}^{old})\]</span></li>
<li>We then evaluate the expectation of complete log likelihood function over the posterior distribution of the latent variables as a function of new parameters <span class="math inline">\(\boldsymbol{\theta}\)</span>: <span class="math display">\[Q(\boldsymbol{\theta}, \boldsymbol{\theta}^{old}) = E_{\mathbf{H} | \mathbf{D}, \boldsymbol{\theta}^{old}}[\ln P(\mathbf{D}, \mathbf{H} | \boldsymbol{\theta}) | \mathbf{D}, \boldsymbol{\theta}^{old}]\]</span></li>
<li>We can rewrite the log likelihood as:
<span class="math display">\[\begin{aligned}
  Q(\boldsymbol{\theta}, \boldsymbol{\theta}^{old}) &amp;= \sum_{\mathbf{H}} P(\mathbf{H} | \mathbf{D}, \boldsymbol{\theta}^{old}) \ln P(\mathbf{D}, \mathbf{H} | \boldsymbol{\theta})\\
  &amp;= \sum^{K}_{k=1}P(Z_{1k} = 1 | \mathbf{D}, \boldsymbol{\theta}^{old}) \ln P(Z_{1k} = 1| \boldsymbol{\pi}) + \sum^N_{n=2}\sum^{K}_{j=1}\sum^{K}_{k=1} P(Z_{nk}, Z_{n-1, j} | \mathbf{D}, \boldsymbol{\theta}^{old}) \ln P(Z_{nk} | Z_{n-1, j}) + \sum^{N}_{n=1}\sum^{K}_{k=1} P(Z_{nk} = 1 | \mathbf{D}, \boldsymbol{\theta}^{old}) \ln P(\mathbf{X}_n| \boldsymbol{\phi}_k, Z_{nk}=1)\\
  &amp;= \sum^{K}_{k=1} \gamma(Z_{nk})\ln \pi_k + \sum^N_{n=2}\sum^{K}_{j=1}\sum^{K}_{k=1} \xi(Z_{nk}, Z_{n-1, j})\ln A_{jk} + \sum^{N}_{n=1}\sum^{K}_{k=1} \gamma(Z_{nk}) \ln P(\mathbf{X}_n| \boldsymbol{\phi}_k, Z_{nk}=1)
  \end{aligned}\]</span>
Where <span class="math inline">\(\gamma (Z_{nk}) = P(Z_{1k} = 1 | \mathbf{D}, \boldsymbol{\theta}^{old})\)</span> and <span class="math inline">\(\xi(Z_{nk}, Z_{n-1, j}) = P(Z_{nk}, Z_{n-1, j} | \mathbf{D}, \boldsymbol{\theta}^{old}) \ln P(Z_{nk} | Z_{n-1, j})\)</span></li>
<li><strong>Our goal is to evaluate these posterior probabilities <span class="math inline">\(\gamma, \xi\)</span> efficiently</strong></li>
</ul></li>
<li><strong>M step</strong>:
<ul>
<li>We maximize <span class="math inline">\(Q(\boldsymbol{\theta}, \boldsymbol{\theta}^{old})\)</span> w.r.t the parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> in which we treat posterior probabilities as constant:</li>
</ul></li>
</ol>
<h1 id="ref">Ref</h1>
<p>PRML Chapter 13</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Intrinsic Motivation</title>
    <url>/2021/06/25/instrinsic-motivation/</url>
    <content><![CDATA[<h1 id="intrinsically-motivated-reinforcement-learning">Intrinsically Motivated Reinforcement Learning</h1>
<h2 id="definitions">Definitions</h2>
<h3 id="extrinsic-motivation">Extrinsic Motivation</h3>
<p>Being moved to do something because of some specific rewarding outcome.</p>
<h3 id="intrinsic-motivation">Intrinsic Motivation</h3>
<p>Being moved to do something because it is inherently enjoyable. Intrinsic motivation leads organisms to engage in exploration, play and other behavior driven by curiosity in the absence of explicit reward.</p>
<h3 id="behavior-intrinsically-motivated">Behavior Intrinsically Motivated</h3>
<p>Psychologists call behavior intrinsically motivated when it is engaged in for its own sake rather than as a step toward solving a specific problem of clear practical value.</p>
<h2 id="reinforcement-learning-of-skills">Reinforcement Learning of Skills</h2>
<p><img src="/images/RL/papers/imrl_1.png" width="600"></p>
<span id="more"></span>
<h3 id="options-skills">Options (Skills)</h3>
<p>Starting from a finite MDP, which we call the core MDP, the simplest kind of <code>option</code> <span class="math inline">\(o\)</span> consists of:</p>
<ol type="1">
<li>A policy <span class="math inline">\(\pi^o: S \times \cup_{s \in S} A_s \rightarrow [0, 1]\)</span></li>
<li>A termination condition <span class="math inline">\(\beta^o: S \rightarrow [0, 1]\)</span></li>
<li>An input set <span class="math inline">\(I^o \subset S\)</span></li>
</ol>
<p>The <code>option</code> is defined by a triplet <span class="math inline">\(o = &lt;I^o, \pi^o, \beta^o&gt;\)</span>. This option is available in state <span class="math inline">\(s\)</span> if and only if <span class="math inline">\(s \in I^o\)</span>.</p>
<p>If the option is executed, then actions are selected according to <span class="math inline">\(\pi^o\)</span> until the option terminates stochastically according to <span class="math inline">\(\beta^o\)</span>.</p>
<p>Example:</p>
<blockquote>
<p>If the current state is <span class="math inline">\(s\)</span>, the next action is <span class="math inline">\(a\)</span> with probability <span class="math inline">\(\pi^o (s, a)\)</span>, the environment makes a transition to state <span class="math inline">\(s^{\prime}\)</span>, where the option either terminates with probability <span class="math inline">\(\beta^o (s^{\prime})\)</span> or else continues, determining the next action <span class="math inline">\(a^{\prime}\)</span> with probability <span class="math inline">\(\pi^o (s^{\prime}, a^{\prime})\)</span> and so on.</p>
</blockquote>
<p>When the option terminates, the agent can select another option from the set of those available at the termination state. Note that any action of the core MDP, a primitive action <span class="math inline">\(a \in \cup_{s \in S} A_s\)</span> is also an option, called an <code>one-step option</code>, with <span class="math inline">\(I = \{s: a \in A_s\}\)</span> and <span class="math inline">\(\beta (s) = 1\)</span> for all <span class="math inline">\(s \in S\)</span>. This one-step option can be regard as taking one step forward for all actions available at the state <span class="math inline">\(s\)</span>.</p>
<p>A policy <span class="math inline">\(\mu\)</span> over options selects option <span class="math inline">\(o\)</span> in state <span class="math inline">\(s\)</span> with probability <span class="math inline">\(\mu(s, o)\)</span>. <span class="math inline">\(o\)</span>'s policy in turn selects other options until <span class="math inline">\(o\)</span> terminates. The policy of each of these selected options selects other options and so on, until one-step options are selected that correspond to actions of the core MDP.</p>
<p>Example:</p>
<blockquote>
<p>We start at <span class="math inline">\(s_0\)</span>, select option <span class="math inline">\(o\)</span> according to <span class="math inline">\(\mu\)</span>, then we select <span class="math inline">\(o_1, ..., o_T\)</span> with probability <span class="math inline">\(\pi^{o} (s_0, o_1), ..., \pi^{o} (s_0, o_T)\)</span>, until option <span class="math inline">\(o_T\)</span> which is a one-step option with <span class="math inline">\(\pi^{o_T} (s_0, a) = 1\)</span> for some primitive action <span class="math inline">\(a\)</span>, then we reach state <span class="math inline">\(s^{\prime}\)</span> with probability <span class="math inline">\(P(s^{\prime} | s_0, a)\)</span>, the process for option <span class="math inline">\(o\)</span> terminates. Repeat for <span class="math inline">\(o_1, ...., o_{T-1}\)</span> and all the child process induced until termination.</p>
</blockquote>
<p>Adding any set of options to a core finite MDP yields a well-defined discrete-time semi-Markov decision process whose actions are the options and whose rewards are the return delivered over the course of an option's execution.</p>
<p>One can define value functions corresponding to options in a manner analogous to how they are defined for simple MDPs. For example, the option-value function corresponding to <span class="math inline">\(\mu\)</span> is defined as:</p>
<p><span class="math display">\[Q^{\mu} (s, o) = E[r_{t+1} + \gamma r_{t+2} + .... + \gamma^{\tau - 1} r_{t+\tau} + ... | \xi (o\mu, s, t)]\]</span></p>
<p>Where <span class="math inline">\(\xi (o\mu, s, t)\)</span> is the event of <span class="math inline">\(o\)</span> being initiated at time <span class="math inline">\(t\)</span> in <span class="math inline">\(s\)</span> and being followed until it terminates after <span class="math inline">\(\tau\)</span> time steps, at which point control continues according to <span class="math inline">\(\mu\)</span>.</p>
<p>A multi-time model of an option, which we can call an <code>option model</code>, generalizes the one-step model of a primitive action. For any option <span class="math inline">\(o\)</span>, let <span class="math inline">\(\xi (o, s, t)\)</span> denote the event of <span class="math inline">\(o\)</span> being initialized in state <span class="math inline">\(s\)</span> at time <span class="math inline">\(t\)</span>. Then the reward part of the option model of <span class="math inline">\(o\)</span> for any <span class="math inline">\(s \in S\)</span> is:</p>
<p><span class="math display">\[R(s, o) = E[r_{t+1} + \gamma r_{t+2} + .... + \gamma^{\tau - 1} r_{t+\tau} | \xi (o, s, t)]\]</span></p>
<p>Where <span class="math inline">\(t + \tau\)</span> is the random time at which <span class="math inline">\(o\)</span> terminates. The state prediction part of the model of <span class="math inline">\(o\)</span> for <span class="math inline">\(s\)</span> is:</p>
<p><span class="math display">\[P(s^{\prime} | s, o) = \sum^{\infty}_{\tau = 1} p(s^{\prime}, \tau) \gamma^{\tau}\]</span></p>
<p>For all <span class="math inline">\(s^{\prime} \in S\)</span>, where <span class="math inline">\(p(s^{\prime}, \tau)\)</span> is the probability that <span class="math inline">\(o\)</span> terminates in <span class="math inline">\(s^{\prime}\)</span> after <span class="math inline">\(\tau\)</span> step when initiated in <span class="math inline">\(s\)</span>. Though not itself a probability, <span class="math inline">\(P(s^{\prime} | s, o)\)</span> is a combination of the probability that <span class="math inline">\(s^{\prime}\)</span> is the state in which <span class="math inline">\(o\)</span> terminates together with a measure of how delayed that outcome is in terms of <span class="math inline">\(\gamma\)</span>.</p>
<p>The quantities <span class="math inline">\(R(s, o), P(s^{\prime} | s, o)\)</span> generalize the reward and transition probabilities in core MDP respectively in such a way that it is possible to write a generalized form of the bellman optimality equation and extend RL methods to options.</p>
<h2 id="intrinsic-rewards-and-options">Intrinsic Rewards and Options</h2>
<p>Identify states that may usefully serve as 'subgoals' for a given task. An option is created whose policy, when it is fully learned, will control the environment to a subgoal state in an efficient manner, usually in minimum time, from any state in the option's input set, which may itself be learned.</p>
<ul>
<li>The option's termination condition is set to be the achievement of a subgoal state</li>
<li>The option's policy is learned via a "pseudo reward function" (different from the reward function of the overall goal, it does not influence the behavior of the agent. It is used only to support the learning of the option's policy) which rewards the achievement of the subgoal and provides a small penalty to all other transitions.</li>
</ul>
<p>The connection between intrinsic motivation and options, is the idea of creating an option upon the occurrence of an intrinsically-rewarding event, where what constitutes an intrinsically-rewarding event can be defined:</p>
<ul>
<li>Intrinsic rewards influences agent behavior. The agent should change its behavior in such as way that it focuses exploration in order to quickly refine its skill in bringing about the intrinsically-rewarding event. A corollary to this is that intrinsic reward should diminish with continued repetition of the activity that generates it. (i.e the agent should eventually get bored and move on to create and learn another option)</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<ol type="1">
<li>construction of temporally-extended skills (option) can confer clear advantages over learning solely with primitive actions.</li>
<li>Defining an effective form of intrinsic reward is not as straightforward.</li>
<li>Intrinsic reward can reduce the speed of learning by making the agent persist in behavior directed toward a salient event long after that behavior has been well learned.</li>
<li>This kind of 'obsessive-compulsive' behavior hinders the attainment of extrinsic goals</li>
<li>Intrinsic reward does not propagate well, tending to remain restricted to the immediate vicinty of the salient event that gave rise to it.</li>
</ol>
<h1 id="reference">Reference</h1>
]]></content>
      <categories>
        <category>RL</category>
        <category>Basics</category>
      </categories>
      <tags>
        <tag>IM</tag>
      </tags>
  </entry>
  <entry>
    <title>K-Means</title>
    <url>/2021/07/19/k-means/</url>
    <content><![CDATA[<h1 id="k-means">K-Means</h1>
<p>Considering the problem of identifying groups, or clusters of data points in a multidimensional space.</p>
<p>Suppose we have a dataset <span class="math inline">\(\mathbf{x}_1, ....., \mathbf{x}_N\)</span> consisting of <span class="math inline">\(N\)</span> observations of a random <span class="math inline">\(D\)</span> dimensional euclidean variable <span class="math inline">\(\mathbf{x}\)</span>. <strong>Our goal is to partition these points in to <span class="math inline">\(K\)</span> clusters</strong>.</p>
<p>A cluster <span class="math inline">\(k\)</span> contains:</p>
<ol type="1">
<li><strong>Cluster center</strong>: <span class="math inline">\(\boldsymbol{\mu}_k \in \mathbb{R}^{D}\)</span>.</li>
<li><strong>Assignment indicator variables</strong>: <span class="math inline">\(\mathbf{r}_{n} \in \mathbb{R}^{K}, \; r_{nk} \in \{0, 1\}\)</span>, one for each data point and each dimension <span class="math inline">\(k\)</span> indicates whether the data point <span class="math inline">\(\mathbf{x}_n\)</span> belongs to cluster <span class="math inline">\(k\)</span></li>
</ol>
<p>So we can reformulate our goal to be: <strong>find an assignment of data points to clusters, as well as a set of cluster centers <span class="math inline">\(\{\boldsymbol{\mu}_k\}^{K}_{k=1}\)</span>, such that the sum of squares of the distances of each data point to its closest cluster center is a minimum.</strong> In equation, our objective is:</p>
<p><span class="math display">\[J(\mathbf{x}; \; \{\boldsymbol{\mu}_{k}, \mathbf{r}_{nk}\}) = \sum^{N}_{n=1}\sum^{K}_{k=1} r_{nk} \|\mathbf{x}_n - \boldsymbol{\mu}_k\|^2_2\]</span></p>
<p>Where the distance measure here is the L2 norm.</p>
<p>Thus, we want to find parameters <span class="math inline">\(\{\boldsymbol{\mu}_{k}, \mathbf{r}_{nk}\}\)</span> such that the objective is minimized.</p>
<h2 id="algorithm">Algorithm</h2>
<ol type="1">
<li>Initialize <span class="math inline">\(\boldsymbol{\mu}_k, \; \forall \; k=1, ...., K\)</span></li>
<li>Given <span class="math inline">\(\{\boldsymbol{\mu}_k\}\)</span>, minimize <span class="math inline">\(J\)</span> w.r.t <span class="math inline">\(\{\mathbf{r}_{n}\}\)</span></li>
<li>Given <span class="math inline">\(\{\mathbf{r}_{n}\}\)</span>, minimize <span class="math inline">\(J\)</span> w.r.t <span class="math inline">\(\{\boldsymbol{\mu}_k\}\)</span></li>
<li>Repeat 2, 3 until converges</li>
</ol>
<p><strong>For phase 2</strong>:</p>
<p>Given the cluster centers, it is obvious that if we assign each point to the closest cluster center, we have the minimum objective:</p>
<p><span class="math display">\[
r_{nk}=
\begin{cases}
1, \quad \text{if }\; k = \underset{k}{\arg\min} \|\mathbf{x}_n - \boldsymbol{\mu}_k\|^2_2\\
0, \quad o.w\\
\end{cases}
\]</span></p>
<p><strong>For phase 3</strong>:</p>
<p>Given the assignments, since the objective is convex, we can take gradient and solve for the optimal <span class="math inline">\(\boldsymbol{\mu}_k\)</span>:</p>
<p><span class="math display">\[\frac{\partial J}{\partial \boldsymbol{\mu}_k} = \sum^{N}_{n=1} -2 r_{nk} \mathbf{x}_n + 2\boldsymbol{\mu}_k \sum^{N}_{n=1} r_{nk} = 0\]</span></p>
<p><span class="math display">\[\implies \boldsymbol{\mu}_k \sum^{N}_{n=1} r_{nk} = \sum^{N}_{n=1} r_{nk} \mathbf{x}_n\]</span></p>
<p><span class="math display">\[\implies \boldsymbol{\mu}_k = \frac{\sum^{N}_{n=1} r_{nk} \mathbf{x}_n}{\sum^{N}_{n=1} r_{nk}}\]</span></p>
<p><span class="math inline">\(\sum^{N}_{n=1} r_{nk} \mathbf{x}_n\)</span> is the sum of all points that belongs to cluster <span class="math inline">\(k\)</span> and <span class="math inline">\(\sum^{N}_{n=1} r_{nk}\)</span> is the count of points in cluster <span class="math inline">\(k\)</span>, so the new <span class="math inline">\(\boldsymbol{\mu}_k\)</span> is just the <strong>sample mean</strong> of the points in cluster <span class="math inline">\(k\)</span>.</p>
<h2 id="convergence">Convergence</h2>
<p>Since:</p>
<ol type="1">
<li><span class="math inline">\(\{\boldsymbol{\mu}_{k}, \mathbf{r}_{nk}\}\)</span> can only take finite values (i.e they are derived from finite subsets of data and uniquely defined for each subset).</li>
<li>At each step, we minimize the objective (i.e we either decrease or maintain the objective).</li>
<li>The cost function is bounded below zero.</li>
<li>Ties are broken consistently.</li>
</ol>
<p>Thus, the algorithm can only take a finite number of non-decreasing steps before terminating at a local minimum.</p>
<h2 id="implementation">Implementation</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeans</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k=<span class="number">2</span>, max_iteration=<span class="number">10</span>, init_method=<span class="string">&#x27;random&#x27;</span></span>):</span></span><br><span class="line">        self.k = k</span><br><span class="line">        self.max_iteration = max_iteration</span><br><span class="line">        self.init_method = init_method</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_transform</span>(<span class="params">self, x: np.array</span>):</span></span><br><span class="line">        n, d = x.shape</span><br><span class="line">        curr_mu = self._init_mu(x)</span><br><span class="line">        curr_iter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> curr_iter &lt;= self.max_iteration:</span><br><span class="line">            r_matrix = np.zeros((n, self.k))</span><br><span class="line">            <span class="comment"># step one, map each instance to cluster center muk</span></span><br><span class="line">            <span class="keyword">for</span> sample <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                distance = []</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                    distance.append(np.linalg.norm(x[sample] - curr_mu[j]))</span><br><span class="line"></span><br><span class="line">                mu_assigned = np.argmin(distance)</span><br><span class="line">                r_matrix[sample][mu_assigned] = <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># step two calculate new mu_k</span></span><br><span class="line">            prev_mu = curr_mu.copy()</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                curr_mu[j] = np.mean(x[r_matrix[:, j] == <span class="number">1</span>], axis=<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># check stopping criteria</span></span><br><span class="line">            <span class="keyword">if</span> np.linalg.norm(prev_mu - curr_mu) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            curr_iter += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;finished k-means algorithm, on iteration <span class="subst">&#123;curr_iter&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> r_matrix, curr_mu</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_mu</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.init_method == <span class="string">&#x27;random&#x27;</span>:</span><br><span class="line">            col_max = x.<span class="built_in">max</span>(axis=<span class="number">0</span>)</span><br><span class="line">            col_min = x.<span class="built_in">min</span>(axis=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> (col_max - col_min) * np.random.random_sample((self.k, x.shape[<span class="number">1</span>])) + col_min</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> self.init_method == <span class="string">&#x27;random_points&#x27;</span>:</span><br><span class="line">            random_int = np.random.randint(<span class="number">0</span>, x.shape[<span class="number">0</span>], size=self.k)</span><br><span class="line">            <span class="keyword">return</span> x[random_int]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>importance_sampling (under construction)</title>
    <url>/2021/05/21/importance-sampling/</url>
    <content><![CDATA[<h1 id="importance-sampling">Importance Sampling</h1>
<h1 id="ref">Ref</h1>
<p>https://www.quora.com/Why-doesn-t-DQN-use-importance-sampling-Dont-we-always-use-this-method-to-correct-the-sampling-error-produced-by-the-off-policy https://danieltakeshi.github.io/2019/01/25/deep-learning-01/</p>
]]></content>
  </entry>
  <entry>
    <title>Kaiming Initialization</title>
    <url>/2021/06/23/kaiming-init/</url>
    <content><![CDATA[<h1 id="delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</h1>
<h2 id="prelu">PReLU</h2>
<h3 id="parametric-rectifiers">Parametric Rectifiers</h3>
<p>Formally, we consider an activation function defined as: <span class="math display">\[
f(y_i)=
\begin{cases}
y_i, \quad &amp; y_i &gt; 0\\
a_i y_i, \quad &amp; y_i \leq 0\\
\end{cases}
\]</span></p>
<p>Here <span class="math inline">\(y_i\)</span> is the input of the nonlinear activation <span class="math inline">\(f\)</span> on the <span class="math inline">\(i\)</span>th channel, and <span class="math inline">\(a_i\)</span> is a coefficient controlling the slop of the negative part of the function. The subscript <span class="math inline">\(i\)</span> in <span class="math inline">\(a_i\)</span> indicates that we allow the nonlinear activation to vary on different channels. When <span class="math inline">\(a_i = 0\)</span>, it becomes ReLU. When <span class="math inline">\(a_i\)</span> is small and fixed value, we have <code>LReLU</code>. When <span class="math inline">\(a_i\)</span> is a learnable parameter, we call this <code>Parametric ReLU (PReLU)</code>.</p>
<p><img src='/images/ML/kaiming_init.png' width="600"></p>
<span id="more"></span>
<p>We can also rewrite the above formula as:</p>
<p><span class="math display">\[f(y_i) = \max (0, y_i) + a_i \min (0, y_i)\]</span></p>
<p>The <code>PReLU</code> only introduces one parameter per channel for each layer which is negligible when considering the total number of weights. At the same time, if we do not consider channels, we can use one <span class="math inline">\(a\)</span> for all channels in same layer, the parameter number reduces to 1.</p>
<h3 id="optimization">Optimization</h3>
<p><code>PReLU</code> can be trained using backpropagation and optimized simultaneously with other layers. For single layer:</p>
<p><span class="math display">\[\frac{\partial L}{\partial a_i} = \sum_{y_i} \frac{\partial L}{\partial f(y_i)} \frac{\partial f(y_i)}{\partial a_i}\]</span></p>
<p>Where <span class="math inline">\(L\)</span> is the objective function, <span class="math inline">\(f(y_1), ...., f(y_N)\)</span> are PReLU transformations. The gradient of PReLU transformation on single activation is given by:</p>
<p><span class="math display">\[
\frac{\partial f(y_i)}{\partial a_i} =
\begin{cases}
0, \quad &amp; y_i &gt; 0\\
y_i, \quad &amp; y_i \leq 0\\
\end{cases}
\]</span></p>
<p>For channel shared version (single <span class="math inline">\(a\)</span> for all channels in a layer):</p>
<p><span class="math display">\[\frac{\partial L}{\partial a} = \sum_{i} \sum_{y_i} \frac{\partial L}{\partial f(y_i)} \frac{\partial f(y_i)}{\partial a}\]</span></p>
<p>When, we can use any gradient based methods to update the parameter (e.g Momentum in this case):</p>
<p><span class="math display">\[a_i = \mu a_i + \epsilon \frac{\partial L}{\partial a_i}\]</span></p>
<h2 id="initialization-of-filter-weights-for-rectifiers">Initialization of Filter Weights for Rectifiers</h2>
<p>The main idea of the derivation is to investigate the variance of the response in each layer.</p>
<h3 id="forward-propagation-case">Forward Propagation Case</h3>
<p>For a conv layer, a response is:</p>
<p><span class="math display">\[\mathbf{y_l} = W_{l} \mathbf{x}_l + \mathbf{b}_l\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{x}_l\)</span> is a <span class="math inline">\(k^2c \times 1\)</span> vector that represents co-located <span class="math inline">\(k \times k\)</span> pixels in <span class="math inline">\(c\)</span> input channels (This is a joint of input pixels) and <span class="math inline">\(k\)</span> is the kernel size (the volume after applying one kernel on the input feature maps).</li>
<li><span class="math inline">\(n = k^2c\)</span></li>
<li><span class="math inline">\(W_l\)</span> is a <span class="math inline">\(d \times n\)</span> weight matrix represents the weights in each kernel flattened in to row in <span class="math inline">\(W\)</span>.</li>
<li><span class="math inline">\(\mathbf{b}\)</span> is a <span class="math inline">\(b \times 1\)</span> bias vector, one dimension for each kernel.</li>
<li><span class="math inline">\(\mathbf{y}\)</span> is the response at a pixel of the output feature map (volume <span class="math inline">\(1 \times 1 \times d\)</span>).</li>
<li><span class="math inline">\(l\)</span> is used to index layers.</li>
<li><span class="math inline">\(\mathbf{x}_l = f(\mathbf{y}_{l - 1})\)</span> where <span class="math inline">\(f\)</span> is the activation function.</li>
<li><span class="math inline">\(c_l = d_{l - 1}\)</span> (input feature maps number is the same as kernel numbers in the previous layer).</li>
</ul>
<p><strong>The general idea in words is:</strong></p>
<p><span class="math inline">\(1 \times 1 \times d\)</span> volumn of the output feature map after applying <span class="math inline">\(d\)</span> kernels on the corresponding <span class="math inline">\(k \times k\)</span> region of <span class="math inline">\(c\)</span> input feature maps.</p>
<p><br></p>
<p>We Assume:</p>
<ol type="1">
<li><p>The initialized elements in <span class="math inline">\(W_l\)</span> be mutually independent random variables draw from the same distribution.</p></li>
<li><p>The elements in <span class="math inline">\(\mathbf{x}_l\)</span> are also mutually independent random variables draw from the same distribution.</p></li>
<li><p>(1) and (2) are independent.</p></li>
</ol>
<p>Thus, we have:</p>
<p><span class="math display">\[Var(y_l) = Var(\mathbf{w}_l \cdot \mathbf{x}_l) = n_l Var(w_l x_l)\]</span></p>
<p>Where <span class="math inline">\(y_l, \; \mathbf{w}_l\)</span> are rows of <span class="math inline">\(\mathbf{y}, \; W_l\)</span> respectively, <span class="math inline">\(w_l, \; x_l\)</span> are elements of <span class="math inline">\(\mathbf{w}_l, \; \mathbf{x}_l\)</span></p>
<p>If <span class="math inline">\(w_l\)</span> has zero mean, then:</p>
<span class="math display">\[\begin{aligned}
Var(y_l) &amp;= n_l Var(w_l x_l) \\
&amp;= n_l Var(w_l) Var(x_l) + Var(w_l)E^{2}[x_l]\\
&amp;= n_l Var(w_l) [Var(x_l) + E^{2}[x_l]]\\
&amp;= n_l Var(w_l) E[x^{2}_l]
\end{aligned}\]</span>
<p>Note here, in Xavier Initialization, we have <span class="math inline">\(E[x_l] = 0\)</span> because random variables with zero means after tanh function have zero mean. For ReLU activation, we have <span class="math inline">\(x_l = max(0, y_{l - 1})\)</span> and thus it does not have zero mean.</p>
<p>If we let <span class="math inline">\(w_{l - 1}\)</span> have a symmetric distribution around zero (<span class="math inline">\(E[w_{l-1}] = 0\)</span>) and <span class="math inline">\(b_{l - 1} = 0\)</span>, then:</p>
<p><span class="math display">\[E[y_{l - 1}] = E[w_l]E[x_l] = 0\]</span></p>
<p>Thus, <span class="math inline">\(y_{l - 1}\)</span> has zero mean and it has a symmetric distribution around zero. This lead to:</p>
<span class="math display">\[\begin{aligned}
E_{Y}[x^2_{l}] &amp;= \int^{\infty}_{\infty} \max(0, y_{l - 1})^2 p_Y (y) dy\\
&amp;= \int^{\infty}_{0} y_{l - 1}^2 p_Y (y) dy\\
&amp;= \frac{1}{2} E[y_{l-1}^2]
\end{aligned}\]</span>
<p>Since <span class="math inline">\(\frac{1}{2} Var(y_{l - 1}) = \frac{1}{2} E[y_{l-1}^2] - \frac{1}{2} E^2[y_{l-1}] = \frac{1}{2} E[y_{l-1}^2]\)</span>:</p>
<p><span class="math display">\[\implies E_{Y}[x^2_{l}] = \frac{1}{2} Var(y_{l - 1})\]</span></p>
<p>Then, putting by this result to previous equation we have:</p>
<p><span class="math display">\[Var(y_l) = n_l Var(w_l) E[x^{2}_l] = \frac{n_l}{2} Var(y_{l - 1}) Var(w_l)\]</span></p>
<p>With <span class="math inline">\(L\)</span> layers put together, we have:</p>
<span class="math display">\[\begin{aligned}
Var(y_L) &amp;= \frac{n_L}{2} Var(y_{L - 1}) Var(w_L)\\
&amp;= \frac{n_L}{2} \frac{n_{L - 1}}{2} Var(w_L) Var(w_{L-1}) Var(y_{L - 2})\\
&amp;= Var(y_1) \prod^{L}_{l=2} \frac{n_l}{2} Var(w_{l})
\end{aligned}\]</span>
<p>The <strong>key</strong> is the product above, we can see that the variance of current activate depends on product of previous weights, this lead to exploding or vanishing of variance of initial activation. <strong>A proper initialization method should avoid reducing or magnifying the magnitudes of input signals exponentially</strong>.</p>
<p>So we expect the above product to take a proper scalar 1, a sufficient condition is:</p>
<p><span class="math display">\[\frac{1}{2} n_{l} Var(w_l) = 1, \; \forall l\]</span></p>
<p>This leads to the algorithm for forward case:</p>
<ol type="1">
<li><p>Initialize <span class="math inline">\(w_l\)</span> from a zero-mean Gaussian distribution (<span class="math inline">\(w_l\)</span> is assumed to be symmetric and with mean 0) whose standard deviation is <span class="math inline">\(\sqrt{\frac{2}{n_l}}\)</span>.</p></li>
<li><p>Initialize <span class="math inline">\(\mathbf{b} = 0\)</span>.</p></li>
<li><p>For the first layer, we initialize the variance to be <span class="math inline">\(\frac{1}{n_1}\)</span>.</p></li>
</ol>
<h3 id="backward-propagation-case">Backward Propagation Case</h3>
<p>For back-propagation, the gradient of a conv layer is computed by:</p>
<p><span class="math display">\[\Delta \mathbf{x}_l =  [\hat{W}_l  \Delta \mathbf{y}_l]_{c \times 1}\]</span></p>
<p>Where <span class="math inline">\(\frac{\partial L}{\partial \mathbf{x}} \triangleq \Delta \mathbf{x}\)</span> and <span class="math inline">\(\frac{\partial L}{\partial \mathbf{y}} \triangleq \Delta \mathbf{y}\)</span>. Notice here, <span class="math inline">\(\Delta \mathbf{y}, \Delta \mathbf{x}\)</span> represents the gradient for single pixel, so each of them has shape <span class="math inline">\(d_i \times 1\)</span>. Recall that, backward pass of a conv layer is also a convolution process with <span class="math inline">\(W^l\)</span> flipped 180 degrees and applying it on gradient map of <span class="math inline">\(\mathbf{y}^l\)</span>, so <span class="math inline">\(\Delta \mathbf{y}_l\)</span> is defined similar to <span class="math inline">\(\mathbf{x}_l\)</span> in the forward pass. It is the <span class="math inline">\(k \times k \times d\)</span> co-located pixels (gradients) in the output feature maps. <span class="math inline">\(\hat{W}_l\)</span> in this case is the original kernel flipped 180 degree.</p>
<p>Notations:</p>
<ol type="1">
<li><span class="math inline">\(\Delta \mathbf{y}_l\)</span> represents <span class="math inline">\(k \times k\)</span> pixels in <span class="math inline">\(d\)</span> dimension channels and is reshaped into a <span class="math inline">\(k^2d \times 1\)</span> vector.</li>
<li><span class="math inline">\(\hat{n} = k^2 d\)</span>, notice here <span class="math inline">\(\hat{n} \neq n\)</span>.</li>
<li><span class="math inline">\(\hat{W}_l\)</span> is a <span class="math inline">\(c \times \hat{n}\)</span> matrix where the filters are rearranged in the way of back-propagation (flipped 180 degree). <span class="math inline">\(W\)</span> and <span class="math inline">\(\hat{W}\)</span> can be reshaped from each other.</li>
<li><span class="math inline">\(\Delta \mathbf{x}\)</span> is a <span class="math inline">\(c \times 1\)</span> vector representing the gradient at a pixel of the input to this layer.</li>
</ol>
<p>Assumptions:</p>
<ol type="1">
<li>We assume <span class="math inline">\(w_l\)</span> is initialized by a symmetric distribution around zero (<span class="math inline">\(w_l, \hat{w}_l\)</span> are from matrix but different representation so their distribution are the same).</li>
<li>We assume <span class="math inline">\(w_l\)</span>, <span class="math inline">\(\Delta y_l\)</span> are independent of each other <span class="math inline">\(\implies E[\Delta x_l] = \hat{n}_lE[w_l]E[\Delta y_l] = 0\)</span> for all <span class="math inline">\(l\)</span></li>
<li>We assume that <span class="math inline">\(f^{\prime} (y_l)\)</span> and <span class="math inline">\(\Delta x_{l + 1}\)</span> are independent.</li>
</ol>
<p><br></p>
<p>Recall that <span class="math inline">\(\Delta \mathbf{y}_l = \Delta \mathbf{x}^T_{l + 1} \frac{\partial \mathbf{x}_{l + 1}}{\partial \mathbf{y}_l}\)</span> and <span class="math inline">\(\frac{\partial \mathbf{x}_{l + 1}}{\partial \mathbf{y}_l}\)</span> is a diagonal Jacobian matrix with <span class="math inline">\(f^{\prime} (y_l)\)</span> on the diagonal, so each element of <span class="math inline">\(\mathbf{y}_l\)</span> will have gradient <span class="math inline">\(\Delta y_l = f^{\prime} (y_l) \Delta x_{l + 1}\)</span>.</p>
<p>For the ReLU case, <span class="math inline">\(f^{\prime} (y_l)\)</span> is defined as:</p>
<p><span class="math display">\[
\frac{\partial x_{l + 1}}{\partial y_l} =
\begin{cases}
1, \quad &amp; y_l \geq 0\\
0, \quad &amp; y_l &lt; 0\\
\end{cases}
\]</span></p>
<p>and their probabilities are equal.</p>
<p>Since assumption 3, we have:</p>
<p><span class="math display">\[E[\Delta y_l] = E[f^{\prime} (y_l)]E[\Delta x_{l+1}] = \frac{E[\Delta x_{l+1}]}{2} = 0\]</span></p>
<p>and also:</p>
<p><span class="math display">\[E[(\Delta y_l)^2] = Var(\Delta y_l) = Var(f^{\prime} (y_l)\Delta x_{l+1}) = \frac{Var[\Delta x_{l+1}]}{2}\]</span></p>
<p>Then the variance of gradient w.r.t to the input to layer <span class="math inline">\(l\)</span> is:</p>
<span class="math display">\[\begin{aligned}
Var[\Delta x_l] &amp;= \hat{n}_l(Var(w_l)Var(\Delta y_l) + Var(w_l)E^2[\Delta y_l] + Var(\Delta y_l)E^2[w_l])\\
&amp;= \hat{n}_lVar(w_l)Var(\Delta y_l)\\
&amp;= \frac{\hat{n}}{2} Var(w_l) Var(\Delta x_{l + 1})
\end{aligned}\]</span>
<p>With <span class="math inline">\(L\)</span> layers together, we have:</p>
<p><span class="math display">\[Var(\Delta x_2) = Var(\Delta x_{L + 1}])\prod^{L}_{l=2} \frac{\hat{n}_l}{2} Var(w_l)\]</span></p>
<p>To make <span class="math inline">\(Var(\Delta x_2) = Var(\Delta x_{L + 1})\)</span>, we need to have:</p>
<p><span class="math display">\[\prod^{L}_{l=2} \frac{\hat{n}_l}{2} Var(w_l) = 1\]</span></p>
<p>Thus a sufficient condition that the gradient is not exponentially large or small:</p>
<p><span class="math display">\[\frac{\hat{n}}{2} Var(w_l) = 1\]</span></p>
<p>This results in a zero-mean Gaussian distribution whose std is <span class="math inline">\(\sqrt{\frac{2}{\hat{n}}}\)</span></p>
<h2 id="discussions">Discussions</h2>
<ol type="1">
<li><p>It is sufficient to use either forward result or backward result alone, because they only differ by a constant which is not diminishing number in common network designs. This means that if the initialization properly scales the backward signal, then this is also the case for the forward signal.</p></li>
<li><p>If the forward/backward signal is inappropriately scaled by a factor <span class="math inline">\(\beta\)</span> in each layer, then the final propagated signal will be rescaled by a factor of <span class="math inline">\(\beta^L\)</span> after <span class="math inline">\(L\)</span> layers, where <span class="math inline">\(L\)</span> can represent some or all layers. When <span class="math inline">\(L\)</span> is large, if <span class="math inline">\(\beta &gt; 1\)</span>, this leads to extremely amplified signals. If <span class="math inline">\(\beta &lt; 1\)</span>, this leads to diminishing signal.</p></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>kernels</title>
    <url>/2022/06/12/kernels/</url>
    <content><![CDATA[<h1 id="kernels">Kernels</h1>
<h2 id="kernel-functions">kernel Functions</h2>
<p>We define a <strong>kernel function</strong> to be a real-valued function of two arguments <span class="math inline">\(k(\mathbf{x}, \mathbf{x}^\prime) = &lt;\Phi(\mathbf{x}), \Phi(\mathbf{x}^\prime)&gt;_H \in \mathbb{R}\)</span>, for <span class="math inline">\(\mathbf{x}, \mathbf{x}^\prime \in \mathbb{X}\)</span> that measures similarity between two inputs. Where <span class="math inline">\(\Phi\)</span> is maps into some inner product space <span class="math inline">\(H\)</span>, sometimes called the <strong>feature space</strong>.</p>
<h3 id="positive-definite-kernel">Positive Definite Kernel</h3>
<p>It can be shown that a kernel that corresponds to an inner product in some inner product space coincides with the class of positive definite kernels.</p>
<h4 id="definition-1-gram-matrix">Definition 1: Gram Matrix</h4>
<p>Given a kernel <span class="math inline">\(k\)</span> and inputs <span class="math inline">\(x_1, ...., x_n \in \mathbb{X}\)</span>, the <span class="math inline">\(n \times n\)</span> matrix:</p>
<p><span class="math display">\[K := (k(x_i, x_j))_{ij}\]</span></p>
<p>is called the Gram matrix or kernel matrix of <span class="math inline">\(k\)</span> w.r.t <span class="math inline">\(x_1, ...., x_n\)</span></p>
<p><br></p>
<h4 id="definition-2-positive-definite-kernel">Definition 2: Positive Definite Kernel</h4>
<p>The function <span class="math inline">\(k\)</span> is called a <strong>positive definite kernel</strong> if:</p>
<p><span class="math display">\[\sum^N_{n=1} \sum^N_{m=1} a_n a_m k(\mathbf{x}_n, \mathbf{x}_m) \geq 0\]</span></p>
<p>for any real numbers <span class="math inline">\(a_n, a_m\)</span> and points <span class="math inline">\(\mathbf{x}_n, \mathbf{x}_m \in \mathbb{X}\)</span> and any <span class="math inline">\(N \in \mathbb{N}\)</span>.</p>
<p><br></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>knapsack</title>
    <url>/2021/07/08/knapsack/</url>
    <content><![CDATA[<h1 id="knapsack-problem">knapsack Problem</h1>
<h2 id="knapsack-problem-1">0–1 knapsack problem</h2>
<p>Given weights and values of <span class="math inline">\(n\)</span> items, put these items in a knapsack of capacity <span class="math inline">\(W\)</span> to get the maximum total value in the knapsack.</p>
<p><span class="math inline">\(f(i, j):\)</span> using only first <span class="math inline">\(i\)</span> items, with maximum capacity of <span class="math inline">\(j\)</span>, the maximum total value you can get.</p>
<p>Then, we can write our base cases:</p>
<ul>
<li><span class="math inline">\(f(0, :) = 0\)</span></li>
<li><span class="math inline">\(f(:, 0) = 0\)</span></li>
</ul>
<p>0 items have values 0 and no items can be put into knapsack with capacity of 0.</p>
<p>At <span class="math inline">\(f(i, j)\)</span>, comparing it to <span class="math inline">\(f(i - 1, j)\)</span>, we can choose to include item <span class="math inline">\(i\)</span> or not. So, we can write out of transition function <span class="math inline">\(f(i, j)\)</span>:</p>
<ol type="1">
<li><p>If there is still extra capacity for item <span class="math inline">\(i\)</span> with total capacity <span class="math inline">\(j\)</span> (i.e <span class="math inline">\(sum(weights[: i + 1]) \leq j)\)</span>), then we can just simply add values of item <span class="math inline">\(i\)</span>. <span class="math display">\[f(i, j) = f(i - 1, j) + values(i)\]</span></p></li>
<li><p>If there is no extra capacity for item <span class="math inline">\(i\)</span> at <span class="math inline">\(j\)</span> and the current weight <span class="math inline">\(weight[i] &gt; j\)</span>, then we only need to keep the previous maximum values because the item <span class="math inline">\(i\)</span> won't fit whatsoever: <span class="math display">\[f(i, j) = f(i - 1, j)\]</span></p></li>
<li><p>If there is no extra capacity for item <span class="math inline">\(i\)</span> at <span class="math inline">\(j\)</span> but <span class="math inline">\(weight[i] \leq j\)</span>, then we can choose to include this item and discard some past items, or move on without considering this item:</p>
<ol type="1">
<li><p>The total values if we include this item (<span class="math inline">\(\text{current value } + \text{ The maximum value we can get after we fill the capacity j with i}\)</span> (we need to <code>exclude</code> the current item)): <span class="math display">\[\text{total}_{include} = values[i] + f(i - 1, j - weights[i])\]</span></p></li>
<li><p>The maximum value exclude current item: <span class="math display">\[f(i - 1, j)\]</span></p></li>
</ol>
<p>By taking the maximum over these two, we have:</p>
<p><span class="math display">\[f(i, j) = \max(f(i - 1, j), \; values[i] + f(i - 1, j - weights[i]))\]</span></p></li>
</ol>
<h2 id="unbounded-knapsack-problem">Unbounded knapsack problem</h2>
<p>Given a knapsack weight <span class="math inline">\(W\)</span> and a set of <span class="math inline">\(n\)</span> items with certain value <span class="math inline">\(v_i\)</span> and weight <span class="math inline">\(w_i\)</span>, we need to calculate the maximum amount that could make up this quantity exactly. This is different from classical Knapsack problem, here we are allowed to use unlimited number of instances of an item.</p>
<p><span class="math inline">\(f(i, j):\)</span> using only first <span class="math inline">\(i\)</span> items, with maximum capacity of <span class="math inline">\(j\)</span>, the maximum total value you can get.</p>
<p>Then, we can write our base cases:</p>
<ul>
<li><span class="math inline">\(f(0, :) = 0\)</span></li>
<li><span class="math inline">\(f(:, 0) = 0\)</span></li>
</ul>
<p>0 items have values 0 and no items can be put into knapsack with capacity of 0.</p>
<p>At <span class="math inline">\(f(i, j)\)</span>, comparing it to <span class="math inline">\(f(i - 1, j)\)</span>, we can choose to include item <span class="math inline">\(i\)</span> or not. So, we can write out of transition function <span class="math inline">\(f(i, j)\)</span>:</p>
<ol type="1">
<li><p>If there is still extra capacity for item <span class="math inline">\(i\)</span> with total capacity <span class="math inline">\(j\)</span> (i.e <span class="math inline">\(sum(weights[: i + 1]) \leq j)\)</span>), then we can just simply add values of item <span class="math inline">\(i\)</span>. <span class="math display">\[f(i, j) = f(i - 1, j) + values(i)\]</span></p></li>
<li><p>If there is no extra capacity for item <span class="math inline">\(i\)</span> at <span class="math inline">\(j\)</span> and the current weight <span class="math inline">\(weight[i] &gt; j\)</span>, then we only need to keep the previous maximum values because the item <span class="math inline">\(i\)</span> won't fit whatsoever: <span class="math display">\[f(i, j) = f(i - 1, j)\]</span></p></li>
<li><p>If there is no extra capacity for item <span class="math inline">\(i\)</span> at <span class="math inline">\(j\)</span> but <span class="math inline">\(weight[i] \leq j\)</span>, then we can choose to include this item and discard some past items, or move on without considering this item:</p>
<ol type="1">
<li><p>The total values if we include this item (<span class="math inline">\(\text{current value } + \text{ The maximum value we have can get after we fill the capacity j with i}\)</span> (we need to <code>include</code> the current item)): <span class="math display">\[\text{total}_{include} = values[i] + f(i, j - weights[i])\]</span></p></li>
<li><p>The maximum value exclude current item: <span class="math display">\[f(i - 1, j)\]</span></p></li>
</ol>
<p>By taking the maximum over these two, we have:</p>
<p><span class="math display">\[f(i, j) = \max(f(i - 1, j), \; values[i] + f(i, j - weights[i]))\]</span></p></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Graphical Models</title>
    <url>/2021/09/09/graphical-models/</url>
    <content><![CDATA[<h1 id="graphical-models">Graphical Models</h1>
<h2 id="conditional-independence">Conditional Independence</h2>
<h3 id="conditional-independence-of-random-variable">Conditional Independence of Random Variable</h3>
<p>Let <span class="math inline">\(\mathbf{X}, \mathbf{Y}, \mathbf{Z}\)</span> be a set of random variables. We say that <span class="math inline">\(\mathbf{X}\)</span> is conditionally independent of <span class="math inline">\(\mathbf{Y}\)</span> given <span class="math inline">\(\mathbf{Z}\)</span> in a distribution <span class="math inline">\(P\)</span> if <span class="math inline">\(P\)</span> satisfies <span class="math inline">\(P(\mathbf{X} = x \perp \mathbf{Y}=y | \mathbf{Z}=z)\)</span> for all values of <span class="math inline">\(x, y, z \in (Val(\mathbf{X}), Val(\mathbf{Y}), Val(\mathbf{Z}))\)</span>. If the set <span class="math inline">\(\mathbf{Z}\)</span> is empty, we write <span class="math inline">\((\mathbf{X} \perp \mathbf{Y})\)</span> and say that <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> are marginally independent.</p>
<p>The distribution <span class="math inline">\(P\)</span> satisfies <span class="math inline">\((\mathbf{X} \perp \mathbf{Y} | \mathbf{Z})\)</span> IFF <span class="math inline">\(P(\mathbf{X}, \mathbf{Y} | \mathbf{Z}) = P(\mathbf{X}| \mathbf{Z}) P(\mathbf{Y} | \mathbf{Z})\)</span></p>
<ul>
<li><strong>Symmetry</strong>: <span class="math display">\[(\mathbf{X} \perp \mathbf{Y} | \mathbf{Z}) \implies (\mathbf{Y} \perp \mathbf{X} | \mathbf{Z})\]</span></li>
<li><strong>Decomposition</strong>: <span class="math display">\[(\mathbf{X} \perp \mathbf{Y}, \mathbf{W} | \mathbf{Z}) \implies (\mathbf{X} \perp \mathbf{Y} | \mathbf{Z}), \;(\mathbf{X} \perp \mathbf{W} | \mathbf{Z})\]</span></li>
<li><strong>Weak Union</strong>: <span class="math display">\[(\mathbf{X} \perp \mathbf{Y}, \mathbf{W} | \mathbf{Z}) \implies (\mathbf{X} \perp \mathbf{Y} | \mathbf{Z}, \mathbf{W}), \; (\mathbf{X} \perp \mathbf{W} | \mathbf{Z}, \mathbf{Y})\]</span></li>
<li><strong>Contraction</strong>: <span class="math display">\[(\mathbf{X} \perp \mathbf{W} | \mathbf{Z}, \mathbf{Y}) \cap (\mathbf{X} \perp \mathbf{Y} | \mathbf{Z}) \implies (\mathbf{X} \perp \mathbf{Y}, \mathbf{W}| \mathbf{Z})\]</span></li>
</ul>
<p>We can represent complicated probabilistic models using diagrammatic representations of probability distributions called <code>probabilistic graphical models</code>. These offer several useful properties:</p>
<ol type="1">
<li>They provide a simple way to visualize the structure of a probabilistic model and can be used to design and motivate new models.</li>
<li>Insights into the properties of the model, including conditional independence properties can be obtained by inspection of the graph.</li>
<li>Complex computations, required to perform inference and learning in sophisticated models, can be expressed in terms of graphical manipulations, in which underlying mathematical expressions are carried along implicitly.</li>
</ol>
<p><br></p>
<p>A probabilistic graphical model consists of:</p>
<ol type="1">
<li><strong>Nodes</strong>: each random variable (or group of random variables) is represented as a node in the graph</li>
<li><strong>Edges (links)</strong>: links express probabilistic relationship between these random variables.
<ul>
<li><strong>Directed graphical models</strong>: in which the edges of the graphs have a particular directionality indicated by arrows (Bayesian networks). Directed graphs are useful for expressing causal relationships between random variables.</li>
<li><strong>Undirected graphical models</strong>: in which the edges of the graph do not carry arrows and have no directional significance (Markov random fields). Undirected graphs are better suited to expressing soft constraints between random variables.</li>
</ul></li>
</ol>
<p>The graph then captures the way in which the joint distribution over all of the random variables can be decomposed into a product of factors each depending only on a subset of the variables.</p>
<h2 id="bayesian-networks">Bayesian Networks</h2>
<p>Consider first an arbitrary joint distribution defined by <span class="math inline">\(P(\mathbf{Z})\)</span> over random vector <span class="math inline">\(\mathbf{Z} = &lt;A, B, C&gt;\)</span>, by product rule, we have:</p>
<p><span class="math display">\[P(\mathbf{Z}) = P(C| A, B) P(A, B) = P(C | A, B) P(B | A) P(A)\]</span></p>
<p>We now represent the right-hand side in terms of a simgple graphical model as follows:</p>
<ol type="1">
<li>First, we introduce a node for each of the random variables <span class="math inline">\(A, B, C\)</span> and associate each node with the corresponding conditional distribution on the right-hand side.</li>
<li>Then, for each conditional distribution we add directed links to the graph from the nodes to the variables on which the distribution is conditioned.</li>
</ol>
<p><img src='/images/ML/gm_1.png' width="600"></p>
<p>If there is a link going from a node <span class="math inline">\(A\)</span> to a node <span class="math inline">\(B\)</span>, then we say that node <span class="math inline">\(A\)</span> is parent of node <span class="math inline">\(B\)</span> and <span class="math inline">\(B\)</span> is the child of node <span class="math inline">\(A\)</span> (change ordering of the decomposition will change the graph).</p>
<p>We can extend the idea to joint distribution of <span class="math inline">\(K\)</span> random variables given by <span class="math inline">\(P(X_1, ...., X_K)\)</span>. By repeated application of the product rule of the probability, this joint distribution can be written as a product of conditional distributions:</p>
<p><span class="math display">\[P(X_1, ...., X_K) = P(X_K | X_{K-1}, ..., X_{1}) ... P(X_2 | X_1) P(X_1)\]</span></p>
<p>We can generate a graph similar to three-variable case, each node having incoming links from all lower numbered nodes. We say this graph is <code>fully connected</code> because there is a link between every pair of nodes. However, it is the <strong>absence</strong> (not fully connected) of links in the graph that conveys interesting information about the properties of the class of distributions that the graph represents.</p>
<p><img src='/images/ML/gm_2.png' width="600"></p>
<p><br></p>
<p>We can now state in general terms the relationship between a given directed graph and the corresponding distribution over the variables. Thus, for a graph with K nodes <span class="math inline">\(\mathbf{X} = &lt;X_1, ...., X_K&gt;\)</span>, the joint distribution is given by:</p>
<p><span class="math display">\[P(\mathbf{X}) = \prod^K_{k=1} P(X_k | \text{Parent}(X_k))\]</span></p>
<p>Where <span class="math inline">\(\text{Parent}(X_k)\)</span> denotes the set of parents of <span class="math inline">\(X_k\)</span>.</p>
<p>Notice that, the directed graphs that we are considering are subject to an important restriction namely that there must be <strong>no</strong> directed cycles, that is, we are working with <code>directed acyclic graphs</code> or DAGs.</p>
<h3 id="example-generative-models">Example: Generative Models</h3>
<p>There are many situations in which we wish to draw samples from a given probability distribution. One technique which is particularly relevant to graphical models is called <code>ancestral sampling</code>.</p>
<p>Consider a joint distribution <span class="math inline">\(P(\mathbf{X}), \mathbf{X} = &lt;X_1, ...., X_K&gt;\)</span> that factorizes into a DAG. We shall suppose that the variables have been ordered from <span class="math inline">\(X_1\)</span> to <span class="math inline">\(X_K\)</span>, in other words each node has a higher index than any of its parents. Our goal is to draw samples <span class="math inline">\(\hat{X}_1, ..., \hat{X}_K\)</span> from the joint distribution.</p>
<p>To do this, we start from <span class="math inline">\(X_1\)</span>, and draw sample <span class="math inline">\(\hat{X}_1\)</span> from the distribution <span class="math inline">\(P(X_1)\)</span>. We then work through each of the nodes in order, so that for node <span class="math inline">\(n\)</span> we draw a sample from the conditional distribution <span class="math inline">\(P(X_n | \text{Parent}(X_n))\)</span>, in which the parent variables have been set to their sampled values.</p>
<p>To obtain a sample from some marginal distribution corresponding to a subset of the random variables, we simply take the sampled values for the required nodes and discard the rest. For example, to draw a sample from the distribution <span class="math inline">\(P(X_2, X_4)\)</span>, we simply sample from the full joint distribution and then retain the values <span class="math inline">\(\hat{X}_2, \hat{X}_4\)</span> and discard the remaining values.</p>
<p>For practical applications of probabilistic models, it will typically be the higher-numbered variables corresponding to terminal nodes of the graph that represent the observations, with lower-numbered nodes corresponding to latent variables. The primary role of the latent variables is to allow a complicated distribution over the observed variables to tbe represented in terms of a model constructed from simpler conditional distributions.</p>
<blockquote>
<blockquote>
<p>Consider an object recognition task in which each observed data point corresponds to an image of on of the objects (vector of pixels). In this case, we can have latent variables be position and orientation of the object. Given a particular observed image, our goal is to find the posterior distribution over objects in which we integrate over all possible positions and orientations. <img src='/images/ML/gm_3.png' width="600"> Given object, position, orientation, we can sample from the conditional distribution of image and generate pixels.</p>
</blockquote>
</blockquote>
<p>The graphical model captures causal process by which the observed data was generated. For this reason, such models are often called <code>generative models</code>.</p>
<h2 id="conditional-independence-1">Conditional Independence</h2>
<p>An important concept for probability distributions over multiple variables is that of <strong>conditional independence</strong>. Consider three random variables <span class="math inline">\(A, B, C\)</span> and suppose that the conditional distribution of <span class="math inline">\(A\)</span>, given <span class="math inline">\(B, C\)</span> is such that it does not depend on the value of <span class="math inline">\(B\)</span>, so that:</p>
<p><span class="math display">\[P(A | B, C) = P(A | C)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[P(A, B | C) = P(A | B, C) P(B | C) = P(A | C) P (B | C)\]</span></p>
<p>Thus, we can see that <span class="math inline">\(A, B\)</span> are statistically independent given <span class="math inline">\(C, \; \forall C\)</span>. Note that this definition of conditional independence will require the above equation holds for all values fo <span class="math inline">\(C\)</span> and not just for some values. The shorthand notation for conditional independence is:</p>
<p><span class="math display">\[A \perp \!\!\! \perp B \;|\; C\]</span></p>
<p>An important and elegant feature of graphical models is that conditional independence properties of the joint distribution can be read directly from the graph without having to perform any analytical manipulations. The general framework for achieving this is called <code>d-seperation</code> (d stands for directed).</p>
<h3 id="three-example-graphs">Three example graphs</h3>
<p>We start by illustrating the key concepts of d-separation by three motivating examples.</p>
<ol type="1">
<li><blockquote>
<p><span class="math inline">\(P(A, B, C) = P(A | C) P(B | C) P(C)\)</span> <img src='/images/ML/gm_4.png' width="600"> <span class="math inline">\(A, B\)</span> are generally <strong>not</strong> statistically independent. However, we can easily see that <span class="math inline">\(A, B\)</span> are conditionally independent given <span class="math inline">\(C\)</span>: <span class="math display">\[P(A, B | C) = \frac{P(A, B, C)}{P(C)} = P(A | C) P (B | C)\]</span> <img src='/images/ML/gm_5.png' width="600"></p>
</blockquote></li>
</ol>
<p>We can provide a simple graphical interpretation of this result by considering the path from node <span class="math inline">\(A\)</span> to node <span class="math inline">\(B\)</span> via <span class="math inline">\(C\)</span>. The node <span class="math inline">\(C\)</span> is said to be <strong>tail-to-tail</strong> with respect to this path because the node is connected to the tails of the two arrows. However, when we condition on node <span class="math inline">\(C\)</span> (observed <span class="math inline">\(C\)</span>), the conditional node blocks the path from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> so causes then to become conditionally independent.</p>
<ol start="2" type="1">
<li><blockquote>
<p><span class="math inline">\(P(A, B, C) = P(B | C) P(C | A) P (A)\)</span> <img src='/images/ML/gm_6.png' width="600"> <span class="math inline">\(A, B\)</span> are generally <strong>not</strong> statistically independent. However, we can easily see that <span class="math inline">\(A, B\)</span> are conditionally independent given <span class="math inline">\(C\)</span> by: <span class="math display">\[P(A, B | C) = \frac{P(A, B, C)}{P(C)} = P(A | C) P (B | C)\]</span></p>
</blockquote></li>
</ol>
<p>We can provide a simple graphical interpretation of this result by considering the path from node <span class="math inline">\(A\)</span> to node <span class="math inline">\(B\)</span> via <span class="math inline">\(C\)</span>. The node <span class="math inline">\(C\)</span> is said to be <strong>head-to-tail</strong> with respect to this path because the node is connected to the head and tail of the two arrows. However, when we condition on node <span class="math inline">\(C\)</span> (observed <span class="math inline">\(C\)</span>), the conditional node blocks the path from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> so causes then to become conditionally independent.</p>
<ol start="3" type="1">
<li><blockquote>
<p><span class="math inline">\(P(A, B, C) = P(A)P(B)P(C | A, B)\)</span> <img src='/images/ML/gm_7.png' width="600"> We can easily see that <span class="math inline">\(A, B\)</span> are <strong>not</strong> conditionally independent. However, we can see that <span class="math inline">\(A, B\)</span> are statistically independent: <span class="math inline">\(P(A, B) = \sum_{C} P(A)P(B)P(C | A, B) = P(A)P(B)\)</span></p>
</blockquote></li>
</ol>
<p>Thus, our third example has the opposite behaviour from the first two. The node <span class="math inline">\(C\)</span> is said to be <strong>head-to-head</strong> with respect to this path because the node is connected to the heads of the two arrows. When the node <span class="math inline">\(C\)</span> is not given (unobserved), it blocks the path so <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is independent, however, when the node <span class="math inline">\(C\)</span> is given, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> becomes dependent.</p>
<p>There is one more relationship associate with third example. First we say that node <span class="math inline">\(Y\)</span> is a <strong>descendant</strong> of node <span class="math inline">\(X\)</span> if there is a path from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> in which each step of the path follows the directions of the arrows. Then it can be shown that a <strong>head to head</strong> path will become unblocked if either the node or any of its descendants is observed.</p>
<h3 id="d-separation">D-separation</h3>
<p>Consider a general directed graph in which <span class="math inline">\(A, B, C\)</span> are arbitrary sets of nodes. We wish to ascertain whether a particular conditional independence statement <span class="math inline">\(A \perp \!\!\! \perp B \;|\; C\)</span> is implied by a given directed acyclic graph. To do so, we consider all possible paths from any node in <span class="math inline">\(A\)</span> to any node in <span class="math inline">\(B\)</span>. Any such path is said to be <strong>blocked</strong> if it includes a node such that either:</p>
<ol type="1">
<li>The arrows on the path meet either head-to-tail or tail-to-tail at the node, and the node is in the set <span class="math inline">\(C\)</span>.</li>
<li>The arrows meet head-to-head at the node, and neither the node, nor any of its descendants, is in the set <span class="math inline">\(C\)</span>.</li>
</ol>
<p>If <strong>all</strong> paths are blocked, then <span class="math inline">\(A\)</span> is said to be <code>d-separated</code> from <span class="math inline">\(B\)</span> by <span class="math inline">\(C\)</span>, and the joint distribution over all of the variables in the graph will satisfy <span class="math inline">\(A \perp \!\!\! \perp B \;|\; C\)</span>.</p>
<blockquote>
<p>Consider the problem of finding the posterior distribution for the mean of an univariate Gaussian distribution. This can be represented by the directed graph in which the joint distribution is defined by a prior <span class="math inline">\(P(\mu)\)</span> and <span class="math inline">\(P(\mathbf{X} | \mu)\)</span> to form the posterior distribution: <span class="math display">\[P(\mu | \mathbf{X}) = P(\mu) P(\mathbf{X} | \mu) \]</span> <img src='/images/ML/gm_8.png' width="600"> In practice, we observe <span class="math inline">\(D = \{X_1, ...., X_N\}\)</span> with conditional distribution <span class="math inline">\(P(X_1 | \mu) , ...., P(X_N | \mu)\)</span> respectively, and our goal is to infer <span class="math inline">\(\mu\)</span>. Using d-separation, we note that there is a unique path from any <span class="math inline">\(X_i\)</span> to any other <span class="math inline">\(X_{j\neq i}\)</span> and that this path is tail-to-tail with respect to the observed node <span class="math inline">\(\mu\)</span>. Every such path is blocked and so the observations <span class="math inline">\(D=\{X_1, ..., X_N\}\)</span> are independent given <span class="math inline">\(\mu\)</span>: <span class="math display">\[P(\mathbf{X} | \mu) = \prod^N_{i=1} P(X_i | \mu)\]</span> However, if we do not conditional on <span class="math inline">\(\mu\)</span>, the data samples are not independent: <span class="math display">\[P(\mathbf{X}) = \int_{\mu} P(\mathbf{X} | \mu) P(\mu) \neq \prod^N_{i=1} P(X_i)\]</span></p>
</blockquote>
<h2 id="markov-random-fields">Markov Random Fields</h2>
<p>Directed Graphical models specify a factorization of the joint distribution over a set of variables into a product of local conditional distributions. They also defined a set of conditional independence properties that must be satisfied by any distribution that factorizes according to the graph. A <code>Markove random field</code> has:</p>
<ol type="1">
<li>A set of nodes each of which corresponds to a random variable or group of random variables</li>
<li>A set of links each of which connects a pair of nodes. The links are <strong>undirected</strong> that is they do not carry arrows.</li>
</ol>
<h3 id="conditional-independence-properties">Conditional Independence Properties</h3>
<p>Testing for conditional independence in undirected graph is simpler than in directed graph. Let <span class="math inline">\(A, B, C\)</span> be three sets of nodes and we consider the conditional independence property <span class="math inline">\(A \perp \!\!\! \perp B \;|\; C\)</span>. To test whether this property is satisfied by a probability distribution defined by the graph:</p>
<ul>
<li>Consider all possible paths that connect nodes in set <span class="math inline">\(A\)</span> to nodes in set <span class="math inline">\(B\)</span>. If all such paths pass through one or more nodes in set <span class="math inline">\(C\)</span>, then <strong>all</strong> such paths are <strong>blocked</strong> and so the conditional independence properties holds. If there is <strong>at least one</strong> such path that is not blocked, then there will exist at least some distributions corresponding to the graph that do not satisfy this conditional independence relation.</li>
</ul>
<p><img src='/images/ML/gm_9.png' width="600"></p>
<h3 id="factorization-properties">Factorization Properties</h3>
<p>We now express the joint distribution <span class="math inline">\(P(\mathbf{X})\)</span> as a product of functions defined over set of random variables that are local to the graph.</p>
<p>If we consider two nodes <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_j\)</span> that are not connected by a link, then these variables must be conditionally independent given all other nodes in the graph, because there is no direct path between the two nodes and all other paths are blocked:</p>
<p><span class="math display">\[P(X_i, X_j | \mathbf{X}_{k\notin \{i, j\}}) = P(X_i | \mathbf{X}_{k\notin \{i, j\}}) P(X_j | \mathbf{X}_{k\notin \{i, j\}})\]</span></p>
<p><br></p>
<p>A <code>clique</code> is a subset of nodes in a graph such that there exists a link between all pairs of nodes in the subset. In other words, the nodes in the set are fully connected. Furthermore, a <code>maximal clique</code> is a clique such that it is not possible to include any other nodes from the graph in the set without it ceasing to be a clique.</p>
<p><img src='/images/ML/gm_10.png' width="600"></p>
<p><br></p>
<p>We can therefore define the factors in the decomposition of the joint distribution to be functions of the variables in the cliques. In fact, we can consider functions of the maximal cliques, without loss of generality because other cliques must be subsets of maximal cliques.</p>
<p>Let <span class="math inline">\(C\)</span> be a clique and the set of random variables in that clique by <span class="math inline">\(\mathbf{X}_C\)</span>. Then the joint distribution is written as a product of <code>potential functions</code> <span class="math inline">\(\psi_C(\mathbf{x}_C) \geq 0\)</span> over the maximal cliques of the graph:</p>
<p><span class="math display">\[P(\mathbf{X}) = \frac{1}{Z} \prod_{C} \psi_{C} (\mathbf{X}_C)\]</span></p>
<p>Here the quantity <span class="math inline">\(Z\)</span> is called <code>partition function</code> which is used for normalization to ensure the result is a proper joint distribution:</p>
<p><span class="math display">\[Z = \sum_{X} \prod_{C} \psi_{C} (\mathbf{X}_C)\]</span></p>
<p>In directed graph, we have the links to be conditional distribution, in undirected graph, we do not restrict the choice of potential functions.</p>
<h1 id="ref">Ref</h1>
<p>PRML chapter 8</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>knn</title>
    <url>/2021/07/19/knn/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Layer Normalization</title>
    <url>/2021/06/02/layer-norm/</url>
    <content><![CDATA[<h1 id="layer-normalization">Layer Normalization</h1>
<p>Unlike Batch normalization, layer normalization directly estimates the normalization statistics from the summed inputs (multiply part of activation) to the neurons within a hidden layer, so the normalization does not introduce any new dependencies between training cases.</p>
<h2 id="notations">Notations</h2>
<p>A feed-forward neural network is a non-linear mapping from a input pattern <span class="math inline">\(\mathbf{x}\)</span> to an output vector <span class="math inline">\(\mathbf{y}\)</span>. Let <span class="math inline">\(\mathbf{a}^l\)</span> be the vector representation of the summed inputs to the neurons in <span class="math inline">\(l\)</span>th layer. It is computed by the weight matrix <span class="math inline">\(W^l = [w_1, ...., w_{N^l}]\)</span> and previous input <span class="math inline">\(h^l\)</span>:</p>
<p><span class="math display">\[a_i^{l} = {w^{l}_i}^T h^l \;\;\;\;\;\;\;\; h_i^{l+1} = f(a_i^l + b_i^l)\]</span></p>
<p>where <span class="math inline">\(f(\cdot)\)</span> is an element-wise non-linear activation function <span class="math inline">\(b_i^l\)</span> is the scalar bias parameter. Batch normalization normalizes the summed inputs (multiply part of activation) to each hidden unit (<span class="math inline">\(a\)</span> + bias) over the training cases:</p>
<p><span class="math display">\[\bar{a}_i^l = \frac{g_i^l}{\sigma_i^l} (a_i^l - \mu_i^l) \;\;\;\;\;\;\;\;\; \mu^l_i = \mathbb{E}_{\mathbf{x} \sim P(\cdot)} [a^l_i] \;\;\;\;\;\;\;\;\; \sigma_i^l = \sqrt{\mathbb{E}_{\mathbf{x} \sim P(\cdot)} [(a^l_i - \mu_i^l)^2]}\]</span></p>
<p>Where <span class="math inline">\(\bar{a}_i^l\)</span> is the normalized summed inputs of <span class="math inline">\(i\)</span>th activation, <span class="math inline">\(g_i\)</span> is the scale parameter (<span class="math inline">\(\gamma_i\)</span> in BN paper). The expectation is over the whole training data, in reality, we use samples from this expectation (mini-batch) to estimate the variance and mean.</p>
<p>In standard RNN, the summed inputs in the recurrent layer are computed from the current input <span class="math inline">\(\mathbf{x}^t\)</span> (one sample) and previous vector of hidden states <span class="math inline">\(\mathbf{h}^{t-1}\)</span>:</p>
<p><span class="math display">\[\mathbf{a}^{t} = W_{hh}^T \mathbf{h}^{t-1} + W_{xh}^T\mathbf{x}^t\]</span></p>
<p>Where <span class="math inline">\(W_{hh}\)</span> is the recurrent hidden to hidden wights and <span class="math inline">\(W_{xh}\)</span> is the input to hidden weights.</p>
<span id="more"></span>
<h2 id="layer-normalization-1">Layer Normalization</h2>
<p>The layer normalization statistics are computed over the hidden units (activations) in the same layer as follows:</p>
<p><span class="math display">\[\mu^l = \frac{1}{H} \sum^{H}_{i=1} a_i^l \;\;\;\;\;\;\;\; \sigma^i = \sqrt{\frac{1}{H} \sum^{H}_{1} (a_i^l - \mu^l)^2}\]</span></p>
<p>Where <span class="math inline">\(H\)</span> denotes number of hidden units in a layer. Unlike batch normalization, layer normalization does not impose any constraint on the size of a mini-batch, and it can be used in the pure online regime with batch size 1.</p>
<h3 id="layer-normalized-recurrent-neural-networks">Layer Normalized Recurrent Neural Networks</h3>
<p>Batch Normalization is problematic in RNN, because text samples often do have same length. If a test sequence is longer than any of the training sequence, then the statistics for those extra words would be zero. Layer normalization does not have this problem because its normalization terms do not depend on other training examples. It also has only one set of gain and bias parameters shared over all time-steps. The layer normalized recurrent layer re-centers and re-scales its activations:</p>
<p><span class="math display">\[\mathbf{h}^t = f[\frac{\mathbf{g}}{\sigma^t} \odot (\mathbf{a}^{t} - \mu^t) + \mathbf{b} ] \;\;\;\;\;\;\;\; \mu^l = \frac{1}{H} \sum^{H}_{i=1} a_i^l \;\;\;\;\;\;\;\; \sigma^i = \sqrt{\frac{1}{H} \sum^{H}_{1} (a_i^l - \mu^l)^2}\]</span></p>
<h2 id="analysis-invariance-under-weights-and-data-transformation">Analysis: Invariance under weights and data transformation</h2>
<p>Layer normalization, batch normalization and weight normalization can be summarized as normalizing the summed inputs <span class="math inline">\(a_i\)</span> to a neuron through the two scalars <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. They also learn an adaptive bias <span class="math inline">\(b\)</span> and gain <span class="math inline">\(g\)</span> for each neuron after the normalization.</p>
<p><span class="math display">\[h_i = f(\frac{g_i}{\sigma_i} (a_i - \mu_i) + b_i)\]</span></p>
<p><img src="/images/ML/layer_norm_1.png"></p>
<h3 id="weight-re-scaling-and-re-centering">Weight re-scaling and re-centering</h3>
<p>Let there be two sets of model parameters <span class="math inline">\(\theta, \theta^{\prime}\)</span> whose weight matrices <span class="math inline">\(W, W^{\prime}\)</span> differ by a scaling factor <span class="math inline">\(\delta\)</span> and all of the incomping weights in <span class="math inline">\(W^{\prime}\)</span> are also shifted by a constant vector <span class="math inline">\(\gamma\)</span>. That is <span class="math inline">\(W^{\prime} = \delta W + \mathbf{1}\gamma\)</span>. Under layer normalization:</p>
<span class="math display">\[\begin{aligned}
\mathbf{h}^{\prime} &amp;= f(\frac{\mathbf{g}}{\sigma^{\prime}} (\delta {W^{\prime}} + \mathbf{1} \gamma)^T \mathbf{x} - \mu) + \mathbf{b})\\
&amp;= f(\frac{\mathbf{g}}{\sigma^{\prime}} (\delta {W^{\prime}}^T + \mathbf{1} \gamma^T)\mathbf{x} - \frac{1}{H}\sum_{i} (\delta{w_i^{\prime}}^T + \gamma^T)\mathbf{x})) + \mathbf{b})\\
&amp;= f(\frac{\mathbf{g}}{\sigma} {W}^T \mathbf{x} - \mu) + \mathbf{b})\\
&amp;= \mathbf{h}
\end{aligned}\]</span>
<h3 id="data-re-scaling-and-re-centering">Data re-scaling and re-centering</h3>
<p>Since the layer normalization only depends on the current input data point <span class="math inline">\(\mathbf{x}\)</span>, let <span class="math inline">\(\mathbf{x}^{\prime} = \delta \mathbf{x} + \lambda\)</span>, then:</p>
<span class="math display">\[\begin{aligned}
h_i &amp;= f(\frac{g_i}{\sigma^{\prime}} ({w_i^{\prime}}^T \mathbf{x}^{\prime} - \mu^{\prime}) + b_i)\\
&amp;= f(\frac{g_i}{\sigma^{\prime}} ({w_i^{\prime}}^T \mathbf{x}^{\prime} - \frac{1}{H}\sum_{i} {w_i^{\prime}}^T\mathbf{x}^{\prime}) + b_i)\\
&amp;= h_i
\end{aligned}\]</span>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode (2)</title>
    <url>/2021/06/05/leet-code-2/</url>
    <content><![CDATA[<p><strong>题目库: <code>[242, 205, 215, 347, 349, 148, 1122, 973, "jz45", 147, 56, 57, 922, 104, 100, 101, 17, 102, 200, 98, 111, 112 103, 199, 994, 114]</code></strong></p>
<h1 id="strings">Strings</h1>
<h2 id="easy">242 Easy</h2>
<p>先排序再比较就行，或者我们可以统计每个字母出现次数，关键是要明白字符数量不同就不相同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isAnagram</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        s = <span class="built_in">sorted</span>(s)</span><br><span class="line">        t = <span class="built_in">sorted</span>(t)</span><br><span class="line">        <span class="keyword">return</span> s == t</span><br></pre></td></tr></table></figure>
<h2 id="easy-1">205 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isIsomorphic</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) != <span class="built_in">len</span>(t):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        mapping_s = &#123;&#125;</span><br><span class="line">        mapping_t = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i, j <span class="keyword">in</span> <span class="built_in">zip</span>(s, t):</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> mapping_s.keys():</span><br><span class="line">                mapping_s[i] = j</span><br><span class="line">                <span class="keyword">if</span> j <span class="keyword">in</span> mapping_t.keys():</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                mapping_t[j] = i</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> mapping_s[i] != j:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h1 id="sort">Sort</h1>
<h2 id="medium">215 Medium</h2>
<p><img src="/images/leetcode/215.png" width="600"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># selection sort</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_max</span>(<span class="params">start</span>):</span></span><br><span class="line">            max_num = nums[start]</span><br><span class="line">            idx = start</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start + <span class="number">1</span>, n):</span><br><span class="line">                <span class="keyword">if</span> max_num &lt; nums[i]:</span><br><span class="line">                    max_num = nums[i]</span><br><span class="line">                    idx = i</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> idx</span><br><span class="line"></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> j &lt; k:</span><br><span class="line">            max_idx = find_max(j)</span><br><span class="line">            val = nums[j]</span><br><span class="line">            nums[j] = nums[max_idx]</span><br><span class="line">            nums[max_idx] = val</span><br><span class="line"></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> nums[j - <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">nums, l, r</span>):</span></span><br><span class="line">            first_small = l</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(l, r):</span><br><span class="line">                <span class="keyword">if</span> nums[j] &gt; nums[r]:</span><br><span class="line">                    swap(nums, first_small, j)</span><br><span class="line">                    first_small += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            swap(nums, first_small, r)</span><br><span class="line">            <span class="keyword">return</span> first_small</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">swap</span>(<span class="params">nums, i, j</span>):</span></span><br><span class="line">            temp = nums[i]</span><br><span class="line">            nums[i] = nums[j]</span><br><span class="line">            nums[j] = temp</span><br><span class="line"></span><br><span class="line">        <span class="keyword">import</span> random</span><br><span class="line">        random.shuffle(nums)</span><br><span class="line">        <span class="comment"># random shuffle 不然quick selection会慢</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        k = k - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            q = partition(nums, l, r)</span><br><span class="line">            <span class="keyword">if</span> q == k:</span><br><span class="line">                <span class="keyword">return</span> nums[q]</span><br><span class="line">            <span class="keyword">elif</span> q &gt; k: </span><br><span class="line">                r = q - <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l = q + <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> nums[l]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-1">347 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">topKFrequent</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        freq_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> freq_dict.keys():</span><br><span class="line">                freq_dict[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                freq_dict[i] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        nums = []</span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> freq_dict.items():</span><br><span class="line">            nums.append((v, i))</span><br><span class="line"></span><br><span class="line">        nums.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        out = []</span><br><span class="line">        <span class="keyword">for</span> counts, idx <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(out) == k:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            out.append(idx)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-2">349 Easy</h2>
<p>大刀看蚂蚁</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersection</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="comment"># merge sort</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">nums</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> nums</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mid = <span class="built_in">len</span>(nums) // <span class="number">2</span></span><br><span class="line">                left_lst = merge_sort(nums[:mid])</span><br><span class="line">                right_lst = merge_sort(nums[mid:])</span><br><span class="line">                out_lst = []</span><br><span class="line">                <span class="keyword">while</span> left_lst <span class="keyword">or</span> right_lst:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> left_lst:</span><br><span class="line">                        out_lst.extend(right_lst)</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">elif</span> <span class="keyword">not</span> right_lst:</span><br><span class="line">                        out_lst.extend(left_lst)</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">elif</span> left_lst[<span class="number">0</span>] &gt; right_lst[<span class="number">0</span>]:</span><br><span class="line">                        out_lst.append(right_lst.pop(<span class="number">0</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        out_lst.append(left_lst.pop(<span class="number">0</span>))</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">return</span> out_lst</span><br><span class="line">        <span class="comment"># binary search</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">sort_lst, target_lst</span>):</span></span><br><span class="line">            out_lst = []</span><br><span class="line">            <span class="keyword">for</span> target <span class="keyword">in</span> target_lst:</span><br><span class="line">                l, r = <span class="number">0</span>, <span class="built_in">len</span>(sort_lst) - <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> target <span class="keyword">not</span> <span class="keyword">in</span> out_lst:</span><br><span class="line">                    <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">                        mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                        <span class="keyword">if</span> target == sort_lst[mid]:</span><br><span class="line">                            out_lst.append(target)</span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line">                        <span class="keyword">elif</span> sort_lst[mid] &gt; target:</span><br><span class="line">                            r = mid - <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            l = mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> out_lst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        nums2 = merge_sort(nums2)</span><br><span class="line">        <span class="keyword">return</span> binary_search(nums2, nums1)</span><br></pre></td></tr></table></figure>
<h2 id="medium-2">148 Medium</h2>
<p>十分丑陋的merge sort</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortList</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">traverse</span>(<span class="params">lst, t</span>):</span></span><br><span class="line">            <span class="keyword">if</span> t == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span>, lst</span><br><span class="line"></span><br><span class="line">            curr_node = lst</span><br><span class="line">            <span class="keyword">while</span> t &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> t == <span class="number">1</span>:</span><br><span class="line">                    right = curr_node.<span class="built_in">next</span></span><br><span class="line">                    curr_node.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                curr_node = curr_node.<span class="built_in">next</span></span><br><span class="line">                t -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> lst, right</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">lst, length</span>):</span></span><br><span class="line">            <span class="keyword">if</span> length &lt;= <span class="number">1</span> :</span><br><span class="line">                <span class="keyword">return</span> lst</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mid = length // <span class="number">2</span></span><br><span class="line">                left, right = traverse(lst, mid)</span><br><span class="line">                left_lst = merge_sort(left, mid)</span><br><span class="line">                right_lst = merge_sort(right, length - mid)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> left_lst:</span><br><span class="line">                    <span class="keyword">return</span> right_lst</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> right_lst:</span><br><span class="line">                    <span class="keyword">return</span> left_lst</span><br><span class="line">                <span class="keyword">elif</span> left_lst.val &gt; right_lst.val:</span><br><span class="line">                    out_lst = right_lst</span><br><span class="line">                    curr_out_node = right_lst</span><br><span class="line">                    right_lst = right_lst.<span class="built_in">next</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    out_lst = left_lst</span><br><span class="line">                    curr_out_node = left_lst</span><br><span class="line">                    left_lst = left_lst.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> left_lst:</span><br><span class="line">                        curr_out_node.<span class="built_in">next</span> = right_lst</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">elif</span> <span class="keyword">not</span> right_lst:</span><br><span class="line">                        curr_out_node.<span class="built_in">next</span> = left_lst</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">elif</span> left_lst.val &gt; right_lst.val:</span><br><span class="line">                        curr_out_node.<span class="built_in">next</span> = right_lst</span><br><span class="line">                        right_lst = right_lst.<span class="built_in">next</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        curr_out_node.<span class="built_in">next</span> = left_lst</span><br><span class="line">                        left_lst = left_lst.<span class="built_in">next</span></span><br><span class="line">                    </span><br><span class="line">                    curr_out_node = curr_out_node.<span class="built_in">next</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">return</span> out_lst</span><br><span class="line"></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        curr_pos = head</span><br><span class="line">        <span class="keyword">while</span> curr_pos:</span><br><span class="line">            curr_pos = curr_pos.<span class="built_in">next</span></span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> merge_sort(head, length)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-3">75 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortColors</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># quick sort</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">nums, l, r</span>):</span></span><br><span class="line">            large_start = l</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l, r):</span><br><span class="line">                <span class="keyword">if</span> nums[i] &lt;= nums[r]:</span><br><span class="line">                    swap(nums, large_start, i)</span><br><span class="line">                    large_start += <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">            swap(nums, large_start, r)</span><br><span class="line">            <span class="keyword">return</span> large_start</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">swap</span>(<span class="params">nums, i, j</span>):</span></span><br><span class="line">            temp = nums[i]</span><br><span class="line">            nums[i] = nums[j]</span><br><span class="line">            nums[j] = temp</span><br><span class="line">            </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">nums, l, r</span>):</span></span><br><span class="line">            <span class="keyword">if</span> (r - l) &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> nums</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mid = partition(nums, l, r)</span><br><span class="line">                left_lst = quick_sort(nums, l, mid - <span class="number">1</span>)</span><br><span class="line">                right_lst = quick_sort(nums, mid + <span class="number">1</span>, r)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> left_lst + [nums[mid]] + right_lst</span><br><span class="line">                </span><br><span class="line">        quick_sort(nums, <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortColors</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># insertion sort</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">swap</span>(<span class="params">nums, i, j</span>):</span></span><br><span class="line">            temp = nums[i]</span><br><span class="line">            nums[i] = nums[j]</span><br><span class="line">            nums[j] = temp</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            j = i</span><br><span class="line">            <span class="keyword">while</span> j &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> nums[j] &lt; nums[j - <span class="number">1</span>]:</span><br><span class="line">                    swap(nums, j, j - <span class="number">1</span>)</span><br><span class="line">                    j -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h2 id="easy-3">1122 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relativeSortArray</span>(<span class="params">self, arr1: <span class="type">List</span>[<span class="built_in">int</span>], arr2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line"></span><br><span class="line">        start = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> arr2:</span><br><span class="line">            <span class="keyword">while</span> (v <span class="keyword">in</span> arr1[start:]):</span><br><span class="line">                idx = arr1[start:].index(v) + start</span><br><span class="line">                temp = arr1[start]</span><br><span class="line">                arr1[start] = arr1[idx]</span><br><span class="line">                arr1[idx] = temp</span><br><span class="line">                start += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        out = arr1[:start]</span><br><span class="line">        out.extend(<span class="built_in">sorted</span>(arr1[start:]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  out</span><br></pre></td></tr></table></figure>
<h2 id="medium-4">973 Medium</h2>
<p>需要剪枝 不然会超过时间</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">kClosest</span>(<span class="params">self, points: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">cal_dist</span>(<span class="params">point</span>):</span></span><br><span class="line">            <span class="keyword">return</span> point[<span class="number">0</span>]**<span class="number">2</span> + point[<span class="number">1</span>]**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">nums, l, r</span>):</span></span><br><span class="line">            large_start = l</span><br><span class="line">            pivot = cal_dist(nums[r])</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l, r):</span><br><span class="line">                <span class="keyword">if</span> cal_dist(nums[i]) &lt;= pivot:</span><br><span class="line">                    swap(nums, large_start, i)</span><br><span class="line">                    large_start += <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">            swap(nums, large_start, r)</span><br><span class="line">            <span class="keyword">return</span> large_start</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">swap</span>(<span class="params">nums, i, j</span>):</span></span><br><span class="line">            temp = nums[i]</span><br><span class="line">            nums[i] = nums[j]</span><br><span class="line">            nums[j] = temp</span><br><span class="line">            </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">nums, l, r, k</span>):</span></span><br><span class="line">            <span class="keyword">if</span> (r - l) &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mid = partition(nums, l, r)</span><br><span class="line">                diff = k - mid - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> diff &lt; <span class="number">0</span>:</span><br><span class="line">                    quick_sort(nums, l, mid - <span class="number">1</span>, k)</span><br><span class="line">                <span class="keyword">elif</span> diff &gt; <span class="number">0</span>:</span><br><span class="line">                    quick_sort(nums, mid + <span class="number">1</span>, r, k)</span><br><span class="line"></span><br><span class="line">        quick_sort(points, <span class="number">0</span>, <span class="built_in">len</span>(points) - <span class="number">1</span>, k)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> points[:k]</span><br></pre></td></tr></table></figure>
<h2 id="剑指-offer-45.-把数组排成最小的数-medium">剑指 Offer 45. 把数组排成最小的数 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Key</span>(<span class="params"><span class="built_in">str</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__lt__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self + other &lt; other + self</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        nums = <span class="built_in">sorted</span>([<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> nums], key=Key)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(nums)</span><br></pre></td></tr></table></figure>
<h2 id="medium-5">147 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertionSortList</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        curr_node, prev_node = head, head</span><br><span class="line">        <span class="keyword">while</span> curr_node:</span><br><span class="line">            <span class="keyword">if</span> curr_node.val &lt; prev_node.val:</span><br><span class="line">                temp_node = head</span><br><span class="line">                <span class="keyword">while</span> temp_node.val &lt; curr_node.val:</span><br><span class="line">                    temp_prev_node, temp_node = temp_node, temp_node.<span class="built_in">next</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> temp_node == head:</span><br><span class="line">                    head, prev_node.<span class="built_in">next</span>, curr_node.<span class="built_in">next</span> = curr_node, curr_node.<span class="built_in">next</span>, temp_node</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    temp_prev_node.<span class="built_in">next</span>, prev_node.<span class="built_in">next</span>, curr_node.<span class="built_in">next</span> = curr_node, curr_node.<span class="built_in">next</span>, temp_node</span><br><span class="line"></span><br><span class="line">            prev_node, curr_node = curr_node, curr_node.<span class="built_in">next</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<h2 id="medium-6">56 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">self, intervals: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        intervals.sort(key=<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>]))</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; (<span class="built_in">len</span>(intervals) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> intervals[i + <span class="number">1</span>][<span class="number">0</span>] &lt;= intervals[i][<span class="number">1</span>]:</span><br><span class="line">                r = <span class="built_in">max</span>(intervals[i][<span class="number">1</span>], intervals[i + <span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">                intervals[i] = [intervals[i][<span class="number">0</span>], r]</span><br><span class="line">                intervals.pop(i + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> intervals</span><br><span class="line">            </span><br></pre></td></tr></table></figure>
<h3 id="medium-7">57 Medium</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self, intervals: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], newInterval: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">intervals: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">            intervals.sort(key=<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>]))</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; (<span class="built_in">len</span>(intervals) - <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> intervals[i + <span class="number">1</span>][<span class="number">0</span>] &lt;= intervals[i][<span class="number">1</span>]:</span><br><span class="line">                    r = <span class="built_in">max</span>(intervals[i][<span class="number">1</span>], intervals[i + <span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">                    intervals[i] = [intervals[i][<span class="number">0</span>], r]</span><br><span class="line">                    intervals.pop(i + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> intervals</span><br><span class="line">            </span><br><span class="line">        intervals.append(newInterval)</span><br><span class="line">        <span class="keyword">return</span> merge(intervals)</span><br></pre></td></tr></table></figure>
<h2 id="easy-4">922 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortArrayByParityII</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(nums)):</span><br><span class="line">                <span class="keyword">if</span> (i % <span class="number">2</span>) == (nums[j] % <span class="number">2</span>):</span><br><span class="line">                    temp = nums[i]</span><br><span class="line">                    nums[i] = nums[j]</span><br><span class="line">                    nums[j] = temp</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure>
<h1 id="search">Search</h1>
<h2 id="easy-5">104 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l = self.maxDepth(root.left) + <span class="number">1</span></span><br><span class="line">            r = self.maxDepth(root.right) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(l, r)</span><br></pre></td></tr></table></figure>
<h2 id="easy-6">101 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">symmetric</span>(<span class="params">root_1, root_2</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root_1 <span class="keyword">and</span> <span class="keyword">not</span> root_2:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">not</span> root_1 <span class="keyword">and</span> root_2) <span class="keyword">or</span> (root_1 <span class="keyword">and</span> <span class="keyword">not</span> root_2):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">elif</span> root_1.val != root_2.val:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    check_left = symmetric(root_1.left, root_2.right)</span><br><span class="line">                    check_right = symmetric(root_1.right, root_2.left)</span><br><span class="line">                    <span class="keyword">return</span> check_left <span class="keyword">and</span> check_right</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> symmetric(root.left, root.right)           </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-7">100 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSameTree</span>(<span class="params">self, p: TreeNode, q: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">check_same</span>(<span class="params">root_1, root_2</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root_1 <span class="keyword">and</span> <span class="keyword">not</span> root_2:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> (<span class="keyword">not</span> root_1 <span class="keyword">and</span> root_2) <span class="keyword">or</span> (root_1 <span class="keyword">and</span> <span class="keyword">not</span> root_2):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">elif</span> root_1.val != root_2.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = check_same(root_1.left, root_2.left)</span><br><span class="line">                right = check_same(root_1.right, root_2.right)</span><br><span class="line">                <span class="keyword">return</span> left <span class="keyword">and</span> right</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> check_same(p, q)</span><br></pre></td></tr></table></figure>
<h2 id="medium-8">17 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">letterCombinations</span>(<span class="params">self, digits: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> digits:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        dig_map = &#123;</span><br><span class="line">            <span class="string">&#x27;2&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;3&#x27;</span>: [<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;4&#x27;</span>: [<span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;i&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;5&#x27;</span>: [<span class="string">&#x27;j&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;l&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;6&#x27;</span>: [<span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;7&#x27;</span>: [<span class="string">&#x27;p&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;8&#x27;</span>: [<span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;v&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;9&#x27;</span>: [<span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        q = dig_map[digits[<span class="number">0</span>]][:]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(digits)):</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(q)):</span><br><span class="line">                head = q.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> dig_map[digits[i]]:</span><br><span class="line">                    q.append(<span class="string">&#x27;&#x27;</span>.join([head, k]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> q</span><br></pre></td></tr></table></figure>
<h2 id="meidum">102 Meidum</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        </span><br><span class="line">        q = [[root]]</span><br><span class="line">        levels = []</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            head = q.pop()</span><br><span class="line">            next_nodes = []</span><br><span class="line">            curr_level = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> head:</span><br><span class="line">                <span class="keyword">if</span> i.left:</span><br><span class="line">                    next_nodes.append(i.left)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> i.right:</span><br><span class="line">                    next_nodes.append(i.right)</span><br><span class="line">                </span><br><span class="line">                curr_level.append(i.val)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> next_nodes:</span><br><span class="line">                q.append(next_nodes)</span><br><span class="line"></span><br><span class="line">            levels.append(curr_level)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> levels</span><br></pre></td></tr></table></figure>
<h2 id="medium-9">200 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numIslands</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">clear_island</span>(<span class="params">i, j</span>):</span></span><br><span class="line">            <span class="keyword">if</span> grid[i][j] == <span class="string">&#x27;0&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                grid[i][j] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">                <span class="keyword">if</span> (i + <span class="number">1</span>) &lt; m:</span><br><span class="line">                    clear_island(i + <span class="number">1</span>, j)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (i - <span class="number">1</span>) &gt;= <span class="number">0</span>:</span><br><span class="line">                    clear_island(i - <span class="number">1</span>, j)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (j - <span class="number">1</span>) &gt;= <span class="number">0</span>:</span><br><span class="line">                    clear_island(i, j - <span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (j + <span class="number">1</span>) &lt; n:</span><br><span class="line">                    clear_island(i, j + <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        counts = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                    counts += <span class="number">1</span></span><br><span class="line">                    clear_island(i, j)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> counts</span><br></pre></td></tr></table></figure>
<h2 id="medium-10">98 Medium</h2>
<p>中遍历</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValidBST</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">is_valid</span>(<span class="params">root, lower=<span class="built_in">float</span>(<span class="params"><span class="string">&#x27;-inf&#x27;</span></span>), upper=<span class="built_in">float</span>(<span class="params"><span class="string">&#x27;inf&#x27;</span></span>)</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> root.val &gt;= upper <span class="keyword">or</span> root.val &lt;= lower:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = is_valid(root.left, lower, root.val)</span><br><span class="line">                right = is_valid(root.right, root.val, upper)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> left <span class="keyword">and</span> right</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> is_valid(root)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValidBST</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">tree</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            tree(node.left)</span><br><span class="line">            ls.append(node.val)</span><br><span class="line">            tree(node.right)</span><br><span class="line">        </span><br><span class="line">        ls = []</span><br><span class="line">        tree(root)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> ls[i] &gt;= ls[i+<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-8">111 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDepth</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        min_depth = <span class="number">10</span>**<span class="number">9</span></span><br><span class="line">        <span class="keyword">if</span> root.left:</span><br><span class="line">            min_depth = <span class="built_in">min</span>(self.minDepth(root.left), min_depth)</span><br><span class="line">        <span class="keyword">if</span> root.right:</span><br><span class="line">            min_depth = <span class="built_in">min</span>(self.minDepth(root.right), min_depth)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> min_depth + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="easy-9">112 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasPathSum</span>(<span class="params">self, root: TreeNode, targetSum: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">cal_sum</span>(<span class="params">root, num</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> root.val == num:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            left = cal_sum(root.right, num - root.val)</span><br><span class="line">            right = cal_sum(root.left, num - root.val)</span><br><span class="line">        </span><br><span class="line">            <span class="keyword">return</span> left <span class="keyword">or</span> right</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> cal_sum(root, targetSum)</span><br></pre></td></tr></table></figure>
<h2 id="medium-11">103 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zigzagLevelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        q = [[root]]</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        out_lst = [[root.val]]</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            nodes = q.pop(<span class="number">0</span>)</span><br><span class="line">            temp_lst = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nodes) - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> nodes[j].right:</span><br><span class="line">                        temp_lst.append(nodes[j].right)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> nodes[j].left:</span><br><span class="line">                        temp_lst.append(nodes[j].left)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> nodes[j].left:</span><br><span class="line">                        temp_lst.append(nodes[j].left)</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> nodes[j].right:</span><br><span class="line">                        temp_lst.append(nodes[j].right)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> temp_lst:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            q.append(temp_lst)</span><br><span class="line">            out_lst.append([k.val <span class="keyword">for</span> k <span class="keyword">in</span> temp_lst])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out_lst</span><br></pre></td></tr></table></figure>
<h2 id="medium-12">199 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rightSideView</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        q = [[root]]</span><br><span class="line">        out = [root.val]</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            nodes = q.pop(<span class="number">0</span>)</span><br><span class="line">            temp_lst = []</span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    temp_lst.append(node.left)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> node.right:</span><br><span class="line">                    temp_lst.append(node.right)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> temp_lst:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            out.append(temp_lst[-<span class="number">1</span>].val)</span><br><span class="line">            q.append(temp_lst)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="medium-13">994 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">orangesRotting</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        n, d = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        q = []</span><br><span class="line">        counts = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(d):</span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="number">1</span>:</span><br><span class="line">                    counts += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="number">2</span>:</span><br><span class="line">                    q.append((i, j))</span><br><span class="line"></span><br><span class="line">        rounds = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> q <span class="keyword">and</span> (counts &gt; <span class="number">0</span>):</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(q)):</span><br><span class="line">                i, j = q.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># check up</span></span><br><span class="line">                <span class="keyword">if</span> i != <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> grid[i - <span class="number">1</span>][j] == <span class="number">1</span>:</span><br><span class="line">                        grid[i - <span class="number">1</span>][j] = <span class="number">2</span></span><br><span class="line">                        q.append((i - <span class="number">1</span>, j))</span><br><span class="line">                        counts -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># check down</span></span><br><span class="line">                <span class="keyword">if</span> i != (n - <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> grid[i + <span class="number">1</span>][j] == <span class="number">1</span>:</span><br><span class="line">                        grid[i + <span class="number">1</span>][j] = <span class="number">2</span></span><br><span class="line">                        q.append((i + <span class="number">1</span>, j))</span><br><span class="line">                        counts -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># check left</span></span><br><span class="line">                <span class="keyword">if</span> j != <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> grid[i][j - <span class="number">1</span>] == <span class="number">1</span>:</span><br><span class="line">                        grid[i][j - <span class="number">1</span>] = <span class="number">2</span></span><br><span class="line">                        q.append((i, j - <span class="number">1</span>))</span><br><span class="line">                        counts -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># check right</span></span><br><span class="line">                <span class="keyword">if</span> j != (d - <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> grid[i][j + <span class="number">1</span>] == <span class="number">1</span>:</span><br><span class="line">                        grid[i][j + <span class="number">1</span>] = <span class="number">2</span></span><br><span class="line">                        q.append((i, j + <span class="number">1</span>))</span><br><span class="line">                        counts -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            rounds += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(d):</span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rounds</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-14">114 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">flatten</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify root in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">linked_lst_tree</span>(<span class="params">root</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">                <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line">            left = linked_lst_tree(root.left)</span><br><span class="line">            right = linked_lst_tree(root.right)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> left:</span><br><span class="line">                temp = left</span><br><span class="line">                <span class="keyword">while</span> temp.right:</span><br><span class="line">                    temp = temp.right</span><br><span class="line"></span><br><span class="line">                temp.right = right</span><br><span class="line">                root.right = left</span><br><span class="line">                root.left = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        </span><br><span class="line">        linked_lst_tree(root)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode (1)</title>
    <url>/2021/05/18/leet-code-1/</url>
    <content><![CDATA[<p><strong>题目库: <code>[455, 605, 122, 435, 665, 763, 452, 167, 88, 142, 633, 680, 524, 69, 34, 81, 350, 154, 53, 35, 374, 367,  744, 287, 1170, 1337, 153, 33, 154, 278]</code></strong></p>
<h1 id="greedy">Greedy</h1>
<h2 id="easy">455 Easy</h2>
<p><img src="/images/leetcode/455.png"></p>
<p>局部最优则全局最优, 将小的饼干满足胃口最小的孩子以此类推</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findContentChildren</span>(<span class="params">self, g: <span class="type">List</span>[<span class="built_in">int</span>], s: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line"></span><br><span class="line">        g.sort()</span><br><span class="line">        s.sort()</span><br><span class="line">        num_people = <span class="number">0</span></span><br><span class="line">        curr_g = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> curr_g &gt;= <span class="built_in">len</span>(g):</span><br><span class="line"></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> v &gt;= g[curr_g]:</span><br><span class="line">                num_people += <span class="number">1</span></span><br><span class="line">                curr_g += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> num_people</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="easy-1">605 Easy</h2>
<p>解法1： 一个一个遍历，判断左右有没有种植</p>
<p>解法2：</p>
<ol type="1">
<li>当遍历到index遇到1时，说明这个位置有花，那必然从index+2的位置才有可能种花，因此当碰到1时直接跳过下一格。</li>
<li>当遍历到index遇到0时，由于每次碰到1都是跳两格，因此前一格必定是0，此时只需要判断下一格是不是1即可得出index这一格能不能种花，如果能种则令n减一，然后这个位置就按照遇到1时处理，即跳两格；如果index的后一格是1，说明这个位置不能种花且之后两格也不可能种花（参照【1】），直接跳过3格。</li>
</ol>
<p>解法3: 在解法1的基础上不需要添加头尾0就不需要边界条件判断</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span> :</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canPlaceFlowers</span>(<span class="params">self, flowerbed: <span class="type">List</span>[<span class="built_in">int</span>], n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(flowerbed):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(flowerbed) - <span class="number">1</span>:</span><br><span class="line">                right = flowerbed[i + <span class="number">1</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left <span class="keyword">and</span> <span class="keyword">not</span> right:</span><br><span class="line">                left = <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> v:</span><br><span class="line">                    n -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> n &lt;= <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canPlaceFlowers</span>(<span class="params">self, flowerbed: <span class="type">List</span>[<span class="built_in">int</span>], n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(flowerbed):</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> flowerbed[i] == <span class="number">0</span>:</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> i == <span class="built_in">len</span>(flowerbed) - <span class="number">1</span>:</span><br><span class="line">                    n -= <span class="number">1</span></span><br><span class="line">                    i = i + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> flowerbed[i + <span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">                        n -= <span class="number">1</span></span><br><span class="line">                        i = i + <span class="number">2</span></span><br><span class="line">                        </span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        i = i + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i = i + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> n &lt;= <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_3</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canPlaceFlowers</span>(<span class="params">self, flowerbed: <span class="type">List</span>[<span class="built_in">int</span>], n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        tmp = [<span class="number">0</span>]+ flowerbed + [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(tmp)-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> tmp[i-<span class="number">1</span>] == <span class="number">0</span> <span class="keyword">and</span> tmp[i] == <span class="number">0</span> <span class="keyword">and</span> tmp[i+<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">                tmp[i] = <span class="number">1</span>  <span class="comment"># 在 i 处栽上花</span></span><br><span class="line">                n -= <span class="number">1</span>   </span><br><span class="line">        <span class="keyword">return</span> n &lt;= <span class="number">0</span>   <span class="comment"># n 小于等于 0 ，表示可以栽完花</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-2">122 Easy</h2>
<p>假如说后一天和今天的差是正的就卖 不然就不卖</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        profit = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(prices) &gt; <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(prices) - <span class="number">1</span>:</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> prices[i] &lt; prices[i + <span class="number">1</span>]:</span><br><span class="line">                    profit += prices[i + <span class="number">1</span>] - prices[i]</span><br><span class="line"></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> profit</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium">435 Medium</h2>
<p>首先我们需要将所有interval根据上限从大到小排列, 接着我们就可以通过对比上限和当前interval下限来塞入符合条件的interval， 同时如果塞入成功 则需要更新新的interval上限</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eraseOverlapIntervals</span>(<span class="params">self, intervals: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        max_inter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        intervals.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">        curr_inter = intervals[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(intervals)):</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> curr_inter &gt; intervals[i][<span class="number">0</span>]:</span><br><span class="line">                max_inter += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                curr_inter = intervals[i][<span class="number">1</span>]</span><br><span class="line">            </span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> max_inter</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-3">665 Easy</h2>
<p>该题思路为在i的时候连续看3个数即i, i-1, i-2，假如出现 i &lt; i - 1，那么则尽量修改小，既然要修改小的话就会出现2种情况:</p>
<ol type="1">
<li>i &lt; i - 1 但是 i &gt; i - 2: 例子 2 5 3, i=3, 这样我们只需要将5改为3即可满足尽量修改小的原则</li>
<li>i &lt; i - 1 同时 i &lt; i - 2：例子 4 5 3, i=3, 这样我们只能将3改为5否则则需要改2次</li>
</ol>
<p>同时处理边角情况并记录修改次数</p>
<p>我们只需要在碰到情况<strong>2</strong>的时候做inplace修改 （<code>nums[i] = nums[i - 1]</code>）因为你在确认 i &lt; i - 2 之前 你已经知道了 i &lt; i -1 也就是说 <code>counts += 1</code> 不管结果如何，所以在碰到 情况<strong>1</strong>时不需要做任何修改只需要<code>counts += 1</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checkPossibility</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        counts = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i] &lt; nums[i - <span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> nums[i] &lt; nums[i - <span class="number">2</span>]:</span><br><span class="line">                        nums[i] = nums[i - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">                counts += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">if</span> counts &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-1">763 Medium</h2>
<ol type="1">
<li><p>解决方案一：</p>
<ul>
<li>遍历s，找到每个字母的区间放入一个dict</li>
<li>将该dict变成list，并通过第一个位置排序</li>
<li>这样该题目就被转化为了一个区间划分问题，只需要将重叠区间合并然后求出该区间长度就行</li>
</ul></li>
<li><p>解决方案二:</p>
<ul>
<li>遍历s，找到每个字母的最后出现位置放入一个dict</li>
<li>再遍历s，记录每个区间开始和结束，并更新区间最后出现位置</li>
</ul></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partitionLabels</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        str_dict = &#123;&#125;</span><br><span class="line">        output_lst = []</span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">in</span> str_dict.keys():</span><br><span class="line">                str_dict[v][<span class="number">1</span>] = i</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                str_dict[v] = [i, i]</span><br><span class="line">        </span><br><span class="line">        temp_lst = []</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> str_dict.items():</span><br><span class="line">            temp_lst.append(v)</span><br><span class="line"></span><br><span class="line">        temp_lst.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line">        curr_low = <span class="number">0</span></span><br><span class="line">        curr_max = temp_lst[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(temp_lst) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> curr_max &lt; temp_lst[i + <span class="number">1</span>][<span class="number">0</span>]:</span><br><span class="line">                output_lst.append(curr_max - curr_low + <span class="number">1</span>)</span><br><span class="line">                curr_low = temp_lst[i + <span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">                curr_max = temp_lst[i + <span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">elif</span> curr_max &lt; temp_lst[i + <span class="number">1</span>][<span class="number">1</span>]:</span><br><span class="line">                curr_max = temp_lst[i + <span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        output_lst.append(curr_max - curr_low + <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output_lst</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partitionLabels</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        str_dict = &#123;&#125;</span><br><span class="line">        output_lst = []</span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            str_dict[v] = i</span><br><span class="line"></span><br><span class="line">        start = <span class="number">0</span></span><br><span class="line">        end = str_dict[s[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> i &gt; end:</span><br><span class="line">                output_lst.append(end - start + <span class="number">1</span>)</span><br><span class="line">                start = i</span><br><span class="line">                end = str_dict[s[i]]</span><br><span class="line">        </span><br><span class="line">            <span class="keyword">if</span> end &lt; str_dict[s[i]]:</span><br><span class="line">                end = str_dict[s[i]]</span><br><span class="line"></span><br><span class="line">        output_lst.append(end - start + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output_lst </span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-2">452 Medium</h2>
<p>先将区间根据第一个数从小到大排列，接着对比上限得到前后2个intervals相交的区间如果相交则更新上限，不需要更新下限因为右边下限永远比当前下限大，假如说不相交的话就会出现下限比上限大的情况， 这时就更新counts重制上限。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMinArrowShots</span>(<span class="params">self, points: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        points.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line">        counts = <span class="number">1</span></span><br><span class="line">        upper = points[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(points) - <span class="number">1</span>):</span><br><span class="line">            upper = <span class="built_in">min</span>(upper, points[i + <span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">if</span> points[i + <span class="number">1</span>][<span class="number">0</span>] &gt; upper:</span><br><span class="line">                counts += <span class="number">1</span></span><br><span class="line">                upper = points[i + <span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> counts</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="双指针">双指针</h1>
<h2 id="easy-4">167 Easy</h2>
<p>一个指针在前一个指针在后，后面指针负责缩小，前面指针负责放大</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span>(<span class="params">self, numbers: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span>  </span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="built_in">len</span>(numbers) - <span class="number">1</span>     </span><br><span class="line">        <span class="keyword">while</span> i &lt; j:</span><br><span class="line">            <span class="keyword">if</span> numbers[i] + numbers[j] == target:</span><br><span class="line">                <span class="keyword">return</span> [i + <span class="number">1</span>, j + <span class="number">1</span>]</span><br><span class="line">            <span class="keyword">elif</span> numbers[i] + numbers[j] &lt; target:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j -= <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="easy-5">88 Easy</h2>
<p>从nums1 最后一个开始比较，插入n和m比较大的，直到n插入完毕</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], m: <span class="built_in">int</span>, nums2: <span class="type">List</span>[<span class="built_in">int</span>], n: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums1 in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">while</span> n &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> m &lt; <span class="number">1</span>:</span><br><span class="line">                nums1[m + n - <span class="number">1</span>] = nums2[n - <span class="number">1</span>]</span><br><span class="line">                n -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums2[n - <span class="number">1</span>] &gt; nums1[m - <span class="number">1</span>]:</span><br><span class="line">                nums1[m + n - <span class="number">1</span>] = nums2[n - <span class="number">1</span>]</span><br><span class="line">                n -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                nums1[m + n -<span class="number">1</span>] = nums1[m - <span class="number">1</span>]</span><br><span class="line">                m -= <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-3">142 Medium</h2>
<p>假设快指针和慢指针相遇的时间为f, 那么快指针走过的路程为 2s, 慢指针为s, 假设环起始位置到head距离为a, 环长度为b，那么 2s 即为快指针在b中走过的路程，2s - s = s = nb 即为慢指针走过的步数。这里n为整数因为相遇快的最少多走1圈 我们head开始一步一步每次走到环出口的步数为k = a + cb，假设c=n，而目前慢指针已经走了 nb这么多路了，我们只需要让另一个指针走a就可以到达出口。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detectCycle</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        fast, slow, very_slow = head, head, head</span><br><span class="line">        <span class="keyword">while</span> head <span class="keyword">and</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line">            fast = fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            slow = slow.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> fast == slow:</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                    <span class="keyword">if</span> slow == very_slow:</span><br><span class="line">                        <span class="keyword">return</span> slow</span><br><span class="line">                    </span><br><span class="line">                    very_slow = very_slow.<span class="built_in">next</span></span><br><span class="line">                    slow = slow.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-4">633 Medium</h2>
<p>一道很简单的双指针问题</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">judgeSquareSum</span>(<span class="params">self, c: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        u = <span class="built_in">int</span>(math.sqrt(c))</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt;= u:</span><br><span class="line">            <span class="keyword">if</span> (i**<span class="number">2</span> + u**<span class="number">2</span>) &gt; c:</span><br><span class="line">                u -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> (i**<span class="number">2</span> + u**<span class="number">2</span>) &lt; c:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if no import </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">judgeSquareSum</span>(<span class="params">self, c: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        u = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> u ** <span class="number">2</span> &lt; c:</span><br><span class="line">           u += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">while</span> i &lt;= u:</span><br><span class="line">            <span class="keyword">if</span> (i**<span class="number">2</span> + u**<span class="number">2</span>) &gt; c:</span><br><span class="line">                u -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> (i**<span class="number">2</span> + u**<span class="number">2</span>) &lt; c:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-6">680 Easy</h2>
<p>双指针，判断s[i] != s[j]， 这时我们有2种选择，删掉i，或者删掉j，假如说删掉i，i+1 不等于j则说明不能删i同样apply to j。接着我们判断删掉之后的东西是不是为一个回文字符串就可以了。 当出现i和j都可以被删除的情况只要判断删掉2个中又一个为回文字符串就行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">validPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="built_in">len</span>(s) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">check</span>(<span class="params">s, i, j</span>):</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; j:</span><br><span class="line">                <span class="keyword">if</span> s[i] != s[j]:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> i &lt; j:</span><br><span class="line">            <span class="keyword">if</span> s[i] != s[j]:</span><br><span class="line">                <span class="keyword">if</span> s[i + <span class="number">1</span>] == s[j] <span class="keyword">and</span> s[j - <span class="number">1</span>] == s[i]:</span><br><span class="line">                    <span class="keyword">return</span> check(s, i + <span class="number">1</span>, j) <span class="keyword">or</span> check(s, i, j - <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">elif</span> s[i + <span class="number">1</span>] == s[j]:</span><br><span class="line">                    <span class="keyword">return</span> check(s, i + <span class="number">1</span>, j)</span><br><span class="line">                <span class="keyword">elif</span> s[j - <span class="number">1</span>] == s[i]:</span><br><span class="line">                    <span class="keyword">return</span> check(s, i, j - <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    </span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-5">524 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findLongestWord</span>(<span class="params">self, s: <span class="built_in">str</span>, dictionary: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        curr_word = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_in_s</span>(<span class="params">word</span>):</span></span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            j = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(s):</span><br><span class="line">                <span class="keyword">if</span> word[j] == s[i]:</span><br><span class="line">                    j += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> j &gt;= <span class="built_in">len</span>(word):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        dictionary.sort(key=<span class="keyword">lambda</span> x: (<span class="built_in">len</span>(x), x))</span><br><span class="line">        <span class="comment"># for word in dictionary:</span></span><br><span class="line">        <span class="comment">#     word_in_dict = find_in_s(word)</span></span><br><span class="line">        <span class="comment">#     if (len(word) &gt; len(curr_word)) and word_in_dict:</span></span><br><span class="line">        <span class="comment">#         curr_word = word</span></span><br><span class="line">        <span class="comment">#     elif (len(word) == len(curr_word)) and (word &lt; curr_word) and word_in_dict:</span></span><br><span class="line">        <span class="comment">#         curr_word = word</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> dictionary:</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(word) &gt; <span class="built_in">len</span>(curr_word)) <span class="keyword">and</span> find_in_s(word):</span><br><span class="line">                curr_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> curr_word</span><br></pre></td></tr></table></figure>
<h2 id="medium-6">287 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findDuplicate</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        s, f = nums[<span class="number">0</span>], nums[nums[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">while</span> f &lt; <span class="built_in">len</span>(nums):</span><br><span class="line">            <span class="keyword">if</span> s == f:</span><br><span class="line">                f = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> f != s:</span><br><span class="line">                    s = nums[s]</span><br><span class="line">                    f = nums[f]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> f</span><br><span class="line"></span><br><span class="line">            s = nums[s]</span><br><span class="line">            f = nums[nums[f]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h1 id="binary-search">Binary Search</h1>
<h2 id="easy-7">69 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mySqrt</span>(<span class="params">self, x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        left, right = <span class="number">0</span>, x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> x == <span class="number">1</span>:</span><br><span class="line">            left = <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">while</span> (right - left) &gt; <span class="number">1</span>:</span><br><span class="line">            mid_point = <span class="built_in">int</span>((right + left) / <span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> x / mid_point == mid_point:</span><br><span class="line">                <span class="keyword">return</span> mid_point</span><br><span class="line">            <span class="keyword">elif</span> x / mid_point &lt; mid_point:</span><br><span class="line">                right = mid_point</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = mid_point</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> left</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-8">278 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The isBadVersion API is already defined for you.</span></span><br><span class="line"><span class="comment"># @param version, an integer</span></span><br><span class="line"><span class="comment"># @return an integer</span></span><br><span class="line"><span class="comment"># def isBadVersion(version):</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">firstBadVersion</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        l, r = <span class="number">1</span>, n</span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> isBadVersion(mid):</span><br><span class="line">                r = mid - <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> l &gt; n:</span><br><span class="line">            <span class="keyword">return</span> l - <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> l</span><br></pre></td></tr></table></figure>
<h2 id="medium-7">34 Medium</h2>
<p>找到左边界，再找到右边界，重点是boundary的判定</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchRange</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_left</span>(<span class="params">left, right</span>):</span></span><br><span class="line">            res = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> (right - left) &gt;= <span class="number">0</span>:</span><br><span class="line">                mid = (right + left) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> nums[mid] &gt; target:</span><br><span class="line">                    right = mid - <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> nums[mid] == target:</span><br><span class="line">                    right = mid - <span class="number">1</span></span><br><span class="line">                    res = mid               </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_right</span>(<span class="params">left, right</span>):</span></span><br><span class="line">            res = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> (right - left) &gt;= <span class="number">0</span>:</span><br><span class="line">                mid = (right + left) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> nums[mid] &lt; target:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> nums[mid] == target:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line">                    res = mid</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    right = mid - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">        out_left = find_left(left, right)</span><br><span class="line">        out_right = find_right(left, right)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> [out_left, out_right]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-8">81 Medium</h2>
<h2 id="easy-9">350 Easy</h2>
<p>先把他们放到一个dict 然后在找共同就行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersect</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        result_lst = []</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_len</span>(<span class="params">array</span>):</span></span><br><span class="line">            out_dict = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(array)):</span><br><span class="line">                <span class="keyword">if</span> array[i] <span class="keyword">in</span> out_dict.keys():</span><br><span class="line">                    out_dict[array[i]] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    out_dict[array[i]] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> out_dict</span><br><span class="line">        </span><br><span class="line">        num1_dict = get_len(nums1)</span><br><span class="line">        num2_dict = get_len(nums2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(num1_dict) &gt; <span class="built_in">len</span>(num2_dict):</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> num2_dict.items():</span><br><span class="line">                <span class="keyword">if</span> k <span class="keyword">in</span> num1_dict.keys():</span><br><span class="line">                    <span class="keyword">if</span> v &gt; num1_dict[k]:</span><br><span class="line">                        result_lst = result_lst + [k] * num1_dict[k]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        result_lst = result_lst + [k] * v</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> num1_dict.items():</span><br><span class="line">                <span class="keyword">if</span> k <span class="keyword">in</span> num2_dict.keys():</span><br><span class="line">                    <span class="keyword">if</span> v &gt; num2_dict[k]:</span><br><span class="line">                        result_lst = result_lst + [k] * num2_dict[k]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        result_lst = result_lst + [k] * v</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result_lst</span><br></pre></td></tr></table></figure>
<h2 id="easy-10">154 Easy</h2>
<p>class Solution: def minArray(self, numbers: List[int]) -&gt; int: for i in range(len(numbers) - 1): if numbers[i] &gt; numbers[i + 1]: return numbers[i + 1]</p>
<pre><code>    return numbers[0]</code></pre>
<h2 id="easy-11">35 Easy</h2>
<p>不需要最后的l边界判断</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchInsert</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            mid = l + (r - l) // <span class="number">2</span> <span class="comment"># prevent overflow</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                <span class="keyword">return</span> mid</span><br><span class="line">            <span class="keyword">elif</span> nums[mid] &lt; target:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums[mid] &gt; target:</span><br><span class="line">                r = mid - <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> l</span><br></pre></td></tr></table></figure>
<h2 id="easy-12">374 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># The guess API is already defined for you.</span></span><br><span class="line"><span class="comment"># @param num, your guess</span></span><br><span class="line"><span class="comment"># @return -1 if my number is lower, 1 if my number is higher, otherwise return 0</span></span><br><span class="line"><span class="comment"># def guess(num: int) -&gt; int:</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">guessNumber</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        l, r = <span class="number">1</span>, n</span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> guess(mid) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> mid</span><br><span class="line">            <span class="keyword">elif</span> guess(mid) &lt; <span class="number">0</span>:</span><br><span class="line">                r = mid - <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> guess(mid) &gt; <span class="number">0</span>:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-13">744 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nextGreatestLetter</span>(<span class="params">self, letters: <span class="type">List</span>[<span class="built_in">str</span>], target: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(letters) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> letters[mid] &gt; target:</span><br><span class="line">                r = mid - <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (r &lt; <span class="number">0</span>) <span class="keyword">or</span> (l &gt; <span class="built_in">len</span>(letters) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">return</span> letters[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> letters[l]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-9">1170 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numSmallerByFrequency</span>(<span class="params">self, queries: <span class="type">List</span>[<span class="built_in">str</span>], words: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">s</span>):</span></span><br><span class="line">            s = <span class="built_in">sorted</span>(s)</span><br><span class="line">            counts = <span class="number">1</span></span><br><span class="line">            target = s[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">while</span> counts &lt; <span class="built_in">len</span>(s):</span><br><span class="line">                <span class="keyword">if</span> target != s[counts]:</span><br><span class="line">                    <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line">                counts += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(s)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(words):</span><br><span class="line">            words[j] = f(w)</span><br><span class="line"></span><br><span class="line">        words.sort()</span><br><span class="line">        <span class="keyword">for</span> i, q <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">map</span>(f, queries)):</span><br><span class="line">            <span class="comment"># counts = 0</span></span><br><span class="line">            <span class="comment"># for f_w in words:</span></span><br><span class="line">            <span class="comment">#     if f_w &lt;= q:</span></span><br><span class="line">            <span class="comment">#         break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#     counts += 1</span></span><br><span class="line"></span><br><span class="line">            l, r = <span class="number">0</span>, <span class="built_in">len</span>(words) - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">                mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> words[mid] &lt;= q:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> words[mid] &gt; q:</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> l &gt;= <span class="built_in">len</span>(words):</span><br><span class="line">                queries[i] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                queries[i] = <span class="built_in">len</span>(words) - l</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> queries</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-14">1337 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">kWeakestRows</span>(<span class="params">self, mat: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">count_soilder</span>(<span class="params">row</span>):</span></span><br><span class="line">            n = <span class="built_in">len</span>(row)</span><br><span class="line">            l, r = <span class="number">0</span>, n - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">                mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> row[mid] == <span class="number">1</span>:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> l</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, r <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">map</span>(count_soilder, mat)):</span><br><span class="line">            mat[i] = (i, r)</span><br><span class="line">        </span><br><span class="line">        mat.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="number">0</span>],  mat[:k]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="medium-10">378 Medium</h2>
<h2 id="medium-11">153 Medium</h2>
<p>应该比较最右边，将最小情况变为 【5， 1】 或者 【1， 5】这种情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMin</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] &lt;= nums[r]:</span><br><span class="line">                r = mid</span><br><span class="line">            <span class="keyword">elif</span> nums[mid] &gt; nums[r]:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nums[l]</span><br></pre></td></tr></table></figure>
<h2 id="medium-12">33 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                <span class="keyword">return</span> mid</span><br><span class="line">            <span class="keyword">elif</span> nums[mid] &gt;= nums[l]:</span><br><span class="line">                <span class="keyword">if</span> (target &lt; nums[mid]) <span class="keyword">and</span> (target &gt;= nums[l]):</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">elif</span> nums[mid] &lt; nums[l]:</span><br><span class="line">                <span class="keyword">if</span> (target &gt; nums[mid]) <span class="keyword">and</span> (target &lt;= nums[r]):</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    r = mid - <span class="number">1</span> </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution_2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># find smallest</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_smallest</span>():</span></span><br><span class="line">            l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> l &lt; r:</span><br><span class="line">                mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> nums[mid] &gt; nums[r]:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    r = mid</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">return</span> l</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">l, r</span>):</span></span><br><span class="line">            <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">                mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                    <span class="keyword">return</span> mid</span><br><span class="line">                <span class="keyword">elif</span> nums[mid] &gt; target:</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> nums[mid] &lt; target:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        smallest_idx = find_smallest()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> smallest_idx == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> binary_search(<span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> target &gt;= nums[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">return</span> binary_search(<span class="number">0</span>, smallest_idx - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> binary_search(smallest_idx, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="medium-13">81 Medium</h2>
<p>similar to 33, but we check back and front, if they equal, we move front one spot to convert this problem to #33</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># find smallest</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_smallest</span>():</span></span><br><span class="line">            l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> l &lt; r:</span><br><span class="line">                <span class="keyword">if</span> nums[l] == nums[-<span class="number">1</span>]:</span><br><span class="line">                    l += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                    <span class="keyword">if</span> nums[mid] &gt; nums[r]:</span><br><span class="line">                        l = mid + <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        r = mid</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">return</span> l</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">l, r</span>):</span></span><br><span class="line">            <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">                mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                <span class="keyword">elif</span> nums[mid] &gt; target:</span><br><span class="line">                    r = mid - <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> nums[mid] &lt; target:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        smallest_idx = find_smallest()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> smallest_idx == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> binary_search(<span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> target &gt;= nums[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">return</span> binary_search(<span class="number">0</span>, smallest_idx - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> binary_search(smallest_idx, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="hard">154 Hard</h2>
<p>153 的重复版</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMin</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># find smallest</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            <span class="keyword">if</span> nums[l] == nums[-<span class="number">1</span>]:</span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mid = l + (r - l) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> nums[mid] &gt; nums[r]:</span><br><span class="line">                    l = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    r = mid</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> nums[l]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode (3)</title>
    <url>/2021/06/16/leet-code-3/</url>
    <content><![CDATA[<p><strong>题目库: <code>[1688， 79, 78, 46, 22, 90, 47, 39, 40, 93, 53, 70, 121, 122, 118, 392, 62, 198, 5, 55, 64, 322, 63, 120, 93, 45 213, 343, 300, 279, 1143, 494, 152, 518, 377, 416, 309, 337, 221, 139, 119, '面试题17.16', 746, 376]</code></strong></p>
<h1 id="backtracking">Backtracking</h1>
<h2 id="easy">1688 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numberOfMatches</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_matches</span>(<span class="params">n</span>):</span></span><br><span class="line">            <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                    counts = find_matches(n // <span class="number">2</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    counts = find_matches(n // <span class="number">2</span> + <span class="number">1</span>) </span><br><span class="line">                </span><br><span class="line">                <span class="keyword">return</span> counts + n // <span class="number">2</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> find_matches(n)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="medium">79 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">exist</span>(<span class="params">self, board: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]], word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        n, d, k = <span class="built_in">len</span>(board), <span class="built_in">len</span>(board[<span class="number">0</span>]), <span class="built_in">len</span>(word)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_word</span>(<span class="params">i, j, target_index, parent</span>):</span></span><br><span class="line">            <span class="keyword">if</span> target_index &gt;= k:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> board[i][j] != word[target_index]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            result = []</span><br><span class="line">            parent.append((i, j))</span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> (i - <span class="number">1</span>, j) <span class="keyword">not</span> <span class="keyword">in</span> parent:</span><br><span class="line">                    result.append(find_word(i - <span class="number">1</span>, j, target_index + <span class="number">1</span>, parent[:]))</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> i &lt; (n - <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> (i + <span class="number">1</span>, j) <span class="keyword">not</span> <span class="keyword">in</span> parent:</span><br><span class="line">                    result.append(find_word(i + <span class="number">1</span>, j, target_index + <span class="number">1</span>, parent[:]))</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> j &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> (i, j - <span class="number">1</span>) <span class="keyword">not</span> <span class="keyword">in</span> parent:</span><br><span class="line">                    result.append(find_word(i, j - <span class="number">1</span>, target_index + <span class="number">1</span>, parent[:]))</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> j &lt; (d - <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> (i, j + <span class="number">1</span>) <span class="keyword">not</span> <span class="keyword">in</span> parent:</span><br><span class="line">                    result.append(find_word(i, j + <span class="number">1</span>, target_index + <span class="number">1</span>, parent[:]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> result:</span><br><span class="line">                <span class="keyword">if</span> target_index &lt; (k - <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">any</span>(result)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(d):</span><br><span class="line">                <span class="keyword">if</span> board[i][j] == word[<span class="number">0</span>]:</span><br><span class="line">                    r = find_word(i, j, <span class="number">0</span>, [])</span><br><span class="line">                    <span class="keyword">if</span> r:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-1">78 Medium</h2>
<p>通过 j + 1来分支</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_subsets</span>(<span class="params">start, curr_sets</span>):</span></span><br><span class="line">            results.append(curr_sets)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(start, <span class="built_in">len</span>(nums)):</span><br><span class="line">                find_subsets(j + <span class="number">1</span>, curr_sets + [nums[j]])</span><br><span class="line">        </span><br><span class="line">        find_subsets(<span class="number">0</span>, [])</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-2">46 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permute</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        results = []</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_permutation</span>(<span class="params">head, nums</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(head) == n:</span><br><span class="line">                results.append(head)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">                    temp = nums[:]</span><br><span class="line">                    val = temp.pop(i)</span><br><span class="line">                    find_permutation(head + [val], temp)</span><br><span class="line"></span><br><span class="line">        find_permutation([], nums)</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-3">22 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateParenthesis</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">parenthesis</span>(<span class="params">curr_str, open_brac, close_brac</span>):</span></span><br><span class="line">            <span class="keyword">if</span> (open_brac == <span class="number">0</span>) <span class="keyword">and</span> (close_brac == <span class="number">0</span>):</span><br><span class="line">                results.append(curr_str)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (close_brac &gt;= open_brac) <span class="keyword">and</span> (open_brac &gt;=<span class="number">0</span>) <span class="keyword">and</span> (close_brac &gt;= <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">if</span> open_brac &lt; close_brac:</span><br><span class="line">                    parenthesis(curr_str + <span class="string">&#x27;)&#x27;</span>, open_brac, close_brac - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                parenthesis(curr_str + <span class="string">&#x27;(&#x27;</span>, open_brac - <span class="number">1</span>, close_brac)</span><br><span class="line">        </span><br><span class="line">        parenthesis(<span class="string">&#x27;&#x27;</span>, n, n)</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-4">90 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsetsWithDup</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        results = []</span><br><span class="line">        nums.sort()</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_subsets</span>(<span class="params">i, curr_subset, curr_seen</span>):</span></span><br><span class="line">            results.append(curr_subset)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(nums)):</span><br><span class="line">                <span class="keyword">if</span> nums[j] <span class="keyword">not</span> <span class="keyword">in</span> curr_seen:</span><br><span class="line">                    find_subsets(j + <span class="number">1</span>, curr_subset + [nums[j]], [])</span><br><span class="line">                    curr_seen.append(nums[j])</span><br><span class="line"></span><br><span class="line">        find_subsets(<span class="number">0</span>, [], [])</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-5">47 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permuteUnique</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        results = []</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">permuatation</span>(<span class="params">curr_nums, next_choice, previous</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(curr_nums) == n:</span><br><span class="line">                results.append(curr_nums)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(next_choice)):</span><br><span class="line">                    <span class="keyword">if</span> next_choice[i] <span class="keyword">not</span> <span class="keyword">in</span> previous:</span><br><span class="line">                        permuatation(curr_nums + [next_choice[i]], next_choice[:i] + next_choice[i+<span class="number">1</span>:], [])</span><br><span class="line">                        previous.append(next_choice[i])</span><br><span class="line">        </span><br><span class="line">        permuatation([], nums, [])</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-6">39 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        results = []</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_combination</span>(<span class="params">i, curr_comb</span>):</span></span><br><span class="line">            curr_sum = <span class="built_in">sum</span>(curr_comb)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> curr_sum == target:</span><br><span class="line">                results.append(curr_comb)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> curr_sum &lt; target:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(candidates)):</span><br><span class="line">                    find_combination(j, curr_comb + [candidates[j]])</span><br><span class="line">        </span><br><span class="line">        find_combination(<span class="number">0</span>, [])</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-7">40 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum2</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        results = []</span><br><span class="line">        candidates.sort()</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_combination</span>(<span class="params">i, nums</span>):</span></span><br><span class="line">            curr_sum = <span class="built_in">sum</span>(nums)</span><br><span class="line">            <span class="keyword">if</span> curr_sum == target:</span><br><span class="line">                results.append(nums)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> curr_sum &lt; target:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(candidates)):</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> (j != i <span class="keyword">and</span> candidates[j - <span class="number">1</span>] == candidates[j]):</span><br><span class="line">                        find_combination(j + <span class="number">1</span>, nums + [candidates[j]])</span><br><span class="line">        </span><br><span class="line">        find_combination(<span class="number">0</span>, [])</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="medium-8">93 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">restoreIpAddresses</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_ip</span>(<span class="params">curr_ip, curr_can</span>):</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(curr_ip) == <span class="number">4</span>) <span class="keyword">and</span> (<span class="built_in">len</span>(curr_can) == <span class="number">0</span>):</span><br><span class="line">                results.append(<span class="string">&#x27;.&#x27;</span>.join(curr_ip))</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(curr_can) &lt;= (<span class="number">4</span> - <span class="built_in">len</span>(curr_ip)) * <span class="number">3</span>) <span class="keyword">and</span> (<span class="built_in">len</span>(curr_can) &gt;= <span class="number">4</span> - <span class="built_in">len</span>(curr_ip)):</span><br><span class="line">                find_ip(curr_ip + [curr_can[<span class="number">0</span>]], curr_can[<span class="number">1</span>:])</span><br><span class="line">                <span class="keyword">if</span> (curr_can[<span class="number">0</span>] != <span class="string">&#x27;0&#x27;</span>) <span class="keyword">and</span> (<span class="built_in">len</span>(curr_can) &gt;= <span class="number">2</span>):</span><br><span class="line">                    find_ip(curr_ip + [curr_can[:<span class="number">2</span>]], curr_can[<span class="number">2</span>:])</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">len</span>(curr_can) &gt;= <span class="number">3</span> <span class="keyword">and</span> <span class="built_in">int</span>(curr_can[:<span class="number">3</span>]) &lt;= <span class="number">255</span>:</span><br><span class="line">                        find_ip(curr_ip + [curr_can[:<span class="number">3</span>]], curr_can[<span class="number">3</span>:])</span><br><span class="line">        </span><br><span class="line">        new_s = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> i.isdigit():</span><br><span class="line">                new_s = <span class="string">&#x27;&#x27;</span>.join([new_s, i])</span><br><span class="line"></span><br><span class="line">        find_ip([], new_s)</span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="dynamic-programming">Dynamic Programming</h2>
<h2 id="easy-1">53 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        curr_max = nums[<span class="number">0</span>]</span><br><span class="line">        prev_sum = nums[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># find the largest sum end with nums[i]</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="comment"># if f[i - 1] + f[i] &gt; f(i) then largest sum end with f[i] is f[i - 1] + f[i] else f[i]</span></span><br><span class="line">            <span class="comment"># in this case, it is same as max(f[i - 1] + f[i], f[i])</span></span><br><span class="line">            curr_sum = <span class="built_in">max</span>(nums[i], prev_sum + nums[i]) </span><br><span class="line">            prev_sum = curr_sum            </span><br><span class="line">            <span class="keyword">if</span> curr_sum &gt; curr_max:</span><br><span class="line">                curr_max = curr_sum</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> curr_max</span><br></pre></td></tr></table></figure>
<h2 id="easy-2">70 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">climbStairs</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        prev_1 = <span class="number">1</span></span><br><span class="line">        prev_2 = <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, n):</span><br><span class="line">            temp = prev_1</span><br><span class="line">            prev_1 = prev_2</span><br><span class="line">            prev_2 = prev_2 + temp</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> prev_1 + prev_2</span><br></pre></td></tr></table></figure>
<h2 id="easy-3">121 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n) = max profit if sell at day n</span></span><br><span class="line">        <span class="comment"># diff(n, n - 1) = prices[n] - price[n - 1] </span></span><br><span class="line">        <span class="comment"># f(n) = max(f(n - 1) + diff(n, n - 1), diff(n, n - 1))</span></span><br><span class="line"></span><br><span class="line">        curr_max = <span class="number">0</span></span><br><span class="line">        prev_profit = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(prices)):</span><br><span class="line">            diff = prices[i] - prices[i - <span class="number">1</span>]</span><br><span class="line">            curr_profit = <span class="built_in">max</span>(prev_profit + diff, diff)</span><br><span class="line">            <span class="keyword">if</span> curr_profit &gt; curr_max:</span><br><span class="line">                curr_max = curr_profit</span><br><span class="line"></span><br><span class="line">            prev_profit = curr_profit</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> curr_max</span><br></pre></td></tr></table></figure>
<h2 id="easy-4">122 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n) = sum of positive gain til end of day n</span></span><br><span class="line">        <span class="comment"># f(n) = f(n - 1) + max(0, profit)</span></span><br><span class="line">        curr_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(prices)):</span><br><span class="line">            profit = prices[i] - prices[i - <span class="number">1</span>]</span><br><span class="line">            curr_sum = <span class="built_in">max</span>(<span class="number">0</span>, profit) + curr_sum</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> curr_sum</span><br></pre></td></tr></table></figure>
<h2 id="easy-5">118 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span>(<span class="params">self, numRows: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        out = [[<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, numRows):</span><br><span class="line">            curr_row = [<span class="number">1</span>] + [out[i - <span class="number">1</span>][j - <span class="number">1</span>] + out[i - <span class="number">1</span>][j] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(out[i - <span class="number">1</span>]))] + [<span class="number">1</span>]</span><br><span class="line">            out.append(curr_row)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-6">392 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSubsequence</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="comment"># f(n): # of common items</span></span><br><span class="line">        <span class="comment"># f(0) = 0</span></span><br><span class="line">        <span class="comment"># f(n) = f(n - 1) + I(s[i] == t[j])</span></span><br><span class="line"></span><br><span class="line">        i, j, n, k = <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(s), <span class="built_in">len</span>(t)</span><br><span class="line">        <span class="keyword">if</span> n &gt; k:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        curr_com = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt; n) <span class="keyword">and</span> (j &lt; k):</span><br><span class="line">            <span class="keyword">if</span> s[i] == t[j]:</span><br><span class="line">                curr_com += <span class="number">1</span></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> curr_com == n:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-9">62 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniquePaths</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(m, n) = number of paths to cell (m, n)</span></span><br><span class="line">        <span class="comment"># f(0, :) = 1</span></span><br><span class="line">        <span class="comment"># f(:, 0) = 1</span></span><br><span class="line">        <span class="comment"># f(m, n) = f(m - 1, n) + f(n, m - 1)</span></span><br><span class="line">        matrix = [[<span class="number">1</span>] * n]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            curr_row = [<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                prev_up = matrix[i - <span class="number">1</span>][j]</span><br><span class="line">                prev_left = curr_row[-<span class="number">1</span>]</span><br><span class="line">                </span><br><span class="line">                curr_row.append(prev_left + prev_up)</span><br><span class="line"></span><br><span class="line">            matrix.append(curr_row)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> matrix[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-10">198 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rob</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n): max # of cash at house n</span></span><br><span class="line">        <span class="comment"># f(1): nums[1]</span></span><br><span class="line">        <span class="comment"># f(2): max(nums[1], nums[2])</span></span><br><span class="line">        <span class="comment"># f(n): max(nums[n] + f(n - 2), f(n - 1))</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        two_before = nums[<span class="number">0</span>]</span><br><span class="line">        one_before = <span class="built_in">max</span>(nums[<span class="number">1</span>], nums[<span class="number">0</span>])</span><br><span class="line">        curr_total = one_before</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            temp = one_before</span><br><span class="line">            curr_total = <span class="built_in">max</span>(two_before + nums[i], one_before)</span><br><span class="line">            one_before = curr_total</span><br><span class="line">            two_before = temp</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> curr_total</span><br></pre></td></tr></table></figure>
<h2 id="medium-11">5 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="comment"># f(i, j): 1 if i -&gt; j is a palindromic substring</span></span><br><span class="line">        <span class="comment"># f(i, i): 1</span></span><br><span class="line">        <span class="comment"># f(i, i + 1): 1 if i -&gt; i+1 is a palindromic substring</span></span><br><span class="line">        <span class="comment"># f(i, j): 1 if s[i] == s[j] and f[i+1 : j-1] else 0</span></span><br><span class="line"></span><br><span class="line">        dp = [[<span class="number">0</span>] * <span class="built_in">len</span>(s) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s))]</span><br><span class="line">        level = <span class="number">1</span></span><br><span class="line">        out_str = s[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            dp[i][i] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> level &lt; <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s) - level):</span><br><span class="line">                <span class="keyword">if</span> s[j] == s[j + level]:</span><br><span class="line">                    l = j + <span class="number">1</span></span><br><span class="line">                    r = j + level - <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> (level == <span class="number">1</span>) <span class="keyword">or</span> (dp[l][r]):</span><br><span class="line">                        dp[j][j + level] = <span class="number">1</span></span><br><span class="line">                        out_str = s[j:j + level + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            level += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> out_str</span><br></pre></td></tr></table></figure>
<h2 id="medium-12">55 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canJump</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="comment"># f(n): if we can get from n -&gt; nums[-1]</span></span><br><span class="line">        <span class="comment"># f(-1): True</span></span><br><span class="line">        <span class="comment"># f(n): True if any([f(n) for i in range(n)])</span></span><br><span class="line">        dp = [<span class="literal">False</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        dp[-<span class="number">1</span>] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(nums[i], <span class="built_in">len</span>(nums) - i) + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> dp[j + i]:</span><br><span class="line">                    dp[i] = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-13">64 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minPathSum</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(i, j) = min sum at position (i, j)</span></span><br><span class="line">        <span class="comment"># f(0, 1:) = f(0, j) + f(0, j - 1)</span></span><br><span class="line">        <span class="comment"># f(1:, 0) = f(i, 0) + f(i - 1, 0)</span></span><br><span class="line">        <span class="comment"># f(i, j) = min(f(i - 1, j), f(i, j - 1)) + grid[i][j]</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            grid[<span class="number">0</span>][i] = grid[<span class="number">0</span>][i] + grid[<span class="number">0</span>][i - <span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            grid[i][<span class="number">0</span>] = grid[i][<span class="number">0</span>] + grid[i - <span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                grid[i][j] = <span class="built_in">min</span>(grid[i - <span class="number">1</span>][j], grid[i][j - <span class="number">1</span>]) + grid[i][j]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> grid[-<span class="number">1</span>][-<span class="number">1</span>]</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<h2 id="medium-14">322 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">coinChange</span>(<span class="params">self, coins: <span class="type">List</span>[<span class="built_in">int</span>], amount: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(i): Minimum coins to get amount, -1 if cannot</span></span><br><span class="line">        <span class="comment"># coins[j]</span></span><br><span class="line">        <span class="comment"># f(0): 0</span></span><br><span class="line">        <span class="comment"># options = []</span></span><br><span class="line">        <span class="comment"># if i - j &lt; 0: pass, if f(i - j) == -1: pass, else options.append(f(i - j) + 1)</span></span><br><span class="line">        <span class="comment"># f(i) = min(options)</span></span><br><span class="line"></span><br><span class="line">        dp = [<span class="number">0</span>] * (amount + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(dp)):</span><br><span class="line">            options = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> coins:</span><br><span class="line">                <span class="keyword">if</span> (i - j &gt;= <span class="number">0</span>) <span class="keyword">and</span> (dp[i - j] != -<span class="number">1</span>):</span><br><span class="line">                    options.append(dp[i - j] + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> options:</span><br><span class="line">                dp[i] = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i] = <span class="built_in">min</span>(options)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-15">63 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniquePathsWithObstacles</span>(<span class="params">self, obstacleGrid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># the key is to set 1 to 0 and initialization </span></span><br><span class="line">        m, n = <span class="built_in">len</span>(obstacleGrid), <span class="built_in">len</span>(obstacleGrid[<span class="number">0</span>])</span><br><span class="line">        assign_num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> obstacleGrid[<span class="number">0</span>][<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> obstacleGrid[<span class="number">0</span>][i] == <span class="number">1</span>:</span><br><span class="line">                obstacleGrid[<span class="number">0</span>][i] = <span class="number">0</span></span><br><span class="line">                assign_num = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                obstacleGrid[<span class="number">0</span>][i] = assign_num</span><br><span class="line">        </span><br><span class="line">        assign_num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            <span class="keyword">if</span> obstacleGrid[i][<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">                obstacleGrid[i][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">                assign_num = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                obstacleGrid[i][<span class="number">0</span>] = assign_num</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                <span class="keyword">if</span> obstacleGrid[i][j] == <span class="number">1</span>:</span><br><span class="line">                    obstacleGrid[i][j] = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    obstacleGrid[i][j] = obstacleGrid[i - <span class="number">1</span>][j] + obstacleGrid[i][j - <span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> obstacleGrid[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-16">120 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minimumTotal</span>(<span class="params">self, triangle: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n, i): Minimum distance to layer n, position i</span></span><br><span class="line">        <span class="comment"># f(len(triangle), :) = triangle[-1]</span></span><br><span class="line">        <span class="comment"># f(n, i) = min(f(n + 1, i), f(n + 1, i + 1)) + triangle[n][i]</span></span><br><span class="line"></span><br><span class="line">        depth = <span class="built_in">len</span>(triangle)</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(depth - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(triangle[n])):</span><br><span class="line">                triangle[n][i] = <span class="built_in">min</span>(triangle[n + <span class="number">1</span>][i], triangle[n + <span class="number">1</span>][i + <span class="number">1</span>]) + triangle[n][i]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> triangle[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-17">91 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numDecodings</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># counts = 0</span></span><br><span class="line">        <span class="comment"># cache = &#123;&#125;</span></span><br><span class="line">        <span class="comment"># def find_combo(curr_str, cand):</span></span><br><span class="line">        <span class="comment">#     if len(curr_str) + len(cand) != len(s):</span></span><br><span class="line">        <span class="comment">#         return</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#     if not cand:</span></span><br><span class="line">        <span class="comment">#         nonlocal counts</span></span><br><span class="line">        <span class="comment">#         counts += 1</span></span><br><span class="line">        <span class="comment">#         return</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment">#     for i in range(len(cand)):</span></span><br><span class="line">        <span class="comment">#         single = cand[i]</span></span><br><span class="line">        <span class="comment">#         double = cand[i:i+2]</span></span><br><span class="line">        <span class="comment">#         if int(single) &gt; 0:</span></span><br><span class="line">        <span class="comment">#             find_combo(curr_str + single, cand[i+1:])</span></span><br><span class="line">        <span class="comment">#             if (len(double) &gt; len(single)) and (10 &lt;= int(double) &lt;= 26):</span></span><br><span class="line">        <span class="comment">#                 find_combo(curr_str + double, cand[i+2:])</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># find_combo(&#x27;&#x27;, s)</span></span><br><span class="line">        <span class="comment"># return counts</span></span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        s = <span class="string">&#x27; &#x27;</span> + s</span><br><span class="line">        f = [<span class="number">0</span>] * <span class="number">3</span></span><br><span class="line">        f[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n + <span class="number">1</span>):</span><br><span class="line">            f[i % <span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">            a = <span class="built_in">ord</span>(s[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">            b = ( <span class="built_in">ord</span>(s[i - <span class="number">1</span>]) - <span class="built_in">ord</span>(<span class="string">&#x27;0&#x27;</span>) ) * <span class="number">10</span> + <span class="built_in">ord</span>(s[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> &lt;= a &lt;= <span class="number">9</span>:</span><br><span class="line">                f[i % <span class="number">3</span>] = f[(i - <span class="number">1</span>) % <span class="number">3</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="number">10</span> &lt;= b &lt;= <span class="number">26</span>:</span><br><span class="line">                f[i % <span class="number">3</span>] += f[(i - <span class="number">2</span>) % <span class="number">3</span>]</span><br><span class="line">        <span class="keyword">return</span> f[n % <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-18">45 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">jump</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n): min jumps to nums[-1]</span></span><br><span class="line">        <span class="comment"># f(n): 0</span></span><br><span class="line">        <span class="comment"># f(n - 1): float(&#x27;inf&#x27;) if 0 else 1</span></span><br><span class="line">        <span class="comment"># f(i): min([f(i) + 1 for i in range(min(n, i))]) </span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        nums[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">        nums[-<span class="number">2</span>] = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">if</span> nums[-<span class="number">2</span>] == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - <span class="number">3</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            curr_min = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">min</span>(nums[i], <span class="built_in">len</span>(nums) - <span class="number">1</span> - i) + <span class="number">1</span>):</span><br><span class="line">                curr_jumps = <span class="number">1</span> + nums[i + j]</span><br><span class="line">                <span class="keyword">if</span> curr_min &gt; curr_jumps:</span><br><span class="line">                    curr_min = curr_jumps</span><br><span class="line"></span><br><span class="line">            nums[i] = curr_min</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> num</span><br></pre></td></tr></table></figure>
<h2 id="medium-19">213 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rob</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(nums)</span><br><span class="line">        </span><br><span class="line">        seq_1 = nums[:-<span class="number">1</span>]</span><br><span class="line">        seq_2 = nums[<span class="number">1</span>:]</span><br><span class="line">        seq_1[<span class="number">1</span>] = <span class="built_in">max</span>(seq_1[<span class="number">0</span>], seq_1[<span class="number">1</span>])</span><br><span class="line">        seq_2[<span class="number">1</span>] = <span class="built_in">max</span>(seq_2[<span class="number">0</span>], seq_2[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">len</span>(seq_1)):</span><br><span class="line">            seq_1[i] = <span class="built_in">max</span>(seq_1[i - <span class="number">2</span>] + seq_1[i], seq_1[i - <span class="number">1</span>])</span><br><span class="line">            seq_2[i] = <span class="built_in">max</span>(seq_2[i - <span class="number">2</span>] + seq_2[i], seq_2[i - <span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(seq_1[-<span class="number">1</span>], seq_2[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h2 id="medium-20">343 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">integerBreak</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n): max mul</span></span><br><span class="line">        <span class="comment"># f(2): 1</span></span><br><span class="line">        <span class="comment"># f(3): 2</span></span><br><span class="line">        <span class="comment"># f(n): f(i) * f(j) where i != j</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        dp = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>, n + <span class="number">1</span>):</span><br><span class="line">            l, r = <span class="number">2</span>, i - <span class="number">2</span></span><br><span class="line">            <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">                curr_prod = dp[l] * dp[r]</span><br><span class="line">                <span class="keyword">if</span> curr_prod &gt; dp[i]:</span><br><span class="line">                    dp[i] = curr_prod</span><br><span class="line"></span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">                r -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-21">300 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(n): max strictly increasing sub sequence ending with n</span></span><br><span class="line">        <span class="comment"># f(0): 1</span></span><br><span class="line">        <span class="comment"># f(n): </span></span><br><span class="line">        dp = [<span class="number">1</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        curr_max = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            vals = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> nums[i] &gt; nums[j]:</span><br><span class="line">                    vals.append(dp[j])</span><br><span class="line"></span><br><span class="line">            dp[i] = <span class="number">1</span> <span class="keyword">if</span> <span class="keyword">not</span> vals <span class="keyword">else</span> <span class="built_in">max</span>(vals) + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> dp[i] &gt; curr_max:</span><br><span class="line">                curr_max = dp[i]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> curr_max</span><br></pre></td></tr></table></figure>
<h2 id="medium-22">279 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numSquares</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        dp = [<span class="number">0</span>] * (n + <span class="number">1</span>)</span><br><span class="line">        vals = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> i ** <span class="number">2</span> &lt;= n:</span><br><span class="line">                dp[i ** <span class="number">2</span>] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            vals.append(i ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">len</span>(dp)):</span><br><span class="line">            curr_min = i</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> vals:</span><br><span class="line">                j = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> (j &lt; <span class="built_in">len</span>(vals)) <span class="keyword">and</span> (vals[j] &lt;= i):</span><br><span class="line">                    curr_counts = <span class="number">1</span> + dp[i - vals[j]]</span><br><span class="line">                    <span class="keyword">if</span> curr_counts &lt; curr_min:</span><br><span class="line">                        curr_min = curr_counts</span><br><span class="line">                    </span><br><span class="line">                    j += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">                dp[i] = curr_min</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-23">1143 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(i, j): largest number of substring match text1[:i], text2[:j]</span></span><br><span class="line">        <span class="comment"># If text1[i] != text2[j], f(i, j) = max(f(i, j - 1), f(i - 1, j))</span></span><br><span class="line">        <span class="comment"># If text1[i] == text2[j], f(i, j) = f(i - 1, j - 1) + 1</span></span><br><span class="line">        M, N = <span class="built_in">len</span>(text1), <span class="built_in">len</span>(text2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (N + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(M + <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, M + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> text1[i - <span class="number">1</span>] == text2[j - <span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[M][N]</span><br></pre></td></tr></table></figure>
<h2 id="medium-24">494 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findTargetSumWays</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], S: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        sumAll = <span class="built_in">sum</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> S &gt; sumAll <span class="keyword">or</span> (S + sumAll) % <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        target = (S + sumAll) // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        dp = [<span class="number">0</span>] * (target + <span class="number">1</span>)</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(target, num - <span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                dp[j] = dp[j] + dp[j - num]</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-25">152 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProduct</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># f(i): max product at i</span></span><br><span class="line">        <span class="comment"># min_prod: current min product</span></span><br><span class="line">        <span class="comment"># max_prod: current max product</span></span><br><span class="line">        <span class="comment"># f(i): max(f(i - 1), max_prod)</span></span><br><span class="line">        </span><br><span class="line">        min_prod = nums[<span class="number">0</span>]</span><br><span class="line">        max_prod = nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            temp = min_prod</span><br><span class="line">            min_prod = <span class="built_in">min</span>(min_prod * nums[i], nums[i], max_prod * nums[i])</span><br><span class="line">            max_prod = <span class="built_in">max</span>(temp * nums[i], nums[i], max_prod * nums[i])</span><br><span class="line">            nums[i] = <span class="built_in">max</span>(nums[i - <span class="number">1</span>], max_prod)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nums[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-26">518 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change</span>(<span class="params">self, amount: <span class="built_in">int</span>, coins: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        n, m = <span class="built_in">len</span>(coins), amount + <span class="number">1</span></span><br><span class="line">        dp = [<span class="number">1</span>] * m</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            <span class="keyword">if</span> i % coins[<span class="number">0</span>] != <span class="number">0</span>:</span><br><span class="line">                dp[i] = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">                <span class="keyword">if</span> coins[i] &lt;= j:</span><br><span class="line">                    dp[j] = dp[j - coins[i]] + dp[j]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-27">377 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum4</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 定义 f[i][j]: 为组合长度为 i 凑成总和为 j 的方案数是多少</span></span><br><span class="line">        <span class="comment"># f[0][0] = 1</span></span><br><span class="line">        <span class="comment"># dp.shape = ((target + 1), (target + 1))</span></span><br><span class="line"></span><br><span class="line">        dp = [[<span class="number">0</span>] * (target + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(target + <span class="number">1</span>)]</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        out = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, target + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, target + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">                    <span class="keyword">if</span> num &lt;= j:</span><br><span class="line">                        dp[i][j] += dp[i - <span class="number">1</span>][j - num]</span><br><span class="line">        </span><br><span class="line">            out += dp[i][j]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="medium-28">416 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canPartition</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="comment"># f(i, j): whether we can form num ber j with nums[:i] items </span></span><br><span class="line">        <span class="comment"># 0/1 knapsack problem.</span></span><br><span class="line">        </span><br><span class="line">        num_sum = <span class="built_in">sum</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> num_sum % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        target = num_sum // <span class="number">2</span></span><br><span class="line">        dp = [<span class="literal">True</span>] + [<span class="literal">False</span>] * (target)</span><br><span class="line">        <span class="keyword">if</span> nums[<span class="number">0</span>] &lt;= (target):</span><br><span class="line">            dp[nums[<span class="number">0</span>]] = <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="comment"># right to left in order to avoid overrdie of dp[j - nums[i]]</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(target, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> nums[i] &lt;= j:</span><br><span class="line">                    dp[j] = dp[j - nums[i]] <span class="keyword">or</span> dp[j]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> j == target <span class="keyword">and</span> dp[j]:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-29">309 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># // 思路：</span></span><br><span class="line"><span class="comment"># //     考虑有多少种状态，每种状态有哪些选择，或者是做了哪些选择后得到哪种状态。</span></span><br><span class="line"><span class="comment"># //     注意：到底是先选择了才有状态，还是先由状态才能选择。这里是先选择了，才有状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># // 状态类型有2种：天数和是否持有。</span></span><br><span class="line"><span class="comment"># //     天数：一共为1-n天</span></span><br><span class="line"><span class="comment"># //     是否持有：分为持有状态、没持有状态1、没持有状态2。</span></span><br><span class="line"><span class="comment"># //         持有状态：选择 无处理 和 买入 都有可能达到该状态</span></span><br><span class="line"><span class="comment"># //         没持有状态1：选择 无处理 后达到该状态。</span></span><br><span class="line"><span class="comment"># //         没持有状态2：选择 卖出 后达到该状态。注意，卖出后进入一天的冻结期。</span></span><br><span class="line"><span class="comment"># //     注意：这里为什么要分两种没持有状态，这是为了便于后续状态转移，如果不区分这两种状态，状态转移没法确定当天是否可以进行买入操作。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># // dp表示的含义：</span></span><br><span class="line"><span class="comment"># //     dp[i][2] : 第i天为没持有状态2时，此时的最大利润</span></span><br><span class="line"><span class="comment"># //     dp[i][1] : 第i天为没持有状态1时，此时的最大利润</span></span><br><span class="line"><span class="comment"># //     dp[i][0] ： 第i天为持有状态时，此时的最大利润</span></span><br><span class="line"><span class="comment"># // 状态转移方程：</span></span><br><span class="line"><span class="comment"># //     dp[i][0]: 第i天为持有状态时，此时的最大利润</span></span><br><span class="line"><span class="comment"># //         无处理后达到该状态： dp[i][0] = dp[i-1][0] // 第i天没有处理就持有股票，证明上一天也持有</span></span><br><span class="line"><span class="comment"># //         买入后达到该状态： dp[i][0] = dp[i-1][1]-prices[n] // 第i天能买入股票，证明上一天没持有股票，且没进行卖出操作</span></span><br><span class="line"><span class="comment"># //         所以dp[i][0] = max(dp[i-1][0], dp[i-1][1]-prices[n]); // 这里思考个问题，两种情况都能到达这个状态的话，那如何选择？为什么是取他们的max？</span></span><br><span class="line"><span class="comment"># //     dp[i][1]: 第i天为没持有状态1时，此时的最大利润</span></span><br><span class="line"><span class="comment"># //         无处理后达到该状态： dp[i][1] = max(dp[i-1][1], dp[i-1][2]) // 有两种到达该状态的情况，取最大那个</span></span><br><span class="line"><span class="comment"># //     dp[i][2]: 第i天为没持有状态2时，此时的最大利润</span></span><br><span class="line"><span class="comment"># //         卖出后达到该状态： dp[i][2] = dp[i-1][0]+prices[i]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># // 最后max(dp[n-1][1], dp[n-1][2])就是题目所需答案。即第n-1天没持有股票时的最大收益</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># // test case: </span></span><br><span class="line"><span class="comment"># // [1,2,3,0,2]</span></span><br><span class="line"><span class="comment"># // [1,2,-2,0,33,0,2]</span></span><br><span class="line"><span class="comment"># // [1,2,3,0,2,3,9,0,2,4]</span></span><br><span class="line"><span class="comment"># // [2,1]</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(prices) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(prices)</span><br><span class="line">        dp = [[<span class="number">0</span>] * <span class="number">3</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">2</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            dp[i][<span class="number">0</span>] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][<span class="number">0</span>], dp[i-<span class="number">1</span>][<span class="number">1</span>]-prices[i])</span><br><span class="line">            dp[i][<span class="number">1</span>] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][<span class="number">1</span>], dp[i-<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">            dp[i][<span class="number">2</span>] = dp[i-<span class="number">1</span>][<span class="number">0</span>] + prices[i]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp[n-<span class="number">1</span>][<span class="number">1</span>], dp[n-<span class="number">1</span>][<span class="number">2</span>]);</span><br></pre></td></tr></table></figure>
<h2 id="medium-30">337 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rob</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">try_rob</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span> [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            left_node = try_rob(node.left)</span><br><span class="line">            right_node = try_rob(node.right)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># do not rob this node, we can rob root.left and root.right</span></span><br><span class="line">            val_1 = <span class="built_in">max</span>(left_node[<span class="number">0</span>], left_node[<span class="number">1</span>]) + <span class="built_in">max</span>(right_node[<span class="number">0</span>], right_node[<span class="number">1</span>])</span><br><span class="line">            <span class="comment"># rob this node, this implies that we cannot rob root.left or root.right</span></span><br><span class="line">            val_2 = left_node[<span class="number">0</span>] + right_node[<span class="number">0</span>] + node.val</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> [val_1, val_2]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(try_rob(root))</span><br></pre></td></tr></table></figure>
<h2 id="medium-31">221 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maximalSquare</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(matrix) == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">len</span>(matrix[<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        maxSide = <span class="number">0</span></span><br><span class="line">        rows, columns = <span class="built_in">len</span>(matrix), <span class="built_in">len</span>(matrix[<span class="number">0</span>])</span><br><span class="line">        dp = [[<span class="number">0</span>] * columns <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(rows)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(columns):</span><br><span class="line">                <span class="keyword">if</span> matrix[i][j] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">or</span> j == <span class="number">0</span>:</span><br><span class="line">                        dp[i][j] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        dp[i][j] = <span class="built_in">min</span>(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>], dp[i - <span class="number">1</span>][j - <span class="number">1</span>]) + <span class="number">1</span></span><br><span class="line">                    maxSide = <span class="built_in">max</span>(maxSide, dp[i][j])</span><br><span class="line">        </span><br><span class="line">        maxSquare = maxSide * maxSide</span><br><span class="line">        <span class="keyword">return</span> maxSquare</span><br></pre></td></tr></table></figure>
<h2 id="medium-32">139 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wordBreak</span>(<span class="params">self, s: <span class="built_in">str</span>, wordDict: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        n = <span class="built_in">len</span>(s) + <span class="number">1</span></span><br><span class="line">        dp = [<span class="literal">False</span>] * n</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="literal">True</span> </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> (s[j:i] <span class="keyword">in</span> wordDict) <span class="keyword">and</span> dp[j]:</span><br><span class="line">                    dp[i] = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="easy-7">119 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getRow</span>(<span class="params">self, rowIndex: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        dp = [<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, rowIndex + <span class="number">1</span>):</span><br><span class="line">            curr_dp = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dp) - <span class="number">1</span>):</span><br><span class="line">                curr_dp.append(dp[j] + dp[j + <span class="number">1</span>])</span><br><span class="line">            dp = [<span class="number">1</span>] + curr_dp + [<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dp</span><br></pre></td></tr></table></figure>
<h2 id="面试题-17.16-easy">面试题 17.16 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">massage</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sum</span>(nums)</span><br><span class="line"></span><br><span class="line">        nums[<span class="number">1</span>] = <span class="built_in">max</span>(nums[<span class="number">1</span>], nums[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            nums[i] = <span class="built_in">max</span>(nums[i - <span class="number">1</span>], nums[i] + nums[i - <span class="number">2</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> nums[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="easy-8">746 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minCostClimbingStairs</span>(<span class="params">self, cost: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cost) - <span class="number">3</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            cost[i] += <span class="built_in">min</span>(cost[i + <span class="number">1</span>], cost[i + <span class="number">2</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>(cost[<span class="number">0</span>], cost[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h2 id="medium-33">376 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wiggleMaxLength</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span>        </span><br><span class="line">        diff = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] - nums[i + <span class="number">1</span>] != <span class="number">0</span>:</span><br><span class="line">                diff.append(nums[i] - nums[i + <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> diff:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        dp = [<span class="number">0</span>] * <span class="built_in">len</span>(diff)</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(dp)):</span><br><span class="line">            cand = [<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                <span class="keyword">if</span> (diff[j] &gt; <span class="number">0</span> <span class="keyword">and</span> diff[i] &lt; <span class="number">0</span>) <span class="keyword">or</span> (diff[j] &lt; <span class="number">0</span> <span class="keyword">and</span> diff[i] &gt; <span class="number">0</span>):</span><br><span class="line">                    cand.append(dp[j] + <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            dp[i] = <span class="built_in">max</span>(cand)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>LGBM</title>
    <url>/2021/09/06/lgb/</url>
    <content><![CDATA[<h1 id="lightgbm-a-highly-efficient-gradient-boosting-decision-tree">LightGBM: A Highly Efficient Gradient Boosting Decision Tree</h1>
<h2 id="background">Background</h2>
<h3 id="gbdt">GBDT</h3>
<p>GBDT is an ensemble model of decision trees, which are trained in sequence. In each iteration, GBDT learns the decision trees by fitting the negative gradients (also known as residual errors).</p>
<p>The main cost in GBDT lies:</p>
<ol type="1">
<li>Learning the decision trees (<strong>finding the best split points</strong>) when there is large number of features and samples.
<ul>
<li><strong>Histogram based algorithm</strong> buckets continuous feature values into discrete bins and uses these bins to construct feature histograms during training. It finds the best split points based on the feature histogram, the criterion is calculated at the interval boundaries. It costs <span class="math inline">\(O(N \times M)\)</span> for histogram building and <span class="math inline">\(O(\text{Number of bins} \times M)\)</span> for split point finding. Since number of bins is much smaller than number of data points, histogram building will dominate the computational complexity. <img src='/images/ML/lgb_1.png' width="600"> <img src='/images/ML/lgb_2.png' width="600"></li>
<li><strong>Pre-sorted algorithm</strong> sorts the values of each numeric attribute, and evaluates the criterion at each possible split point to find the splitting point with the minimum criterion. The sorting requires <span class="math inline">\(O(n\log (n))\)</span>.</li>
</ul></li>
<li><strong>Number of Samples</strong>:
<ul>
<li>Down sampling the data instance (i.e weights, random subsets), most of the algorithms are based on adaboost which has weights but not GBDT which does not have weights natively. Random subsets hurt the performance.</li>
</ul></li>
<li><strong>Number of Features</strong>:
<ul>
<li>PCA to remove weak correlated features (depends on assumption that features contain significant redundancy which might not always be true in practice)</li>
</ul></li>
</ol>
<h3 id="gradient-based-one-side-sampling">Gradient-based One-Side Sampling</h3>
<p>In AdaBoost, the sample weight serves as a good indicator for the importance of data instances. In GBDT, gradient for each data instance provides us with useful information for data sampling. That is, if an instance is associated with a small gradient, the training error for this instance is small and it is already well-trained. A straightforward idea is to discard those data instances with small gradients. However, <strong>the data distribution will be changed by doing so</strong>. To avoid this problem, GOSS keeps all the instances with large gradients and performs random sampling on the instances with samll gradients.</p>
<p>In order to compensate the influence to the data distribution, when computing the information gain, GOSS introduces a constant multiplier for the data instances with samll gradients. Specifically, GOSS:</p>
<ol type="1">
<li>Firstly sorts the data instances according to the absolute value of their gradients.</li>
<li>Selects the top <span class="math inline">\(a \times 100%\)</span> instances.</li>
<li>Then it randomly samples <span class="math inline">\(b \times 100%\)</span> from the rest of the data.</li>
<li>Amplifies the sampled data with small gradients by a constant <span class="math inline">\(\frac{1 - a}{b}\)</span> when calculating the criterion to normalize the sum of the gradients.</li>
</ol>
<p><img src='/images/ML/lgb_3.png' width="600"></p>
<h3 id="exclusive-feature-bundling">Exclusive Feature Bundling</h3>
<p>High-dimensional data are usually very sparse. The sparsity of the feature space provides us a possibility of designing a nearly lossless approach to reduce the number of features. Specifically, in a sparse feature space, many features are mutually exclusive (they never take nonzero values simultaneously), we can safely bundle these features into a single feature. In this way, the complexity of histogram building changes from <span class="math inline">\(O(N \times M)\)</span> to <span class="math inline">\(O(N \times \text{Number of bundles})\)</span>. Then we can significantly speed up the training of GBDT without hurting the accuracy.</p>
<h4 id="which-features-to-bundle">Which Features to Bundle</h4>
<p>Partitioning features into smallest number of exclusive bundles is NP-hard, thus it is impossible to find an exact solution within polynomial time. Thus, a greedy algorithm which can produce reasonable good results are being used. Furthermore, we can allow a small fraction of conflicts which is controlled by <span class="math inline">\(\gamma\)</span> (there are usually quite a few features, although not 100% mutually exclusive, also rarely take nonzero values simultaneously) to have an even smaller number of feature bundles and further improve the computational efficiency. For small <span class="math inline">\(\gamma\)</span>, we will be able to achieve a good balance between accuracy and efficiency.</p>
<p>Intuitively, it:</p>
<ol type="1">
<li>Builds a graph with features as vertices and weighted edges as total conflicts between features (Edge only occurs when two features are not mutually exclusive).</li>
<li>Sort the features by their degrees (Number of edges)</li>
<li>Check each feature in the ordered list and either append it to existing list (if total conflicts between feature and bundle less than <span class="math inline">\(\gamma\)</span>) or create a new bundle.</li>
</ol>
<p><img src='/images/ML/lgb_4.png' width="600"></p>
<p><br></p>
<p>The time complexity of algorithm 3 is <span class="math inline">\(O(M^2)\)</span> and it is only processed once before training. This complexity is acceptable when the number of features is not very large.</p>
<h4 id="how-to-construct-the-bundle">How to Construct the Bundle</h4>
<p>The key is to ensure that the values of the original features can be identified from the feature bundles. This can be done by adding offsets to the original values of the features:</p>
<ol type="1">
<li>Calculate the offset to be added to every feature in feature bundle.</li>
<li>Iterate over every data instance and feature.</li>
<li>Initialize the new bucket as zero for instances where all features are zero.</li>
<li>Calculate the new bucket for every non zero instance of a feature by adding respective offset to original bucket of that feature</li>
</ol>
<p><img src='/images/ML/lgb_5.png' width="600"> <img src='/images/ML/lgb_6.png' width="600"></p>
<h1 id="ref">Ref</h1>
<p>https://www.researchgate.net/publication/351133481_Comparison_of_Gradient_Boosting_Decision_Tree_Algorithms_for_CPU_Performance</p>
<p>https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf</p>
<p>https://robotenique.github.io/posts/gbm-histogram/</p>
<p>https://www.aaai.org/Papers/KDD/1998/KDD98-001.pdf</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear Algebra (2)</title>
    <url>/2022/01/09/linear-algebra-2/</url>
    <content><![CDATA[<h1 id="linear-algebra-2">Linear Algebra (2)</h1>
<h2 id="finite-dimensional-vector-space">Finite Dimensional Vector Space</h2>
<h3 id="span-and-linear-independence">Span and Linear Independence</h3>
<p><strong>List of vectors are written without surrounding parentheses. For example <span class="math inline">\((4, 1, 6), (9, 5, 7)\)</span> is a list of length 2 of vectors in <span class="math inline">\(\mathbb{R}^3\)</span></strong>.</p>
<h4 id="definition-2.3-linear-combination">Definition 2.3: Linear Combination</h4>
<p>A <strong>linear combination</strong> of a list <span class="math inline">\(v_1, ..., v_m\)</span> of vectors in <span class="math inline">\(V\)</span> is a vector of the form:</p>
<p><span class="math display">\[a_1v_1 + ... + a_m v_m\]</span></p>
<p>where <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span></p>
<blockquote>
<p><span class="math inline">\((17, -4, 2)\)</span> is a linear combination of list of vectosr <span class="math inline">\((2, 1, -3), (1, -2, 4)\)</span> with <span class="math inline">\(a_1 = 6, a_2=5\)</span>.</p>
</blockquote>
<h4 id="definition-2.5-span-linear-span">Definition 2.5: Span (Linear Span)</h4>
<p>The set of all linear combinations of a list of vectors <span class="math inline">\(v_1, ..., v_m\)</span> in <span class="math inline">\(V\)</span> is called the <strong>span</strong> of <span class="math inline">\(v_1, ..., v_m\)</span>, denoted <span class="math inline">\(span(v_1, ..., v_m)\)</span>. In other words,</p>
<p><span class="math display">\[span(v_1, ..., v_m) = \{a_1v_1 + .... + a_m v_m; a_1, ..., a_m \in \mathbb{F}\}\]</span></p>
<p><strong>The span of a list of vectors in <span class="math inline">\(V\)</span> is the smallest subspace of <span class="math inline">\(V\)</span> containing all the vectors in the list.</strong> <span id="more"></span></p>
<h4 id="definition-2.8-spans">Definition 2.8: Spans</h4>
<p>If <span class="math inline">\(span(v_1, .., v_m) = V\)</span>, we say that <span class="math inline">\(v_1, ..., v_m\)</span> <strong>spans</strong> <span class="math inline">\(V\)</span>.</p>
<h4 id="definition-2.10-finite-dimensional-vector-space">Definition 2.10: Finite-dimensional Vector Space</h4>
<p>A vector space is called <strong>finite-dimensional</strong> if some list of vectors in it spans the space. (every list has finite length)</p>
<h4 id="definition-2.11-polynomial-pmathbbf">Definition 2.11: Polynomial, <span class="math inline">\(P(\mathbb{F})\)</span></h4>
<p>A function <span class="math inline">\(p: \mathbb{F} \rightarrow \mathbb{F}\)</span> is called a <strong>polynomial</strong> with coefficients in <span class="math inline">\(\mathbb{F}\)</span> if there exist <span class="math inline">\(a_0, ..., a_m \in \mathbb{F}\)</span> s.t:</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + a_2z^2 + .... + a_m z^m\]</span></p>
<p>for all <span class="math inline">\(z \in \mathbb{F}\)</span>.</p>
<p><span class="math inline">\(P(\mathbb{F})\)</span> is the set of all polynomials with coefficients in <span class="math inline">\(\mathbb{F}\)</span>. (so it is the set of functions) With the usual operations of addition and scalar multiplication, <span class="math inline">\(P(\mathbb{F})\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span> or it is a subspace of <span class="math inline">\(\mathbb{F}^{\mathbb{F}}\)</span>.</p>
<h4 id="definition-2.12-degree-of-a-polynomial">Definition 2.12: Degree of a Polynomial</h4>
<p>A polynomial <span class="math inline">\(p \in P(\mathbb{F})\)</span> is said to have <strong>degree</strong> <span class="math inline">\(m\)</span> if there exist scalars <span class="math inline">\(a_0 ,..., a_m \in \mathbb{F}\)</span> with <span class="math inline">\(a_m \neq 0\)</span> s.t</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + ... + a_m z^m\]</span></p>
<p>for all <span class="math inline">\(z \in \mathbb{F}\)</span> . If <span class="math inline">\(p\)</span> has degree <span class="math inline">\(m\)</span>, we write <span class="math inline">\(\text{deg} \;p = m\)</span>.</p>
<p>The polynomial that is identically <span class="math inline">\(0\)</span> is said to have degree <span class="math inline">\(-\infty\)</span>.</p>
<h4 id="definition-2.13-p_mmathbbf">Definition 2.13: <span class="math inline">\(P_m(\mathbb{F})\)</span></h4>
<p>For <span class="math inline">\(m\)</span> a nonnegative integer, <span class="math inline">\(P_m (\mathbb{F})\)</span> denotes the set of all polynomials with coefficients in <span class="math inline">\(\mathbb{F}\)</span> and degree at most <span class="math inline">\(m\)</span>. Then <span class="math inline">\(P_m (\mathbb{F})\)</span> is a finite-dimensional vector space for each nonnegative integer <span class="math inline">\(m\)</span>.</p>
<h4 id="definition-2.15-infinite-dimensional-vector-space">Definition 2.15: Infinite-Dimensional Vector Space</h4>
<p>A vector space is called <strong>infinite-dimensional</strong> if it is not finite-dimensional.</p>
<h4 id="definition-2.17-linearly-independent">Definition 2.17: Linearly Independent</h4>
<p>A list <span class="math inline">\(v_1, ..., v_m\)</span> of vectors in <span class="math inline">\(V\)</span> is called <strong>linearly independent</strong> if the only choice of <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span> that makes <span class="math inline">\(a_1v_1 + ... + a_mv_m = 0\)</span> is <span class="math inline">\(a_1 = ... = a_m = 0\)</span>.</p>
<p>The empty list <span class="math inline">\(()\)</span> is also declared to be linearly independent.</p>
<h4 id="definition-2.19-linearly-dependent">Definition 2.19: Linearly Dependent</h4>
<p>A list of vector in <span class="math inline">\(V\)</span> is called <strong>linearly dependent</strong> if it is not linearly independent.</p>
<p>In other words, a list <span class="math inline">\(v_1, ..., v_m\)</span> of vectors in <span class="math inline">\(V\)</span> is linearly dependent if there exist <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span>, not all <span class="math inline">\(0\)</span>, such that:</p>
<p><span class="math display">\[a_1v_1 + ... + a_mv_m = 0\]</span></p>
<h4 id="lemma-2.21-linear-dependence-lemma">Lemma 2.21: Linear Dependence Lemma</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_m\)</span> is a linearly dependent list in <span class="math inline">\(V\)</span>. Then there exists <span class="math inline">\(j \in \{1, 2, ...., m\}\)</span> such that the following hold:</p>
<ol type="1">
<li><span class="math inline">\(v_j \in span(v_1, ..., v_{j-1})\)</span></li>
<li>If the <span class="math inline">\(j\)</span>th term is removed from <span class="math inline">\(v_1, ...., v_m\)</span>, the span of the remaining list equals <span class="math inline">\(span(v_1, ..., v_m)\)</span>.</li>
</ol>
<h4 id="definition-2.23-length-of-linearly-independent-list-leq-length-of-spanning-list">Definition: 2.23: Length of Linearly Independent List <span class="math inline">\(\leq\)</span> Length of Spanning List</h4>
<p>In a finite-dimensional vector space, the length of every linearly independent list of vectors is less than or equal to the length of every spanning list of vectors (i.e every list of vectors that spans <span class="math inline">\(V\)</span>).</p>
<h4 id="definition-2.26-finite-dimensional-subspaces">Definition 2.26: Finite-dimensional Subspaces</h4>
<p>Every subspace of a finite-dimensional vector space is finite-dimensional.</p>
<h3 id="bases">Bases</h3>
<h4 id="definition-2.27-basis">Definition 2.27: Basis</h4>
<p>A <strong>basis</strong> of <span class="math inline">\(V\)</span> is a list of vectors in <span class="math inline">\(V\)</span> that is linearly independent and spans <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.31-spanning-list-contains-a-basis">Corollary 2.31: Spanning List Contains a Basis</h4>
<p>Every spanning list in a vector space can be reduced to a basis of the vector space.</p>
<h4 id="corollary-2.32-basis-of-finite-dimensional-vector-space">Corollary 2.32: Basis of Finite-Dimensional Vector Space</h4>
<p>Every finite-dimensional vector space has a basis.</p>
<h4 id="corollary-2.33-linearly-independent-list-extands-to-a-basis">Corollary 2.33: Linearly Independent List Extands to a Basis</h4>
<p>Every linearly independent list of vectors in a finite-dimensional vector space can be extended to a basis of the vector space.</p>
<h4 id="corollary-2.34-every-subspace-of-v-is-part-of-a-direct-sum-equal-to-v">Corollary 2.34: Every Subspace of <span class="math inline">\(V\)</span> is part of a Direct Sum Equal to <span class="math inline">\(V\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then there is a subspace <span class="math inline">\(W\)</span> of <span class="math inline">\(V\)</span> s.t <span class="math inline">\(V = U \oplus W\)</span>.</p>
<h3 id="dimension">Dimension</h3>
<h4 id="corollary-2.35-basis-length-does-not-depend-on-basis">Corollary 2.35: Basis Length Does Not Depend on Basis</h4>
<p>Any two bases of a finite-dimensional vector space have the same length.</p>
<h4 id="definition-2.36-dimension-dim-v">Definition 2.36: Dimension, dim <span class="math inline">\(V\)</span></h4>
<p>The <strong>dimension</strong> of a finite-dimensional vector space is the length of any basis of the vector space.</p>
<p>The dimension of <span class="math inline">\(V\)</span> (if <span class="math inline">\(V\)</span> is finite-dimensional) is denoted by dim <span class="math inline">\(V\)</span></p>
<h4 id="corollary-2.38-dimension-of-a-subspace">Corollary 2.38: Dimension of a Subspace</h4>
<p>If <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>, then dim <span class="math inline">\(U\)</span> dim <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.39-linearly-independent-list-of-the-right-length-is-a-basis">Corollary 2.39: Linearly Independent List of the Right Length is a Basis</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then every linearly independent list of vectors in <span class="math inline">\(V\)</span> with length dim <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.42-spanning-list-of-the-right-length-is-a-basis">Corollary 2.42: Spanning List of the Right Length is a Basis</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then, every spanning list of vectors in <span class="math inline">\(V\)</span> with length dim <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.43-dimension-of-a-sum">Corollary 2.43: Dimension of a Sum</h4>
<p>If <span class="math inline">\(U_1\)</span> amd <span class="math inline">\(U_2\)</span> are subspaces of a finite-dimensional vector space, then</p>
<p><span class="math display">\[\text{dim}(U_1 + U_2) = \text{dim } U_1 + \text{dim } U_2 - \dim(U_1 \cap U_2)\]</span></p>
<h2 id="linear-maps">Linear Maps</h2>
<h3 id="the-vector-space-of-linear-map">The Vector Space of Linear Map</h3>
<p>Assume <span class="math inline">\(V, U, W\)</span> are vector spaces.</p>
<h4 id="definition-3.2-linear-map-linear-transformation">Definition 3.2: Linear Map (Linear Transformation)</h4>
<p>A <strong>linear map</strong> from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is a function <span class="math inline">\(T: V \rightarrow W\)</span> with the following properties:</p>
<ol type="1">
<li><strong>Additivity</strong>: <span class="math display">\[T(v + w) = T(v) + T(w)\]</span></li>
<li><strong>Homogeneity</strong>: <span class="math display">\[T(\lambda v) = \lambda (Tv), \; \forall \lambda \in \mathbb{F}, \; \forall v \in V\]</span></li>
</ol>
<p><span class="math inline">\(Tv = T(v)\)</span></p>
<h4 id="notation-3.3-lv-w">Notation 3.3: <span class="math inline">\(L(V, W)\)</span></h4>
<p>The set of all linear maps from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is denoted <span class="math inline">\(L(V, W)\)</span>.</p>
<h4 id="corollary-3.5-linear-maps-and-basis-of-domain">Corollary 3.5: Linear Maps and Basis of Domain</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_n\)</span> is a basis of <span class="math inline">\(W\)</span>. Then there exists a unique linear map <span class="math inline">\(T: V \rightarrow W\)</span> s.t</p>
<p><span class="math display">\[Tv_j = w_j\]</span></p>
<p>for each <span class="math inline">\(j=1, ..., n\)</span></p>
<h4 id="definition-3.6-addition-and-scalar-multiplication-on-lv-w">Definition 3.6: Addition and Scalar Multiplication on <span class="math inline">\(L(V, W)\)</span></h4>
<p>Suppose <span class="math inline">\(S,T \in L(V, W)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. The <strong>sum</strong> <span class="math inline">\(S+T\)</span> and the <strong>product</strong> <span class="math inline">\(\lambda T\)</span> are the linear maps from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> defined by:</p>
<p><span class="math display">\[(S + T) (v) = Sv + Tv\]</span></p>
<p><span class="math display">\[\lambda (T)(v) = \lambda (Tv)\]</span></p>
<h4 id="corollary-3.7-lw-v-is-a-vector-space">Corollary 3.7: <span class="math inline">\(L(W, V)\)</span> is a Vector Space</h4>
<p>With the operations of addition and scalar multiplication as defined in <code>Definition 3.6</code>, <span class="math inline">\(L(V, W)\)</span> is a vector space.</p>
<h4 id="definition-3.8-product-of-linear-maps">Definition 3.8: Product of Linear Maps</h4>
<p>If <span class="math inline">\(T \in L(U, V)\)</span> and <span class="math inline">\(S \in L(V, W)\)</span>, then the <strong>product</strong> <span class="math inline">\(ST \in L(U, W)\)</span> is defined by</p>
<p><span class="math display">\[(ST)(u) = S(T(u))\]</span></p>
<p>for <span class="math inline">\(u \in U\)</span>. In other words, we can write this as composition:</p>
<p><span class="math display">\[(S \circ T) (u)\]</span></p>
<h4 id="corollary-3.9-algebraic-properties-of-products-of-linear-maps">Corollary 3.9: Algebraic Properties of Products of Linear Maps</h4>
<p>Assume all products make sense.</p>
<ol type="1">
<li><p><strong>Associativity</strong>: <span class="math display">\[(T_1T_2)T_3 = T_1(T_2T_3)\]</span></p></li>
<li><p><strong>Identity</strong>: <span class="math display">\[TI = IT = T\]</span> Whenever <span class="math inline">\(T \in L(V, W)\)</span>, the first <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(V\)</span>, the second <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(W\)</span>.</p></li>
<li><p><strong>Distributive</strong>: <span class="math display">\[(S_1 + S_2) T = S_1T + S_2T\]</span> <span class="math display">\[S(T_1 + T_2) = ST_1 + ST_2\]</span></p>
<p>Whenever <span class="math inline">\(T, T_1, T_2 \in L(U, V)\)</span>, <span class="math inline">\(S, S_1, S_2 \in L(V, W)\)</span></p></li>
</ol>
<h4 id="corollary-3.11-linear-maps-take-0-to-0">Corollary 3.11: Linear Maps Take <span class="math inline">\(0\)</span> to <span class="math inline">\(0\)</span></h4>
<p>Suppose <span class="math inline">\(T\)</span> is a linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span>. Then <span class="math inline">\(T(0) = 0\)</span>. In other words, the linear map, maps additive identity in <span class="math inline">\(V\)</span> to additive identity in <span class="math inline">\(W\)</span>.</p>
<p><br></p>
<h3 id="null-spaces-and-ranges">Null Spaces and Ranges</h3>
<h4 id="definition-3.12-null-space-null-t">Definition 3.12: Null Space, null <span class="math inline">\(T\)</span></h4>
<p>For <span class="math inline">\(T \in L(V, W)\)</span>, the <strong>null space</strong> of <span class="math inline">\(T\)</span>, denoted null <span class="math inline">\(T\)</span>, is the subset of <span class="math inline">\(V\)</span> consisting of those vectors that <span class="math inline">\(T\)</span> maps to <span class="math inline">\(0\)</span>:</p>
<p><span class="math display">\[\text{null } T = \{v \in V: T(v) = 0\}\]</span></p>
<h4 id="corollary-3.14-the-null-space-is-a-subspace">Corollary 3.14: The Null Space is a Subspace</h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Then null <span class="math inline">\(T\)</span> is a subspace of <span class="math inline">\(V\)</span>.</p>
<h4 id="definition-3.15-injective-one-to-one">Definition 3.15: Injective (One to One)</h4>
<p>A fuinction <span class="math inline">\(T: V \rightarrow W\)</span> is called <strong>injective</strong> if <span class="math inline">\(T(u) = T(v) \implies u = v\)</span>.</p>
<h4 id="corollary-3.16-injectivity-is-equivalent-to-null-space-equals-0">Corollary 3.16: Injectivity is Equivalent to Null Space Equals <span class="math inline">\(\{0\}\)</span></h4>
<p>Let <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(T\)</span> is injective if and only if null <span class="math inline">\(T = \{0\}\)</span>.</p>
<h4 id="definition-3.17-range-image">Definition 3.17: Range (Image)</h4>
<p>For <span class="math inline">\(T: V \rightarrow W\)</span>, the <strong>range</strong> of <span class="math inline">\(T\)</span> is the subset of <span class="math inline">\(W\)</span> consisting of those vectors that are of the form <span class="math inline">\(T(v)\)</span> for some <span class="math inline">\(v \in V\)</span>:</p>
<p><span class="math display">\[\text{range } T = \{T(v): v \in V\}\]</span></p>
<h4 id="corollary-3.19-the-range-is-a-subspace">Corollary 3.19: The Range is a Subspace</h4>
<p>If <span class="math inline">\(T \in L(V, W)\)</span>, then range <span class="math inline">\(T\)</span> is a subspace of <span class="math inline">\(W\)</span>.</p>
<h4 id="definition-3.20-surjective-on-to">Definition 3.20: Surjective (On to)</h4>
<p>A function <span class="math inline">\(T: V \rightarrow W\)</span> is called <strong>surjective</strong> if its range equals <span class="math inline">\(W\)</span>:</p>
<p><span class="math display">\[\text{range } T = W\]</span></p>
<h4 id="theorem-3.22-fundamental-theorem-of-linear-maps">Theorem 3.22: Fundamental Theorem of Linear Maps</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. The range <span class="math inline">\(T\)</span> is finite-dimensional and</p>
<p><span class="math display">\[\dim V = \dim \text{null } T + \dim \text{range } T\]</span></p>
<h4 id="corollary-3.23-a-map-to-a-smaller-dimensional-space-is-not-injective">Corollary 3.23: A Map to a Smaller Dimensional Space is not Injective</h4>
<p>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces such that <span class="math inline">\(\dim V &gt; \dim W\)</span>. Then no linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is injective.</p>
<h4 id="corollary-3.24-a-map-to-a-larger-dimensional-space-is-not-surjective">Corollary 3.24: A Map to a Larger Dimensional Space is not Surjective</h4>
<p>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces such that <span class="math inline">\(\dim V &lt; \dim W\)</span>. Then no linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is surjective.</p>
<h4 id="corollary-3.26-homogeneous-system-of-linear-equations-ax-0">Corollary 3.26: Homogeneous System of Linear Equations (<span class="math inline">\(Ax = 0\)</span>)</h4>
<p>A homogeneous system of linear equations with more variables than equations has nonzero solutions. (followed by Corollary 3.23)</p>
<h4 id="corollary-3.29-inhomogeneous-system-of-linear-equations-ax-c">Corollary 3.29: Inhomogeneous System of Linear Equations (<span class="math inline">\(Ax = c\)</span>)</h4>
<p>An inhomogeneous system of linear equations with more equations than variables has no solution for <strong>some choice</strong> of the constant terms. (followed by Corollary 3.24)</p>
<h3 id="matrices">Matrices</h3>
<p><strong>If <span class="math inline">\(T\)</span> is a linear map from <span class="math inline">\(\mathbb{F}^n\)</span> to <span class="math inline">\(\mathbb{F^m}\)</span>, then unless stated, assume the bases in question are the standard ones where the <span class="math inline">\(k\)</span>th basis vector is <span class="math inline">\(1\)</span> in the <span class="math inline">\(k\)</span>th slot and <span class="math inline">\(0\)</span> o.w.</strong></p>
<h4 id="definition-3.30-matrix-a_jk">Definition 3.30: Matrix <span class="math inline">\(A_{j,k}\)</span></h4>
<p>Let <span class="math inline">\(m, n\)</span> denote positive integers. An <span class="math inline">\(m \times n\)</span> <strong>matrix</strong> <span class="math inline">\(A\)</span> is a rectangular array of elements of <span class="math inline">\(\mathbb{F}\)</span> with <span class="math inline">\(m\)</span> rows and <span class="math inline">\(n\)</span> columns:</p>
<p><span class="math display">\[
A = 
\begin{bmatrix}
A_{1, 1} &amp; ... &amp; A_{1, n}\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
A_{m, 1} &amp; ... &amp; A_{m, n}
\end{bmatrix}
\]</span> The notation <span class="math inline">\(A_{j, k}\)</span> denotes the entry in row <span class="math inline">\(j\)</span>, column <span class="math inline">\(k\)</span> of <span class="math inline">\(A\)</span>.</p>
<h4 id="definition-3.32-matrix-of-a-linear-map-m-t">Definition 3.32: Matrix of a Linear Map, <span class="math inline">\(M (T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. The <strong>matrix</strong> of <span class="math inline">\(T\)</span> with respect to these bases is the <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix <span class="math inline">\(M(T)\)</span> whose entries <span class="math inline">\(A_{j, k}\)</span> are defined by:</p>
<p><span class="math display">\[T(v_k) = A_{1, k} w_1 + .... + A_{m, k} w_m\]</span></p>
<p>If the bases are not clear from the context, then the notation <span class="math inline">\(M(T, (v_1, ...., v_n), (w_1, ...., w_m))\)</span> are used.</p>
<p><strong>We can think of the <span class="math inline">\(k\)</span>th column of <span class="math inline">\(M(T)\)</span> as <span class="math inline">\(T\)</span> applied to the <span class="math inline">\(k\)</span>th standard basis vector and formed by standard basis in <span class="math inline">\(W\)</span>.</strong></p>
<blockquote>
<p>Suppose <span class="math inline">\(T \in L(\mathbb{F}^2, \mathbb{F}^3)\)</span> is defined as <span class="math display">\[T(x, y) = (x + 3y, 2x+5y, 7x + 9y)\]</span> then, the matrix of <span class="math inline">\(T\)</span> w.r.t the standard bases of <span class="math inline">\(\mathbb{F}^2\)</span> and <span class="math inline">\(\mathbb{F}^3\)</span> is: <span class="math display">\[T(1, 0) = A_1 = (1, 2, 7)\]</span> <span class="math display">\[T(0, 1) = A_2 = (3, 5, 9)\]</span> <span class="math display">\[M(T)  = [A_1, A_2]\]</span></p>
</blockquote>
<h4 id="definition-3.35-matrix-addition">Definition 3.35: Matrix Addition</h4>
<p>The <strong>sum of two matrices <span class="math inline">\(A, C\)</span> of the same size</strong> is the matrix obtained by adding corresponding entries in the matrices:</p>
<p><span class="math display">\[(A + C)_{j, k} = A_{j, k} + C_{j, k}\]</span></p>
<h4 id="corollary-3.36-the-matrix-of-the-sum-of-linear-maps">Corollary 3.36: The Matrix of the Sum of Linear Maps</h4>
<p>Suppose <span class="math inline">\(S, T \in L(V, W)\)</span>. Then <span class="math inline">\(M(S + T) = M(S) + M(T)\)</span></p>
<h4 id="definition-3.37-scalar-multiplication-of-a-matrix">Definition 3.37: Scalar Multiplication of a Matrix</h4>
<p>The product of a scalar <span class="math inline">\(\lambda\)</span> and a matrix <span class="math inline">\(A\)</span> is the matrix obtained by multiplying each entry in the matrix by the scalar:</p>
<p><span class="math display">\[(\lambda A)_{j, k} = \lambda A_{j, k}\]</span></p>
<h4 id="corollary-3.38-the-matrix-of-a-scalar-times-a-linear-map">Corollary 3.38: The Matrix of a Scalar Times a Linear Map</h4>
<p>Suppose <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(M(\lambda T) = \lambda M(T)\)</span>.</p>
<h4 id="notation-3.39-mathbbfm-times-n">Notation 3.39: <span class="math inline">\(\mathbb{F}^{m \times n}\)</span></h4>
<p>For <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> positive integers, the <strong>set</strong> of all <span class="math inline">\(m\)</span>-by-<span class="math inline">\(n\)</span> matrices with entries in <span class="math inline">\(\mathbb{F}\)</span> is denoted by <span class="math inline">\(\mathbb{F}^{m, n}\)</span>.</p>
<h4 id="corollary-3.40-dim-mathbbfm-n-mn">Corollary 3.40: <span class="math inline">\(\dim \mathbb{F}^{m, n} = mn\)</span></h4>
<p>Suppose <span class="math inline">\(m, n\)</span> are positive integers. With addition and scalar multiplication defined in <code>3.35, 3.35</code>, <span class="math inline">\(\mathbb{F}^{m, n}\)</span> is a vector space with dimension <span class="math inline">\(mn\)</span>.</p>
<h4 id="definition-3.41-matrix-multiplication">Definition 3.41: Matrix Multiplication</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix. Then <span class="math inline">\(AC\)</span> is defined to be the <span class="math inline">\(m\)</span> by <span class="math inline">\(p\)</span> matrix whose entry in row <span class="math inline">\(j\)</span>, column <span class="math inline">\(k\)</span>, is given by the following equation:</p>
<p><span class="math display">\[(AC)_{j,k} = \sum^{n}_{r=1} A_{j, r}C_{r, k}\]</span></p>
<p>In other words, the entry in row <span class="math inline">\(j\)</span>, column <span class="math inline">\(k\)</span>, of <span class="math inline">\(AC\)</span> is computed by taking row <span class="math inline">\(j\)</span> of <span class="math inline">\(A\)</span> and column <span class="math inline">\(k\)</span> of <span class="math inline">\(C\)</span>, multiplying together corresponding entries and then summing.</p>
<h4 id="corollary-3.43-the-matrix-of-the-product-of-linear-maps">Corollary 3.43: The Matrix of the Product of Linear Maps</h4>
<p>If <span class="math inline">\(T \in L(U, V)\)</span> and <span class="math inline">\(S \in L(V, W)\)</span>, then <span class="math inline">\(M(ST) = M(S) M(T)\)</span></p>
<h4 id="notation-3.44-a_j-cdot-a_cdot-k">Notation 3.44: <span class="math inline">\(A_{j, \cdot}, A_{\cdot, k}\)</span></h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix:</p>
<ul>
<li>If <span class="math inline">\(1 \leq j \leq m\)</span>, then <span class="math inline">\(A_{j, \cdot}\)</span>, donotes the <span class="math inline">\(1\)</span> by <span class="math inline">\(n\)</span> matrix consisting of row <span class="math inline">\(j\)</span> of <span class="math inline">\(A\)</span>.</li>
<li>If <span class="math inline">\(1 \leq k \leq n\)</span>, then <span class="math inline">\(A_{\cdot, k}\)</span> denotes the <span class="math inline">\(n\)</span> by <span class="math inline">\(1\)</span> matrix consisting of column <span class="math inline">\(k\)</span> of <span class="math inline">\(A\)</span>.</li>
</ul>
<p>Thus, we can think of matrix multiplication as row times column.</p>
<h4 id="corollary-3.49-column-of-matrix-product-equals-matrix-times-column">Corollary 3.49: Column of Matrix Product Equals Matrix Times Column</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix. Then</p>
<p><span class="math display">\[(AC)_{\cdot, k} = A C_{\cdot, k}\]</span></p>
<p>for <span class="math inline">\(1 \leq k \leq p\)</span>.</p>
<h4 id="corollary-3.52-linear-combination-of-columns">Corollary 3.52: Linear Combination of Columns</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(c = [c_1 .... c_n]^T\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(1\)</span> matrix, then:</p>
<p><span class="math display">\[Ac = c_1 A_{\cdot, 1} + ... + c_n A_{\cdot, n}\]</span></p>
<p>In other words, <span class="math inline">\(Ac\)</span> is a linear combination of the columns of <span class="math inline">\(A\)</span>, with the scalars that multiply the columns coming from <span class="math inline">\(c\)</span>.</p>
<h4 id="corollary-3.53-row-of-matrix-product-equals-row-times-matrix">Corollary 3.53: Row of Matrix Product Equals Row Times Matrix</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix, then:</p>
<p><span class="math display">\[(AC)_{j, \cdot} = A_{j, \cdot} C\]</span></p>
<p>for <span class="math inline">\(1 \leq j \leq m\)</span>.</p>
<h4 id="corollary-3.54-linear-combination-of-rows">Corollary 3.54: Linear Combination of Rows</h4>
<p>Suppose <span class="math inline">\(a = [a_1 ... a_n]\)</span> is a <span class="math inline">\(1 \times n\)</span> matrix and <span class="math inline">\(C\)</span> is a <span class="math inline">\(n \times p\)</span> matrix:</p>
<p><span class="math display">\[aC = a_1 C_{1, \cdot} + ... + a_n C_{n, \cdot}\]</span></p>
<p><br></p>
<h3 id="invertibility-and-isomorphic-vector-spaces">Invertibility and Isomorphic Vector Spaces</h3>
<h4 id="definition-3.53-invertible-inverse">Definition 3.53: Invertible, Inverse</h4>
<ul>
<li>A linear map <span class="math inline">\(T \in L(V, W)\)</span> is called <strong>invertible</strong> if there exists a linear map <span class="math inline">\(S \in L(W, V)\)</span> s.t <span class="math inline">\(ST\)</span> equals the identity map on <span class="math inline">\(V\)</span> and <span class="math inline">\(TS\)</span> equals the identity map on <span class="math inline">\(W\)</span>.</li>
<li>A linear map <span class="math inline">\(S \in L(W, V)\)</span> satisfying <span class="math inline">\(ST = I\)</span> and <span class="math inline">\(TS = I\)</span> is called an <strong>inverse</strong> of <span class="math inline">\(T\)</span> (note that the first <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(V\)</span> and the second <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(W\)</span>).</li>
</ul>
<h4 id="definition-3.54-inverse-is-unique">Definition 3.54: Inverse is Unique</h4>
<p>An invertible linear map has a unique inverse.</p>
<h4 id="notation-3.55-t-1">Notation 3.55: <span class="math inline">\(T^{-1}\)</span></h4>
<p>If <span class="math inline">\(T\)</span> is invertible, then its inverse is denoted by <span class="math inline">\(T^{-1}\)</span>. In other words, if <span class="math inline">\(T \in L(V, W)\)</span> is invertible, then <span class="math inline">\(T^{-1}\)</span> is the unique element of <span class="math inline">\(L(W, V)\)</span> s.t <span class="math inline">\(T^{-1}T = I\)</span> and <span class="math inline">\(TT^{-1} = I\)</span>.</p>
<h4 id="corollary-3.56-invertibility-is-equivalent-to-injectivity-and-surjectivity">Corollary 3.56: Invertibility is Equivalent to Injectivity and Surjectivity</h4>
<p>A linear map is invertible if and only if it is injective and surjective.</p>
<h4 id="definition-3.58-isomorphism-isomorphic-equal-shape">Definition 3.58: Isomorphism, Isomorphic (Equal Shape)</h4>
<ul>
<li>An <strong>isomorphism</strong> is an invertible linear map.</li>
<li>Two vector space are called <strong>isomorphic</strong> if there is an isomorphism from one vector space onto the other one.</li>
</ul>
<p>One way to think of <strong>isomorphic</strong> is that we can always label <span class="math inline">\(v \in V\)</span> by <span class="math inline">\(T(v) \in W\)</span>, because there is always a linear map that maps <span class="math inline">\(T(v) \in W\)</span> back to <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="corollary-3.59-dimension-shows-whether-vector-spaces-are-isomorphic">Corollary 3.59: Dimension Shows Whether Vector Spaces are Isomorphic</h4>
<p>Two finite-dimensional vector spaces over <span class="math inline">\(\mathbb{F}\)</span> are isomorphic if and only if they have the same dimension.</p>
<h4 id="corollary-3.60-m-is-a-linear-mapping">Corollary 3.60: <span class="math inline">\(M\)</span> is a Linear Mapping</h4>
<p>Given bases of <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, <span class="math inline">\(M\)</span> is a linear mapping following <code>3.36, 3.38</code>.</p>
<h4 id="corollary-3.60-lv-w-and-mathbbfmn-are-isomorphic">Corollary 3.60: <span class="math inline">\(L(V, W)\)</span> and <span class="math inline">\(\mathbb{F}^{m,n}\)</span> are Isomorphic</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. Then <span class="math inline">\(M\)</span> is an isomorphism between <span class="math inline">\(L(V, W)\)</span> and <span class="math inline">\(\mathbb{F}^{m, n}\)</span>.</p>
<h4 id="corollary-3.61-dim-lv-w-dim-v-dim-w">Corollary 3.61: <span class="math inline">\(\dim L(V, W) = (\dim V) (\dim W)\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional. Then <span class="math inline">\(L(V, W)\)</span> is finite dimensional and:</p>
<p><span class="math display">\[\dim L(V, W) = (\dim V) (\dim W)\]</span></p>
<h4 id="definition-3.62-matrix-of-a-vector-mv">Definition 3.62: Matrix of a Vector, <span class="math inline">\(M(v)\)</span></h4>
<p>Suppose <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(v_1, ...., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>. The <strong>matrix of <span class="math inline">\(v\)</span></strong> w.r.t this basis is the <span class="math inline">\(n\)</span> by <span class="math inline">\(1\)</span> matrix:</p>
<p><span class="math display">\[
M(v) = 
\begin{bmatrix}
c_1\\
.\\
.\\
.\\
c_n
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(c_1, ..., c_n\)</span> are the scalars such that:</p>
<p><span class="math display">\[v = c_1 v_1 + ... + c_n v_n\]</span></p>
<p><span class="math inline">\(M(v)\)</span> depends on the bases, so they should be clear from the context and thus it is not included in the notation. <strong>M</strong> is an isomorphism of <span class="math inline">\(V\)</span> onto <span class="math inline">\(\mathbb{F}^{n, 1}\)</span>.</p>
<h4 id="definition-3.64-mt_cdot-k-mtv_k">Definition 3.64: <span class="math inline">\(M(T)_{\cdot, k} = M(T(v_k))\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. Let <span class="math inline">\(1 \leq k \leq n\)</span>. Then the <span class="math inline">\(k\)</span>th column of <span class="math inline">\(M(T)\)</span>, which is denoted by <span class="math inline">\(M(T)_{\cdot, k}\)</span>, equals <span class="math inline">\(M(T(v_k))\)</span>.</p>
<h4 id="theorem-3.65-linear-maps-act-like-matrix-multiplication">Theorem 3.65: Linear Maps Act Like Matrix Multiplication</h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span> and <span class="math inline">\(v \in V\)</span>. Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. Then:</p>
<p><span class="math display">\[M(T(v)) = M(T) M(v)\]</span></p>
<p><br></p>
<p>We can think of every linear map as Matrix because, we can identify any <span class="math inline">\(T(v) \in W\)</span> by:</p>
<p><span class="math display">\[M(T(v)) = M(T) M(v)\]</span></p>
<p><span class="math inline">\(M(T(v))\)</span> can be used to recover any <span class="math inline">\(T(v)\)</span>.</p>
<h4 id="definition-3.67-operator-lv">Definition 3.67: Operator, <span class="math inline">\(L(V)\)</span></h4>
<ul>
<li>A linear map from a vector space to itself is called an <strong>operator</strong>.</li>
<li>The notation <span class="math inline">\(L(V)\)</span> denotes the set of all operators on <span class="math inline">\(V\)</span>: <span class="math display">\[L(V) = L(V, V)\]</span></li>
</ul>
<h4 id="theorem-3.69-injectivity-is-equivalent-ot-surjectivity-in-finite-dimensions">Theorem 3.69: Injectivity is Equivalent ot Surjectivity in Finite Dimensions</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li>T is invertible.</li>
<li>T is injective.</li>
<li>T is surjective.</li>
</ol>
<p><strong>In infinite-dimensional vector space, neither injectivity nor surjectivity implies invertibility.</strong></p>
<h3 id="products-and-quotients-of-vector-spaces">Products and Quotients of Vector Spaces</h3>
<p>As usual when dealing with more than oen vector space, all the vector spaces in use should be over the same field.</p>
<h4 id="definition-3.71-product-of-vector-spaces">Definition 3.71: Product of Vector Spaces</h4>
<p>Suppose <span class="math inline">\(V_1, ..., V_m\)</span> are vector spaces over <span class="math inline">\(\mathbb{F}\)</span>.</p>
<ul>
<li>The <strong>product</strong> <span class="math inline">\(V_1 \times V_2 \times .... \times V_m\)</span> is defined by: <span class="math display">\[V_1 \times ... \times V_2 = \{(v_1, ..., v_m): v_1 \in V_1 , ..., v_m \in V_m\}\]</span></li>
<li>Addition on <span class="math inline">\(V_1 \times V_2 \times ... \times V_m\)</span> is defined by: <span class="math display">\[(u_1, ...., u_m) + (v_1, ...., v_m) = (u_1 + v_1 , ...., u_m + v_m)\]</span></li>
<li>Scalar multiplication on <span class="math inline">\(V_1 \times .... \times V_m\)</span> is defined by: <span class="math display">\[\lambda (v_1, ..., v_m) = (\lambda v_1 , ..., \lambda v_m)\]</span></li>
</ul>
<blockquote>
<p>Elements of <span class="math inline">\(P_2(\mathbb{R}) \times \mathbb{R}^3\)</span> are lists of length 2:</p>
<p><span class="math display">\[(5 - 6x + 16x^2, (1, 2, 3)) \in P_2(\mathbb{R}) \times \mathbb{R}^3\]</span></p>
</blockquote>
<h4 id="theorem-3.73-product-of-vector-space-is-a-vector-space">Theorem 3.73: Product of Vector Space is a Vector Space</h4>
<p>Suppose <span class="math inline">\(V_1, ..., V_m\)</span> are vector spaces over <span class="math inline">\(\mathbb{F}\)</span>. Then <span class="math inline">\(V_1 \times ... \times V_m\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span>.</p>
<p><strong>Elements in <span class="math inline">\(\mathbb{R}^2 \times \mathbb{R}^3\)</span> has length 2 and elements in <span class="math inline">\(\mathbb{R}^5\)</span> has length 5, so they are not identical. But the linear map that takes a vector from first space to second space is clearly an isomorphism, thus these two vector spaces are isomorphic.</strong></p>
<h4 id="theorem-3.76-dimension-of-a-product-is-the-sum-of-dimensions">Theorem 3.76: Dimension of a Product is the Sum of Dimensions</h4>
<p>Suppose <span class="math inline">\(V_1, ..., V_m\)</span> are finite-dimensional vector spaces. Then <span class="math inline">\(V_1 \times ... \times V_m\)</span> is finite-dimensional and:</p>
<p><span class="math display">\[\dim(V_1 \times ... \times V_m) = \dim V_1 + ... + \dim V_m\]</span></p>
<h4 id="proof-of-theorem-3.76">Proof of Theorem 3.76</h4>
<p>Choose a basis of each <span class="math inline">\(V_j\)</span>. For each basis vector of each <span class="math inline">\(V_j\)</span>, consider the element of <span class="math inline">\(V_1 \times ... \times V_m\)</span> that equals the basis vector in the <span class="math inline">\(j\)</span>th slot and 0 in other slots. The list of all such vectors is linearly independent and spans the product space. Thus, it is a basis of <span class="math inline">\(V_1 \times ... \times V_m\)</span>. The length is <span class="math inline">\(\dim V_1 + ... + \dim V_m\)</span>.</p>
<h4 id="theorem-3.77-products-and-direct-sums">Theorem 3.77: Products and Direct Sums</h4>
<p>Suppose that <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Define a linear map <span class="math inline">\(\Gamma: U_1 \times .... \times U_m \rightarrow U_1 + ... + U_m\)</span> by:</p>
<p><span class="math display">\[\gamma (u_1, ...., u_m) = u_1 + ... + u_m\]</span></p>
<p>Then <span class="math inline">\(U_1 + ... + U_m\)</span> is a direct sum if and only if <span class="math inline">\(\Gamma\)</span> is injective (By definition of sum of subspace, we have <span class="math inline">\(\Gamma\)</span> surjective, so we can replace the <strong>injective</strong> by <strong>invertible</strong>).</p>
<h5 id="proof-of-theorem-3.77">Proof of Theorem 3.77:</h5>
<ol type="1">
<li><span class="math inline">\(\leftarrow\)</span>: The linear map <span class="math inline">\(\Gamma\)</span> is injective iff the only way to write <span class="math inline">\(0\)</span> as a sum <span class="math inline">\(u_1 + ... + u_m\)</span> is by taking every <span class="math inline">\(u_j = 0\)</span>, this leads to the <code>Def 1.44</code>.</li>
<li><span class="math inline">\(\rightarrow\)</span>: by <code>Def 1.44</code>, the only way for <span class="math inline">\(U_1 + ... + U_m\)</span> to be direct sum is to have <span class="math inline">\(\text{null } \Gamma = \{0\}\)</span>, which implies injectivity.</li>
</ol>
<h4 id="theorem-3.78-a-sum-is-a-direct-sum-iff-dimensions-add-up">Theorem 3.78: A Sum is a Direct Sum IFF Dimensions Add Up</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U_1 + ... + U_m\)</span> is a direct sum IFF:</p>
<p><span class="math display">\[\dim (U_1 + ... + U_m) = \dim (U_1) + ... + \dim (U_m)\]</span></p>
<h5 id="proof-of-theorem-3.78">Proof of Theorem 3.78:</h5>
<p>Suppose that <span class="math inline">\(\Gamma\)</span> is invertible, then by <code>3.22</code>:</p>
<p><span class="math display">\[\dim (U_1 \times ... \times U_m) = \dim \text{null } (\Gamma) + \dim \text{range } \Gamma\]</span></p>
<p>Since <span class="math inline">\(\Gamma\)</span> is injective, we have:</p>
<p><span class="math display">\[\dim (U_1 \times ... \times U_m) =  \dim \text{range } \Gamma\]</span></p>
<p>Since <span class="math inline">\(\Gamma\)</span> is surjective, we have:</p>
<p><span class="math display">\[\dim \text{range } \Gamma = \dim (U_1 + ... + U_m)\]</span> <span class="math display">\[\implies \dim (U_1 \times ... \times U_m) = \dim (U_1 + ... + U_m)\]</span></p>
<p>By <code>3.76</code> and <code>3.77</code>, we have <span class="math inline">\(\dim (U_1 + ... + U_m)\)</span> is a direct sum and:</p>
<p><span class="math display">\[\dim (U_1) + ... + \dim(U_m) = \dim (U_1 + ... + U_m)\]</span></p>
<h4 id="definition-3.79-v-u">Definition 3.79: <span class="math inline">\(v + U\)</span></h4>
<p>Suppose <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(v + U\)</span> is the subset of <span class="math inline">\(V\)</span> defined by:</p>
<p><span class="math display">\[v + U = \{v + u: u \in U\}\]</span></p>
<h4 id="definition-3.81-affine-subset-parallel">Definition 3.81: Affine subset, Parallel</h4>
<ul>
<li>An <strong>affine subset</strong> of <span class="math inline">\(V\)</span> is a subset of <span class="math inline">\(V\)</span> of the form <span class="math inline">\(v + U\)</span> for some <span class="math inline">\(v \in V\)</span> and some subspace <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span>.</li>
<li>For <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(U\)</span> a subspace of <span class="math inline">\(V\)</span>, the affine subset <span class="math inline">\(v + U\)</span> is said to be <strong>parallel</strong> to <span class="math inline">\(U\)</span>.</li>
</ul>
<blockquote>
<p>If <span class="math inline">\(U = \{(x, y, 0) \in \mathbb{R}^3: x, y \in \mathbb{R}\}\)</span>, then the affine subsets of <span class="math inline">\(\mathbb{R}^3\)</span> parallel to <span class="math inline">\(U\)</span> are the planes in <span class="math inline">\(\mathbb{R}^3\)</span> that are parallel to the <span class="math inline">\(xy\)</span>-plane <span class="math inline">\(U\)</span> in the usual sense.</p>
</blockquote>
<h4 id="definition-3.83-quotient-space-v-u">Definition 3.83: Quotient Space, <span class="math inline">\(V / U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then the <strong>quotient space</strong> <span class="math inline">\(V / U\)</span> is the set of all affine subsets of <span class="math inline">\(V\)</span> parallel to <span class="math inline">\(U\)</span>. In other words:</p>
<p><span class="math display">\[V / U = \{v + U: v \in V\}\]</span></p>
<blockquote>
<p>If <span class="math inline">\(U = \{(x, 2x) \in \mathbb{R}^2: x \in \mathbb{R}\}\)</span>, then <span class="math inline">\(\mathbb{R}^2 / U\)</span> is the subset of all lines with slope of <span class="math inline">\(2\)</span>. If <span class="math inline">\(U\)</span> is a line in <span class="math inline">\(\mathbb{R}^3\)</span> containing the origin, then <span class="math inline">\(\mathbb{R}^3 / U\)</span> is the set of all lines in <span class="math inline">\(\mathbb{R}^3\)</span> parallel to <span class="math inline">\(U\)</span>.</p>
</blockquote>
<h4 id="theorem-3.85-two-affine-subsets-parallel-to-u-are-equal-or-disjoint">Theorem 3.85: Two Affine Subsets Parallel to <span class="math inline">\(U\)</span> are Equal or Disjoint</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(v, w \in V\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(v - w \in U\)</span></li>
<li><span class="math inline">\(v + U = w + U\)</span></li>
<li><span class="math inline">\((v + U) \cap (w + U) = \emptyset\)</span></li>
</ol>
<h5 id="proof-of-theorem-3.85">Proof of Theorem 3.85</h5>
<p>Assume <span class="math inline">\((1)\)</span> holds, then we have for some <span class="math inline">\(u \in U\)</span>:</p>
<p><span class="math display">\[v + u = w + \underbrace{(v - w + u)}{\in U} \in w + U\]</span></p>
<p>Since the additive inverse <span class="math inline">\(w - v\)</span>, is also in <span class="math inline">\(U\)</span>,</p>
<p><span class="math display">\[w + u = v + \underbrace{(w - v + u)}{\in U} \in v + U\]</span></p>
<p>Then we have:</p>
<p><span class="math display">\[v + U \subseteq w + U\]</span></p>
<p>and</p>
<p><span class="math display">\[w + U \subseteq v + U\]</span></p>
<p>Thus, <span class="math inline">\(v + U = w + U\)</span>, this implies <span class="math inline">\((3)\)</span> holds.</p>
<p>Assume <span class="math inline">\((3)\)</span> holds, then <span class="math inline">\(\exists \; u_1, u_2 \in U\)</span>, then we have:</p>
<p><span class="math display">\[v + u_1 = w + u_2 \implies v - w = u_2 - u_1 \in U\]</span></p>
<p>Since <span class="math inline">\((1) \implies (2)\)</span>, we have <span class="math inline">\((3) \implies (2)\)</span>.</p>
<h4 id="definition-3.86-addition-and-scalar-multiplication-on-v-u">Definition 3.86: Addition and Scalar Multiplication on <span class="math inline">\(V / U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then <strong>addition</strong> and <strong>scalar multiplication</strong> are defined on <span class="math inline">\(V / U\)</span> by:</p>
<p><span class="math display">\[(v + U) + (w + U) = (v + w) + U\]</span> <span class="math display">\[\lambda (v + U) = (\lambda v) + U\]</span></p>
<p>for <span class="math inline">\(v, w \in V\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>.</p>
<h4 id="theorem-3.87-quotient-space-is-a-vector-space">Theorem 3.87 Quotient Space is a Vector Space</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(V / U\)</span>, with the operations of addition and scalar multiplication as defined above, is a vector space.</p>
<p>Notice the additive inverse of <span class="math inline">\(v + U\)</span> is <span class="math inline">\((-v) + U\)</span>, and additive identity is <span class="math inline">\(0 + U\)</span>.</p>
<h4 id="definition-3.88-quotient-map-pi">Definition 3.88: Quotient Map, <span class="math inline">\(\pi\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. The <strong>quotient map <span class="math inline">\(\pi\)</span></strong> is the linear map <span class="math inline">\(\pi : V \rightarrow V / U\)</span> defined by:</p>
<p><span class="math display">\[\pi(v) = v + U\]</span></p>
<p>for <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="theorem-3.89-dimension-of-a-quotient-space">Theorem 3.89: Dimension of a Quotient Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\dim V / U = \dim V - \dim U\]</span></p>
<h5 id="proof-of-theorem-3.89">Proof of Theorem 3.89</h5>
<p>Since <span class="math inline">\(0 + U\)</span> is the additive identity in <span class="math inline">\(V / U\)</span>, so it is the set of <span class="math inline">\(U\)</span>, and we can clearly see that the range <span class="math inline">\(\pi = V / U\)</span>. Thus:</p>
<p><span class="math display">\[\dim V = \dim U + \dim V / U \implies \dim V / U = \dim V - \dim U\]</span></p>
<h4 id="definition-3.90-tildet">Definition 3.90: <span class="math inline">\(\tilde{T}\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Define <span class="math inline">\(\tilde{T}: V / (\text{null } T) \rightarrow W\)</span> by:</p>
<p><span class="math display">\[\tilde{T} (v + \text{null } T) = T(v)\]</span></p>
<h4 id="theorem-3.91-null-space-and-range-of-tildet">Theorem 3.91: Null Space and Range of <span class="math inline">\(\tilde{T}\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(\tilde{T}\)</span> is a linear map from <span class="math inline">\(V / \text{null } T\)</span> to <span class="math inline">\(W\)</span>.</li>
<li><span class="math inline">\(\tilde{T}\)</span> is injective.</li>
<li><span class="math inline">\(\text{range } \tilde{T} = \text{range }T\)</span>.</li>
<li><span class="math inline">\(V / (\text{null } T)\)</span> is isomorphic to <span class="math inline">\(\text{range }T\)</span>.</li>
</ol>
<h3 id="duality">Duality</h3>
<h4 id="definition-3.92-linear-functional">Definition 3.92: Linear Functional</h4>
<p>A <strong>linear functional</strong> on <span class="math inline">\(V\)</span> is a linear map from <span class="math inline">\(V\)</span> to the scalar field <span class="math inline">\(\mathbb{F}\)</span>. In other words, a linear functional is an element of <span class="math inline">\(L(V, \mathbb{F})\)</span>.</p>
<blockquote>
<p>Define <span class="math inline">\(\phi: \mathbb{R}^3 \rightarrow \mathbb{R}\)</span> by <span class="math inline">\(\phi(x, y, z) = 4x - 5y + 2z\)</span>. Then <span class="math inline">\(\phi\)</span> is a linear functional on <span class="math inline">\(\mathbb{R}^3\)</span></p>
</blockquote>
<h4 id="definition-3.94-dual-space-vprime">Definition 3.94: Dual Space, <span class="math inline">\(V^{\prime}\)</span></h4>
<p>The <strong>dual space</strong> of <span class="math inline">\(V\)</span>, denoted <span class="math inline">\(V^{\prime}\)</span>, is the vector space of all linear functionals on <span class="math inline">\(V\)</span>. In other words:</p>
<p><span class="math display">\[T^{\prime} = L(V, \mathbb{F})\]</span></p>
<h4 id="theorem-3.95-dim-vprime-dim-v">Theorem 3.95: <span class="math inline">\(\dim V^{\prime} = \dim V\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then <span class="math inline">\(V^{\prime}\)</span> is also finite-dimensional and <span class="math inline">\(\dim V^{\prime} = \dim V\)</span>.</p>
<h5 id="proof-of-theorem-3.95">Proof of Theorem 3.95:</h5>
<p>By <code>Corollary 3.6.1</code>, we have <span class="math inline">\(\dim L(V, \mathbb{F}) = \dim (V) \dim (\mathbb{F}) = \dim V\)</span></p>
<h4 id="definition-3.96-dual-basis">Definition 3.96: Dual Basis</h4>
<p>If <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, then the <strong>dual basis</strong> of <span class="math inline">\(v_1, ..., v_n\)</span> is the list <span class="math inline">\(\psi_1 , ..., \psi_n\)</span> of elements of <span class="math inline">\(V^{\prime}\)</span>, where each <span class="math inline">\(\psi_j\)</span> is a linear functional on <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[
\psi_j(v_k)=
\begin{cases}
1, \quad \text{if} \;\; k = j\\
0, \quad \text{if} \;\; k \neq j
\end{cases}
\]</span></p>
<blockquote>
<p>What is the dual basis of the standard basis <span class="math inline">\(e_1, ..., e_n\)</span> of <span class="math inline">\(\mathbb{F}^n\)</span>?</p>
<p>For <span class="math inline">\(1 \leq j \leq n\)</span>, define <span class="math inline">\(\psi_j\)</span> to be the linear functional on <span class="math inline">\(\mathbb{F}^n\)</span> that:</p>
<p><span class="math display">\[\psi_j(x_1, ..., x_n) = x_j, \quad \quad (x_1, ..., x_n) \in \mathbb{F}^n\]</span> Clearly: <span class="math display">\[
\psi_j(e_k)=
\begin{cases}
1, \quad \text{if} \;\; k = j\\
0, \quad \text{if} \;\; k \neq j
\end{cases}
\]</span></p>
</blockquote>
<h4 id="theorem-3.98-dual-basis-is-a-basis-of-the-dual-space">Theorem 3.98: Dual Basis is a Basis of the Dual Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then the dual basis of a basis of <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V^{\prime}\)</span>.</p>
<h5 id="proof-of-theorem-3.98">Proof of Theorem 3.98</h5>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, let <span class="math inline">\(\psi_1, ..., \psi_n\)</span> be dual basis. Then, for all <span class="math inline">\(v_j \in (v_1, ..., v_n)\)</span>:</p>
<p><span class="math display">\[a_1 \psi_n + ... + a_n \psi_n = 0 \implies (a_1 \psi_n + ... + a_n \psi_n) (v_j) = a_j = 0\]</span></p>
<p>Thus, all <span class="math inline">\(a_j = 0\)</span>, the dual basis is independent.</p>
<p>Since <span class="math inline">\(\psi_1, ..., \psi_n\)</span> is independent, by <code>theorem 3.95, 2.39</code>, it is a basis of the dual space.</p>
<h4 id="definition-3.99-dual-map-tprime">Definition 3.99: Dual Map, <span class="math inline">\(T^{\prime}\)</span></h4>
<p>If <span class="math inline">\(T \in L(V, W)\)</span>, then the <strong>dual map</strong> of <span class="math inline">\(T\)</span> is the linear map <span class="math inline">\(T^{\prime} \in L(W^{\prime}, V^{\prime})\)</span> defined by <span class="math inline">\(T^{\prime} (\psi) = \psi \circ T\)</span> for <span class="math inline">\(\psi \in W^{\prime}\)</span>. so:</p>
<p><span class="math display">\[T^{\prime} (\psi): V \rightarrow \mathbb{F}\]</span></p>
<h4 id="theorem-3.101-algebraic-properties-of-dual-maps">Theorem 3.101: Algebraic Properties of Dual Maps</h4>
<ol type="1">
<li><span class="math inline">\((S+T)^{\prime} = S^{\prime} + T^{\prime}\)</span></li>
<li><span class="math inline">\((\lambda T)^{\prime} = \lambda T^{\prime}\)</span> for all <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and all <span class="math inline">\(T \in L(V, W)\)</span></li>
<li><span class="math inline">\((ST)^{\prime} = T^{\prime}S^{\prime}\)</span> for all <span class="math inline">\(T \in L(U, V)\)</span> and all <span class="math inline">\(S \in L(V, W)\)</span></li>
</ol>
<h5 id="proof-of-theorem-3.101">Proof of Theorem 3.101</h5>
<ol type="1">
<li><span class="math inline">\((S + T)^{\prime} (\psi) = \psi \circ (S + T) = \psi \circ S + \psi \circ T = S^{\prime} + T^{\prime}\)</span></li>
<li><span class="math inline">\((\lambda T)^{\prime} (\psi)= \lambda \psi \circ T = \lambda T^{\prime}\)</span></li>
<li><span class="math inline">\((ST)^\prime (\psi) = \psi \circ (ST) = (\psi \circ S) \circ T = T^{\prime} (\psi \circ S) = T^{\prime} (S^{\prime} (\psi)) = T^{\prime} S^{\prime}\)</span> by <code>definition 3.8</code></li>
</ol>
<h4 id="definition-3.102-annihilator-u0">Definition 3.102: Annihilator, <span class="math inline">\(U^0\)</span></h4>
<p>For <span class="math inline">\(U \subseteq V\)</span>, the <strong>annihilator</strong> of <span class="math inline">\(U\)</span>, denoted <span class="math inline">\(U^0\)</span> is defined by:</p>
<p><span class="math display">\[U^0 = \{\psi \in V^{\prime}: \psi (u) = 0, \; \forall u \in U\}\]</span></p>
<h4 id="theorem-3.105-the-annihilator-is-a-subspace">Theorem 3.105: The Annihilator is a Subspace</h4>
<p>Suppose <span class="math inline">\(U \subseteq V\)</span>. Then <span class="math inline">\(U^0\)</span> is a subspace of <span class="math inline">\(V^\prime\)</span>. Where <span class="math inline">\(0 \in U^0\)</span> the is <span class="math inline">\(0\)</span> linear functional that maps every <span class="math inline">\(v \in V\)</span> to <span class="math inline">\(0 \in \mathbb{F}\)</span>.</p>
<h4 id="theorem-3.106-dimension-of-the-annihilator">Theorem 3.106: Dimension of the Annihilator</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\dim U + \dim U^0 = \dim V\]</span></p>
<h4 id="theorem-3.107-the-null-space-of-tprime">Theorem 3.107: The Null Space of <span class="math inline">\(T^{\prime}\)</span></h4>
<ol type="1">
<li>null <span class="math inline">\(T^\prime\)</span> = <span class="math inline">\((\text{range } T)^0\)</span></li>
<li><span class="math inline">\(\dim \text{null }T^{\prime} = \dim \text{null }T + \dim W - \dim V\)</span></li>
</ol>
<h4 id="theorem-3.108-t-surjective-is-equivalent-to-tprime-injective">Theorem 3.108: <span class="math inline">\(T\)</span> Surjective is Equivalent to <span class="math inline">\(T^{\prime}\)</span> Injective</h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(T\)</span> is surjective iff <span class="math inline">\(T^{\prime}\)</span> is injective.</p>
<h4 id="theorem-3.109-the-range-of-tprime">Theorem 3.109: The Range of <span class="math inline">\(T^{\prime}\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(\dim \text{range }T^{\prime} = \dim \text{range } T\)</span></li>
<li><span class="math inline">\(\text{range }T^{\prime} = (\text{null } T)^0\)</span></li>
</ol>
<h4 id="theorem-3.110-t-injective-is-equivalent-to-tprime-surjective">Theorem 3.110: <span class="math inline">\(T\)</span> injective is equivalent to <span class="math inline">\(T^{\prime}\)</span> Surjective</h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(T\)</span> is injective if and only if <span class="math inline">\(T^{\prime}\)</span> is surjective.</p>
<h3 id="matrix-of-the-dual-of-a-linear-map">Matrix of the Dual of a Linear Map</h3>
<h4 id="definition-3.111-transpose-at">Definition 3.111: Transpose, <span class="math inline">\(A^T\)</span></h4>
<p>The <strong>transpose</strong> of a matrix <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(A^T\)</span>, is the matrix obtained from <span class="math inline">\(A\)</span> by interchanging the rows and columns. More specifically, if <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix, then <span class="math inline">\(A^T\)</span> is a <span class="math inline">\(n \times m\)</span> matrix whose entries are given by:</p>
<p><span class="math display">\[(A^T)_{k, j} = A_{j, k}\]</span></p>
<h4 id="theorem-3.113">Theorem 3.113:</h4>
<p>If <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n \times p\)</span> matrix:</p>
<p><span class="math display">\[(AC)^T = C^TA^T\]</span> <span class="math display">\[(A + C)^T = A^T + C^T\]</span> <span class="math display">\[(\lambda A)^T = \lambda A^T\]</span></p>
<h4 id="theorem-3.114-the-matrix-of-tprime-is-the-transpose-of-the-matrix-of-t">Theorem 3.114: The Matrix of <span class="math inline">\(T^{\prime}\)</span> is the Transpose of the Matrix of <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>, then <span class="math inline">\(M(T^{\prime}) = (M(T))^T\)</span></p>
<h4 id="definition-3.115-row-rank-column-rank">Definition 3.115: Row Rank, Column Rank</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix with entries in <span class="math inline">\(\mathbb{F}\)</span>.</p>
<ul>
<li>The <strong>row rank</strong> of <span class="math inline">\(A\)</span> is the dimension of the span of the rows of <span class="math inline">\(A\)</span> in <span class="math inline">\(\mathbb{F}^{1, n}\)</span>.</li>
<li>The <strong>column rank</strong> of <span class="math inline">\(A\)</span> is the dimension of the span of the columns of <span class="math inline">\(A\)</span> in <span class="math inline">\(\mathbb{F}^{m , 1}\)</span></li>
</ul>
<h4 id="theorem-3.117-dimension-of-range-t-equals-column-rank-of-mt">Theorem 3.117: Dimension of range <span class="math inline">\(T\)</span> Equals Column Rank of <span class="math inline">\(M(T)\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(\dim \text{range } T\)</span> equals the column rank of <span class="math inline">\(M(T)\)</span>.</p>
<h5 id="proof-of-theorem-3.117">Proof of Theorem 3.117:</h5>
<p>Assume <span class="math inline">\(v_1, ..., v_n, w_1, ..., w_m\)</span> are basis of <span class="math inline">\(V, W\)</span> respectively. Since <span class="math inline">\(M\)</span> is an isomorphism from <span class="math inline">\(W \rightarrow \mathbb{F}^{m \times 1}\)</span> (<code>def 3.62</code>), we have <span class="math inline">\(M: \text{span }(Tv_1, ..., Tv_n) \rightarrow \text{range } M\)</span> isomorphic. Then:</p>
<p><span class="math display">\[M(a_1 Tv_1 + ... + a_n Tv_n) = a_1 M (Tv_1) + .... + a_n M(Tv_n) \implies \text{span }(M(Tv_1), ..., M(Tv_n)) = \text{range } M\]</span></p>
<p>Thus, <span class="math inline">\(M: \text{span }(Tv_1, ..., Tv_n) \rightarrow \text{span }(M(Tv_1), ..., M(Tv_n))\)</span> isomorphic and by <code>corollary 3.59</code>, we have:</p>
<p><span class="math display">\[\dim \text{span }(Tv_1, ..., Tv_n) = \dim \text{span }(M(Tv_1), ..., M(Tv_n))\]</span></p>
<p>in other words, we have:</p>
<p><span class="math display">\[\dim \text{range } T  = \text{span } (\text{columns of $A$}) = \text{The column rank of $M(T)$}\]</span></p>
<h4 id="theorem-3.118-row-rank-equals-column-rank">Theorem 3.118: Row Rank Equals Column Rank</h4>
<p>Suppose <span class="math inline">\(A \in \mathbb{F^{m, n}}\)</span>. Then the row rank of <span class="math inline">\(A\)</span> equals the column rank of <span class="math inline">\(A\)</span>.</p>
<h5 id="definition-3.119-rank">Definition 3.119: Rank</h5>
<p>The <strong>rank</strong> of a matrix <span class="math inline">\(A \in \mathbb{F}^{m, n}\)</span> is the column rank of <span class="math inline">\(A\)</span>.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode(4)</title>
    <url>/2021/07/13/leet-code-4/</url>
    <content><![CDATA[<p><strong>题目库: <code>[94, 144, 145, 226, 110,   105, 107, 543, 113, 116, 129, 108, 617, 404, 222, 'jz40', 912, 1046, 451, 703, 206, 2 , 21, 19, 692, 24, 83, 82, 876, 328, 143, 86, 61, 92, 160]</code></strong></p>
<h1 id="trees">Trees</h1>
<h2 id="easy">94 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        out = []</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inorder</span>(<span class="params">root</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line">            inorder(root.left)</span><br><span class="line">            out.append(root.val)</span><br><span class="line">            inorder(root.right)</span><br><span class="line">        </span><br><span class="line">        inorder(root)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-1">144 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        out = []</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">preorder</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            out.append(node.val)</span><br><span class="line">            preorder(node.left)</span><br><span class="line">            preorder(node.right)</span><br><span class="line">        </span><br><span class="line">        preorder(root)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="easy-2">145 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        out = []</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">postorder</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            postorder(node.left)</span><br><span class="line">            postorder(node.right)</span><br><span class="line">            out.append(node.val)</span><br><span class="line">        </span><br><span class="line">        postorder(root)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-3">226 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; TreeNode:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">invert</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            node.left, node.right = node.right, node.left</span><br><span class="line">            invert(node.left)</span><br><span class="line">            invert(node.right)</span><br><span class="line">        </span><br><span class="line">        invert(root)</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<h2 id="easy-4">110 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBalanced</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">height</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span> [<span class="number">0</span>, <span class="literal">True</span>]</span><br><span class="line">            </span><br><span class="line">            left_height = height(node.left)</span><br><span class="line">            right_height = height(node.right)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left_height[<span class="number">1</span>] <span class="keyword">or</span> <span class="keyword">not</span> right_height[<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> [<span class="number">0</span>, <span class="literal">False</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (left_height[<span class="number">0</span>] - right_height[<span class="number">0</span>]) &gt; <span class="number">1</span> <span class="keyword">or</span> (left_height[<span class="number">0</span>] - right_height[<span class="number">0</span>]) &lt; -<span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> [<span class="number">0</span>, <span class="literal">False</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> [<span class="built_in">max</span>(right_height[<span class="number">0</span>], left_height[<span class="number">0</span>]) + <span class="number">1</span>, <span class="literal">True</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> height(root)[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium">105 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildTree</span>(<span class="params">self, preorder: <span class="type">List</span>[<span class="built_in">int</span>], inorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">myBuildTree</span>(<span class="params">preorder_left: <span class="built_in">int</span>, preorder_right: <span class="built_in">int</span>, inorder_left: <span class="built_in">int</span>, inorder_right: <span class="built_in">int</span></span>):</span></span><br><span class="line">            <span class="keyword">if</span> preorder_left &gt; preorder_right:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 前序遍历中的第一个节点就是根节点</span></span><br><span class="line">            preorder_root = preorder_left</span><br><span class="line">            <span class="comment"># 在中序遍历中定位根节点</span></span><br><span class="line">            inorder_root = index[preorder[preorder_root]]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 先把根节点建立出来</span></span><br><span class="line">            root = TreeNode(preorder[preorder_root])</span><br><span class="line">            <span class="comment"># 得到左子树中的节点数目</span></span><br><span class="line">            size_left_subtree = inorder_root - inorder_left</span><br><span class="line">            <span class="comment"># 递归地构造左子树，并连接到根节点</span></span><br><span class="line">            <span class="comment"># 先序遍历中「从 左边界+1 开始的 size_left_subtree」个元素就对应了中序遍历中「从 左边界 开始到 根节点定位-1」的元素</span></span><br><span class="line">            root.left = myBuildTree(preorder_left + <span class="number">1</span>, preorder_left + size_left_subtree, inorder_left, inorder_root - <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 递归地构造右子树，并连接到根节点</span></span><br><span class="line">            <span class="comment"># 先序遍历中「从 左边界+1+左子树节点数目 开始到 右边界」的元素就对应了中序遍历中「从 根节点定位+1 到 右边界」的元素</span></span><br><span class="line">            root.right = myBuildTree(preorder_left + size_left_subtree + <span class="number">1</span>, preorder_right, inorder_root + <span class="number">1</span>, inorder_right)</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        </span><br><span class="line">        n = <span class="built_in">len</span>(preorder)</span><br><span class="line">        <span class="comment"># 构造哈希映射，帮助我们快速定位根节点</span></span><br><span class="line">        index = &#123;element: i <span class="keyword">for</span> i, element <span class="keyword">in</span> <span class="built_in">enumerate</span>(inorder)&#125;</span><br><span class="line">        <span class="keyword">return</span> myBuildTree(<span class="number">0</span>, n - <span class="number">1</span>, <span class="number">0</span>, n - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="medium-1">107 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrderBottom</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        q = [root]</span><br><span class="line">        out = [[root.val]]</span><br><span class="line">        next_level = []</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            curr_node = q.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> curr_node.left:</span><br><span class="line">                next_level.append(curr_node.left)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> curr_node.right:</span><br><span class="line">                next_level.append(curr_node.right)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> q:</span><br><span class="line">                <span class="keyword">if</span> next_level:</span><br><span class="line">                    temp = []</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(next_level)):</span><br><span class="line">                        temp.append(next_level[i].val)</span><br><span class="line">                    out.insert(<span class="number">0</span>, temp)</span><br><span class="line"></span><br><span class="line">                q = next_level</span><br><span class="line">                next_level = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-5">543 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">diameterOfBinaryTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">diameter</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span> [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            left_depth = diameter(node.left)</span><br><span class="line">            right_depth = diameter(node.right)</span><br><span class="line"></span><br><span class="line">            total_diameter = left_depth[<span class="number">0</span>] + right_depth[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> [<span class="built_in">max</span>(left_depth[<span class="number">0</span>], right_depth[<span class="number">0</span>]) + <span class="number">1</span>, <span class="built_in">max</span>(left_depth[<span class="number">1</span>], right_depth[<span class="number">1</span>], total_diameter)]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> diameter(root)[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="medium-2">113 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">self, root: TreeNode, targetSum: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        paths = []</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_path</span>(<span class="params">node, path, path_sum</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right <span class="keyword">and</span> (node.val + path_sum) == targetSum:</span><br><span class="line">                paths.append(path + [node.val])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            find_path(node.left, path + [node.val], path_sum + node.val)</span><br><span class="line">            find_path(node.right, path + [node.val], path_sum + node.val)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        find_path(root, [], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> paths</span><br></pre></td></tr></table></figure>
<h2 id="medium-3">116 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node:</span></span><br><span class="line"><span class="string">    def __init__(self, val: int = 0, left: &#x27;Node&#x27; = None, right: &#x27;Node&#x27; = None, next: &#x27;Node&#x27; = None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.left = left</span></span><br><span class="line"><span class="string">        self.right = right</span></span><br><span class="line"><span class="string">        self.next = next</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self, root: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; &#x27;Node&#x27;:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line">        q = [root]</span><br><span class="line">        curr_level = []</span><br><span class="line">        <span class="keyword">while</span> q:     </span><br><span class="line">            curr_node = q.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> curr_node.left:</span><br><span class="line">                curr_level.append(curr_node.left)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> curr_node.right:</span><br><span class="line">                curr_level.append(curr_node.right)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> q:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(curr_level) - <span class="number">1</span>):</span><br><span class="line">                    curr_level[i].<span class="built_in">next</span> = curr_level[i + <span class="number">1</span>]</span><br><span class="line">                </span><br><span class="line">                q = curr_level</span><br><span class="line">                curr_level = []</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<h2 id="medium-4">129 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumNumbers</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        out = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_sums</span>(<span class="params">node, num</span>):</span></span><br><span class="line">            <span class="keyword">nonlocal</span> out</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">                out += <span class="built_in">int</span>(num + <span class="built_in">str</span>(node.val))</span><br><span class="line">            </span><br><span class="line">            find_sums(node.left, num + <span class="built_in">str</span>(node.val))</span><br><span class="line">            find_sums(node.right, num + <span class="built_in">str</span>(node.val))</span><br><span class="line">        </span><br><span class="line">        find_sums(root, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-6">108 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortedArrayToBST</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">build_tree</span>(<span class="params">subset</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> subset:</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            l, r = <span class="number">0</span>, <span class="built_in">len</span>(subset) - <span class="number">1</span></span><br><span class="line">            mid = l + (l + r) // <span class="number">2</span></span><br><span class="line">            curr_node = TreeNode(val=subset[mid], left=build_tree(subset[:mid]), right=build_tree(subset[mid+<span class="number">1</span>:]))</span><br><span class="line">            <span class="keyword">return</span> curr_node</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> build_tree(nums)</span><br></pre></td></tr></table></figure>
<h2 id="easy-7">617 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mergeTrees</span>(<span class="params">self, root1: TreeNode, root2: TreeNode</span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root1 <span class="keyword">or</span> <span class="keyword">not</span> root2:</span><br><span class="line">            <span class="keyword">return</span> root1 <span class="keyword">if</span> <span class="keyword">not</span> root2 <span class="keyword">else</span> root2</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">node_1, node_2</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node_1:</span><br><span class="line">                <span class="keyword">return</span> node_2</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node_2:</span><br><span class="line">                <span class="keyword">return</span> node_1</span><br><span class="line">            </span><br><span class="line">            node_1.val = node_1.val + node_2.val</span><br><span class="line">            node_1.left = merge(node_1.left, node_2.left)</span><br><span class="line">            node_1.right = merge(node_1.right, node_2.right)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> node_1</span><br><span class="line">        </span><br><span class="line">        merge(root1, root2)</span><br><span class="line">        <span class="keyword">return</span> root1</span><br></pre></td></tr></table></figure>
<h2 id="easy-8">404 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumOfLeftLeaves</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        left_sum = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_sum</span>(<span class="params">node, left</span>):</span></span><br><span class="line">            <span class="keyword">nonlocal</span> left_sum</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> left <span class="keyword">and</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">                left_sum += node.val</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            find_sum(node.left, left=<span class="literal">True</span>)</span><br><span class="line">            find_sum(node.right, left=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        find_sum(root, <span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> left_sum</span><br></pre></td></tr></table></figure>
<h2 id="medium-5">222 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 1.dfs</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.dfs(root, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, k</span>):</span></span><br><span class="line">        <span class="keyword">if</span> root==<span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> root.left==<span class="literal">None</span> <span class="keyword">and</span> root.right==<span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> k</span><br><span class="line">        </span><br><span class="line">        max1 = self.dfs(root.left, <span class="number">2</span>*k)</span><br><span class="line">        max2 = self.dfs(root.right, <span class="number">2</span>*k+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(max1, max2)</span><br></pre></td></tr></table></figure>
<h1 id="heap">Heap</h1>
<h2 id="剑指-offer-40-easy">剑指 Offer 40 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getLeastNumbers</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">import</span> heapq</span><br><span class="line">        heapq.heapify(arr)</span><br><span class="line">        out_lst = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            out_lst.append(heapq.heappop(arr))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out_lst</span><br></pre></td></tr></table></figure>
<h2 id="medium-6">912 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">import</span> heapq</span><br><span class="line">        heapq.heapify(nums)</span><br><span class="line">        sorted_lst = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            sorted_lst.append(heapq.heappop(nums))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> sorted_lst</span><br></pre></td></tr></table></figure>
<h2 id="easy-9">1046 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lastStoneWeight</span>(<span class="params">self, stones: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">import</span> heapq</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(stones)):</span><br><span class="line">            stones[i] = -stones[i]</span><br><span class="line">        </span><br><span class="line">        heapq.heapify(stones)</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(stones) &gt; <span class="number">1</span>:</span><br><span class="line">            biggest = heapq.heappop(stones)</span><br><span class="line">            s_biggest = heapq.heappop(stones)</span><br><span class="line">            diff = biggest - s_biggest</span><br><span class="line">            <span class="keyword">if</span> diff:</span><br><span class="line">                heapq.heappush(stones, diff)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> stones:</span><br><span class="line">            <span class="keyword">return</span> -stones[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-7">451 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">frequencySort</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        count_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> count_dict.keys():</span><br><span class="line">                count_dict[i] = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                count_dict[i] -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        temp_lst = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            temp_lst.append((count_dict[i], i))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">import</span> heapq</span><br><span class="line">        heapq.heapify(temp_lst)</span><br><span class="line">        out_str = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            out_str += heapq.heappop(temp_lst)[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out_str</span><br></pre></td></tr></table></figure>
<h2 id="medium-8">692 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">topKFrequent</span>(<span class="params">self, words: <span class="type">List</span>[<span class="built_in">str</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span></span><br><span class="line">        <span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">        <span class="keyword">from</span> functools <span class="keyword">import</span> cmp_to_key</span><br><span class="line">        counter = Counter(words)</span><br><span class="line">        words = [(v, k) <span class="keyword">for</span> k, v <span class="keyword">in</span> counter.items()]</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">key_sort</span>(<span class="params">x, y</span>):</span></span><br><span class="line">            <span class="keyword">if</span> x[<span class="number">0</span>] == y[<span class="number">0</span>]:</span><br><span class="line">                l_x = <span class="built_in">len</span>(x[<span class="number">1</span>])</span><br><span class="line">                l_y = <span class="built_in">len</span>(y[<span class="number">1</span>])</span><br><span class="line">                i = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> i &lt; <span class="built_in">min</span>(l_x, l_y):</span><br><span class="line">                    <span class="keyword">if</span> x[<span class="number">1</span>][i] &lt; y[<span class="number">1</span>][i]:</span><br><span class="line">                        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> x[<span class="number">1</span>][i] &gt; y[<span class="number">1</span>][i]:</span><br><span class="line">                        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> l_x &lt; l_y:</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">elif</span> x[<span class="number">0</span>] &gt; y[<span class="number">0</span>]:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        words.sort(key=cmp_to_key(key_sort), reverse=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            words[i] = words[i][-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> words[:k]</span><br></pre></td></tr></table></figure>
<h2 id="easy-10">703 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KthLargest</span>:</span></span><br><span class="line">    <span class="keyword">import</span> heapq</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k: <span class="built_in">int</span>, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span></span><br><span class="line">        heapq.heapify(nums)</span><br><span class="line">        self.k = k</span><br><span class="line">        self.nums = nums</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(self.nums) &gt; k:</span><br><span class="line">            heapq.heappop(self.nums)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.nums) &lt; self.k:</span><br><span class="line">            heapq.heappush(self.nums, val)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> val &gt; self.nums[<span class="number">0</span>]:</span><br><span class="line">            heapq.heappop(self.nums)</span><br><span class="line">            heapq.heappush(self.nums, val)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.nums[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Your KthLargest object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = KthLargest(k, nums)</span></span><br><span class="line"><span class="comment"># param_1 = obj.add(val)</span></span><br></pre></td></tr></table></figure>
<h1 id="linkedlist">LinkedList</h1>
<h2 id="easy-11">206 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseList</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">reverse</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.<span class="built_in">next</span>:</span><br><span class="line">                <span class="keyword">return</span> node</span><br><span class="line">            </span><br><span class="line">            next_node = reverse(node.<span class="built_in">next</span>)</span><br><span class="line">            next_node.<span class="built_in">next</span> = node</span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            last_node = head</span><br><span class="line">            <span class="keyword">while</span> last_node.<span class="built_in">next</span>:</span><br><span class="line">                last_node = last_node.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            reverse(head)</span><br><span class="line">            head.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">return</span> last_node</span><br></pre></td></tr></table></figure>
<h2 id="medium-9">2 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addTwoNumbers</span>(<span class="params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        l1_num = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        l2_num = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> l1:</span><br><span class="line">            l1_num += <span class="built_in">str</span>(l1.val)</span><br><span class="line">            l1 = l1.<span class="built_in">next</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> l2:</span><br><span class="line">            l2_num += <span class="built_in">str</span>(l2.val)</span><br><span class="line">            l2 = l2.<span class="built_in">next</span></span><br><span class="line">        </span><br><span class="line">        result_num = <span class="built_in">str</span>(<span class="built_in">int</span>(l1_num[::-<span class="number">1</span>]) + <span class="built_in">int</span>(l2_num[::-<span class="number">1</span>]))</span><br><span class="line">        new_head = ListNode(val=<span class="built_in">int</span>(result_num[-<span class="number">1</span>]))</span><br><span class="line">        curr_head = new_head</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result_num) - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            curr_node = ListNode(val=<span class="built_in">int</span>(result_num[i]))</span><br><span class="line">            curr_head.<span class="built_in">next</span> = curr_node</span><br><span class="line">            curr_head = curr_node</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> new_head</span><br></pre></td></tr></table></figure>
<h2 id="easy-12">21 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mergeTwoLists</span>(<span class="params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l1:</span><br><span class="line">            <span class="keyword">return</span> l2</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l2:</span><br><span class="line">            <span class="keyword">return</span> l1</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> l1.val &lt; l2.val:</span><br><span class="line">            out_head = l1</span><br><span class="line">            l1 = l1.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            out_head = l2</span><br><span class="line">            l2 = l2.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        temp_head = out_head</span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">and</span> l2:</span><br><span class="line">            <span class="keyword">if</span> l1.val &lt; l2.val:</span><br><span class="line">                temp_head.<span class="built_in">next</span> = l1</span><br><span class="line">                l1 = l1.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp_head.<span class="built_in">next</span> = l2</span><br><span class="line">                l2 = l2.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            temp_head = temp_head.<span class="built_in">next</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l1:</span><br><span class="line">            temp_head.<span class="built_in">next</span> = l2</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l2:</span><br><span class="line">            temp_head.<span class="built_in">next</span> = l1</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out_head</span><br></pre></td></tr></table></figure>
<h2 id="medium-10">19 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeNthFromEnd</span>(<span class="params">self, head: ListNode, n: <span class="built_in">int</span></span>) -&gt; ListNode:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">remove</span>(<span class="params">node</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            curr_level = remove(node.<span class="built_in">next</span>) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> curr_level == (n + <span class="number">1</span>):</span><br><span class="line">                node.<span class="built_in">next</span> = node.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> curr_level</span><br><span class="line"></span><br><span class="line">        curr_level = remove(head)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> curr_level == n:</span><br><span class="line">            <span class="keyword">return</span> head.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<h2 id="medium-11">24 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">swapPairs</span>(<span class="params">self, head</span>):</span></span><br><span class="line">		<span class="comment"># 递归的终止条件</span></span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">not</span> (head <span class="keyword">and</span> head.<span class="built_in">next</span>):</span><br><span class="line">			<span class="keyword">return</span> head</span><br><span class="line">		<span class="comment"># 假设链表是 1-&gt;2-&gt;3-&gt;4</span></span><br><span class="line">		<span class="comment"># 这句就先保存节点2</span></span><br><span class="line">		tmp = head.<span class="built_in">next</span></span><br><span class="line">		<span class="comment"># 继续递归，处理节点3-&gt;4</span></span><br><span class="line">		<span class="comment"># 当递归结束返回后，就变成了4-&gt;3</span></span><br><span class="line">		<span class="comment"># 于是head节点就指向了4，变成1-&gt;4-&gt;3</span></span><br><span class="line">		head.<span class="built_in">next</span> = self.swapPairs(tmp.<span class="built_in">next</span>)</span><br><span class="line">		<span class="comment"># 将2节点指向1</span></span><br><span class="line">		tmp.<span class="built_in">next</span> = head</span><br><span class="line">		<span class="keyword">return</span> tmp</span><br></pre></td></tr></table></figure>
<h2 id="easy-13">83 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">del_dup</span>(<span class="params">head</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">                <span class="keyword">return</span> head, []</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> head.<span class="built_in">next</span>:</span><br><span class="line">                <span class="keyword">return</span> head, [head.val]</span><br><span class="line">            </span><br><span class="line">            curr_node, val_lst = del_dup(head.<span class="built_in">next</span>)</span><br><span class="line">            <span class="keyword">if</span> head.val <span class="keyword">in</span> val_lst:</span><br><span class="line">                <span class="keyword">return</span> curr_node, val_lst</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                head.<span class="built_in">next</span> = curr_node</span><br><span class="line">                <span class="keyword">return</span> head, val_lst + [head.val]</span><br><span class="line">        </span><br><span class="line">        out, _ = del_dup(head)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="medium-12">82 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">del_dup</span>(<span class="params">head</span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> head <span class="keyword">or</span> <span class="keyword">not</span> head.<span class="built_in">next</span>:</span><br><span class="line">                <span class="keyword">return</span> head</span><br><span class="line">            </span><br><span class="line">            next_node = del_dup(head.<span class="built_in">next</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> next_node:</span><br><span class="line">                <span class="keyword">if</span> head.val == head.<span class="built_in">next</span>.val:</span><br><span class="line">                    <span class="keyword">return</span> next_node</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    head.<span class="built_in">next</span> = next_node</span><br><span class="line">                    <span class="keyword">return</span> head</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> head.val == next_node.val:</span><br><span class="line">                <span class="keyword">return</span> next_node.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">elif</span> head.val == head.<span class="built_in">next</span>.val:</span><br><span class="line">                <span class="keyword">return</span> next_node</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                head.<span class="built_in">next</span> = next_node</span><br><span class="line">                <span class="keyword">return</span> head</span><br><span class="line"></span><br><span class="line">        out = del_dup(head)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="easy-14">876 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">middleNode</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_mid</span>(<span class="params">head, curr_count=<span class="number">1</span></span>):</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> head.<span class="built_in">next</span>:</span><br><span class="line">                <span class="keyword">return</span> head, curr_count // <span class="number">2</span> + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            node, count = find_mid(head.<span class="built_in">next</span>, curr_count + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> count == curr_count:</span><br><span class="line">                <span class="keyword">return</span> head, count</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> node, count</span><br><span class="line">        </span><br><span class="line">        out, count = find_mid(head)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="medium-13">328 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">oddEvenList</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        i = <span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head <span class="keyword">or</span> <span class="keyword">not</span> head.<span class="built_in">next</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line"></span><br><span class="line">        double_head, double_curr = head.<span class="built_in">next</span>, head.<span class="built_in">next</span></span><br><span class="line">        single_head = head</span><br><span class="line">        curr_node = head.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">while</span> curr_node:</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                double_curr.<span class="built_in">next</span> = curr_node</span><br><span class="line">                double_curr = double_curr.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                single_head.<span class="built_in">next</span> = curr_node</span><br><span class="line">                single_head = single_head.<span class="built_in">next</span></span><br><span class="line">            </span><br><span class="line">            curr_node = curr_node.<span class="built_in">next</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        double_curr.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        single_head.<span class="built_in">next</span> = double_head</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<h2 id="medium-14">143 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reorderList</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify head in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        slow, fast = head, head</span><br><span class="line">        <span class="keyword">while</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line">            slow = slow.<span class="built_in">next</span></span><br><span class="line">            fast = fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        stack = []</span><br><span class="line">        second_lst = slow.<span class="built_in">next</span></span><br><span class="line">        slow.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> second_lst:</span><br><span class="line">            stack.append(second_lst)</span><br><span class="line">            second_lst = second_lst.<span class="built_in">next</span>        </span><br><span class="line"></span><br><span class="line">        temp = head</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            curr_node = stack.pop()</span><br><span class="line">            temp.<span class="built_in">next</span>, curr_node.<span class="built_in">next</span> = curr_node, temp.<span class="built_in">next</span></span><br><span class="line">            temp = curr_node.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-15">86 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">self, head: ListNode, x: <span class="built_in">int</span></span>) -&gt; ListNode:</span></span><br><span class="line">        small_head = ListNode()</span><br><span class="line">        large_head = ListNode()</span><br><span class="line">        curr_node, curr_small, curr_large = head, small_head, large_head</span><br><span class="line">        <span class="keyword">while</span> curr_node:</span><br><span class="line">            <span class="keyword">if</span> curr_node.val &lt; x:</span><br><span class="line">                curr_small.<span class="built_in">next</span> = curr_node</span><br><span class="line">                curr_small = curr_small.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                curr_large.<span class="built_in">next</span> = curr_node</span><br><span class="line">                curr_large = curr_large.<span class="built_in">next</span></span><br><span class="line">            </span><br><span class="line">            curr_node = curr_node.<span class="built_in">next</span></span><br><span class="line">            </span><br><span class="line">        curr_small.<span class="built_in">next</span> = large_head.<span class="built_in">next</span></span><br><span class="line">        curr_large.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> small_head.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h2 id="medium-16">61 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotateRight</span>(<span class="params">self, head: ListNode, k: <span class="built_in">int</span></span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span> <span class="keyword">or</span> <span class="keyword">not</span> head <span class="keyword">or</span> <span class="keyword">not</span> head.<span class="built_in">next</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        </span><br><span class="line">        n = <span class="number">1</span></span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> cur.<span class="built_in">next</span>:</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">            n += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (add := n - k % n) == n:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        </span><br><span class="line">        cur.<span class="built_in">next</span> = head</span><br><span class="line">        <span class="keyword">while</span> add:</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">            add -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        ret = cur.<span class="built_in">next</span></span><br><span class="line">        cur.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>
<h2 id="medium-17">92 Medium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseBetween</span>(<span class="params">self, head: ListNode, left: <span class="built_in">int</span>, right: <span class="built_in">int</span></span>) -&gt; ListNode:</span></span><br><span class="line">        stack = []</span><br><span class="line">        new_head = ListNode()</span><br><span class="line">        new_head.<span class="built_in">next</span> = head</span><br><span class="line">        curr_node = new_head</span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        left += <span class="number">1</span></span><br><span class="line">        right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> curr_node:</span><br><span class="line">            <span class="keyword">if</span> i + <span class="number">1</span> == left:</span><br><span class="line">                start_node = curr_node</span><br><span class="line">                curr_node = curr_node.<span class="built_in">next</span></span><br><span class="line">                i = i + <span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span> i &lt;= right:</span><br><span class="line">                    stack.append(curr_node)</span><br><span class="line">                    curr_node = curr_node.<span class="built_in">next</span></span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                end_node = curr_node</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">while</span> stack:</span><br><span class="line">                    start_node.<span class="built_in">next</span> = stack.pop()</span><br><span class="line">                    start_node = start_node.<span class="built_in">next</span></span><br><span class="line">                </span><br><span class="line">                start_node.<span class="built_in">next</span> = end_node</span><br><span class="line"></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            curr_node = curr_node.<span class="built_in">next</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        out = new_head.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="easy-15">160 Easy</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIntersectionNode</span>(<span class="params">self, headA: ListNode, headB: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        A, B = headA, headB</span><br><span class="line">        <span class="keyword">while</span> A != B:</span><br><span class="line">            A = A.<span class="built_in">next</span> <span class="keyword">if</span> A <span class="keyword">else</span> headB</span><br><span class="line">            B = B.<span class="built_in">next</span> <span class="keyword">if</span> B <span class="keyword">else</span> headA</span><br><span class="line">        <span class="keyword">return</span> A</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear Algebra (3)</title>
    <url>/2022/01/19/linear-algebra-3/</url>
    <content><![CDATA[<h1 id="linear-algebra-3">Linear Algebra (3)</h1>
<h2 id="polynomials">Polynomials</h2>
<h3 id="complex-conjugate-and-absolute-value">Complex Conjugate and Absolute Value</h3>
<h4 id="definition-4.2-rez-imz">Definition 4.2: <span class="math inline">\(Re(z)\)</span>, <span class="math inline">\(Im(z)\)</span></h4>
<p>Suppose <span class="math inline">\(z = a + b_i\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are real numbers.</p>
<ul>
<li>The <strong>real part</strong> of <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(Re(z)\)</span>, is defined by <span class="math inline">\(Re(z) = a\)</span>.</li>
<li>The <strong>imaginary part</strong> of <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(Im(z)\)</span>, is defined by <span class="math inline">\(Im(z) = b\)</span>.</li>
</ul>
<p>Thus for every complex number <span class="math inline">\(z\)</span>, we have:</p>
<p><span class="math display">\[z = Re(z) + Im(z) i\]</span></p>
<h4 id="definition-4.3-complex-conjugate-barz-absolute-value-z.">Definition 4.3: Complex Conjugate, <span class="math inline">\(\bar{z}\)</span>, absolute value, |z|.</h4>
<p>Suppose <span class="math inline">\(z \in \mathbb{C}\)</span>:</p>
<ul>
<li>The <strong>complex conjugate</strong> of <span class="math inline">\(z \in \mathbb{C}\)</span>, denoted <span class="math inline">\(\bar{z}\)</span>, is defined by: <span class="math display">\[\bar{z} = Re(z) - Im(z)i\]</span></li>
<li>The <strong>absolute value</strong> of a complex number <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(|z|\)</span>, is defined by: <span class="math display">\[|z| = \sqrt{(Re (z))^2 + (Im (z))^2}\]</span></li>
</ul>
<h4 id="theorem-4.5-properties-of-complex-numbers">Theorem 4.5: Properties of Complex Numbers</h4>
<p>Suppose <span class="math inline">\(w, z \in \mathbb{C}\)</span>. Then:</p>
<ul>
<li><strong>Sum of <span class="math inline">\(z\)</span> and <span class="math inline">\(\bar{z}\)</span></strong>: <span class="math display">\[z + \bar{z} = 2 Re(z)\]</span></li>
<li><strong>Difference of <span class="math inline">\(z\)</span> and <span class="math inline">\(\bar{z}\)</span></strong>: <span class="math display">\[z - \bar{z} = 2(Im (z)) i\]</span></li>
<li><strong>Product of <span class="math inline">\(z\)</span> and <span class="math inline">\(\bar{z}\)</span></strong>: <span class="math display">\[z \bar{z} = |z|^2\]</span></li>
<li><strong>Additive and Multiplicative of Complex Conjugate</strong>: <span class="math display">\[\overline{w + z} = \bar{w} + \bar{z}, \quad \overline{wz} = \bar{w}\bar{z}\]</span></li>
<li><strong>Conjugate of Conjugate</strong>: <span class="math display">\[\bar{\bar{z}} = z\]</span></li>
<li><strong>Real and Imaginary Parts are Bounded by <span class="math inline">\(|z|\)</span></strong>: <span class="math display">\[|Re (z)| \leq |z|, \quad |Im(z)| \leq |z|\]</span></li>
<li><strong>Absolute Value of the Complex Conjugate</strong>: <span class="math display">\[|\bar{z}| = |z|\]</span></li>
<li><strong>Multiplicative of Absolute Value</strong> <span class="math display">\[|wz| = |w||z|\]</span></li>
<li><strong>Triangle Inequality</strong>: <span class="math display">\[|w + z| \leq |w| + |z|\]</span></li>
</ul>
<span id="more"></span>
<h3 id="uniqueness-of-coefficients-for-polynomials">Uniqueness of Coefficients for Polynomials</h3>
<p>A function <span class="math inline">\(p: \mathbb{F} \rightarrow \mathbb{F}\)</span> is called a polynomial with coefficients in <span class="math inline">\(\mathbb{F}\)</span> if there exists <span class="math inline">\(a_0 , ..., a_m \in \mathbb{F}\)</span> s.t:</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + .... + a_mz^m\]</span></p>
<p>for all <span class="math inline">\(z \in \mathbb{F}\)</span></p>
<h4 id="theorem-4.7-if-a-polynomial-is-the-zero-function-then-all-coefficients-are-0">Theorem 4.7: If a Polynomial is the Zero Function, Then All Coefficients are <span class="math inline">\(0\)</span></h4>
<p>Suppose <span class="math inline">\(a_0, ..., a_m \in \mathbb{F}\)</span>. If</p>
<p><span class="math display">\[a_0 + a_1 z + ... + a_m z^m = 0\]</span></p>
<p>for every <span class="math inline">\(z \in \mathbb{F}\)</span>, then <span class="math inline">\(a_0 = ... = a_m = 0\)</span></p>
<p><strong>This results show that the coefficients of a polynomial are uniquely determined</strong>.</p>
<p>Recall that if a polynomial <span class="math inline">\(p\)</span> with <span class="math inline">\(a_m \neq 0\)</span>, then we say that <span class="math inline">\(p\)</span> has degree <span class="math inline">\(m\)</span>, and we write <span class="math inline">\(\deg p = m\)</span>. The degree of <span class="math inline">\(0\)</span> polynomial is defined to be <span class="math inline">\(-\infty\)</span>.</p>
<h4 id="theorem-4.8-division-algorithm-for-polynomials">Theorem 4.8: Division Algorithm for Polynomials</h4>
<p>Suppose that <span class="math inline">\(p, s \in P(\mathbb{F})\)</span>, with <span class="math inline">\(s \neq 0\)</span>. Then there exist unique polynomials, <span class="math inline">\(q, r \in P(\mathbb{F})\)</span> s.t:</p>
<p><span class="math display">\[p = sq + r\]</span></p>
<p>and <span class="math inline">\(\text{deg } r &lt; \text{deg } s\)</span></p>
<h4 id="definition-4.9-zero-of-a-polynomial">Definition 4.9: Zero of a Polynomial</h4>
<p>A number <span class="math inline">\(\lambda \in \mathbb{F}\)</span> is called a <strong>zero or root</strong> of a polynomial <span class="math inline">\(p \in P(\mathbb{F})\)</span> if:</p>
<p><span class="math display">\[p(\lambda) = 0\]</span></p>
<h4 id="definition-4.10-factor">Definition 4.10: Factor</h4>
<p>A polynomial <span class="math inline">\(s \in P(\mathbb{F})\)</span> is called a <strong>factor</strong> of <span class="math inline">\(p \in P(\mathbb{F})\)</span> if there exists a polynoimal <span class="math inline">\(q \in P(\mathbb{F})\)</span> s.t <span class="math inline">\(p = sq\)</span>.</p>
<h4 id="theorem-4.11-each-zero-of-a-polynomial-corresponds-to-a-degree-1-factor">Theorem 4.11: Each Zero of a Polynomial Corresponds to a Degree-1 Factor</h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{F})\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Then <span class="math inline">\(p(\lambda) = 0\)</span> if and only if there is a polynomial <span class="math inline">\(q \in P(\mathbb{F})\)</span> s.t:</p>
<p><span class="math display">\[p(z) = (z - \lambda) q(z)\]</span></p>
<p>for every <span class="math inline">\(z \in \mathbb{F}\)</span></p>
<h4 id="theorem-4.12-a-polynomial-has-at-most-as-many-zeros-as-its-degree">Theorem 4.12: A Polynomial has at most as many Zeros as Its Degree</h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{F})\)</span> is a polynomial with degree <span class="math inline">\(m \geq 0\)</span>. Then <span class="math inline">\(p\)</span> has at most <span class="math inline">\(m\)</span> distinct zeros in <span class="math inline">\(\mathbb{F}\)</span>.</p>
<h4 id="theorem-4.13-fundamental-theorem-of-algebra">Theorem 4.13: Fundamental Theorem of Algebra</h4>
<p>Every nonconstant polynomial with complex coefficients has a zero.</p>
<h4 id="theorem-4.14-factorization-of-a-polynomial-over-mathbbc">Theorem 4.14: Factorization of a Polynomial over <span class="math inline">\(\mathbb{C}\)</span></h4>
<p>If <span class="math inline">\(p \in P(\mathbb{C})\)</span> is a nonconstant polynomial, then <span class="math inline">\(p\)</span> has a unique factorization except for the order of the factors of the form:</p>
<p><span class="math display">\[p(z) = c(z - \lambda_1) ... (z - \lambda_m)\]</span></p>
<p>where <span class="math inline">\(c, \lambda_1, ..., \lambda_m \in \mathbb{C}\)</span>, <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are the zeros of <span class="math inline">\(p\)</span>.</p>
<p><strong>The failure of the fundamental theorem of algebra for <span class="math inline">\(\mathbb{R}\)</span> accounts for the differences between operators on real and complex vector spaces.</strong></p>
<h4 id="theorem-4.15-polynomials-with-real-coefficients-have-zeros-in-pairs">Theorem 4.15: Polynomials with Real Coefficients Have Zeros in Pairs</h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{C})\)</span> is a polynomial with real coefficients. If <span class="math inline">\(\lambda \in \mathbb{C}\)</span> is a zero of <span class="math inline">\(p\)</span>, then so is <span class="math inline">\(\bar{\lambda}\)</span>.</p>
<h5 id="proof-of-theorem-4.15">Proof of Theorem 4.15</h5>
<p>Let:</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + .... + a_m z^m\]</span></p>
<p>If <span class="math inline">\(\lambda\)</span> is a root of <span class="math inline">\(p\)</span>, we have:</p>
<p><span class="math display">\[p(\lambda) = a_0 + a_1 \lambda_m + .... + a_m \lambda^m = 0\]</span></p>
<p>By taking the conjugate:</p>
<p><span class="math display">\[\overline{a_0 + a_1 \lambda_m + .... + a_m \lambda^m} = a_0 + a_1 \bar{\lambda} + ... + a_m \bar{\lambda}^m = 0\]</span></p>
<h4 id="theorem-4.16-factorization-of-a-quadratic-polynomial">Theorem 4.16: Factorization of a Quadratic Polynomial</h4>
<p>Suppose <span class="math inline">\(b, c \in \mathbb{R}\)</span>. Then there is a polynomial factorization of the form:</p>
<p><span class="math display">\[x^2 + bx + c = (x  - \lambda_1) (x - \lambda_2)\]</span></p>
<p>with <span class="math inline">\(\lambda_1, \lambda_2 \in \mathbb{R}\)</span> if and only if <span class="math inline">\(b^2 \geq 4c\)</span></p>
<h4 id="theorem-4.17-factorization-of-a-polynomial-over-mathbbr">Theorem 4.17: Factorization of a Polynomial over <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{R})\)</span> is a nonconstant polynomial. Then <span class="math inline">\(p\)</span> has a unique factorization of the form:</p>
<p><span class="math display">\[p(x) = c(x - \lambda_1) ... (x - \lambda_m) (x^2 + b_1 x + c_1 ) ... (x^2 + b_M x + c_M)\]</span></p>
<p>where <span class="math inline">\(c, \lambda_1, ..., \lambda_m, b_1, ..., b_M, c_1, ..., c_M \in \mathbb{R}\)</span>, with <span class="math inline">\(b_j^2 &lt; 4c_j\)</span> for each <span class="math inline">\(j\)</span>.</p>
<p><br></p>
<h2 id="eigenvalues-eigenvectors-and-invariant-subspaces">Eigenvalues, Eigenvectors, and Invariant Subspaces</h2>
<h3 id="invariant-subspaces">Invariant Subspaces</h3>
<p>Let <span class="math inline">\(T \in L(V)\)</span>, <span class="math inline">\(U \subseteq V\)</span> be a proper subspace, then <span class="math inline">\(T|_U\)</span> denotes the domain of <span class="math inline">\(T\)</span> restrict to the set <span class="math inline">\(U\)</span>.</p>
<h4 id="definition-5.2-invariant-subspace">Definition 5.2: Invariant Subspace</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is an operator on <span class="math inline">\(V\)</span>. A subspace <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> is called <strong>invariant</strong> under <span class="math inline">\(T\)</span> if <span class="math inline">\(u \in U \implies T(u) \in U\)</span>.</p>
<p>In other words, <span class="math inline">\(U\)</span> is invariant under <span class="math inline">\(T\)</span> if <span class="math inline">\(T|_U\)</span> is an operator on <span class="math inline">\(U\)</span>.</p>
<blockquote>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>, then the following subspaces are invariant under <span class="math inline">\(T\)</span>:</p>
<p><span class="math inline">\(\{0\}\)</span></p>
<p><span class="math inline">\(V\)</span></p>
<p><span class="math inline">\(\text{null } T\)</span></p>
<p><span class="math inline">\(\text{range } T\)</span></p>
</blockquote>
<h3 id="eigenvalues-and-eigenvectors">EigenValues and Eigenvectors</h3>
<p>Take any <span class="math inline">\(v \in V\)</span> with <span class="math inline">\(v \neq 0\)</span> and let <span class="math inline">\(U\)</span> equal the set of all scalar multiples of <span class="math inline">\(v\)</span>:</p>
<p><span class="math display">\[U = \{\lambda v : \lambda \in \mathbb{F}\} = span (v)\]</span></p>
<p>Then <span class="math inline">\(U\)</span> is a 1-dimensional subspace of <span class="math inline">\(V\)</span>. If <span class="math inline">\(T\)</span> is a linear operator s.t <span class="math inline">\(T(v) \in U\)</span>, then:</p>
<p><span class="math display">\[T(v) = \lambda v\]</span></p>
<p>For some <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Conversely, if <span class="math inline">\(T(v) = \lambda v\)</span> for some <span class="math inline">\(\lambda \in \mathbb{F}\)</span>, then <span class="math inline">\(U = span(v)\)</span> is a 1-dimensional invariant subspace of <span class="math inline">\(V\)</span> under <span class="math inline">\(T\)</span>.</p>
<h4 id="definition-5.5-eigenvalue">Definition 5.5: Eigenvalue</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. A number <span class="math inline">\(\lambda \in \mathbb{F}\)</span> is called an <strong>eigenvalue</strong> of <span class="math inline">\(T\)</span> if there exists <span class="math inline">\(v \in V\)</span> s.t <span class="math inline">\(v \neq 0\)</span> and <span class="math inline">\(T(v) = \lambda v\)</span>.</p>
<p>In other words, <span class="math inline">\(T\)</span> has a 1-dimensional subspace IFF <span class="math inline">\(T\)</span> has an eigenvalue.</p>
<h4 id="theorem-5.6-equivalent-conditions-to-be-an-eigenvalue">Theorem 5.6 Equivalent Conditions to be an Eigenvalue</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional, <span class="math inline">\(T \in L(V)\)</span>, and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T - \lambda I\)</span> is not injective.</li>
<li><span class="math inline">\(T - \lambda I\)</span> is not surjective.</li>
<li><span class="math inline">\(T - \lambda I\)</span> is not invertible.</li>
</ol>
<p>where <span class="math inline">\(I \in L(V)\)</span> is the identity operator defined by <span class="math inline">\(I(v) = v, \; \forall v \in V\)</span>.</p>
<h4 id="definition-5.7-eigenvector">Definition 5.7: Eigenvector</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>. A vector <span class="math inline">\(v \in V\)</span> is called an <strong>eigenvector</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(v \neq 0\)</span> and <span class="math inline">\(T(v) = \lambda v\)</span>.</p>
<p>In other words, a vector <span class="math inline">\(v \in V\)</span> is an eigenvector of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> IFF <span class="math inline">\(v \in \text{null } (T - \lambda I)\)</span></p>
<h4 id="theorem-5.10-linearly-independent-eigenvectors">Theorem 5.10: Linearly Independent Eigenvectors</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are distinct eigenvalues of <span class="math inline">\(T\)</span> and <span class="math inline">\(v_1, ..., v_m\)</span> are corresponding eigenvectors. Then <span class="math inline">\(v_1, ..., v_m\)</span> is linearly independent.</p>
<h4 id="theorem-5.13-number-of-eigenvalues">Theorem 5.13: Number of Eigenvalues</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then each operator on <span class="math inline">\(V\)</span> has at most <span class="math inline">\(\dim V\)</span> distinct eigenvalues.</p>
<h4 id="definition-5.14-t_u-and-t-u">Definition 5.14: <span class="math inline">\(T|_U\)</span> and <span class="math inline">\(T / U\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> invariant under <span class="math inline">\(T\)</span>.</p>
<ul>
<li><p>The <strong>restriction operator</strong> <span class="math inline">\(T|_U \in L(U)\)</span> is defined by: <span class="math display">\[T|_U (u) = T(u)\]</span></p>
<p>for <span class="math inline">\(u \in U\)</span>.</p></li>
<li><p>The <strong>quotient operator</strong> <span class="math inline">\(T / U \in L(V / U)\)</span> is defined by: <span class="math display">\[(T / U) (v + U) = T(v) + U\]</span></p>
<p>for <span class="math inline">\(v \in V\)</span></p></li>
</ul>
<h3 id="eigenvectors-and-upper-triangular-matrices">Eigenvectors and Upper-Triangular Matrices</h3>
<p><strong>The main reason that a richer theory exists for operators (which map a vector space into itself) than for more general linear maps is that operators can be raised to powers.</strong></p>
<h4 id="definition-5.16-tm">Definition 5.16 <span class="math inline">\(T^m\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(m\)</span> is a positive integer.</p>
<ul>
<li><p><span class="math inline">\(T^m\)</span> is defined by: <span class="math display">\[T^m = T \underbrace{...}_{m \text{ times}} T\]</span></p></li>
<li><p><span class="math inline">\(T^0\)</span> is defined to be the identity operator <span class="math inline">\(I\)</span> on <span class="math inline">\(V\)</span>.</p></li>
<li><p>If <span class="math inline">\(T\)</span> is invertible with inverse <span class="math inline">\(T^{-1}\)</span>, then <span class="math inline">\(T^{-m}\)</span> is defined by: <span class="math display">\[T^{-m} = (T^{-1})^m\]</span></p></li>
<li><p><span class="math inline">\(T^m T^n = T^{m + n}\)</span>, <span class="math inline">\((T^{m})^n = T^{mn}\)</span></p></li>
</ul>
<h4 id="definition-5.17-pt">Definition 5.17: <span class="math inline">\(p(T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(p \in P(\mathbb{F})\)</span> is a polynomial given by:</p>
<p><span class="math display">\[p(z) = a_0 + a_1 z + a_2 z^2 + ... + a_m z^m\]</span></p>
<p>for <span class="math inline">\(z \in \mathbb{F}\)</span>. Then, <span class="math inline">\(p(T)\)</span> is the operator defined by:</p>
<p><span class="math display">\[p(T) = a_1 I + a_1 T + .... + a_m T^m\]</span></p>
<blockquote>
<p>Suppose <span class="math inline">\(D \in L(P(\mathbb{R}))\)</span> is the differentiation operator defined by <span class="math inline">\(D(q) = q^{\prime}\)</span> and <span class="math inline">\(p(x) = 16 - 3 x + 5x^3\)</span>. Then:</p>
<p><span class="math display">\[p(D) = 16I - 3 D + 5D^3\]</span></p>
<p>and</p>
<p><span class="math display">\[(p(D))(q) = 16 I - 3 q^{\prime} + 5 q^{\prime \prime \prime}\]</span></p>
</blockquote>
<p><strong>If we fix an operator <span class="math inline">\(T \in L(V)\)</span>, then the function <span class="math inline">\(M: P(\mathbb{F}) \rightarrow L(V)\)</span> defined by <span class="math inline">\(M(p) = p(T)\)</span> is linear.</strong></p>
<h4 id="definition-5.19-product-of-polynomials">Definition 5.19: Product of Polynomials</h4>
<p>If <span class="math inline">\(p, q \in P(\mathbb{F})\)</span>, then <span class="math inline">\(pq \in P(\mathbb{F})\)</span> is the polynomial defined by:</p>
<p><span class="math display">\[(pq)(z) = p(z) q(z)\]</span></p>
<p>for <span class="math inline">\(z \in \mathbb{F}\)</span></p>
<h4 id="theorem-5.20-multiplicative-properties-of-polynomials">Theorem 5.20: Multiplicative Properties of Polynomials</h4>
<p>Suppose <span class="math inline">\(p, q \in P(\mathbb{F})\)</span> and <span class="math inline">\(T \in L(V)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\((pq)(T) = p(T) q(T)\)</span></li>
<li><span class="math inline">\(p(T)q(T) = q(T)p(T)\)</span></li>
</ol>
<p><strong>When expanding a product of polynomials using the distributive property, it does not matter whether the symbol is <span class="math inline">\(z\)</span> or <span class="math inline">\(T\)</span></strong></p>
<h4 id="theorem-5.21-operators-on-complex-vector-spaces-have-an-eigenvalue">Theorem 5.21: Operators on Complex Vector Spaces Have an Eigenvalue</h4>
<p>Every operator on a finite-dimensional, nonzero, complex vector space has an eigenvalue.</p>
<h4 id="definition-5.22-matrix-of-an-operator-mt">Definition 5.22 Matrix of an Operator, <span class="math inline">\(M(T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>. The <strong>matrix of <span class="math inline">\(T\)</span></strong> w.r.t this basis is the <span class="math inline">\(n \times n\)</span> matrix:</p>
<p><span class="math display">\[
M(T) = 
\begin{bmatrix}
A_{1, 1} &amp; ... &amp; A_{1, n}\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
A_{n, 1} &amp; ... &amp; A_{n, n}
\end{bmatrix}
\]</span></p>
<p>whose entries <span class="math inline">\(A_{j, k}\)</span> are defined by:</p>
<p><span class="math display">\[T(v_k) = A_{1, k} v_1 + .... + A_{n, k} v_n\]</span></p>
<p>The <span class="math inline">\(k\)</span>th column of the matrix is formed from the coefficients used to write <span class="math inline">\(T(v_k)\)</span> as a linear combination of <span class="math inline">\(v_1, ..., v_n\)</span>. If the basis is not clear from the context, then the notation <span class="math inline">\(M(T, (v_1, ..., v_n))\)</span> is used or standard bases are assumed.</p>
<blockquote>
<p>Define <span class="math inline">\(T \in L(\mathbb{R}^3)\)</span> by <span class="math inline">\(T(x, y, z) = (2x + y, 5y + 3x, 8z)\)</span>, then <span class="math display">\[
M(T) = 
\begin{bmatrix}
2 &amp; 1 &amp; 0\\
0 &amp; 5 &amp; 3\\
0 &amp; 0 &amp; 8\\
\end{bmatrix}
\]</span></p>
</blockquote>
<h4 id="definition-5.24-diagonal-of-a-matrix">Definition 5.24: Diagonal of a Matrix</h4>
<p>THe <strong>diagonal</strong> of a square matrix consists of the entries along the line from the upper left corner to the bottom right corner.</p>
<h4 id="definition-5.25-upper-triangular-matrix">Definition 5.25 Upper-Triangular Matrix</h4>
<p>A matrix is called <strong>upper triangular</strong> if all the entries below the diagonal equal <span class="math inline">\(0\)</span>.</p>
<h4 id="theorem-5.26-conditions-for-upper-triangular-matrix">Theorem 5.26: Conditions for Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li>The matrix of <span class="math inline">\(T\)</span> w.r.t <span class="math inline">\(v_1, ..., v_n\)</span> is upper triangular.</li>
<li><span class="math inline">\(T(v_j) \in span(v_1, ..., v_j)\)</span> for each <span class="math inline">\(j = 1, ...., n\)</span>.</li>
<li><span class="math inline">\(span(v_1, ..., v_j)\)</span> is invariant under <span class="math inline">\(T\)</span> for each <span class="math inline">\(j = 1 , ..., n\)</span>.</li>
</ol>
<h5 id="proof-of-theorem-5.26">Proof of Theorem 5.26:</h5>
<p><span class="math inline">\(1 \Longleftrightarrow 2, 3 \rightarrow 2\)</span> is trivial, so we only need to prove <span class="math inline">\(2 \rightarrow 3\)</span>.</p>
<p>Suppose <span class="math inline">\(2\)</span> holds and fix <span class="math inline">\(j \in \{1, ..., n\}\)</span> then we have:</p>
<p><span class="math display">\[T(v_1) = span(v_1) \subseteq span(v_1, ..., v_j)\]</span> <span class="math display">\[T(v_2) = span(v_1, v_2) \subseteq span(v_1, ..., v_j)\]</span> <span class="math display">\[.\]</span> <span class="math display">\[.\]</span> <span class="math display">\[.\]</span> <span class="math display">\[T(v_j) = span(v_1, ..., v_j)\]</span></p>
<p>Let <span class="math inline">\(v \in span(v_1, ..., v_j)\)</span>, then <span class="math inline">\(v = a_1v_1 + ... + a_j v_j\)</span>:</p>
<p><span class="math display">\[T(v) = a_1 T(v_1) + ... + a_j T(v_j) \in span(v_1, ..., v_j)\]</span></p>
<p>Thus, we can conclude that <span class="math inline">\(span (v_1, ..., v_j)\)</span> is invariant under <span class="math inline">\(T\)</span>.</p>
<h4 id="theorem-5.27-over-mathbbc-every-operator-has-an-upper-triangular-matrix">Theorem 5.27: Over <span class="math inline">\(\mathbb{C}\)</span>, Every Operator has an Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a finite-dimensional complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>.</p>
<p><strong>This result does not hold for real number space, because we are not guaranteed to have an eigenvalue for every operator in the real number vector space.</strong></p>
<h4 id="theorem-5.30-determination-of-invertibility-from-upper-triangular-matrix">Theorem 5.30: Determination of Invertibility from Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(T\)</span> is invertible if and only if all the entries on the diagonal of that upper-triangular matrix are nonzero.</p>
<h4 id="theorem-5.32-determination-of-eigenvalues-from-upper-triangular-matrix">Theorem 5.32: Determination of Eigenvalues from Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>. Then the eigenvalues of <span class="math inline">\(T\)</span> are precisely the entries on the diagonal of that upper-triangular matrix.</p>
<h5 id="proof-of-theorem-5.32">Proof of Theorem 5.32:</h5>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has an upper-triangular matrix:</p>
<p><span class="math display">\[
M(T) = 
\begin{bmatrix}
\lambda_1 &amp; ... &amp; *\\
. &amp; \lambda_2 &amp; .\\
. &amp; ... &amp; .\\
\end{bmatrix}
\]</span></p>
<p>Let <span class="math inline">\(\lambda \in \mathbb{F}\)</span>, then:</p>
<p><span class="math display">\[
M(T - \lambda I) = M(T) - \lambda M(I) = 
\begin{bmatrix}
\lambda_1 - \lambda &amp; ... &amp; *\\
. &amp; \lambda_2 - \lambda &amp; .\\
. &amp; ... &amp; .\\
\end{bmatrix}
\]</span></p>
<p><span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span> IFF <span class="math inline">\(T - \lambda I\)</span> is not invertible, which means that by <code>theorem 5.30</code>, at least one of the diagonal entries of <span class="math inline">\(M(T - \lambda I)\)</span> has to be zero. So the eigenvalue is one of the diagonal entries.</p>
<h3 id="eigenspaces-and-diagonal-matrices">Eigenspaces and Diagonal Matrices</h3>
<h4 id="definition-5.34-diagonal-matrix">Definition 5.34: Diagonal Matrix</h4>
<p>A <strong>diagonal matrix</strong> is a square matrix that is <span class="math inline">\(0\)</span> everywhere except possibly along the diagonal.</p>
<p>If an operator has a diagonal matrix with respect to some basis, then the entries along the diagonal are precisely the eigenvalues of the operator.</p>
<h4 id="definition-5.36-eigenspace-elambda-t">Definition 5.36: Eigenspace, <span class="math inline">\(E(\lambda, T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. The <strong>eigenspace</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span>, denoted <span class="math inline">\(E(\lambda, T)\)</span>, is defined by:</p>
<p><span class="math display">\[E(\lambda, T) = \text{null}(T - \lambda I)\]</span></p>
<p>In other words, <span class="math inline">\(E(\lambda, T)\)</span> is the set of span of all eigenvectors of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span>, along with the <span class="math inline">\(0\)</span> vector and <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span> IFF <span class="math inline">\(E(\lambda, T) \neq \{0\}\)</span>.</p>
<h4 id="theorem-5.38-sum-of-eigenspaces-is-a-direct-sum">Theorem 5.38: Sum of Eigenspaces is a Direct Sum</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V)\)</span>. Suppose also that <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are distinct eigenvalues of <span class="math inline">\(T\)</span>. Then:</p>
<p><span class="math display">\[E(\lambda_1, T) + ... + E(\lambda_m, T)\]</span></p>
<p>is a direct sum. Furthermore,</p>
<p><span class="math display">\[\dim E(\lambda_1, T) + ... + \dim E(\lambda_m, T) \leq \dim V\]</span></p>
<h4 id="definition-5.39-diagonalizable">Definition 5.39: Diagonalizable</h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is called diagonalizable if the operator has a diagonal matrix with respect ot some basis of <span class="math inline">\(V\)</span>.</p>
<blockquote>
<p>Define <span class="math inline">\(T \in L(\mathbb{R}^2)\)</span> by: <span class="math display">\[T(x, y) = (41x + 7y, -20x + 74y)\]</span></p>
<p><span class="math inline">\(T\)</span> is diagonalizable w.r.t the basis <span class="math inline">\((1, 4), (7, 5)\)</span></p>
</blockquote>
<h4 id="theorem-5.41-conditions-equivalent-to-diagonalizability">Theorem 5.41: Conditions Equivalent to Diagonalizability</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> denote the distinct eigenvalues of <span class="math inline">\(T\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(T\)</span> is diagonalizable.</li>
<li><span class="math inline">\(V\)</span> has a basis consisting of eigenvectors of <span class="math inline">\(T\)</span>.</li>
<li>There exists <span class="math inline">\(1\)</span>-dimensional subspaces <span class="math inline">\(U_1, ..., U_n\)</span> of <span class="math inline">\(V\)</span>, each invariant under <span class="math inline">\(T\)</span>, such that: <span class="math display">\[V = U_1 \oplus .... \oplus U_n\]</span></li>
<li><span class="math inline">\(V = E(\lambda_1, T) \oplus ... \oplus E(\lambda_m, T)\)</span></li>
<li><span class="math inline">\(\dim V = \dim E(\lambda_1, T) + ... + \dim E(\lambda_m, T)\)</span></li>
</ol>
<h5 id="proof-of-theorem-5.41">Proof of Theorem 5.41</h5>
<p><span class="math inline">\(1 \Longleftrightarrow 2\)</span> is trivial. Let <span class="math inline">\(v_1, .., v_n\)</span> be a basis s.t <span class="math inline">\(T\)</span> is diagonalizable, then we have <span class="math inline">\(T(v_j) = \lambda_j v_j\)</span>, so <span class="math inline">\(\{v_j\}\)</span> are eigenvectors of <span class="math inline">\(T\)</span> and basis of <span class="math inline">\(V\)</span>.</p>
<p>Suppose <span class="math inline">\(2\)</span> holds, then <span class="math inline">\(v_1, ..., v_n\)</span> is an eigenvector basis of <span class="math inline">\(V\)</span>. Let <span class="math inline">\(U_1 = span(v_1), ...., U_n = span(v_n)\)</span>, since <span class="math inline">\(v_1, ..., v_n\)</span> are eigenvectors of <span class="math inline">\(T\)</span>, then <span class="math inline">\(U_1, ..., U_n\)</span> are <span class="math inline">\(1\)</span>-dimensional invariant subspaces. Since <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, we have each vector <span class="math inline">\(v \in V\)</span> can be uniquely write as linear combination of <span class="math inline">\(u_j \in U_j\)</span>:</p>
<p><span class="math display">\[v = a_1v_1 + ... + a_n v_n = u_1 + ... + u_n\]</span></p>
<p>Thus, we have <span class="math inline">\(V = U_1 \oplus ... \oplus U_n\)</span>, <span class="math inline">\(2 \rightarrow 3\)</span>.</p>
<p>Suppose <span class="math inline">\(3\)</span> holds, then <span class="math inline">\(U_1 = span(v_1), ..., U_n = span(v_n)\)</span>, where <span class="math inline">\(u_1, ..., u_n\)</span> are eigenvector of <span class="math inline">\(T\)</span>, since <span class="math inline">\(V = U_1 \oplus ... \oplus U_n\)</span>, we have:</p>
<p><span class="math display">\[v = u_1 + ... + u_n = a_1 v_1 + ... + a_n v_n, \; \forall v \in V\]</span></p>
<p>Thus, we have <span class="math inline">\(v_1, ..., v_n\)</span> being eigenvector basis of <span class="math inline">\(V\)</span>, which implies <span class="math inline">\(2\)</span>.</p>
<p>Suppose <span class="math inline">\(2\)</span> holds, we have a basis consisting of eigenvectors of <span class="math inline">\(T\)</span>. Hence, every vector of <span class="math inline">\(V\)</span> can be written as:</p>
<p><span class="math display">\[v = a_1 v_1 + ... + a_n v_n = u_1 + ... + u_n\]</span></p>
<p>Where <span class="math inline">\(u_i \in \text{null} (T - \lambda_j I), \; i \in \{1, ..., n\}, j \in \{1, ..., m\}\)</span>. Thus, we have:</p>
<p><span class="math display">\[V = E(\lambda_1, T) + ... + E(\lambda_m, T)\]</span></p>
<p>By <code>theorem 5.38</code>, we have:</p>
<p><span class="math display">\[V = E(\lambda_1, T) \oplus ... \oplus E(\lambda_m, T)\]</span></p>
<p>Thus, <span class="math inline">\(2 \rightarrow 4\)</span>.</p>
<p>By <code>theorem 5.38</code>, we can easily see that <span class="math inline">\(4 \rightarrow 5\)</span></p>
<p>Finally, suppose <span class="math inline">\(5\)</span> holds, we have:</p>
<p><span class="math display">\[\dim V = \dim E(\lambda_1, T) + ... +  \dim E(\lambda_m, T)\]</span></p>
<p>Choose a basis of each <span class="math inline">\(E(\lambda_j, T)\)</span> and put all these bases together to form a list <span class="math inline">\((v_1, ..., v_n)\)</span> of eigenvectors of <span class="math inline">\(T\)</span>, where <span class="math inline">\(n = \dim V\)</span>. To show that they are linearly independent, suppose that:</p>
<p><span class="math display">\[a_1 v_1 + ... a_n v_n = 0\]</span></p>
<p>For each <span class="math inline">\(j = 1, ..., m\)</span>, let <span class="math inline">\(u_j\)</span> denote the sum of all the terms <span class="math inline">\(a_kv_k\)</span> s.t <span class="math inline">\(v_k \in E(\lambda_j, T)\)</span>. Thus, each <span class="math inline">\(u_j\)</span> is in <span class="math inline">\(E(\lambda_j, T)\)</span>, and:</p>
<p><span class="math display">\[u_1 + ... + u_m = 0\]</span></p>
<p>Since eigenvectors corresponding to different eigenvalues are independent and <span class="math inline">\(u_i\)</span> is sum of basis in <span class="math inline">\(E(\lambda_j, T)\)</span>, we have <span class="math inline">\(u_1, ..., u_m\)</span> independent and all <span class="math inline">\(a_k = 0\)</span>. Thus, <span class="math inline">\(5 \rightarrow 2\)</span>.</p>
<h4 id="theorem-5.44-enough-eigenvalues-implies-diagonalizability">Theorem 5.44: Enough Eigenvalues Implies Diagonalizability</h4>
<p>If <span class="math inline">\(T \in L(V)\)</span> has <span class="math inline">\(\dim V\)</span> distinct eigenvalues, then <span class="math inline">\(T\)</span> is diagonalizable.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>linear-algebra</title>
    <url>/2022/01/06/linear-algebra/</url>
    <content><![CDATA[<h1 id="linear-algebra-1">Linear Algebra (1)</h1>
<p>All the notes precisely follows <strong>Linear Algebra Done Right by Sheldon Axler</strong></p>
<h2 id="vector-spaces">Vector Spaces</h2>
<h3 id="complex-numbers">Complex Numbers</h3>
<h4 id="definition-1.1-complex-numbers">Definition 1.1: Complex Numbers</h4>
<ol type="1">
<li>A <strong>Complex Number</strong> is an order pair <span class="math inline">\((a, b)\)</span>, where <span class="math inline">\(a, b \in \mathbb{R}\)</span>.</li>
<li><strong>Addition and multiplication</strong> is defined as: <span class="math display">\[x + y = (a + b) + (c + d) = (a + c, b + d)\]</span> <span class="math display">\[xy = (a + b) (c + d) = (ac - bd, ad + bc)\]</span></li>
<li><span class="math inline">\(i = (0, 1)\)</span> and <span class="math inline">\(i^2 = (0, 1) (0, 1) = -1\)</span></li>
<li>Every complex number can be written as <span class="math display">\[x = (a, b) = (a, 0) + (0, b) = (a, 0) + (b, 0)(0, 1) = a + bi\]</span></li>
<li>The set of all complex numbers is denoted by <span class="math inline">\(\mathbb{C}\)</span>: <span class="math display">\[\mathbb{C} = \{a + bi: a, b \in \mathbb{R}\}\]</span></li>
<li><strong>Addition and multiplication</strong> on <span class="math inline">\(\mathbb{C}\)</span> are defined by <span class="math display">\[(a + bi) + (c + di) = (a + c) + (b + d)i\]</span> <span class="math display">\[(a + bi) (c + di) = (ac - bd) + (ad + bc)i\]</span></li>
</ol>
<p><span class="math inline">\(a, c, b, d \in \mathbb{R}\)</span></p>
<p>If <span class="math inline">\(a \in \mathbb{R}\)</span>, we identify <span class="math inline">\(a + 0i\)</span> with the real number <span class="math inline">\(a\)</span>. Thus we can think of <span class="math inline">\(\mathbb{R}\)</span> as a subset of <span class="math inline">\(\mathbb{C}\)</span>.</p>
<h4 id="definition-1.2-conjugate">Definition 1.2: Conjugate</h4>
<p>If <span class="math inline">\(a, b\)</span> are real and <span class="math inline">\(z = a + bi\)</span>, then the complex number <span class="math inline">\(\bar{z} = a - bi\)</span> is called the <strong>conjugate</strong> of <span class="math inline">\(z\)</span>. The numbers <span class="math inline">\(a, b\)</span> are the real part and the imaginary part of <span class="math inline">\(z\)</span> respectively:</p>
<p><span class="math display">\[a = Re(z), \quad \quad b = Im(z)\]</span></p>
<h4 id="theorem-1.3a">Theorem 1.3A</h4>
<p>If <span class="math inline">\(z\)</span> and <span class="math inline">\(w\)</span> are complex, then</p>
<ol type="1">
<li><span class="math inline">\(\overline{z + w} = \bar{z} + \bar{w}\)</span></li>
<li><span class="math inline">\(\overline{zw} = \bar{z}\bar{w}\)</span></li>
<li><span class="math inline">\(z + \bar{z} = 2Re(z),\quad z - \bar{z} = 2i Im(z)\)</span></li>
<li>If <span class="math inline">\(z = a + bi\)</span>, <span class="math inline">\(z \bar{z} = a^2 + b^2\)</span> is real and positive.</li>
<li><span class="math inline">\(|z| = \sqrt{z\bar{z}} = \sqrt{a^2 + b^2}\)</span> is unique.</li>
<li><span class="math inline">\(|zw| = |z||w|\)</span></li>
</ol>
<span id="more"></span>
<h4 id="theorem-1.3b-schwarz-inequality">Theorem 1.3B: Schwarz Inequality</h4>
<p>If <span class="math inline">\(a_1, ..., a_n\)</span> and <span class="math inline">\(b_1, ..., b_n\)</span> are complex numbers, then:</p>
<p><span class="math display">\[|\sum^n_{j=1} a_j \bar{b_j}|^2 \leq \sum^n_{j=1} |a_j|^2 \sum^{n}_{j=1} |b_j|^2\]</span></p>
<h4 id="property-1.4-properties-of-complex-arithmetic">Property 1.4: Properties of Complex Arithmetic</h4>
<ol type="1">
<li><p>Commutativity:</p>
<p><span class="math display">\[\alpha + \beta = \beta + \alpha, \;\; \alpha \beta = \beta \alpha, \quad \alpha, \beta \in \mathbb{C}\]</span></p></li>
<li><p>Associativity:</p>
<p><span class="math display">\[(\alpha + \beta) + \lambda = \alpha + (\beta + \lambda), \;\; (\alpha\beta)\lambda = \alpha (\beta\lambda), \quad \alpha, \beta, \lambda \in \mathbb{C}\]</span></p></li>
<li><p>Identities:</p>
<p><span class="math display">\[\lambda + 0 = \lambda, \;\; \lambda 1 = \lambda, \quad \forall \lambda \in \mathbb{C}\]</span></p></li>
<li><p>Additive Inverse:</p>
<p>For all <span class="math inline">\(\alpha \in \mathbb{C}\)</span>, there exists a unique <span class="math inline">\(\beta \in \mathbb{C}\)</span> such that <span class="math inline">\(\alpha + \beta = 0\)</span>.</p></li>
<li><p>Multiplicative Inverse:</p>
<p>For all <span class="math inline">\(\alpha \in \mathbb{C}, \alpha \neq 0\)</span>, there exists a unique <span class="math inline">\(\beta \in \mathbb{C}\)</span> such that <span class="math inline">\(\alpha\beta = 1\)</span>.</p></li>
<li><p>Distributive Property:</p>
<p><span class="math display">\[\lambda (\alpha + \beta) = \lambda \alpha + \lambda \beta, \quad \forall \lambda, \alpha, \beta \in \mathbb{C}\]</span></p></li>
</ol>
<h4 id="definition-1.5--alpha-subtraction-frac1alpha-division">Definition 1.5: <span class="math inline">\(-\alpha\)</span>, Subtraction, <span class="math inline">\(\frac{1}{\alpha}\)</span>, Division</h4>
<p>Let <span class="math inline">\(\alpha, \beta \in \mathbb{C}\)</span>:</p>
<ol type="1">
<li>Let <span class="math inline">\(-\alpha\)</span> denote the additive inverse of <span class="math inline">\(\alpha\)</span>. Thus, <span class="math inline">\(-\alpha\)</span> is the unique complex number s.t: <span class="math display">\[\alpha + (- \alpha) = 0\]</span></li>
<li><strong>Subtraction</strong> on <span class="math inline">\(\mathbb{C}\)</span> is defined by: <span class="math display">\[\beta - \alpha = \beta + (-\alpha)\]</span></li>
<li>For <span class="math inline">\(\alpha \neq 0\)</span>, let <span class="math inline">\(\frac{1}{\alpha}\)</span> denote the multiplicative inverse of <span class="math inline">\(\alpha\)</span>. Thus <span class="math inline">\(\frac{1}{\alpha}\)</span> is the unique complex number s.t: <span class="math display">\[\alpha (\frac{1}{\alpha}) = 1\]</span></li>
<li><strong>Division</strong> on <span class="math inline">\(\mathbb{C}\)</span> is defined by: <span class="math display">\[\frac{\beta}{\alpha} = \beta\frac{1}{\alpha}\]</span></li>
</ol>
<h4 id="definition-1.7-mathbbf">Definition 1.7: <span class="math inline">\(\mathbb{F}\)</span></h4>
<p><span class="math inline">\(\mathbb{F}\)</span> stands for either <span class="math inline">\(\mathbb{R}, \mathbb{C}\)</span>. Elements of <span class="math inline">\(\mathbb{F}\)</span> are called <strong>scalars</strong> which is a fancy word for number.</p>
<h4 id="definition-1.8-list-length">Definition 1.8: List, Length</h4>
<p>Suppose <span class="math inline">\(n\)</span> is a nonnegative integer. A <strong>list</strong> of <strong>length</strong> <span class="math inline">\(n\)</span> (<span class="math inline">\(n-tuple\)</span>) is an ordered collection of <span class="math inline">\(n\)</span> elements (can be numbers, other lists or more abstract entities) separated by commas and surrounded by parentheses. A list of length <span class="math inline">\(n\)</span> looks like:</p>
<p><span class="math display">\[(x_1, ..., x_n)\]</span></p>
<p>Two lists are <strong>equal</strong>, if and only if they have the same length and the same elements in the same order.</p>
<p>Each list has a finite length that is a nonnegative integer. Thus an object with <strong>infinite length is not a list</strong>.</p>
<p>A list of length 0 is denoted as <span class="math inline">\(()\)</span>.</p>
<h4 id="definition-1.10-mathbbfn">Definition 1.10: <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p><span class="math inline">\(\mathbb{F}^n\)</span> is the set of all lists of length <span class="math inline">\(n\)</span> of elements of <span class="math inline">\(\mathbb{F}\)</span>:</p>
<p><span class="math display">\[\mathbb{F}^{n} = \{(x_1, ..., x_n): x_j \in \mathbb{F}, \; \forall j=1, ..., n\}\]</span></p>
<p>For <span class="math inline">\((x_1, ..., x_n) \in \mathbb{F}^n\)</span> and <span class="math inline">\(j \in \{1, ..., n\}\)</span>, we say that <span class="math inline">\(x_j\)</span> is the <span class="math inline">\(j\)</span>th <strong>coordinate</strong> of <span class="math inline">\((x_1, ..., x_n)\)</span>.</p>
<h4 id="definition-1.12-addition-in-mathbbfn">Definition 1.12: Addition in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p><strong>Addition</strong> in <span class="math inline">\(\mathbb{F}^n\)</span> is defined by adding corresponding coordinates:</p>
<p><span class="math display">\[(x_1, ...., x_n) + (y_1, ...., y_n) = (x_1 + y_1, ...., x_n + y_n)\]</span></p>
<h4 id="definition-1.13-commutativity-of-addition-in-mathbbfn">Definition 1.13: Commutativity of Addition in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p>If <span class="math inline">\(x, y \in \mathbb{F}^n\)</span>, then <span class="math inline">\(x + y = y + x\)</span></p>
<p><strong>If a single letter is used to denote an element of <span class="math inline">\(\mathbb{F}^n\)</span>, then the same letter with appropriate subscripts is often used when coordinates must be displayed.</strong></p>
<h4 id="definition-1.14-0">Definition 1.14: 0</h4>
<p>Let <span class="math inline">\(0\)</span> denote the list of length <span class="math inline">\(n\)</span> whose coordinates are all 0:</p>
<p><span class="math display">\[0 = (0, ..., 0)\]</span></p>
<h4 id="definition-1.16-additive-inverse-in-mathbbfn">Definition 1.16: Additive Inverse in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p>For <span class="math inline">\(x \in \mathbb{F}^n\)</span>, the <strong>additive inverse</strong> of <span class="math inline">\(x\)</span>, denoted <span class="math inline">\(-x\)</span>, is the vector <span class="math inline">\(-x \in \mathbb{F}^n\)</span> such that</p>
<p><span class="math display">\[x + (-x) = 0\]</span></p>
<p>In order words, if <span class="math inline">\(x = (x_1, ...., x_n)\)</span>, then <span class="math inline">\(-x = (-x_1, ..., -x_n)\)</span></p>
<h4 id="definition-1.17-scalar-multiplication-in-mathbbfn">Definition 1.17: Scalar Multiplication in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p>The <strong>product</strong> of a number <span class="math inline">\(\lambda\)</span> and a vector in <span class="math inline">\(\mathbb{F}^n\)</span> is computed by multiplying each coordinate of the vector by <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[\lambda (x_1, ..., x_n) = (\lambda x_1, ...., \lambda x_n)\]</span></p>
<p>here <span class="math inline">\(\lambda \in \mathbb{F}, \;\ (x_1, ..., x_n) \in \mathbb{F}^n\)</span></p>
<h4 id="field">Field</h4>
<p>A <strong>field</strong> is a set containing at least two distinct elements called <span class="math inline">\(0, 1\)</span>, along with operations of addition and multiplication satisfying all the properties in <strong>Definition 1.3</strong>. Thus, <span class="math inline">\(\mathbb{R}, \mathbb{C}\)</span> are fields.</p>
<h3 id="definition-of-vector-space">Definition of Vector Space</h3>
<h4 id="definition-1.18-addition-scalar-multiplication">Definition 1.18: Addition, Scalar Multiplication</h4>
<ol type="1">
<li>An <strong>addition</strong> on a set <span class="math inline">\(V\)</span> is a function that assigns an element <span class="math inline">\(u + v \in V\)</span> to each pair of elements <span class="math inline">\(u, v \in V\)</span>.</li>
<li>A <strong>scalar multiplication</strong> on a set <span class="math inline">\(V\)</span> is a function that assigns an element <span class="math inline">\(\lambda v \in V\)</span> to each <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and each <span class="math inline">\(v \in V\)</span>.</li>
</ol>
<h4 id="definition-1.19-vector-space">Definition 1.19: Vector Space</h4>
<p>A <strong>vector space</strong> is a set <span class="math inline">\(V\)</span> along with an addition on <span class="math inline">\(V\)</span> and a scalar multiplication on <span class="math inline">\(V\)</span> such that the following properties hold:</p>
<ol type="1">
<li><p><strong>Commutativity</strong>: <span class="math display">\[u + v = v + u, \; \forall u, v \in V\]</span></p></li>
<li><p><strong>Associativity</strong>: <span class="math display">\[(u + v) + w = u + (v + w) \text{ and } (ab) v = a(bv), \;  \forall u, v, w \in V, \; \forall a, b \in \mathbb{F}\]</span></p></li>
<li><p><strong>Additive Identity</strong>:</p>
<p>There exists an element <span class="math inline">\(0 \in V\)</span> such that <span class="math inline">\(v + 0 = v, \; \forall v \in V\)</span></p></li>
<li><p><strong>Additive Inverse</strong>: <span class="math display">\[\forall v \in V, \exists \; w \in V \; s.t \; v + w = 0\]</span></p></li>
<li><p><strong>Multiplicative Identity</strong>: <span class="math display">\[1v = v, \; \forall v \in V\]</span></p></li>
<li><p><strong>Distributive Properties</strong>: <span class="math display">\[a(u + v) = au + av \text{ and } (a + b)v = av + bv, \; \forall a, b \in \mathbb{F}, \; \forall u, v \in \mathbb{F}\]</span></p></li>
</ol>
<h4 id="definition-1.20-vector-point">Definition 1.20: Vector, Point</h4>
<p>Elements of a vector space are called <strong>vectors</strong> or <strong>points</strong>.</p>
<p>Since the scalar multiplication in a vector space depends on <span class="math inline">\(\mathbb{F}\)</span>, thus we need to be precise. We say that <span class="math inline">\(V\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span> (i.e <span class="math inline">\(\mathbb{R}^n\)</span> is a vector space over <span class="math inline">\(\mathbb{R}\)</span>).</p>
<h4 id="definition-1.21-real-vector-space-complex-vector-space">Definition 1.21: Real Vector Space, Complex Vector Space</h4>
<ol type="1">
<li>A vector space over <span class="math inline">\(\mathbb{R}\)</span> is called a <strong>real vector space</strong>.</li>
<li>A vector space over <span class="math inline">\(\mathbb{C}\)</span> is called a <strong>complex vector space</strong>.</li>
</ol>
<h4 id="definition-1.23-mathbbfs">Definition 1.23 <span class="math inline">\(\mathbb{F}^S\)</span></h4>
<ol type="1">
<li>If <span class="math inline">\(S\)</span> is a set, then <span class="math inline">\(\mathbb{F}^S\)</span> denotes the set of functions from <span class="math inline">\(S\)</span> to <span class="math inline">\(\mathbb{F}\)</span>.</li>
<li>For <span class="math inline">\(f, g \in \mathbb{F}^S\)</span>, the <strong>sum</strong> <span class="math inline">\(f + g \in \mathbb{F}^S\)</span> is the function defined by: <span class="math display">\[(f + g) (x) = f(x) + g(x), \; \forall x \in S\]</span></li>
<li>For <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and <span class="math inline">\(f \in \mathbb{F}^S\)</span>, the <strong>product</strong> <span class="math inline">\(\lambda f \in \mathbb{F}^S\)</span> is the function defined by: <span class="math display">\[(\lambda f)(x) = \lambda f(x), \; \forall x \in S\]</span></li>
</ol>
<p>We can think of <span class="math inline">\(\mathbb{F}^n\)</span> as special case of <span class="math inline">\(\mathbb{F}^S\)</span>, because it can be represented as <span class="math inline">\(\mathbb{F}^{\{1, ...., n\}}\)</span> which is the set of functions:</p>
<p><span class="math display">\[\{f: \{1, ..., n\} \rightarrow \mathbb{F}\}\]</span></p>
<p>and <span class="math inline">\(f(i)\)</span> is the <span class="math inline">\(i\)</span>th element of the list (i.e <span class="math inline">\((f(1) ,...., f(n)) \in \mathbb{F}^n\)</span>). Since the sequence of numbers in <span class="math inline">\(\mathbb{F}\)</span> is a function that maps from natural number to <span class="math inline">\(\mathbb{F}\)</span>.</p>
<h4 id="property-1.25-unique-additive-identity">Property 1.25: Unique Additive Identity</h4>
<p>A vector space has a unique additive identity.</p>
<h4 id="property-1.26-unique-additive-inverse">Property 1.26: Unique Additive Inverse</h4>
<p>Every element in a vector space has a unique additive inverse.</p>
<h4 id="definition-1.27--v-w---v">Definition 1.27: <span class="math inline">\(-v, w - v\)</span></h4>
<p>Let <span class="math inline">\(v, w \in V\)</span>, where <span class="math inline">\(V\)</span> is a vector space. Then</p>
<ol type="1">
<li><span class="math inline">\(-v\)</span> denotes the additive inverse of <span class="math inline">\(v\)</span>.</li>
<li><span class="math inline">\(w - v\)</span> is defined to be <span class="math inline">\(w + (-v)\)</span>.</li>
</ol>
<h4 id="property-1.29-the-scalar-0-times-a-vector">Property 1.29: The <strong>scalar</strong> 0 times a vector</h4>
<p><span class="math inline">\(0v = 0, \forall v \in V\)</span>, where <span class="math inline">\(V\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span>.</p>
<h4 id="property-1.29-a-scalar-times-a-vector-0">Property 1.29: A scalar times a <strong>vector</strong> 0</h4>
<p><span class="math inline">\(a0 = 0, \forall a \in \mathbb{F}\)</span>.</p>
<h4 id="property-1.31-the-number--1-times-a-vector">Property 1.31: The number <span class="math inline">\(-1\)</span> times a vector</h4>
<p><span class="math inline">\((-1)v = -v, \forall v \in V\)</span>, where <span class="math inline">\(V\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span></p>
<h3 id="subspaces">Subspaces</h3>
<h4 id="definition-1.32-subspace-linear-subspace">Definition 1.32: Subspace (Linear Subspace)</h4>
<p>A subset <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> is called a <strong>subspace</strong> of <span class="math inline">\(V\)</span> if <span class="math inline">\(U\)</span> is also a vector space (using the same addition adn scalar multiplication as on <span class="math inline">\(V\)</span>).</p>
<h4 id="definition-1.34-conditions-for-a-subspace">Definition 1.34 Conditions for a Subspace</h4>
<p>A subset <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> is a subspace of <span class="math inline">\(V\)</span> if and only if <span class="math inline">\(U\)</span> satisfies the following three conditions:</p>
<ol type="1">
<li>Additive Identity: <span class="math display">\[0 \in U\]</span></li>
<li>Closed under Addition: <span class="math display">\[u, w \in U \implies u + w \in U\]</span></li>
<li>closed under scalar multiplication: <span class="math display">\[a \in \mathbb{F}, u \in U \implies au \in U\]</span></li>
</ol>
<h4 id="definition-1.36-sum-of-subsets">Definition 1.36: Sum of Subsets</h4>
<p>Suppose <span class="math inline">\(U_1, ...., U_m\)</span> are subsets of <span class="math inline">\(V\)</span>. The <strong>sum</strong> of <span class="math inline">\(U_1, ..., U_m\)</span>, denoted <span class="math inline">\(U_1 + ... + U_m\)</span>, is the set of all possible sums of elements of <span class="math inline">\(U_1 ,...., U_m\)</span>:</p>
<p><span class="math display">\[U_1 + .... + U_m = \{u_1 + ... u_m: u_1 \in U_1, ..., u_m \in U_m\}\]</span></p>
<p><strong>The union of subspaces is rarely a subspace which is why we usually work with sums rather than unions.</strong></p>
<h4 id="definition-1.39-sum-of-subspaces-is-the-smallest-containing-subspace">Definition 1.39: Sum of Subspaces is the Smallest Containing Subspace</h4>
<p>Suppose <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U_1 + .... + U_m\)</span> is the smallest subspace of <span class="math inline">\(V\)</span> containing <span class="math inline">\(U_1, ...., U_m\)</span>.</p>
<h4 id="definition-1.40-direct-sum">Definition 1.40: Direct Sum</h4>
<p>Suppose <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>:</p>
<ol type="1">
<li>The sum <span class="math inline">\(U_1 + ... + U_m\)</span> is called a <strong>direct sum</strong> if each element of the resulting set <span class="math inline">\(U_1 + ... + U_m\)</span> can be written in only one way as a sum <span class="math inline">\(u_1 + ... + u_m\)</span>, where each <span class="math inline">\(u_j\)</span> is in <span class="math inline">\(U_j\)</span>.</li>
<li>If <span class="math inline">\(U_1 + .... + U_m\)</span> is a direct sum, then <span class="math inline">\(U_1 \oplus ... \oplus U_m\)</span> denotes <span class="math inline">\(U_1 + ... + U_m\)</span>, with the <span class="math inline">\(\oplus\)</span> indicating the direct sum.</li>
</ol>
<blockquote>
<p><span class="math display">\[U_1 = \{(x, y, 0) \in \mathbb{F}^3: x, y \in \mathbb{F}\}\]</span> <span class="math display">\[U_2 = \{(0, 0, z) \in \mathbb{F}^3: x, y \in \mathbb{F}\}\]</span> <span class="math display">\[U_3 = \{(0, y, y) \in \mathbb{F}^3: x, y \in \mathbb{F}\}\]</span></p>
<p>Then, <span class="math inline">\(U_1 + U_2 + U_3 = \mathbb{F}^3\)</span> is not a direct sum because the element <span class="math inline">\((0, 0, 0) \in \mathbb{F}^3\)</span>, can be written in two different ways using the sum:</p>
<p><span class="math display">\[(0, 1, 0) + (0, 0, 1) + (0, -1, -1) = (0, 0, 0)\]</span> <span class="math display">\[(0, 0, 0) + (0, 0, 0) + (0, 0, 0) = (0, 0, 0)\]</span></p>
</blockquote>
<h4 id="definition-1.44-condition-for-a-direct-sum">Definition 1.44 Condition for a Direct Sum</h4>
<p>Suppose <span class="math inline">\(U_1, ...., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U_1 + ... + U_m\)</span> is a direct sum if and only if the only way to write <span class="math inline">\(0\)</span> as a sum <span class="math inline">\(u_1 + ... + u_m\)</span>, where each <span class="math inline">\(u_j\)</span> is in <span class="math inline">\(U_j\)</span>, is by taking each <span class="math inline">\(u_j\)</span> equal to <span class="math inline">\(0\)</span>.</p>
<h4 id="definition-1.45-direct-sum-of-two-subspaces">Definition 1.45 Direct Sum of Two Subspaces</h4>
<p>Suppose <span class="math inline">\(U, W\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U + W\)</span> is a direct sum if and only if <span class="math inline">\(U \cap W = \{0\}\)</span>. <strong>The result only limit to two subspaces.</strong></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear Algebra (5)</title>
    <url>/2022/02/04/linear-algebra-5/</url>
    <content><![CDATA[<h1 id="linear-algebra-5">Linear Algebra (5)</h1>
<h2 id="operators-on-complex-vector-spaces">Operators on Complex Vector Spaces</h2>
<h3 id="null-spaces-of-powers-of-an-operator">Null Spaces of Powers of an Operator</h3>
<h4 id="theorem-8.2-sequence-of-increasing-null-spaces">Theorem 8.2: Sequence of Increasing Null Spaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then</p>
<p><span class="math display">\[\{0\} = \text{null }T^0 \subseteq \text{null }T^1 \subseteq ... \subseteq \text{null }T^k \subseteq .... \]</span></p>
<p>where <span class="math inline">\(T^0 = I\)</span> is the identity mapping in <span class="math inline">\(V\)</span>.</p>
<h5 id="proof-of-theorem-8.2">Proof of Theorem 8.2:</h5>
<p>Suppose <span class="math inline">\(k\)</span> is non-negative integer and <span class="math inline">\(v \in \text{null }T^k\)</span>, then <span class="math inline">\(T^k(v) = 0 \implies T^{k+1}(v) = TT^k(v) = T(0) = 0\)</span>, thus, <span class="math inline">\(\forall v \in \text{null }T^k\)</span>, <span class="math inline">\(v \in \text{null }T^{k+1}\)</span>.</p>
<p><br></p>
<span id="more"></span>
<h4 id="theorem-8.3-equality-in-the-sequence-of-null-spaces">Theorem 8.3: Equality in the Sequence of Null Spaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(m\)</span> is a non-negative integer such that <span class="math inline">\(\text{null }T^m = \text{null }T^{m+1}\)</span>. Then:</p>
<p><span class="math display">\[\text{null } T^m = \text{null }T^{m+1} = \text{null }T^{m+2} = ...\]</span></p>
<h5 id="proof-of-theorem-8.3">Proof of Theorem 8.3:</h5>
<p>Let <span class="math inline">\(k\)</span> be a positive integer, we want to prove:</p>
<p><span class="math display">\[\text{null } T^{m+k} = \text{null } T^{m+k+1}\]</span></p>
<p>Since we know by <code>theorem 8.2</code>, <span class="math inline">\(\text{null } T^{m+k} \subseteq \text{null } T^{m+k+1}\)</span>, we only need to prove:</p>
<p><span class="math display">\[\text{null } T^{m+k+1} \subseteq \text{null } T^{m+k}\]</span></p>
<p>Let <span class="math inline">\(v \in \text{null } T^{m+k+1}\)</span>, then:</p>
<p><span class="math display">\[T^{m + 1}(T^k (v)) = T^{m+k+1} (v) = 0\]</span></p>
<p>Thus, <span class="math inline">\(T^k(v) \in \text{null } T^{m+1}\)</span>, since <span class="math inline">\(\text{null } T^m = \text{null } T^{m+1}\)</span> by assumption, we have:</p>
<p><span class="math display">\[T^k(v) \in \text{null } T^m \implies T^m (T^k(v)) = T^{m+k} (v) = 0\]</span></p>
<p>Thus, <span class="math inline">\(\forall v \in \text{null } T^{m+k+1}\)</span>, we have <span class="math inline">\(v \in \text{null } T^{m+k}\)</span>.</p>
<h4 id="theorem-8.4-null-spaces-stop-growing">Theorem 8.4: Null Spaces Stop Growing</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then:</p>
<p><span class="math display">\[\text{null } T^n = \text{null } T^{n+1} = ....\]</span></p>
<p><br></p>
<h4 id="theorem-8.5-v-is-the-direct-sum-of-textnull-tdim-v-and-textrange-tdim-v">Theorem 8.5: <span class="math inline">\(V\)</span> is the Direct Sum of <span class="math inline">\(\text{null } T^{\dim V}\)</span> and <span class="math inline">\(\text{range } T^{\dim V}\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then:</p>
<p><span class="math display">\[V = \text{null } T^n \oplus \text{range } T^n\]</span></p>
<p><strong>In general, <span class="math inline">\(V \neq \text{null } T \oplus \text{range }T\)</span></strong>.</p>
<h4 id="proof-of-theorem-8.5">Proof of Theorem 8.5:</h4>
<p>We first show that:</p>
<p><span class="math display">\[(\text{null } T^n) \cap (\text{range }T^n) = \{0\}\]</span></p>
<p>Where <span class="math inline">\(n = \dim V\)</span>. Let <span class="math inline">\(v \in (\text{null } T^n) \cap (\text{range }T^n)\)</span>, then <span class="math inline">\(T^n(v) = 0\)</span> and <span class="math inline">\(\exists u \in V, T^n(u) = v\)</span>. Then we have:</p>
<p><span class="math display">\[T^n(T^n (u)) = T^n (v) = 0 \implies T^{2n} (u) = 0\]</span></p>
<p>By <code>theorem 8.4</code>, we have <span class="math inline">\(\text{null } T^{2n} = \text{null }T^n\)</span>, thus:</p>
<p><span class="math display">\[T^{n} (u) = v = 0\]</span></p>
<p>Thus, <span class="math inline">\(v = 0\)</span>.</p>
<p>Then by <code>theorem 1.45</code>, we have <span class="math inline">\((\text{null } T^n) \oplus (\text{range }T^n)\)</span>, then by <code>theorem 3.22</code>, we have:</p>
<p><span class="math display">\[\dim V = \dim\text{null } T^n + \dim\text{range }T^n = \dim \{(\text{null } T^n) \oplus (\text{range }T^n)\}\]</span></p>
<p><br></p>
<h4 id="definition-8.9-generalized-eigenvector">Definition 8.9: Generalized Eigenvector</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>. A vector <span class="math inline">\(v \in V\)</span> is called a <strong>generalized eigenvector</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(v \neq 0\)</span> and:</p>
<p><span class="math display">\[(T - \lambda I)^j (v) = 0\]</span></p>
<p>for some positive integer <span class="math inline">\(j\)</span>.</p>
<p><strong>Although <span class="math inline">\(j\)</span> is allowed to be an arbitrary integer in the equation, every generalized eigenvector satisfies this equation with <span class="math inline">\(j = \dim V\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-8.10-generalized-eigenspace-glambda-t">Definition 8.10: Generalized Eigenspace, <span class="math inline">\(G(\lambda, T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. The <strong>generalized eigenspace</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span>, denoted <span class="math inline">\(G(\lambda, T)\)</span>, is defined to be the set of all generalized eigenvectors of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> along with the <span class="math inline">\(0\)</span> vector.</p>
<p>If <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>, then:</p>
<p><span class="math display">\[E(\lambda, T) \subseteq G(\lambda, T)\]</span></p>
<p><strong>Generalized eigenspace is a subspace of <span class="math inline">\(V\)</span> because null space is subspace of <span class="math inline">\(V\)</span>.</strong></p>
<p><br></p>
<h4 id="theorem-8.11-description-of-generalized-eigenspaces">Theorem 8.11: Description of Generalized Eigenspaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Then:</p>
<p><span class="math display">\[G(\lambda, T) = \text{null }(T - \lambda I)^{\dim V}\]</span></p>
<h5 id="proof-of-theorem-8.11">Proof of Theorem 8.11:</h5>
<p>Suppose <span class="math inline">\(v \in \text{null }(T - \lambda I)^{\dim V}\)</span>, then <span class="math inline">\(v \in G(\lambda, T)\)</span> by <code>definition 8.10</code>.</p>
<p>Suppose <span class="math inline">\(v \in G(\lambda, T)\)</span>, then there exists an integer <span class="math inline">\(j\)</span> s.t <span class="math inline">\((T - \lambda I)^j (v) = 0\)</span>. If we let <span class="math inline">\(j = \dim V\)</span>, then by <code>theorem 8.2, 8.4</code>, we have:</p>
<p><span class="math display">\[v \in \text{null } (T - \lambda I)^{i}, \forall i \in \mathbb{Z}\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[v \in G(\lambda, T)\]</span></p>
<p><br></p>
<h4 id="theorem-8.13-linearly-independent-generalized-eigenvectors">Theorem 8.13: Linearly Independent Generalized Eigenvectors</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are distinct eigenvalues of <span class="math inline">\(T\)</span> and <span class="math inline">\(v_1, ..., v_m\)</span> are corresponding generalized eigenvectors. Then <span class="math inline">\(v_1, ..., v_m\)</span> is linearly independent.</p>
<p><br></p>
<h4 id="definition-8.16-nilpotent">Definition 8.16: Nilpotent</h4>
<p>An operator is called <strong>nilpotent</strong> if some power of it equals <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.18-nilpotent-operator-raised-to-dimension-of-domain-is-0">Theorem 8.18: Nilpotent Operator Raised to Dimension of Domain is <span class="math inline">\(0\)</span></h4>
<p>Suppose <span class="math inline">\(N \in L(V)\)</span> is nilpotent. Then <span class="math inline">\(N^{\dim V} = 0\)</span>.</p>
<h5 id="proof-of-theorem-8.18">Proof of Theorem 8.18</h5>
<p>Since <span class="math inline">\(N\)</span> is nilpotent, we have <span class="math inline">\(G(0, N) = V\)</span>, since for some integer <span class="math inline">\(j\)</span>, we have <span class="math inline">\(N^j = 0 \implies N^j(v) = 0, \; \forall v \in V\)</span>. Thus, by <code>theorem 8.11</code>, we have:</p>
<p><span class="math display">\[\text{null }(N)^{\dim V} = V\]</span></p>
<p>Thus, <span class="math inline">\(N^{\dim V} = 0\)</span>.</p>
<h4 id="theorem-8.19-matrix-of-a-nilpotent-operator">Theorem 8.19: Matrix of a Nilpotent Operator</h4>
<p>Suppose <span class="math inline">\(N\)</span> is a nilpotent operator on <span class="math inline">\(V\)</span>. Then there is a basis of <span class="math inline">\(V\)</span> w.r.t which the matrix of <span class="math inline">\(N\)</span> has the form:</p>
<p><span class="math display">\[
A = 
\begin{bmatrix}
0 &amp; ... &amp; *\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; 0\\
\end{bmatrix}
\]</span></p>
<p>here all entries on and below the diagonal are <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h3 id="decomposition-of-an-operator">Decomposition of an Operator</h3>
<h4 id="theorem-8.20-the-null-space-and-range-of-pt-are-invariant-under-t">Theorem 8.20: The Null Space and Range of <span class="math inline">\(p(T)\)</span> are Invariant Under <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(p \in P(\mathbb{F})\)</span>. Then <span class="math inline">\(\text{null } p(T)\)</span> and <span class="math inline">\(\text{range } p(T)\)</span> are invariant under <span class="math inline">\(T\)</span>.</p>
<h5 id="proof-of-theorem-8.21">Proof of Theorem 8.21:</h5>
<ol type="1">
<li><p><span class="math inline">\(\text{null } p(T)\)</span> is invariant under <span class="math inline">\(T\)</span>:</p>
<p>Suppose <span class="math inline">\(v \in \text{null } p(T)\)</span>, we want to show that <span class="math inline">\(p(T)(T(v)) = 0\)</span>. Thus, <span class="math inline">\(p(T) (v) = 0 \implies T(p(T)(v)) = T(0) = 0 = p(T) (T(v)) = 0\)</span></p></li>
<li><p><span class="math inline">\(\text{range } p(T)\)</span> is invariant under <span class="math inline">\(T\)</span>:</p>
<p>Suppose <span class="math inline">\(v \in \text{range } p(T)\)</span>, we want to show that <span class="math inline">\(T(v) = p(T)(u)\)</span> for some <span class="math inline">\(u \in V\)</span>. Let <span class="math inline">\(v = p(T)(u)\)</span>, then <span class="math inline">\(T(v) = T(p(T)(u)) = p(T)(T(u))\)</span>, let <span class="math inline">\(u = T(u)\)</span>, we have the desired result.</p></li>
</ol>
<p><br></p>
<h4 id="theorem-8.21-description-of-operators-on-complex-vector-space">Theorem 8.21: Description of Operators on Complex Vector Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> be the distinct eigenvalues of <span class="math inline">\(T\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(V = G(\lambda_1, T) \oplus ... \oplus G(\lambda_m, T)\)</span>.</li>
<li>Each <span class="math inline">\(G(\lambda_j, T)\)</span> is invariant under <span class="math inline">\(T\)</span>.</li>
<li>Each <span class="math inline">\((T - \lambda_j I )|_{G(\lambda_j, T)}\)</span> is nilpotent.</li>
</ol>
<p><br></p>
<h4 id="theorem-8.23-a-basis-of-generalized-eigenvectors">Theorem 8.23: A Basis of Generalized Eigenvectors</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then there is a basis of <span class="math inline">\(V\)</span> consisting of generalized eigenvectors of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="definition-8.24-multiplicity">Definition 8.24: Multiplicity</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. The <strong>multiplicity</strong> of an eigenvalue <span class="math inline">\(\lambda\)</span> of <span class="math inline">\(T\)</span> is defined to be the dimension of the corresponding generalized eigenspace <span class="math inline">\(G(\lambda, T)\)</span>.</p>
<p>In other words, the multiplicity of an eigenvalue <span class="math inline">\(\lambda\)</span> of <span class="math inline">\(T\)</span> equals <span class="math inline">\(\dim \text{null }(T - \lambda I)^{\dim V}\)</span>.</p>
<p>The <strong>algebraic multiplicity of <span class="math inline">\(\lambda\)</span></strong> is defined above.</p>
<p>The <strong>geometric multiplicity of <span class="math inline">\(\lambda\)</span></strong> is defined to be the dimension of corresponding eigenspace:</p>
<p><span class="math display">\[\dim E(\lambda, T)\]</span></p>
<p><br></p>
<h4 id="theorem-8.26-sum-of-the-multiplicities-equals-dim-v">Theorem 8.26: Sum of the Multiplicities Equals <span class="math inline">\(\dim V\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the sum of the multiplicities of all eigenvalues of <span class="math inline">\(T\)</span> equals <span class="math inline">\(\dim V\)</span>.</p>
<p><br></p>
<h4 id="definition-8.27-block-diagonal-matrix">Definition 8.27: Block Diagonal Matrix</h4>
<p>A <strong>block diagonal matrix</strong> is a square matrix of the form:</p>
<p><span class="math display">\[
\begin{bmatrix}
A_1 &amp; ... &amp; 0\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; A_m\\
\end{bmatrix}
\]</span></p>
<p>Where <span class="math inline">\(A_1, ..., A_m\)</span> are square matrices lying along the diagonal and all the other entries of the matrix equal 0. If <span class="math inline">\(A_1, ..., A_m\)</span> are <span class="math inline">\(1 \times 1\)</span> matrix, we have diagonal matrix.</p>
<p><br></p>
<h4 id="theorem-8.29-block-diagonal-matrix-with-upper-triangular-blocks">Theorem 8.29: Block Diagonal Matrix with Upper-Triangular Blocks</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> be the distinct eigenvalues of <span class="math inline">\(T\)</span>, with multiplicities <span class="math inline">\(d_1, ..., d_m\)</span>. Then there is a basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has a <strong>block diagonal matrix</strong> of the form:</p>
<p><span class="math display">\[
\begin{bmatrix}
A_1 &amp; ... &amp; 0\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; A_m\\
\end{bmatrix}
\]</span></p>
<p>Where each <span class="math inline">\(A_j\)</span> is a <span class="math inline">\(d_j \times d_j\)</span> upper-triangular matrix of the form:</p>
<p><span class="math display">\[
A_i = 
\begin{bmatrix}
\lambda_j &amp; ... &amp; *\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; \lambda_j\\
\end{bmatrix}
\]</span></p>
<p><br></p>
<h4 id="theorem-8.31-identity-plus-nilpotent-has-a-square-root">Theorem 8.31: Identity Plus Nilpotent Has a Square Root</h4>
<p>Suppose <span class="math inline">\(N \in L(V)\)</span> is nilpotent. Then <span class="math inline">\(I + N\)</span> has a square root.</p>
<p><br></p>
<h4 id="theorem-8.33-over-mathbbc-invertible-operators-have-square-roots">Theorem 8.33: Over <span class="math inline">\(\mathbb{C}\)</span>, Invertible Operators Have Square Roots</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span> is invertible. Then <span class="math inline">\(T\)</span> has a square root.</p>
<p><br></p>
<h3 id="characteristic-and-minimal-polynomials">Characteristic and Minimal Polynomials</h3>
<h4 id="definition-8.34-characteristic-polynomial-complex-vector-space">Definition 8.34: Characteristic Polynomial (<strong>Complex Vector Space</strong>)</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space, and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> denote the distinct eigenvalues of <span class="math inline">\(T\)</span>, with multiplicities <span class="math inline">\(d_1, ..., d_m\)</span>. The polynomial <span class="math inline">\(q\)</span> defined as:</p>
<p><span class="math display">\[q(z) = (z - \lambda_1)^{d_1} ... (z - \lambda_m)^{d_m}\]</span></p>
<p>is called the <strong>characteristic polynomial</strong> of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.36-degree-and-zeros-of-characteristic-polynomial">Theorem 8.36: Degree and Zeros of Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then:</p>
<ol type="a">
<li>The characteristic polynomial of <span class="math inline">\(T\)</span> has degree <span class="math inline">\(\dim V\)</span>.</li>
<li>The zeros of the characteristic polynomial of <span class="math inline">\(T\)</span> are the eigenvalues of <span class="math inline">\(T\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-8.37-cayley-hamilton-theorem-this-also-works-for-real-vector-space-see-theorem-9.24">Theorem 8.37: Cayley-Hamilton Theorem (<strong>This also works for real vector space</strong>, see <code>theorem 9.24</code>)</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(q\)</span> denotes the characteristic polynomial of <span class="math inline">\(T\)</span>. Then <span class="math inline">\(q(T) = 0\)</span>.</p>
<h5 id="proof-of-theorem-8.37">Proof of Theorem 8.37:</h5>
<p>Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> be eigenvalues of <span class="math inline">\(T\)</span> and <span class="math inline">\(d_1, ..., d_m\)</span> be dimensions of the corresponding generalized eigenspace <span class="math inline">\(G(\lambda_1, T), ... ,G(\lambda_m, T)\)</span>. Then by <code>theorem 8.18</code>, we have:</p>
<p><span class="math display">\[(T - \lambda_j I)^{d_j}|_{G(\lambda_j, T)} = 0\]</span></p>
<p>Since <span class="math inline">\(V\)</span> is direct sum of the generalized eigenspaces, we can write every <span class="math inline">\(v \in V\)</span> as <span class="math inline">\(v = g_1, ...., g_m, \; g_1 \in G(\lambda_1, T), g_m \in G(\lambda_m, T)\)</span> and:</p>
<p><span class="math display">\[q(T) (v) = q(T) (g_1) + .... + q(T)(g_m)\]</span></p>
<p>Thus, to show that <span class="math inline">\(q(T) = 0\)</span>, we only need to show that</p>
<p><span class="math display">\[q(T)|_{G(\lambda_j, T)} = 0, \; \forall j=1, ..., m\]</span></p>
<p>We have:</p>
<p><span class="math display">\[q(T) = (T - \lambda_1 I)^{d_1} .... (T - \lambda_m I)^{d_m}\]</span></p>
<p>For every <span class="math inline">\(g_1 \in G(\lambda_1, T)\)</span>, we can write (by <code>theorem 5.20</code>):</p>
<p><span class="math display">\[q(T) (g_1) = (T - \lambda_m I)^{d_m} .... ((T - \lambda_1 I)^{d_1} (g_1)) = 0\]</span></p>
<p><br></p>
<h4 id="definition-8.38-monic-polynomial">Definition 8.38: Monic Polynomial</h4>
<p>A <strong>monic polynomial</strong> is a polynomial whose <strong>highest-degree coefficient</strong> equals <span class="math inline">\(1\)</span>.</p>
<blockquote>
<p><span class="math inline">\(z\)</span></p>
<p><span class="math inline">\(2 + 6z^2 + z^7\)</span></p>
</blockquote>
<p><br></p>
<h4 id="theorem-8.40-minimal-polynomial">Theorem 8.40: Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then there is a unique monic polynomial <span class="math inline">\(p\)</span> of the smallest degree such that <span class="math inline">\(p(T) = 0\)</span>.</p>
<p><br></p>
<h4 id="definition-8.43-minimal-polynomial">Definition 8.43: Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the <strong>minimal polynomial</strong> of <span class="math inline">\(T\)</span> is the unique monic polynomial <span class="math inline">\(p\)</span> of the smallest degree such that <span class="math inline">\(p(T) = 0\)</span></p>
<p>From <code>theorem 8.37, 8.36</code>, we know that if <span class="math inline">\(V\)</span> is a complex vector space, then <span class="math inline">\(p\)</span> has degree at most <span class="math inline">\(\dim V\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.46-qt-0-implies-q-is-a-multiple-of-the-minimal-polynomial">Theorem 8.46: <span class="math inline">\(q(T) = 0 \implies q\)</span> is a Multiple of the Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(q \in P(\mathbb{F})\)</span>. Then <span class="math inline">\(q(T) = 0\)</span> IFF <span class="math inline">\(q\)</span> is a polynomial multiple of the minimal polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.48-characteristic-polynomial-is-a-multiple-of-minimal-polynomial-complex-vector-space">Theorem 8.48: Characteristic Polynomial is a Multiple of Minimal Polynomial (<strong>Complex Vector Space</strong>)</h4>
<p>Suppose <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then the characteristic polynomial of <span class="math inline">\(T\)</span> is a polynomial multiple of the minimal polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.49-eigenvalues-are-the-zeros-of-the-minimal-polynomial">Theorem 8.49: Eigenvalues are the Zeros of the Minimal Polynomial</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Then the zeros of the minimal polynomial of <span class="math inline">\(T\)</span> are precisely the eigenvalues of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h3 id="jordan-form">Jordan Form</h3>
<h4 id="theorem-8.55-basis-corresponding-to-a-nilpotent-operator">Theorem 8.55: Basis Corresponding to a Nilpotent Operator</h4>
<p>Suppose <span class="math inline">\(N \in L(V)\)</span> is nilpotent. Then there exist vectors <span class="math inline">\(v_1, ..., v_n \in V\)</span> and non-negative integer <span class="math inline">\(m_1, ..., m_n\)</span> s.t:</p>
<ol type="a">
<li><span class="math inline">\(N^{m_1}(v_1), ...., N(v_1), v_1, ..., N^{m_n}(v_n), ..., N(v_n)\)</span> is a basis of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(N^{m_1 + 1} (v_1) = ... = N^{m_n + 1}(v_n) = 0\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-8.59-jordan-basis">Definition 8.59: Jordan Basis</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. A basis of <span class="math inline">\(V\)</span> is called <strong>jordan basis</strong> for <span class="math inline">\(T\)</span> if with respect to this basis <span class="math inline">\(T\)</span> has a block diagonal matrix"</p>
<p><span class="math display">\[
\begin{bmatrix}
A_1 &amp; ... &amp; 0\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; A_m\\
\end{bmatrix}
\]</span></p>
<p>where each <span class="math inline">\(A_j\)</span> is an upper-triangular matrix of the form:</p>
<p><span class="math display">\[
A_j = 
\begin{bmatrix}
\lambda_j &amp; 1 &amp;  &amp; 0\\
 &amp;  &amp; 1 &amp; \\
 &amp;  &amp;  &amp; 1\\
0 &amp;  &amp;  &amp; \lambda_j\\
\end{bmatrix}
\]</span></p>
<h4 id="theorem-8.60-jordan-form">Theorem 8.60: Jordan Form</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space. If <span class="math inline">\(T \in L(V)\)</span>, then there is a basis of <span class="math inline">\(V\)</span> that is a jordan basis for <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h2 id="operators-on-real-vector-spaces">Operators on Real Vector Spaces</h2>
<h3 id="complexification">Complexification</h3>
<h4 id="definition-9.2-complexification-of-v-v_c">Definition 9.2: Complexification of <span class="math inline">\(V, V_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space.</p>
<ul>
<li>The <strong>complexification</strong> of <span class="math inline">\(V\)</span>, denoted <span class="math inline">\(V_C\)</span>, equals <span class="math inline">\(V \times V\)</span>. An element of <span class="math inline">\(V_C\)</span> is an ordered pair <span class="math inline">\(u, v\)</span> where <span class="math inline">\(u, v \in V\)</span>, but we will write this as <span class="math inline">\(u + iv\)</span>.</li>
<li>Addition on <span class="math inline">\(V_C\)</span> is defined by: <span class="math display">\[(u_1 + iv_1) + (u_2 + iv_2) = (u_1 + u_2) + i(v_1 + v_2)\]</span> for <span class="math inline">\(u_1, v_1, u_2, v_2 \in V\)</span></li>
<li>Complex scalar multiplication on <span class="math inline">\(V_C\)</span> is defined by: <span class="math display">\[(a + bi)(u + iv) = (au - bv) + i(av + bu)\]</span></li>
</ul>
<p>We can think of <span class="math inline">\(V\)</span> as a subset of <span class="math inline">\(V_C\)</span> by identifying <span class="math inline">\(u \in V\)</span> with <span class="math inline">\(u + i0\)</span></p>
<p><br></p>
<h4 id="theorem-9.3-v_c-is-a-complex-vector-space">Theorem 9.3: <span class="math inline">\(V_C\)</span> is a complex vector space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space. Then with the definition of addition and scalar multiplication above, <span class="math inline">\(V_C\)</span> is a complex vector space.</p>
<p><br></p>
<h4 id="theorem-9.4-basis-of-v-is-a-basis-of-v_c">Theorem 9.4: Basis of <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space.</p>
<ol type="1">
<li>If <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, then <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V_C\)</span>.</li>
<li>The dimension of <span class="math inline">\(V_C\)</span> equals the dimension of <span class="math inline">\(V\)</span> (<span class="math inline">\(\dim(V \times V) = \dim V + \dim V\)</span> over same <span class="math inline">\(\mathbb{F}\)</span>, in this case, we extend from <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span> to <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span>).</li>
</ol>
<p><br></p>
<h4 id="definition-9.5-complexification-of-t-t_c">Definition 9.5: Complexification of <span class="math inline">\(T, T_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. The <strong>complexification</strong> of <span class="math inline">\(T\)</span>, denoted <span class="math inline">\(T_C\)</span>, is the operator <span class="math inline">\(T_C \in L(V_C)\)</span> defined by:</p>
<p><span class="math display">\[T_C(u + iv) = T(u) + iT(v)\]</span></p>
<p>for <span class="math inline">\(u, v \in V\)</span></p>
<blockquote>
<p>Suppose <span class="math inline">\(A\)</span> is a <span class="math inline">\(n \times n\)</span> matrix of real numbers. Define <span class="math inline">\(T \in L(\mathbb{R}^n)\)</span> by <span class="math inline">\(T(x) = Ax\)</span> where the element in <span class="math inline">\(\mathbb{R}^n\)</span> are though of as <span class="math inline">\(n \times 1\)</span> column vectors. Then, we have <span class="math inline">\(T_C(z) = Az\)</span>, where <span class="math inline">\(z \in \mathbb{C}^n\)</span>. <strong>Thus, we can think of <span class="math inline">\(T_C\)</span> as matrix multiplication by the same <span class="math inline">\(A\)</span> of <span class="math inline">\(T\)</span> on <span class="math inline">\(\mathbb{R}^n\)</span> that acts on larger domain <span class="math inline">\(\mathbb{C}^n\)</span>.</strong></p>
</blockquote>
<p><br></p>
<h4 id="theorem-9.7-matrix-of-t_c-equals-matrix-of-t">Theorem 9.7: Matrix of <span class="math inline">\(T_C\)</span> equals Matrix of <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space with basis <span class="math inline">\(v_1, .., v_n\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(M(T) = M(T_C)\)</span>, where both matrices are w.r.t the basis <span class="math inline">\(v_1, ..., v_n\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.8-every-operator-has-an-invariant-subspace-of-dimension-1-or-2">Theorem 9.8: Every Operator Has an Invariant Subspace of Dimension 1 or 2</h4>
<p>Every operator on a nonzero finite-dimensional vector space has an invariant subspace of dimension 1 or 2.</p>
<p><br></p>
<h4 id="theorem-9.10-minimal-polynomial-of-t_c-equals-minimal-polynomial-of-t">Theorem 9.10: Minimal Polynomial of <span class="math inline">\(T_C\)</span> Equals Minimal Polynomial of <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the minimal polynomial of <span class="math inline">\(T_C\)</span> equals the minimal polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.11-real-eigenvalues-of-t_c">Theorem 9.11: Real Eigenvalues of <span class="math inline">\(T_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, and <span class="math inline">\(\lambda \in \mathbb{R}\)</span>. Then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span> if and only if <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>.</p>
<h5 id="proof-of-theorem-9.11">Proof of Theorem 9.11:</h5>
<p>The real eigenvalues of <span class="math inline">\(T\)</span> are the real zeros of the minimal polynomial of <span class="math inline">\(T\)</span>. The real eigenvalues of <span class="math inline">\(T_C\)</span> are the real zeros of minimal polynomial of <span class="math inline">\(T_C\)</span>. Since their polynomials are the same, we can conclude that the real eigenvalues of <span class="math inline">\(T, T_C\)</span> are the same.</p>
<p><br></p>
<h4 id="theorem-9.12-t_c---lambda-i-t_c---barlambda-i">Theorem 9.12 <span class="math inline">\(T_C - \lambda I, T_C - \bar{\lambda} I\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, <span class="math inline">\(\lambda \in \mathbb{C}\)</span>, <span class="math inline">\(j\)</span> is a non-negative integer, and <span class="math inline">\(u, v \in V\)</span>. Then:</p>
<p><span class="math display">\[(T_C - \lambda I)^j (u + iv) = 0 \quad \text{ IFF } \quad (T_C - \bar{\lambda} I)^j (u - iv) = 0\]</span></p>
<p><br></p>
<h4 id="theorem-9.16-non-real-eigenvalues-of-t_c-come-in-pairs">Theorem 9.16: Non-real Eigenvalues of <span class="math inline">\(T_C\)</span> Come in Pairs</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, and <span class="math inline">\(\lambda \in \mathbb{C}\)</span>. Then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span> IFF <span class="math inline">\(\bar{\lambda}\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.17-multiplicity-of-lambda-equals-multiplicity-of-barlambda">Theorem 9.17: Multiplicity of <span class="math inline">\(\lambda\)</span> Equals Multiplicity of <span class="math inline">\(\bar{\lambda}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, <span class="math inline">\(\lambda \in \mathbb{C}\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span>. Then the multiplicity of <span class="math inline">\(\lambda\)</span> as an eigenvalue of <span class="math inline">\(T_C\)</span> equals the multiplicity of <span class="math inline">\(\bar{\lambda}\)</span> as an eigenvalue of <span class="math inline">\(T_C\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.19-operator-on-odd-dimensional-vector-space-has-eigenvalue">Theorem 9.19: Operator on Odd-dimensional Vector Space Has Eigenvalue</h4>
<p>Every operator on an odd-dimensional real vector space has an eigenvalue.</p>
<h5 id="proof-of-theorem-9.19">Proof of Theorem 9.19:</h5>
<p>Since all complex eigenvalues of <span class="math inline">\(T_C\)</span> comes in conjugate pairs and the dimensions of generalized eigenspaces add up to the dimension of <span class="math inline">\(V_C\)</span>, we have that at least 1 real eigenvalue exists.</p>
<p><br></p>
<h4 id="theorem-9.20-characteristic-polynomial-of-t_c">Theorem 9.20 Characteristic Polynomial of <span class="math inline">\(T_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the coefficients of the characteristic polynomial of <span class="math inline">\(T_C\)</span> are all real.</p>
<p><br></p>
<h4 id="definition-9.21-characteristic-polynomial">Definition 9.21: Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the <strong>characteristic polynomial</strong> of <span class="math inline">\(T\)</span> is defined to be the characteristic polynomial of <span class="math inline">\(T_C\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.23-degree-and-zeros-of-characteristic-polynomials">Theorem 9.23: Degree and Zeros of Characteristic Polynomials</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then:</p>
<ol type="1">
<li>The coefficients of the characteristic polynomial of <span class="math inline">\(T\)</span> are all real.</li>
<li>The characteristic polynomial of <span class="math inline">\(T\)</span> has degree <span class="math inline">\(\dim V\)</span>.</li>
<li>The eigenvalues of <span class="math inline">\(T\)</span> are precisely the real zeros of the characteristic polynomial of <span class="math inline">\(T\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-9.24-cayley-hamilton-theorem">Theorem 9.24: Cayley-Hamilton Theorem</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(q\)</span> denotes the characteristic polynomial of <span class="math inline">\(T\)</span>, then <span class="math inline">\(q(T) = 0\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.26-characteristic-polynomial-is-a-multiple-of-minimal-polynomial">Theorem 9.26: Characteristic Polynomial is a Multiple of Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then:</p>
<ol type="1">
<li>The degree of minimal polynomial of <span class="math inline">\(T\)</span> is at most <span class="math inline">\(\dim V\)</span>.</li>
<li>The characteristic polynomial of <span class="math inline">\(T\)</span> is a polynomial multiple of the minimal polynomial of <span class="math inline">\(T\)</span>.</li>
</ol>
<p><br></p>
<h3 id="operators-on-real-inner-product-spaces">Operators on Real Inner Product Spaces</h3>
<h4 id="theorem-9.27-normal-but-not-self-ajoint-operators">Theorem 9.27: Normal But Not Self-Ajoint Operators</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a 2-dimensional real inner product space and <span class="math inline">\(T \in L(V)\)</span>.</p>
<p>Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is normal but not self-adjoint.</li>
<li>The matrix of <span class="math inline">\(T\)</span> w.r.t every orthonormal basis of <span class="math inline">\(V\)</span> has the form: <span class="math display">\[
 \begin{bmatrix}
 a &amp; -b\\
 b &amp; a\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(b \neq 0\)</span></li>
<li>The matrix of <span class="math inline">\(T\)</span> w.r.t some orthonormal basis of <span class="math inline">\(V\)</span> has the form: <span class="math display">\[
 \begin{bmatrix}
 a &amp; -b\\
 b &amp; a\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(b &gt; 0\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-9.30-normal-operators-and-invariant-subspaces">Theorem 9.30: Normal Operators and Invariant Subspaces</h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner-product space, <span class="math inline">\(T \in L(V)\)</span> is normal, and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> that is invariant under <span class="math inline">\(T\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(U^{\perp}\)</span> is invariant under <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(U\)</span> is invariant under <span class="math inline">\(T^*\)</span>.</li>
<li><span class="math inline">\((T|_U)^* = (T^*)|_U\)</span></li>
<li><span class="math inline">\(T|_U \in L(U)\)</span> and <span class="math inline">\(T|_{U^{\perp}} \in L(U^{\perp})\)</span> are normal operators.</li>
</ol>
<p><br></p>
<h4 id="theorem-9.34-characterization-of-normal-operators-when-mathbbf-mathbbr">Theorem 9.34 Characterization of Normal Operators When <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real inner product space and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is normal.</li>
<li>There is an orthonormal basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has a block diagonal matrix s.t each block is a <span class="math inline">\(1 \times 1\)</span> matrix or a <span class="math inline">\(2 \times 2\)</span> matrix of the form: <span class="math display">\[
 \begin{bmatrix}
 a &amp; -b\\
 b &amp; a\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(b &gt; 0\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-9.36-description-of-isometries-when-mathbbf-mathbbr">Theorem 9.36: Description of Isometries When <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real inner product space and <span class="math inline">\(S \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(S\)</span> is an isometry.</li>
<li>There is an orthonormal basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(S\)</span> has a block diagonal matrix such that each block on the diagonal is a <span class="math inline">\(1 \times 1\)</span> matrix containing <span class="math inline">\(1\)</span> or <span class="math inline">\(-1\)</span> or is a <span class="math inline">\(2 \times 2\)</span> matrix of the form: <span class="math display">\[
 \begin{bmatrix}
 \cos \theta &amp; -\sin \theta\\
 \sin \theta &amp; \cos \theta\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(\theta \in (0, \pi)\)</span></li>
</ol>
<p><br></p>
<h2 id="trace-and-determinant">Trace and Determinant</h2>
<h3 id="trace">Trace</h3>
<h4 id="definition-10.2-identity-matrix-i">Definition 10.2: Identity Matrix, <span class="math inline">\(I\)</span></h4>
<p>Suppose <span class="math inline">\(n\)</span> is a positive integer. The <span class="math inline">\(n \times n\)</span> diagonal matrix:</p>
<p><span class="math display">\[
\begin{bmatrix}
1 \theta &amp; 0\\
0 &amp; \cos 1\\
\end{bmatrix}
\]</span></p>
<p>is called the <strong>identity matrix</strong> and is denoted <span class="math inline">\(I\)</span>. With respect to every basis of <span class="math inline">\(V\)</span>, the matrix of identity operator <span class="math inline">\(I \in L(V)\)</span> is the identity matrix.</p>
<p><br></p>
<h4 id="definition-10.3-invertible-inverse-a-1-non-singular">Definition 10.3, Invertible, inverse, <span class="math inline">\(A^{-1}\)</span> (<strong>non-singular</strong>)</h4>
<p>A square matrix <span class="math inline">\(A\)</span> is called <strong>invertible</strong> if there is a unique matrix <span class="math inline">\(B\)</span> of the same size such that <span class="math inline">\(AB = BA = I\)</span>. We call <span class="math inline">\(B\)</span> the <strong>inverse</strong> of <span class="math inline">\(A\)</span> and denotes it by <span class="math inline">\(A^{-1}\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.4-the-matrix-of-the-product-of-linear-maps">Theorem 10.4: The Matrix of the Product of Linear Maps</h4>
<p>Suppose <span class="math inline">\(u_1, ..., u_n\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> and <span class="math inline">\(w_1, ..., w_n\)</span> are all bases of <span class="math inline">\(V\)</span>. Suppose <span class="math inline">\(S, T \in L(V)\)</span>. Then:</p>
<p><span class="math display">\[M(ST, (u_1, ..., u_n), (w_1, ..., w_n)) = M(S, (v_1,....,v_n), (w_1, ..., w_n))M(T, (u_1, ..., u_n), (v_1, ..., v_n)\]</span></p>
<p><br></p>
<h4 id="theorem-10.5-matrix-of-the-identity-w.r.t-two-bases">Theorem 10.5: Matrix of the Identity w.r.t Two Bases</h4>
<p>Suppose <span class="math inline">\(u_1, ..., u_n\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> are bases of <span class="math inline">\(V\)</span>. Then the matrices <span class="math inline">\(M(I, (u_1, ..., u_n), (v_1, ..., v_n)))\)</span> and <span class="math inline">\(M(I, (v_1, .., v_n), (u_1, ..., u_n))\)</span> are invertible, and each is the inverse of the other.</p>
<h5 id="proof-of-theorem-10.5">Proof of Theorem 10.5:</h5>
<p>Let <span class="math inline">\(u_j = w_j\)</span> in <code>theorem 10.4</code>, then we have:</p>
<p><span class="math display">\[M(II, (u_j), (u_j)) = M(I, (v_j), (u_j))M(I, (u_j)(v_j)) = I\]</span></p>
<p>interchange the role of <span class="math inline">\(v_j, u_j\)</span> we have</p>
<p><span class="math display">\[M(II, (v_j), (v_j)) = M(I, (u_j), (v_j))M(I, (v_j)(u_j)) = I\]</span></p>
<p><br></p>
<h4 id="theorem-10.7-change-of-basis-formula">Theorem 10.7: Change of Basis Formula</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(u_1, ..., u_n\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> be bases of <span class="math inline">\(V\)</span>. Let <span class="math inline">\(A = M(I, (u_1, ..., u_n), (v_1, ..., v_n))\)</span>. Then:</p>
<p><span class="math display">\[M(T, (u_1, ..., u_n)) = A^{-1} M(T, (v_1, ..., v_n)) A\]</span></p>
<h5 id="proof-of-theorem-10.7">Proof of Theorem 10.7</h5>
<p>By <code>theorem 10.4</code>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(u_j\)</span>, we have:</p>
<p><span class="math display">\[M(IT, (u_j), (v_j))) = M(I, (v_j), (u_j)) M(T, (u_j), (v_j)) = A^{-1} M(T, (u_j), (v_j))\]</span></p>
<p>By <code>theorem 10.4</code>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(v_j\)</span>, we have:</p>
<p><span class="math display">\[M(IT, (u_j), (v_j))) = A^{-1} M(T, (u_j), (v_j)) M(T, (v_j), (v_j)) M(I, (u_j), (v_j)) = A^{-1} M(T, (v_j)) A\]</span></p>
<p><br></p>
<h4 id="definition-10.9-trace-of-an-operator">Definition 10.9: Trace of an Operator</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>:</p>
<ul>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span>, then the <strong>trace</strong> of <span class="math inline">\(T\)</span> is the sum of eigenvalues of <span class="math inline">\(T\)</span>, with each eigenvalue repeated according to its multiplicity.</li>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the <strong>trace</strong> of <span class="math inline">\(T\)</span> is the sum of the eigenvalues of <span class="math inline">\(T_C\)</span>, with each eigenvalue repeated according to its multiplicity.</li>
</ul>
<p><span class="math display">\[tr(T) = d_1 \lambda_1 + ... + d_m \lambda_m\]</span></p>
<p>Where <span class="math inline">\(\lambda_i\)</span> are eigenvalues of <span class="math inline">\(T_C\)</span> or <span class="math inline">\(T\)</span> depends on <span class="math inline">\(\mathbb{F}\)</span>, and <span class="math inline">\(d_i\)</span> are multiplicities of eigenvalues.</p>
<p><br></p>
<h4 id="theorem-10.12-trace-and-characteristic-polynomial">Theorem 10.12: Trace and Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then <span class="math inline">\(tr(T)\)</span> equals the negative of the coefficient of <span class="math inline">\(z^{n-1}\)</span> in the characteristic polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="definition-10.13-trace-of-a-matrix">Definition 10.13: Trace of a Matrix</h4>
<p>The <strong>trace</strong> of a square matrix <span class="math inline">\(A\)</span>, denoted trace <span class="math inline">\(A\)</span>, is defined to be the sum of the diagonal entries of <span class="math inline">\(A\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.14-trab-trba">Theorem 10.14: <span class="math inline">\(tr(AB) = tr(BA)\)</span></h4>
<p>If <span class="math inline">\(A, B\)</span> are square matrices of the same size, then:</p>
<p><span class="math display">\[tr(AB) = tr(BA)\]</span></p>
<p><br></p>
<h4 id="theorem-10.15-trace-of-matrix-of-operator-does-not-depend-on-basis">Theorem 10.15: Trace of Matrix of Operator Does Not Depend on Basis</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(v_1, ..., v_n\)</span> and <span class="math inline">\(u_1, ..., u_n\)</span> are bases of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[tr(M(T, (u_1, ..., u_n))) = tr(M(T, (v_1, ..., v_n)))\]</span></p>
<p><br></p>
<h4 id="theorem-10.16-trace-of-an-operator-equals-trace-of-its-matrix">Theorem 10.16: Trace of an Operator Equals Trace of Its Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(tr(T) = tr(M(T))\)</span>.</p>
<p>This implies that the sum of eigenvalues of <span class="math inline">\(T\)</span> or <span class="math inline">\(T_C\)</span> is equal to the sum of diagonal of matrix of <span class="math inline">\(T\)</span> regardless of the basis.</p>
<p><br></p>
<h4 id="theorem-10.18-trace-is-additive">Theorem 10.18: Trace is Additive</h4>
<p>Suppose <span class="math inline">\(S, T \in L(V)\)</span>. Then <span class="math inline">\(tr(S + T) = tr(S) + tr(T)\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.19-the-identity-is-not-the-difference-of-st-and-ts">Theorem 10.19: The Identity is not the Difference of <span class="math inline">\(ST\)</span> and <span class="math inline">\(TS\)</span></h4>
<p>There do not exist operators <span class="math inline">\(S, T \in L(V)\)</span> s.t <span class="math inline">\(ST - TS = I\)</span></p>
<p><br></p>
<h3 id="determinant">Determinant</h3>
<h4 id="determinant-of-an-operator-det-t">Determinant of an Operator, <span class="math inline">\(\det T\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span></p>
<ul>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span>, then the <strong>determinant</strong> of <span class="math inline">\(T\)</span> is the product of the eigenvalues of <span class="math inline">\(T\)</span> with each eigenvalue repeated according to its multiplicity.</li>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the <strong>determinant</strong> of <span class="math inline">\(T\)</span> is the product of the eigenvalues of <span class="math inline">\(T_C\)</span> with each eigenvalue repeated according to its multiplicity.</li>
</ul>
<p>The determinant of <span class="math inline">\(T\)</span> is denoted by <span class="math inline">\(\det T\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.22-determinant-and-characteristic-polynomial">Theorem 10.22: Determinant and Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then <span class="math inline">\(\det T\)</span> equals <span class="math inline">\((-1)^n\)</span> times the constant term of the characteristic polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.23-characteristic-polynomial-trace-and-determinant">Theorem 10.23: Characteristic Polynomial, Trace and Determinant</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the characteristic polynomial of <span class="math inline">\(T\)</span> can be written as:</p>
<p><span class="math display">\[z^n - (tr(T)) z^{n-1} + ... + (-1)^n \det T\]</span></p>
<p><br></p>
<h4 id="theorem-10.24-invertible-is-equivalent-to-nonzero-determinant">Theorem 10.24: Invertible is Equivalent to Nonzero Determinant</h4>
<p>An operator on <span class="math inline">\(V\)</span> is invertible IFF its determinant is nonzero.</p>
<h5 id="proof-of-theorem-10.24">Proof of Theorem 10.24:</h5>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>, then by <code>theorem 5.30</code>, <span class="math inline">\(T\)</span> is invertible IFF all its eigenvalues are nonzero. Clearly this happens IFF the product of the eigenvalues of <span class="math inline">\(T\)</span> is not 0.</p>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, then if 0 is not an eigenvalue of <span class="math inline">\(T\)</span>, then the eigenvalues of <span class="math inline">\(T_C\)</span> do not contain 0, thus the product of eigenvalues does not equal 0.</p>
<p><br></p>
<h4 id="theorem-10.25-characteristic-polynomial-of-t-equals-det-zi---t">Theorem 10.25: Characteristic Polynomial of <span class="math inline">\(T\)</span> Equals <span class="math inline">\(\det (zI - T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the characteristic polynomial of <span class="math inline">\(T\)</span> equals <span class="math inline">\(\det (zI - T)\)</span>.</p>
<h5 id="proof-of-theorem-10.25">Proof of Theorem 10.25:</h5>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space, if <span class="math inline">\(\lambda, z \in \mathbb{C}\)</span>, then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span> IFF <span class="math inline">\(z - \lambda\)</span> is an eigenvalue of <span class="math inline">\((zI - T)\)</span> because:</p>
<p><span class="math display">\[-(T - \lambda I) = (\underbrace{(zI - T)}_{\text{operator}} - \underbrace{(z - \lambda)}_{\text{eigenvalue}} I)\]</span></p>
<p>Then we have:</p>
<p><span class="math display">\[\dim (\text{null }(-(T - \lambda I))^{\dim V}) = \dim (\text{null }((zI - T) - (z - \lambda))^{\dim V})\]</span></p>
<p>Suppose <span class="math inline">\(T\)</span> has eigenvalues <span class="math inline">\(\lambda_1, ..., \lambda_n\)</span> repeated to its multiplicity, then we have <span class="math inline">\((z - \lambda_1), ...., (z - \lambda_n)\)</span> as eigenvalues of <span class="math inline">\(zI - T\)</span> repeated to its multiplicity. Thus, we have:</p>
<p><span class="math display">\[\det(zI - T) = (z - \lambda_1) .... (z - \lambda_n)\]</span></p>
<p>Which is the same as the characteristic polynomial of <span class="math inline">\(T\)</span> with eigenvalues <span class="math inline">\(\lambda_1, ..., \lambda_n\)</span> repeated to its multiplicity.</p>
<p>The proof of real vector space is the same as complex vector space.</p>
<p><br></p>
<h4 id="definition-10.27-permutation-textperm-n">Definition 10.27: Permutation, <span class="math inline">\(\text{perm } n\)</span></h4>
<ul>
<li>A <strong>permutation</strong> of <span class="math inline">\((1 ,..., n)\)</span> is a list <span class="math inline">\((m_1, ..., m_n)\)</span> that contains each of the numbers <span class="math inline">\(1, ..., n\)</span> exactly once.</li>
<li>The set of all permutations of <span class="math inline">\((1, ..., n)\)</span> is denoted <span class="math inline">\(\text{perm } n.\)</span></li>
</ul>
<p>We should think of an element of <span class="math inline">\(\text{perm } n\)</span> as a rearrangement of the first <span class="math inline">\(n\)</span> items of the list.</p>
<p><br></p>
<h4 id="definition-10.30-sign-of-a-permutation">Definition 10.30: Sign of a Permutation</h4>
<ul>
<li>The <strong>sign</strong> of a permutation <span class="math inline">\((m_1, ..., m_n)\)</span> is defined to be <span class="math inline">\(1\)</span> if the number of paris of integers <span class="math inline">\((j, k)\)</span> with <span class="math inline">\(1 \leq j &lt; k \leq n\)</span> s.t <span class="math inline">\(j\)</span> appears after <span class="math inline">\(k\)</span> in the list <span class="math inline">\((m_1, ..., m_n)\)</span> is even and <span class="math inline">\(-1\)</span> if the number of such pairs is odd.</li>
<li>In other words, the sign of a permutation equals <span class="math inline">\(1\)</span> if the natural order has been changed an even number of times and equals <span class="math inline">\(-1\)</span> if the natural order has been changed an odd number times.</li>
</ul>
<blockquote>
<p>The only par of integers <span class="math inline">\((j, k)\)</span> with <span class="math inline">\(j &lt; k\)</span> s.t <span class="math inline">\(j\)</span> appears after <span class="math inline">\(k\)</span> in the permutation <span class="math inline">\(2, 1, 3, 4\)</span> is (1, 2), thus, the permutation has sign 1.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-10.32-interchanging-two-entries-in-a-permutation">Theorem 10.32: Interchanging Two Entries in a Permutation</h4>
<p>Interchanging two entries in a permutation multiplies the sign of the permutation by <span class="math inline">\(-1\)</span>.</p>
<p><br></p>
<h4 id="definition-10.33-determinant-of-a-matrix-det-a">Definition 10.33: Determinant of a Matrix, <span class="math inline">\(\det A\)</span></h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times n\)</span> matrix:</p>
<p><span class="math display">\[
A = 
\begin{bmatrix}
A_{1,1} &amp; ... &amp; A_{1,n}\\
. &amp; ... &amp; .\\
A_{n,1} &amp; ... &amp; A_{n,n}\\
\end{bmatrix}
\]</span></p>
<p>The <strong>determinant</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\det A\)</span>, is defined by:</p>
<p><span class="math display">\[\det A = \sum_{(m_1, ..., m_n) \in \text{perm n}} (sign(m_1, ..., m_n)) A_{m_1, 1} .... A_{m_n, n}\]</span></p>
<p><br></p>
<h4 id="theorem-10.36-interchanging-two-columns-in-a-matrix">Theorem 10.36: Interchanging Two Columns in a Matrix</h4>
<p>Suppose <span class="math inline">\(A\)</span> is a square matrix and <span class="math inline">\(B\)</span> is the matrix obtained from <span class="math inline">\(A\)</span> by interchanging two columns. Then:</p>
<p><span class="math display">\[\det A = -\det B\]</span></p>
<p><br></p>
<h4 id="theorem-10.37-matrix-with-two-equal-columns">Theorem 10.37: Matrix with Two Equal Columns</h4>
<p>If <span class="math inline">\(A\)</span> is a square matrix that has two equal columns, then <span class="math inline">\(\det A = 0\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.38-permuting-the-columns-of-a-matrix">Theorem 10.38: Permuting the Columns of a Matrix</h4>
<p>Suppose <span class="math inline">\(A = [A_{\cdot, 1} .... A_{\cdot, n}]\)</span> is an <span class="math inline">\(n \times n\)</span> matrix and <span class="math inline">\((m_1, ..., m_n)\)</span> is a permutation. Then:</p>
<p><span class="math display">\[\det (A_{\cdot, m_1} .... A_{\cdot, m_n}) = sign(m_1, ..., m_n) \det A\]</span></p>
<p><br></p>
<h4 id="theorem-10.39-determinant-is-a-linear-function-of-each-column">Theorem 10.39: Determinant is a Linear Function of Each Column</h4>
<p>Suppose <span class="math inline">\(k, n\)</span> are positive integers with <span class="math inline">\(1 \leq k \leq n\)</span>. Fix <span class="math inline">\(n \times 1\)</span> matrices <span class="math inline">\(A_{\cdot, 1}, ..., A_{\cdot, k}\)</span>. Then the function that takes an <span class="math inline">\(n \times 1\)</span> column vector <span class="math inline">\(A_{\cdot, k}\)</span> to:</p>
<p><span class="math display">\[\det(A_{\cdot, 1} ... A_{\cdot, k} .... A_{\cdot, n})\]</span></p>
<p>is a linear map from the vector space of <span class="math inline">\(n \times 1\)</span> matrices with entries in <span class="math inline">\(\mathbb{F}\)</span> to <span class="math inline">\(\mathbb{F}\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.40-determinant-is-multiplicative">Theorem 10.40: Determinant is Multiplicative</h4>
<p>Suppose <span class="math inline">\(A, B\)</span> are square matrices of the same size. Then:</p>
<p><span class="math display">\[\det(AB) = \det(BA) = \det(A)\det(B)\]</span></p>
<p><br></p>
<h4 id="theorem-10.41-determinant-of-matrix-of-operator-does-not-depend-on-basis">Theorem 10.41: Determinant of Matrix of Operator Does not Depend on Basis</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(u_1, ..., u_j\)</span> and <span class="math inline">\(v_1, ...., v_n\)</span> are bases of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\det M(T, (u_1, ..., u_n)) = \det M(T, (v_1, ..., v_n))\]</span></p>
<p><br></p>
<h4 id="theorem-10.42-determinant-of-an-operator-equals-determinant-of-its-matrix">Theorem 10.42: Determinant of an Operator Equals Determinant of Its Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(\det T = \det M(T)\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.43-isometries-have-determinant-with-absolute-value-1">Theorem 10.43: Isometries Have Determinant with Absolute Value <span class="math inline">\(1\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner product space and <span class="math inline">\(S \in L(V)\)</span> is an isometry. Then <span class="math inline">\(|\det S| = 1\)</span>.</p>
<p><br></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear Algebra (4)</title>
    <url>/2022/01/25/linear-algebra-4/</url>
    <content><![CDATA[<h1 id="linear-algebra-4">Linear Algebra (4)</h1>
<h2 id="inner-product-spaces">Inner Product Spaces</h2>
<p><strong>If <span class="math inline">\(\lambda\)</span> is a complex number, then we define <span class="math inline">\(\lambda \geq 0\)</span> to be real number and nonnegative.</strong></p>
<h3 id="inner-products-and-norms">Inner Products and Norms</h3>
<p>For <span class="math inline">\(z \in \mathbb{F}^n\)</span>, we define the norm of <span class="math inline">\(z\)</span> w.r.t Euclidian inner product by:</p>
<p><span class="math display">\[\|z\| = \sqrt{|z_1|^2 + ... + |z_n|^2}\]</span></p>
<p>Where <span class="math inline">\(|z_1|^2 = z\bar{z} = a^2 + b^2\)</span></p>
<h4 id="definition-6.2-dot-product">Definition 6.2: Dot Product</h4>
<p>For <span class="math inline">\(x, y \in \mathbb{R}^n\)</span>, the <strong>dot product</strong> of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, denoted <span class="math inline">\(x \cdot y\)</span>, is defined by:</p>
<p><span class="math display">\[x \cdot y = x_1y_1 + ... + x_ny_n\]</span></p>
<p>where <span class="math inline">\(x=(x_1, ..., x_n), y=(y_1, ..., y_n)\)</span></p>
<p>It has the following properties:</p>
<ol type="1">
<li><span class="math inline">\(x \cdot x \geq 0, \; \forall x \in \mathbb{R}^n\)</span></li>
<li><span class="math inline">\(x \cdot x = 0\)</span> IFF <span class="math inline">\(x = 0\)</span></li>
<li>For <span class="math inline">\(y \in \mathbb{R}^n\)</span> fixed, the map from <span class="math inline">\(\mathbb{R}^n \rightarrow \mathbb{R}\)</span> that sends <span class="math inline">\(x \in \mathbb{R}^n\)</span> to <span class="math inline">\(x \cdot y\)</span> is linear.</li>
<li><span class="math inline">\(x \cdot y = y \cdot x, \; \forall x, y \in \mathbb{R}^n\)</span></li>
</ol>
<span id="more"></span>
<h4 id="definition-6.3-inner-product">Definition 6.3: Inner Product</h4>
<p>An <strong>inner product</strong> on <span class="math inline">\(V\)</span> is a <strong>function</strong> that takes each ordered pair <span class="math inline">\((u, v)\)</span> of elements of <span class="math inline">\(V\)</span> to a number <span class="math inline">\(&lt;u, v&gt; \in \mathbb{F}\)</span> and has the following properties:</p>
<ol type="1">
<li><strong>Positive</strong>: <span class="math display">\[&lt;v, v&gt; \geq 0 , \; \forall v \in V\]</span></li>
<li><strong>Definiteness</strong>: <span class="math display">\[&lt;v, v&gt; = 0 \;\; \text{ IFF } \;\; v = 0\]</span></li>
<li><strong>Additivity in first slot</strong>: <span class="math display">\[&lt;u + v, w&gt; = &lt;u, w&gt; + &lt;v, w&gt;, \; \forall u, v, w \in V\]</span></li>
<li><strong>Homogeneity in first slot</strong>: <span class="math display">\[&lt;\lambda u, v&gt; = \lambda &lt;u, v&gt;, \; \forall \lambda \in \mathbb{F}, u,v \in V\]</span></li>
<li><strong>Conjugate Symmetry</strong>: <span class="math display">\[&lt;u, v&gt; = \overline{&lt;v, u&gt;}, \; \forall u, v \in V\]</span></li>
</ol>
<blockquote>
<p>The <strong>Euclidean inner product on <span class="math inline">\(\mathbb{F}^n\)</span></strong> is defined by: <span class="math display">\[&lt;(w_1, ..., w_n), (z_1, ..., z_n)&gt; = w_1 \bar{z}_1 + .... + w_n \bar{z}_n\]</span></p>
<p>If <span class="math inline">\(c_1, ..., c_n\)</span> are positive numbers, then an inner product can be defined on <span class="math inline">\(\mathbb{F}^n\)</span> by: <span class="math display">\[&lt;(w_1,  ...., w_n), (z_1, ..., z_n)&gt; = c_1w_1 \bar{z}_1 + .... + c_nw_n \bar{z}_n\]</span></p>
<p>An inner product can be defined on the vector space of continuous real-valued functions on the interval <span class="math inline">\([-1, 1]\)</span> by: <span class="math display">\[&lt;f, g&gt; = \int^1_{-1} f(x)g(x) dx\]</span></p>
<p>An inner product can be defined on <span class="math inline">\(P(\mathbb{R})\)</span> by: <span class="math display">\[&lt;p, q&gt; = \int^{\infty}_{0} p(x) q(x) e^{-x} dx\]</span></p>
</blockquote>
<h4 id="definition-6.5-inner-product-space">Definition 6.5: Inner Product Space</h4>
<p>An <strong>inner product space</strong> is a vector space <span class="math inline">\(V\)</span> along with an inner product on <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<p><span style="color:red"><strong>For the rest of the Inner product space chapter, <span class="math inline">\(V\)</span> denotes inner product space over <span class="math inline">\(\mathbb{F}\)</span>. If the inner product on <span class="math inline">\(V\)</span> is missing from the context, we assume it to be Euclidean inner product if the vector space is <span class="math inline">\(\mathbb{F}^n\)</span></strong></span>.</p>
<p><br></p>
<h4 id="theorem-6.7-basic-properties-of-an-inner-product">Theorem 6.7: Basic Properties of an Inner Product</h4>
<ol type="1">
<li>For each fixed <span class="math inline">\(u \in V\)</span>, the function that takes <span class="math inline">\(v\)</span> to <span class="math inline">\(&lt;v, u&gt;\)</span> is a linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(\mathbb{F}\)</span>.</li>
<li><span class="math inline">\(&lt;0, u&gt; = 0\)</span> for every <span class="math inline">\(u \in V\)</span>.</li>
<li><span class="math inline">\(&lt;u, 0&gt; = 0\)</span> for every <span class="math inline">\(u \in V\)</span>.</li>
<li><span class="math inline">\(&lt;u, v + w&gt; = &lt;u, v&gt; + &lt;u, w&gt;\)</span> for all <span class="math inline">\(u, v, w \in V\)</span>.</li>
<li><span class="math inline">\(&lt;u, \lambda v&gt; = \bar{\lambda} &lt;u, v&gt; \; \forall \lambda \in \mathbb{F}, u, v \in V\)</span>.</li>
</ol>
<h4 id="definition-6.8-norm-v">Definition 6.8: Norm, <span class="math inline">\(\| v \|\)</span></h4>
<p>For <span class="math inline">\(v \in V\)</span>, the <strong>norm</strong> of <span class="math inline">\(v\)</span>, denoted <span class="math inline">\(\|v\|\)</span>, is defined by:</p>
<p><span class="math display">\[\|v\| = \sqrt{&lt;v, v&gt;}\]</span></p>
<h4 id="theorem-6.10-basic-properties-of-the-norm">Theorem 6.10: Basic Properties of the Norm</h4>
<p>Suppose <span class="math inline">\(v \in V\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\|v\| = 0\)</span>, if and only if <span class="math inline">\(v = 0\)</span>.</li>
<li><span class="math inline">\(\|\lambda v\| = |\lambda| \|v\|, \; \forall \lambda \in \mathbb{F}\)</span>.</li>
</ol>
<h4 id="definition-6.11-orthogonal">Definition 6.11: Orthogonal</h4>
<p>Two vectors <span class="math inline">\(u, v \in V\)</span> are called <strong>orthogonal</strong> if <span class="math inline">\(&lt;u, v&gt; = 0\)</span>.</p>
<h4 id="theorem-6.12-orthogonality-and-0">Theorem 6.12: Orthogonality and <span class="math inline">\(0\)</span></h4>
<ol type="1">
<li><span class="math inline">\(0\)</span> is orthogonal to every vector in <span class="math inline">\(V\)</span>.</li>
<li>0 is the only vector in <span class="math inline">\(V\)</span> that is orthogonal to itself.</li>
</ol>
<h4 id="theorem-6.13-pythagorean-theorem">Theorem 6.13 Pythagorean Theorem</h4>
<p>Suppose <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are <strong>orthogonal</strong> vectors in <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\|u + v\|^2 = \|u\|^2 + \|v\|^2\]</span></p>
<h4 id="theorem-6.14-an-orthogonal-decomposition">Theorem 6.14: An Orthogonal Decomposition</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>, with <span class="math inline">\(v \neq 0\)</span>. Set <span class="math inline">\(c = \frac{&lt;u, v&gt;}{\|v\|^2}\)</span> and <span class="math inline">\(w = u - \frac{&lt;u, v&gt;}{\|v\|^2} v\)</span>. Then:</p>
<p><span class="math display">\[&lt;w, v&gt; = 0\]</span></p>
<p>and</p>
<p><span class="math display">\[u = cv + w\]</span></p>
<h4 id="theorem-6.15-cauchy-schwarz-inequality">Theorem 6.15: Cauchy-Schwarz Inequality</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>. Then:</p>
<p><span class="math display">\[|&lt;u, v&gt;| \leq \|u\|\|v\|\]</span></p>
<p>This inequality is an equality if and only if one of <span class="math inline">\(u, v\)</span> is a scalar multiple of the other.</p>
<h5 id="proof-of-theorem-6.15">Proof of theorem 6.15:</h5>
<p>If <span class="math inline">\(v = 0\)</span>, we have <span class="math inline">\(0 = 0\)</span>, thus, we can assume <span class="math inline">\(v \neq 0\)</span>. Then, by <code>theorem 6.14</code>, we have:</p>
<p><span class="math display">\[u = \frac{&lt;u, v&gt; v}{\|v\|^2} + w\]</span></p>
<p>Since <span class="math inline">\(v, w\)</span> are orthogonal, by taking the norm square on both side we have:</p>
<p><span class="math display">\[\|u\|^2 = \|\frac{&lt;u, v&gt; v}{\|v\|^2}\|^2 + \|w\|^2\]</span></p>
<p>Since <span class="math inline">\(\frac{&lt;u, v&gt;}{\|v\|^2} \in \mathbb{F}\)</span>, we can take them out:</p>
<p><span class="math display">\[\|u\|^2 = \frac{|&lt;u, v&gt;|^2}{\|v\|^4}\|v\|^2 + \|w\|^2 \geq \frac{|&lt;u, v&gt;|}{\|v\|^2}\]</span></p>
<p>Multiply both sides by <span class="math inline">\(\|v\|^2\)</span>, we have:</p>
<p><span class="math display">\[\|w\|^2\|v\|^2 \geq |&lt;u, v&gt;|\]</span></p>
<p>Notice that, the equality only happens when <span class="math inline">\(\|w\|^2 = 0\)</span>, in other words, <span class="math inline">\(w = u - \frac{&lt;u, v&gt;}{\|v\|^2} v = 0 \implies u = \frac{&lt;u, v&gt;}{\|v\|^2} v\)</span>, thus, if <span class="math inline">\(u\)</span> is scalar multiple of <span class="math inline">\(v\)</span>.</p>
<h4 id="theorem-6.18-triangle-inequality">Theorem 6.18: Triangle Inequality</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>. Then</p>
<p><span class="math display">\[\|u + v\| \leq \|u\| + \|v\|\]</span></p>
<p>This inequality is an equality if and only if one of <span class="math inline">\(u, v\)</span> is a nonnegative multiple of the other.</p>
<h4 id="theorem-6.22-parallelogram-equality">Theorem 6.22 Parallelogram Equality</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>. Then:</p>
<p><span class="math display">\[\|u + v\|^2 + \|u - v\|^2 = 2 (\|u\|^2 + \|v\|^2)\]</span></p>
<h4 id="theorem-the-polarization-identities">Theorem: The Polarization Identities</h4>
<p><a href="https://unapologetic.wordpress.com/2009/04/23/the-polarization-identities/">Polarization Identities</a></p>
<h3 id="orthonormal-bases">Orthonormal Bases</h3>
<h4 id="definition-6.23-orthonormal">Definition 6.23: Orthonormal</h4>
<p>A list of vectors is called <strong>orthonormal</strong> if each vector in the list has norm <span class="math inline">\(1\)</span> and is orthogonal to all the other vectors in the list. In other words, a list <span class="math inline">\(e_1, ..., e_m\)</span> of vectors in <span class="math inline">\(V\)</span> is orthonormal if</p>
<p><span class="math display">\[
&lt;e_j, e_j&gt; =
\begin{cases}
1, \quad \text{if} \;\; k = j\\
0, \quad \text{if} \;\; k \neq j
\end{cases}
\]</span></p>
<blockquote>
<p>The standard basis in <span class="math inline">\(\mathbb{F}^n\)</span> w.r.t Euclidean inner product is an orthonormal list.</p>
</blockquote>
<h4 id="theorem-6.25-the-norm-of-an-orthonormal-linear-combination">Theorem 6.25: The Norm of an Orthonormal Linear Combination</h4>
<p>If <span class="math inline">\(e_1, ..., e_m\)</span> is an orthonormal list of vectors in <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[\|a_1e_1 + ... + a_m e_m\|^2 = |a_1|^2 + ... + |a_m|^2\]</span></p>
<p>for all <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span></p>
<h4 id="theorem-6.26-an-orthonormal-list-is-linearly-independent">Theorem 6.26: An Orthonormal List is linearly Independent</h4>
<p>Every orthonormal list of vectors is linearly independent.</p>
<h4 id="definition-6.27-orthonormal-basis">Definition 6.27: Orthonormal Basis</h4>
<p>An <strong>orthonormal basis</strong> of <span class="math inline">\(V\)</span> is an orthonormal list of vectors in <span class="math inline">\(V\)</span> that is also a basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.28-an-orthonormal-list-of-the-right-length-is-an-orthonormal-basis">Theorem 6.28: An Orthonormal List of the Right Length is an Orthonormal Basis</h4>
<p>Every orthonormal list of vectors in <span class="math inline">\(V\)</span> with length <span class="math inline">\(\dim V\)</span> is an orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.30-writing-a-vector-as-linear-combination-of-orthonormal-basis">Theorem 6.30: Writing a Vector as Linear Combination of Orthonormal Basis</h4>
<p>Suppose <span class="math inline">\(e_1, ..., e_n\)</span> is an orthonormal basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(v \in V\)</span>. Then:</p>
<p><span class="math display">\[v = &lt;v, e_1&gt; e_1 + ... + &lt;v, e_n&gt;e_n\]</span></p>
<p>and</p>
<p><span class="math display">\[\|v\|^2 = |&lt;v, e_1&gt;|^2 + ... + |&lt;v, e_n&gt;|^2\]</span></p>
<h5 id="proof-of-theorem-6.30">Proof of Theorem 6.30</h5>
<p>Since <span class="math inline">\(e_1, ...., e_n\)</span> is an orthonormal basis, there exists a list of scalars <span class="math inline">\(a_1, ..., a_n\)</span> s.t:</p>
<p><span class="math display">\[v = a_1e_1 + ... + a_ne_n\]</span></p>
<p>Take the inner product of <span class="math inline">\(e_j\)</span> on both sides, we have:</p>
<p><span class="math display">\[&lt;v, e_j&gt; = a_j\]</span></p>
<h4 id="theorem-6.31-gram-schmidt-procedure">Theorem 6.31: Gram-Schmidt Procedure</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_m\)</span> is a linearly independent list of vectors in <span class="math inline">\(V\)</span>. Let <span class="math inline">\(e_1 = \frac{v_1}{\|v_1\|}\)</span>. For <span class="math inline">\(j=2, ..., m\)</span>, define <span class="math inline">\(e_j\)</span> inductively by:</p>
<p><span class="math display">\[e_j = \frac{v_j - &lt;v_j, e_1&gt; e_1 - ... - &lt;v_j, e_{j-1}&gt;e_{j-1}}{\|v_j - &lt;v_j, e_1&gt; e_1 - ... - &lt;v_j, e_{j-1}&gt;e_{j-1}\|}\]</span></p>
<p>Then <span class="math inline">\(e_j, ..., e_m\)</span> is an orthonormal list of vectors in <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[span(v_1, ..., v_j) = span(e_1, ..., e_j)\]</span></p>
<p>for <span class="math inline">\(j = 1, ..., m\)</span></p>
<h4 id="theorem-6.34-existence-of-orthonormal-basis">Theorem 6.34: Existence of Orthonormal Basis</h4>
<p>Every finite-dimensional inner product space has an orthonormal basis.</p>
<h4 id="theorem-6.35-orthonormal-list-extends-to-orthonormal-basis">Theorem 6.35: Orthonormal List Extends to Orthonormal Basis</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then every orthonormal list of vectors in <span class="math inline">\(V\)</span> can be extended to an orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.37-upper-triangular-matrix-w.r.t-orthonormal-basis">Theorem 6.37: Upper-Triangular Matrix w.r.t Orthonormal Basis</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. If <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>, then <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h5 id="proof-theorem-6.37">Proof Theorem 6.37:</h5>
<p>Assume <span class="math inline">\(v_1, ..., v_n\)</span> is a basis s.t <span class="math inline">\(T\)</span> has an upper triangular matrix, then by <code>theorem 5.26</code>, we have <span class="math inline">\(span(v_1, .., v_j)\)</span> is invariant under <span class="math inline">\(T\)</span> for each <span class="math inline">\(j=1\)</span>. Then by Gram-Schmidt Procedure, we can construct <span class="math inline">\(e_1, ..., e_n\)</span> from <span class="math inline">\(v_1, ..., v_n\)</span> s.t</p>
<p><span class="math display">\[span(e_1, ..., e_j) = span(v_1, ..., v_j)\]</span></p>
<p>Then, by <code>theorem 5.26</code>, we can conclude the <span class="math inline">\(e_1, ..., e_n\)</span> is a basis s.t <span class="math inline">\(T\)</span> has an upper triangular matrix.</p>
<h4 id="theorem-6.38-schurs-theorem">Theorem 6.38: Schur's Theorem</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a finite-dimensional complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.42-riesz-representation-theorem">Theorem 6.42: Riesz Representation Theorem</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(\psi\)</span> is a linear functional on <span class="math inline">\(V\)</span>. Then there is a <strong>unique</strong> vector <span class="math inline">\(u \in V\)</span> that does not depend on the choice of basis s.t</p>
<p><span class="math display">\[\psi (v) = &lt;v, u&gt;\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span>.</p>
<p>In other words, any linear functional on <span class="math inline">\(V\)</span> can be written as the map that sends <span class="math inline">\(v \in V\)</span> to inner product.</p>
<h5 id="proof-theorem-6.42">Proof Theorem 6.42</h5>
<p>Let <span class="math inline">\(e_1, ..., e_n\)</span> be an orthonormal basis of <span class="math inline">\(V\)</span>. Then:</p>
<span class="math display">\[\begin{aligned}
\psi (v) &amp;= \psi (&lt;v, e_1&gt; e_1 + ... + &lt;v, e_n&gt; e_n) \\
&amp;= &lt;v, e_1&gt; \psi(e_1) + ... + &lt;v, e_n&gt;\psi(e_n)\\
&amp;= &lt;v, \overline{\psi(e_1)} e_1 + .... + \overline{\psi(e_n)} e_n&gt;
\end{aligned}\]</span>
<p>Let <span class="math inline">\(u = \overline{\psi(e_1)} e_1 + .... + \overline{\psi(e_n)} e_n\)</span>, then we have:</p>
<p><span class="math display">\[\psi(v) = &lt;v, u&gt;\]</span></p>
<p>We now show that <span class="math inline">\(u\)</span> is unique. Suppose <span class="math inline">\(\psi (v) = &lt;v, u_1 &gt; = &lt;v, u_2&gt;\)</span>, then:</p>
<p><span class="math display">\[&lt;v, u_1&gt; - &lt;v, u_2&gt; = 0\]</span></p>
<p>Thus, we have <span class="math inline">\(\forall v \in V\)</span>:</p>
<p><span class="math display">\[&lt;v, u_1 - u_2&gt; = 0\]</span></p>
<p>This shows that <span class="math inline">\(u_1 = u_2\)</span>.</p>
<h3 id="orthogonal-complements-and-minimization-problems">Orthogonal Complements and Minimization Problems</h3>
<h4 id="definition-6.45-orthogonal-complement-uperp">Definition 6.45: Orthogonal Complement, <span class="math inline">\(U^{\perp}\)</span></h4>
<p>If <span class="math inline">\(U\)</span> is a subset of <span class="math inline">\(V\)</span>, then the <strong>orthogonal complement</strong> of <span class="math inline">\(U\)</span>, denoted <span class="math inline">\(U^{\perp}\)</span> is the set of all vectors in <span class="math inline">\(V\)</span>, that are orthogonal to every vector in <span class="math inline">\(U\)</span>:</p>
<p><span class="math display">\[U^{\perp} = \{v \in V: &lt;v, u&gt; = 0; \forall u \in U\}\]</span></p>
<h4 id="theorem-6.46-basic-properties-of-orthogonal-complement">Theorem 6.46 Basic Properties of Orthogonal Complement</h4>
<ol type="1">
<li>If <span class="math inline">\(U\)</span> is a subset of <span class="math inline">\(V\)</span>, then <span class="math inline">\(U^{\perp}\)</span> is a subspace of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(\{0\}^{\perp} = V\)</span>.</li>
<li><span class="math inline">\(V^{\perp} = \{0\}\)</span>.</li>
<li>If <span class="math inline">\(U\)</span> is a subset of <span class="math inline">\(V\)</span>, then <span class="math inline">\(U \cap U^{\perp} \subseteq \{0\}\)</span>. (<strong>empty set is subset of every set</strong>)</li>
<li>If <span class="math inline">\(U\)</span> and <span class="math inline">\(W\)</span> are subsets of <span class="math inline">\(V\)</span> and <span class="math inline">\(U \subseteq W\)</span>, then <span class="math inline">\(W^{\perp} \subseteq U^{\perp}\)</span>.</li>
</ol>
<h5 id="proof-of-theorem-6.46">Proof of Theorem 6.46:</h5>
<p>1 to 4 are trivial.</p>
<ol start="5" type="1">
<li>Suppose <span class="math inline">\(U, W\)</span> are subsets of <span class="math inline">\(V\)</span> and <span class="math inline">\(U \subseteq W\)</span>. Suppose <span class="math inline">\(v \in W^{\perp}\)</span>, then <span class="math inline">\(\forall u \in W\)</span>, we have <span class="math inline">\(&lt;u, v&gt; = 0\)</span>. Thus, we have <span class="math inline">\(\forall u \in U\)</span>, <span class="math inline">\(&lt;v, u&gt; = 0\)</span>, so <span class="math inline">\(v \in U^{\perp}, \forall v\in W^{\perp}\)</span>. Hence, <span class="math inline">\(W^{\perp} \subseteq U^{\perp}\)</span>.</li>
</ol>
<h4 id="theorem-6.47-direct-sum-of-a-subspace-and-its-orthogonal-complement">Theorem 6.47: Direct Sum of a Subspace and Its Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(U\)</span> is finite-dimensional subspace of <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[V = U \oplus U^{\perp}\]</span></p>
<h5 id="proof-of-theorem-6.47">Proof of Theorem 6.47:</h5>
<p>We first show that:</p>
<p><span class="math display">\[V = U + W\]</span></p>
<p>Let <span class="math inline">\(U, W\)</span> be a subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(e_1, ..., e_m\)</span> be orthonormal basis of <span class="math inline">\(U\)</span>. Then, <span class="math inline">\(\forall v \in V\)</span> by <code>theorem 6.30</code>:</p>
<p><span class="math display">\[v = \underbrace{(v - &lt;v, e_1&gt;e_1 + ... + &lt;v, e_m&gt;e_m)}_{w} + \underbrace{(&lt;v, e_1&gt;e_1 + ... + &lt;v, e_m&gt;e_m)}_{u}\]</span></p>
<p>Let <span class="math inline">\(u, w\)</span> be defined as above, we clearly have <span class="math inline">\(u \in U\)</span>. Thus:</p>
<p><span class="math display">\[&lt;w, e_j&gt; = &lt;v - &lt;v, e_1&gt;e_1 + ... + &lt;v, e_m&gt;e_m, e_j&gt; = &lt;v, e_j&gt; - &lt;v, e_j&gt; = 0\]</span></p>
<p>So, we have <span class="math inline">\(\forall u \in U\)</span>, <span class="math inline">\(&lt;w, u&gt; = 0\)</span>, so <span class="math inline">\(w \in U^{\perp} = W\)</span>. Thus, <span class="math inline">\(\forall v \in V\)</span> we have:</p>
<p><span class="math display">\[v = u + w\]</span></p>
<p>and <span class="math inline">\(U, W\)</span> are subspaces of <span class="math inline">\(V\)</span>.</p>
<p>Since <span class="math inline">\(U \cap U^{\perp} \subseteq \{0\}\)</span> and <span class="math inline">\(U\)</span> is a subspace so we have <span class="math inline">\(U \cap U^{\perp} = \{0\}\)</span>, by <code>theorem 1.45</code>, we have:</p>
<p><span class="math display">\[V = U \oplus W = U \oplus U^{\perp}\]</span></p>
<h4 id="theorem-6.50-dimension-of-the-orthogonal-complement">Theorem 6.50 Dimension of the Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\dim U^{\perp} = \dim V - \dim U\]</span></p>
<h4 id="theorem-6.51-the-orthogonal-complement-of-the-orthogonal-complement">Theorem 6.51: The Orthogonal Complement of the Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[U = (U^{\perp})^{\perp}\]</span></p>
<h4 id="definition-6.53-orthogonal-projection-p_u">Definition 6.53: Orthogonal Projection, <span class="math inline">\(P_U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span>. For <span class="math inline">\(v \in V\)</span>, write <span class="math inline">\(v = u + w\)</span>, where <span class="math inline">\(u \in U, w \in U^{\perp}\)</span>, the <strong>orthogonal projection</strong> of <span class="math inline">\(V\)</span> onto <span class="math inline">\(U\)</span> is the operator <span class="math inline">\(P_U \in L(V)\)</span> defined as:</p>
<p><span class="math display">\[P_{U} (v) = u\]</span></p>
<blockquote>
<p>Suppose <span class="math inline">\(v \in V\)</span>. Let <span class="math inline">\(x \in V, x \neq 0\)</span> and <span class="math inline">\(U = span(x)\)</span>, then:</p>
<p><span class="math display">\[v = (\frac{&lt;v, x&gt;}{\|x\|^2} x) + (v - \frac{&lt;v, x&gt;}{\|x\|^2} x)\]</span></p>
<p>The first term is in <span class="math inline">\(U\)</span> and the second therm is in <span class="math inline">\(U^{\perp}\)</span>, thus</p>
<p><span class="math display">\[P_U(v) = \frac{&lt;v, x&gt;}{\|x\|^2} x\]</span></p>
</blockquote>
<h4 id="theorem-6.55-properties-of-the-orthogonal-projection-p_u">Theorem 6.55: Properties of the Orthogonal Projection <span class="math inline">\(P_{U}\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(v \in V\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(P_U \in L(V)\)</span>.</li>
<li><span class="math inline">\(P_U (u) = u, \; \forall u \in U\)</span>.</li>
<li><span class="math inline">\(P_u (w) = 0, \; \forall w \in U^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{range } P_{U} = U\)</span>.</li>
<li><span class="math inline">\(\text{null } P_U = U^{\perp}\)</span>.</li>
<li><span class="math inline">\(v - P_U(v) \in U^{\perp}\)</span></li>
<li><span class="math inline">\(P^2_U = P_U\)</span>.</li>
<li><span class="math inline">\(\|P_U (v)\| \leq \|v\|\)</span>.</li>
<li>For every orthonormal basis <span class="math inline">\(e_1, ..., e_m\)</span> of <span class="math inline">\(U\)</span>, <span class="math display">\[P_U (v) = &lt;v, e_1&gt;e_1 + .... + &lt;v, e_m&gt;e_m\]</span></li>
</ol>
<h4 id="theorem-6.56-minimizing-the-distance-to-a-subspace">Theorem 6.56 Minimizing the Distance to a Subspace</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span>, <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(u \in U\)</span>. Then:</p>
<p><span class="math display">\[\|v - P_U (v)\| \leq \|v - u\|\]</span></p>
<p>Furthermore, the inequality above is an equality iFF <span class="math inline">\(u = P_U(v)\)</span>.</p>
<p><strong>Notice there, <span class="math inline">\(u\)</span> and <span class="math inline">\(P_U (v)\)</span> might be different.</strong></p>
<h2 id="operators-on-inner-product-spaces">Operators on Inner Product Spaces</h2>
<h3 id="self-adjoint-and-normal-operators">Self-Adjoint and Normal Operators</h3>
<h4 id="definition-7.2-adjoint-t">Definition 7.2: Adjoint, <span class="math inline">\(T^*\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. The <strong>adjoint</strong> of <span class="math inline">\(T\)</span> is the function <span class="math inline">\(T^*: W \rightarrow V\)</span> s.t:</p>
<p><span class="math display">\[&lt;T(v), w&gt; = &lt;v, T^*(w)&gt;\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span> and every <span class="math inline">\(w \in W\)</span>.</p>
<p><strong>To see why this definition makes sense</strong>, let <span class="math inline">\(T: V \rightarrow \mathbb{F}\)</span> be a linear functional on <span class="math inline">\(V\)</span> defined as:</p>
<p><span class="math display">\[T(v) = &lt;T(v), w&gt;\]</span></p>
<p>for some <span class="math inline">\(w \in W\)</span>. By <code>theorem 6.42</code>, there exists a unique element <span class="math inline">\(v_2\)</span> in <span class="math inline">\(V\)</span> s.t for every element <span class="math inline">\(v \in V\)</span>:</p>
<p><span class="math display">\[T(v) = &lt;T(v), w&gt; = &lt;v, v_2&gt;\]</span></p>
<p>We call this unique vector <span class="math inline">\(T^* (w)\)</span>.</p>
<blockquote>
<p>Define <span class="math inline">\(T: \mathbb{R}^3 \rightarrow \mathbb{R}^2\)</span> by: <span class="math display">\[T(x_1, x_2, x_3) = (x_2 + 3x_3, 2x_1)\]</span></p>
<p>Here <span class="math inline">\(T^*: \mathbb{R}^2 \rightarrow \mathbb{R}^3\)</span> can be found by:</p>
<p><span class="math display">\[&lt;(x_1, x_2, x_3), T^*(y_1, y_2)&gt; = &lt;T(x_1, x_2, x_3), (y_1, y_2)&gt; = &lt;(x_1, x_2, x_3), (2y_2, y_1, 3y_1)&gt;\]</span></p>
<p>Where <span class="math inline">\((y_1, y_2) \in \mathbb{R}^2, (x_1, x_2, x_3) \in \mathbb{R}^3\)</span>.</p>
</blockquote>
<h4 id="theorem-7.5-the-adjoint-is-a-linear-map">Theorem 7.5: The Adjoint is a Linear Map</h4>
<p>If <span class="math inline">\(T \in L(V, W)\)</span>, then <span class="math inline">\(T^* \in L(W, V)\)</span>.</p>
<h4 id="theorem-7.6-properties-of-the-adjoint">Theorem 7.6: Properties of the Adjoint</h4>
<ol type="a">
<li><span class="math inline">\((S + T)^* = S^* + T^*, \; \forall S, T \in L(V, W)\)</span></li>
<li><span class="math inline">\((\lambda T)^* = \bar{\lambda} T^*, \; \forall \lambda \in \mathbb{F}, T \in L(V, W)\)</span></li>
<li><span class="math inline">\((T^*)^* = T\)</span></li>
<li><span class="math inline">\(I^* = I\)</span>, where <span class="math inline">\(I\)</span> is the identity operator on <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\((ST)^* = T^* S^*, \; \forall T \in L(V, W), S \in L(W, U)\)</span></li>
</ol>
<h4 id="theorem-7.7-null-space-and-range-of-t">Theorem 7.7: Null Space and Range of <span class="math inline">\(T^*\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(\text{null } T^* = (\text{range }T)^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{range }T^* = (\text{null } T)^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{null }T = (\text{range }T^*)^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{range }T = (\text{null }T^*)^{\perp}\)</span>.</li>
</ol>
<h4 id="definition-7.8-conjugate-transpose">Definition 7.8: Conjugate Transpose</h4>
<p>The <strong>conjugate transpose</strong> of an <span class="math inline">\(m \times n\)</span> matrix is the <span class="math inline">\(n \times m\)</span> matrix obtained by interchanging the rows and columns and then taking the complex conjugate of each entry. If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the conjugate transpose of a matrix is the same as its <strong>transpose</strong>.</p>
<h4 id="theorem-7.10-the-matrix-of-t">Theorem 7.10: The Matrix of <span class="math inline">\(T^*\)</span></h4>
<p>Let <span class="math inline">\(T \in L(V, W)\)</span>. Suppose <span class="math inline">\(e_1, ..., e_n\)</span> is an <strong>orthonormal basis</strong> of <span class="math inline">\(V\)</span> and <span class="math inline">\(f_1, ..., f_m\)</span> is an orthonormal basis of <span class="math inline">\(W\)</span>. Then:</p>
<p><span class="math display">\[M(T^*, (f_1, ..., f_m), (e_1, ..., e_n))\]</span></p>
<p>is the conjugate transpose of:</p>
<p><strong>Notice that, the result above only applies when we have orthonormal bases, for non-orthonormal bases, the matrix <span class="math inline">\(T^*\)</span> does not necessarily equal the conjugate transpose of the matrix of <span class="math inline">\(T\)</span>.</strong></p>
<h4 id="definition-7.11-self-adjoint-hermitian">Definition 7.11: Self-Adjoint (Hermitian)</h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is called <strong>self-adjoint</strong> if <span class="math inline">\(T = T^*\)</span>. In other words, <span class="math inline">\(T \in L(V)\)</span> is self-adjoint if and only if:</p>
<p><span class="math display">\[&lt;T(v), w&gt; = &lt;v, T(w)&gt;\]</span></p>
<p>for all <span class="math inline">\(v, w \in V\)</span>.</p>
<p><strong>Adjoint on <span class="math inline">\(L(V)\)</span> plays a role similar to complex conjugation on <span class="math inline">\(\mathbb{C}\)</span> and self-adjoint operator is analogous to a real number. Sometimes, people use symmetric for the matrix of self-adjoint operator with real entries.</strong></p>
<h4 id="theorem-7.13-eigenvalues-of-self-adjoint-operators-are-real">Theorem 7.13: Eigenvalues of Self-Adjoint Operators are Real</h4>
<p>Every eigenvalue of a self-adjoint operator is real.</p>
<h4 id="theorem-7.14">Theorem 7.14:</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a <strong>complex inner product space</strong> and <span class="math inline">\(T \in L(V)\)</span>. Suppose:</p>
<p><span class="math display">\[&lt;T(v), v&gt; = 0\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>. Then <span class="math inline">\(T = 0\)</span>.</p>
<p><strong>This result is not true for real value space.</strong></p>
<h4 id="theorem-7.15-over-mathbbc-tv-v-is-real-for-all-v-only-for-self-adjoint-operators">Theorem 7.15: Over <span class="math inline">\(\mathbb{C}\)</span>, <span class="math inline">\(&lt;T(v), v&gt;\)</span> is real for all <span class="math inline">\(v\)</span> only for self-adjoint operators</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex inner product space and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(T\)</span> is self-adjoint if and only if:</p>
<p><span class="math display">\[&lt;T(v), v&gt; \in \mathbb{R}\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span></p>
<h4 id="theorem-7.16-if-t-t-and-tv-v-0-forall-v-then-t-0">Theorem 7.16: If <span class="math inline">\(T = T^*\)</span> and <span class="math inline">\(&lt;T(v), v&gt; = 0; \forall v\)</span>, Then <span class="math inline">\(T = 0\)</span></h4>
<p>Suppose <span class="math inline">\(T\)</span> is self-adjoint operator on <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[&lt;Tv, v&gt; = 0\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>. Then <span class="math inline">\(T = 0\)</span>.</p>
<h4 id="definition-7.18-normal">Definition 7.18: Normal</h4>
<p>An operator on an inner product space is called <strong>normal</strong> if it commutes with its adjoint. In other words, <span class="math inline">\(T \in L(V)\)</span> is normal if <span class="math display">\[TT^* = T^*T\]</span></p>
<p><strong>Every self-adjoint operator is normal</strong></p>
<h4 id="theorem-7.20-t-is-normal-iff-tv-tv-forall-v">Theorem 7.20: <span class="math inline">\(T\)</span> is Normal IFF <span class="math inline">\(\|T(v)\| = \|T^*(v)\| \; \forall v\)</span></h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is normal if and only if:</p>
<p><span class="math display">\[\|T(v)\| = \|T^*(v)\|\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="theorem-7.21-for-t-normal-t-t-have-the-same-eigenvectors">Theorem 7.21: For <span class="math inline">\(T\)</span> normal, <span class="math inline">\(T, T^*\)</span> Have the Same Eigenvectors</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is normal and <span class="math inline">\(v \in V\)</span> is an eigenvector of <span class="math inline">\(T\)</span> with eigenvalue <span class="math inline">\(\lambda\)</span>. Then <span class="math inline">\(v\)</span> is also an eigenvector of <span class="math inline">\(T^*\)</span> with eigenvalue <span class="math inline">\(\bar{\lambda}\)</span>.</p>
<h4 id="theorem-7.22-orthogonal-eigenvectors-for-normal-operators">Theorem 7.22: Orthogonal Eigenvectors for Normal Operators</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is normal. Then eigenvectors of <span class="math inline">\(T\)</span> corresponding to distinct eigenvalues are orthogonal.</p>
<h3 id="the-spectral-theorem">The Spectral Theorem</h3>
<h4 id="theorem-7.24-complex-spectral-theorem">Theorem 7.24: Complex Spectral Theorem</h4>
<p>Suppose <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(T\)</span> is normal.</li>
<li><span class="math inline">\(V\)</span> has an orthonormal basis consisting of eigenvectors of <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T\)</span> has a diagonal matrix with respect to some orthonormal basis of <span class="math inline">\(V\)</span>.</li>
</ol>
<h5 id="proof-theorem-7.24">Proof Theorem 7.24</h5>
<p>Suppose 2 holds, then <span class="math inline">\(T\)</span> has a diagonal matrix, then <span class="math inline">\(T^*\)</span> has a diagonal matrix, since diagonal matrices commute, we have 1.</p>
<p>Suppose 3 holds, similarly 1 holds.</p>
<p>Suppose 1 holds, so <span class="math inline">\(T\)</span> is normal. by <code>theorem 6.38</code>, there is an orthonormal basis <span class="math inline">\(e_1, ..., e_n\)</span> of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has an upper-triangular matrix. Thus, have:</p>
<p><span class="math display">\[\|T(e_1)\|^2 = |a_{1, 1}|^2\]</span></p>
<p><span class="math display">\[\|T^*(e_1)\|^2 = |\overline{a_{1, 1}}|^2 + .... + |\overline{a_{1, n}}|^2 = |a_{1, 1}|^2 + .... + |a_{1, n}|^2\]</span></p>
<p>Since <span class="math inline">\(\|T^*(e_1)\|^2 = \|T(e_1)\|^2\)</span>, we have all entries equal 0 except possibly <span class="math inline">\(a_{1, 1}\)</span>. Repeat this procedure for second column, we have 3.</p>
<h4 id="theorem-7.26-invertible-quadratic-expressions">Theorem 7.26: Invertible Quadratic Expressions</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is self-adjoint and <span class="math inline">\(b, c \in \mathbb{R}\)</span> are such that <span class="math inline">\(b^2 &lt; 4c\)</span>. Then:</p>
<p><span class="math display">\[T^2 + bT + cI\]</span></p>
<p>is invertible.</p>
<h4 id="theorem-7.27-self-adjoint-operators-have-eigenvalues">Theorem 7.27: Self-Adjoint Operators Have Eigenvalues</h4>
<p>Suppose <span class="math inline">\(V \neq \{0\}\)</span> and <span class="math inline">\(T \in L(V)\)</span> is a self-adjoint operator. Then <span class="math inline">\(T\)</span> has an eigenvalue.</p>
<h4 id="theorem-7.28-self-adjoint-operators-and-invariant-subspaces">Theorem 7.28: Self-Adjoint Operators and Invariant Subspaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is self-adjoint and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> that is invariant under <span class="math inline">\(T\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(U^{\perp}\)</span> is invariant under <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T|_{U} \in L(U)\)</span> is self-adjoint.</li>
<li><span class="math inline">\(T|_{U^{\perp}} \in L(U^{\perp})\)</span> is self-adjoint.</li>
</ol>
<h4 id="theorem-7.29-real-spectral-theorem">Theorem 7.29: Real Spectral Theorem</h4>
<p>Suppose <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(T\)</span> is self-adjoint (Symmetric).</li>
<li><span class="math inline">\(V\)</span> has an orthonormal basis consisting of eigenvectors of <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T\)</span> has a diagonal matrix w.r.t to some orthonormal basis of <span class="math inline">\(V\)</span>.</li>
</ol>
<h3 id="positive-operators-and-isometries">Positive Operators and Isometries</h3>
<h4 id="definition-7.31-positive-operator-positive-semi-definite">Definition 7.31: Positive Operator (Positive Semi-definite)</h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is called <strong>positive</strong> if <span class="math inline">\(T\)</span> is self-adjoint and</p>
<p><span class="math display">\[&lt;T(v), v&gt; \geq 0\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>.</p>
<p><strong>If <span class="math inline">\(V\)</span> is a complex vector space, then the requirement that <span class="math inline">\(T\)</span> is self-joint can be dropped because we require <span class="math inline">\(&lt;T(v), v&gt; \in \mathbb{R}\)</span></strong>.</p>
<blockquote>
<p>If U is a subspace of <span class="math inline">\(V\)</span>, then the orthogonal projection <span class="math inline">\(P_U\)</span> is a positive operator because: <span class="math display">\[&lt;P_U (v), v&gt; = &lt;u, u + w&gt; = \|u\|^2 \geq 0\]</span></p>
<p>At the same time, <span class="math inline">\(P_U\)</span> is a self-adjoint operator because the matrix of <span class="math inline">\(P_U\)</span> is identity matrix w.r.t orthonormal basis <span class="math inline">\(e_1, ..., e_m\)</span>.</p>
</blockquote>
<h4 id="definition-7.33-square-root">Definition 7.33: Square Root</h4>
<p>An operator <span class="math inline">\(R\)</span> is called a <strong>square root</strong> of an operator <span class="math inline">\(T\)</span> if <span class="math inline">\(R^2 = T\)</span>.</p>
<blockquote>
<p>If <span class="math inline">\(T \in L(\mathbb{F}^3)\)</span> is defined by <span class="math inline">\(T(z_1, z_2, z_3) = (z_3, 0, 0)\)</span>, then the operator <span class="math inline">\(R \in L(\mathbb{F}^3)\)</span> defined by <span class="math inline">\(R(z_1, z_2, z_3) = (z_2, z_3, 0)\)</span> is a square root of <span class="math inline">\(T\)</span>.</p>
</blockquote>
<h4 id="theorem-7.35-characterization-of-positive-operators">Theorem 7.35: Characterization of Positive Operators</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is positive.</li>
<li><span class="math inline">\(T\)</span> is self-adjoint and all the eigenvalues of <span class="math inline">\(T\)</span> are non-negative.</li>
<li><span class="math inline">\(T\)</span> has a positive square root.</li>
<li><span class="math inline">\(T\)</span> has a self-adjoint square root.</li>
<li>There exists an operator <span class="math inline">\(R \in L(V)\)</span> s.t <span class="math inline">\(T = R^*R\)</span>.</li>
</ol>
<h4 id="theorem-7.36-every-positive-operator-has-only-one-positive-square-root">Theorem 7.36: Every Positive Operator Has Only One Positive Square Root</h4>
<p>Every positive operator on <span class="math inline">\(V\)</span> has a unique positive square root.</p>
<p><strong>A positive operator can have infinitely many square roots, although only one of them can be positive.</strong></p>
<h4 id="definition-7.37-isometry">Definition 7.37: Isometry</h4>
<p>An operator <span class="math inline">\(S \in L(V)\)</span> is called an <strong>isometry</strong> if:</p>
<p><span class="math display">\[\|S(v)\| = \|v\|\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span></p>
<p>In other words, an operator is an isometry if it preserves norms</p>
<h4 id="theorem-7.42-characterization-of-isometries">Theorem 7.42: Characterization of Isometries</h4>
<p>Suppose <span class="math inline">\(S \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(S\)</span> is an isometry.</li>
<li><span class="math inline">\(&lt;S(u), S(v)&gt; = &lt;u, v&gt;, \; \forall u, v \in V\)</span>.</li>
<li><span class="math inline">\(S(e_1) , ...., S(e_n)\)</span> is orthonormal for every orthonormal list of vectors <span class="math inline">\(e_1, ..., e_n \in V\)</span>.</li>
<li>There exists an orthonormal basis <span class="math inline">\(e_1, ..., e_n\)</span> of <span class="math inline">\(V\)</span> s.t <span class="math inline">\(S(e_1), ..., S(e_n)\)</span> is orthonormal.</li>
<li><span class="math inline">\(S^*S = I\)</span></li>
<li><span class="math inline">\(SS^* = I\)</span></li>
<li><span class="math inline">\(S^*\)</span> is an isometry.</li>
<li><span class="math inline">\(S\)</span> is invertible and <span class="math inline">\(S^{-1} = S^*\)</span>.</li>
<li><span class="math inline">\(S\)</span> is normal.</li>
</ol>
<h4 id="theorem-7.43-description-of-isometries-when-mathbbf-mathbbc">Theorem 7.43: Description of Isometries When <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex inner product space and <span class="math inline">\(S \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(S\)</span> is an isometry.</li>
<li>There is an orthonormal basis of <span class="math inline">\(V\)</span> consisting of eigenvectors of <span class="math inline">\(S\)</span> whose corresponding eigenvalues all have absolute value <span class="math inline">\(1\)</span>.</li>
</ol>
<h3 id="polar-decomposition-and-singular-value-decomposition">Polar Decomposition and Singular Value Decomposition</h3>
<h4 id="definition-7.44-sqrtt">Definition 7.44: <span class="math inline">\(\sqrt{T}\)</span></h4>
<p>If <span class="math inline">\(T\)</span> is a positive operator, then <span class="math inline">\(\sqrt{T}\)</span> denotes the unique positive square root of <span class="math inline">\(T\)</span>.</p>
<h4 id="theorem-7.45-polar-decomposition">Theorem 7.45: Polar Decomposition</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then there exists an isometry <span class="math inline">\(S \in L(V)\)</span> s.t:</p>
<p><span class="math display">\[T = S\sqrt{T^*T}\]</span></p>
<h4 id="definition-7.49-singular-value-decomposition">Definition 7.49: Singular Value Decomposition</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. The <strong>singular values</strong> of <span class="math inline">\(T\)</span> are the eigenvalues of <span class="math inline">\(\sqrt{T^* T}\)</span>, with each eigenvalue <span class="math inline">\(\lambda\)</span> repeated <span class="math inline">\(\dim E(\lambda, \sqrt{T^*T})\)</span> times.</p>
<p><strong>The singular values of <span class="math inline">\(T\)</span> are all non-negative, because they are the eigenvalues of the positive operator <span class="math inline">\(\sqrt{T^*T}\)</span></strong></p>
<blockquote>
<p>Define <span class="math inline">\(T \in L(\mathbb{F}^4)\)</span>: <span class="math display">\[T(z_1, z_2, z_3, z_4) = (0, 3z_1, 2z_2, -3z_4)\]</span></p>
<p>a bit calculation, we have:</p>
<p><span class="math display">\[T^* (x_1, x_2, x_3, x_4) = (3x_2, 2x_3, 0, -3x_4)\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[T^*T(z_1, z_2, z_3, z_4) = (9z_1, 4z_2, 0, 9z_4)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sqrt{T^* T} (z_1, z_2, z_3, z_4) = (3z_1, 2z_2, 0, 3z_4)\]</span></p>
<p>The eigenvalues are <span class="math inline">\(3, 2, 0\)</span> and: <span class="math display">\[\dim E(3, \sqrt{T^*T}) = 2, \dim E(2, \sqrt{T^*T}) = 1, \dim E(0, \sqrt{T^*T}) = 1\]</span></p>
<p>Hence, the singular values of <span class="math inline">\(T\)</span> are <span class="math inline">\(3, 3, 2, 0\)</span></p>
</blockquote>
<h4 id="theorem-7.51-singular-value-decomposition">Theorem 7.51: Singular Value Decomposition</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> has singular values <span class="math inline">\(s_1, ..., s_n\)</span>. Then there exist orthonormal bases <span class="math inline">\(e_1, ..., e_n\)</span> and <span class="math inline">\(f_1, ..., f_n\)</span> of <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[T(v) = s_1 &lt;v, e_1&gt;f_1 + .... + s_n&lt;v, e_n&gt;f_n\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="theorem-7.52-singular-values-without-taking-square-root-of-an-operator">Theorem 7.52: Singular Values Without Taking Square Root of an Operator</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the singular values of <span class="math inline">\(T\)</span> are the non-negative square roots of the eigenvalues of <span class="math inline">\(T^*T\)</span>, with each eigenvalue <span class="math inline">\(\lambda\)</span> repeated <span class="math inline">\(\dim E(\lambda, T^*T) times\)</span>.</p>
<h5 id="proof-of-theorem-7.52">Proof of Theorem 7.52:</h5>
<p>Let <span class="math inline">\(e_1, ..., e_n\)</span> be orthonormal basis of <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[\sqrt{T^*T} (e_j) = s_j e_j\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sqrt{T^*T}\sqrt{T^*T} (e_j) = \sqrt{T^*T}(s_j e_j) = s^2_j e_j = T^*T(e_j)\]</span></p>
<p>Thus, <span class="math inline">\(s^2_j = \lambda_j\)</span> which is the eigenvalue of <span class="math inline">\(T^*T(e_j)\)</span>.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Monte Carlo Estimation</title>
    <url>/2021/05/15/mc/</url>
    <content><![CDATA[<h1 id="learning-from-stream-of-data-monte-carlo-methods">Learning From Stream of Data (Monte Carlo Methods)</h1>
<h2 id="mc-policy-evaluation">MC Policy Evaluation</h2>
<p>The Goal is to learn or estimate the value function <span class="math inline">\(V^{\pi}\)</span> and <span class="math inline">\(Q^{\pi}\)</span> of a policy.</p>
<p>Recall that:</p>
<p><span class="math display">\[V^{\pi}(x) = E[G^{\pi}_{t} | X_t=x]\]</span></p>
<p>This is the expected return starting from state <span class="math inline">\(x\)</span>. At the same time, obtain a sample from return <span class="math inline">\(G^{\pi}\)</span> is easy: if the agent starts at state <span class="math inline">\(x\)</span>, and follows <span class="math inline">\(\pi\)</span>, we can draw one sample of r.v <span class="math inline">\(G^{\pi}\)</span> by computing the cumulative sum of rewards collected during the episode starting from the state <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[\hat{G^{\pi}_{t}} = \sum^{\infty}_{k=t} \gamma^{k-t} R_{k}\]</span></p>
<p>If we repeat this process from the same state, we get another draw of r.v <span class="math inline">\(G^{\pi}\)</span>, let us call these samples <span class="math inline">\(G^{\pi (1)} (x)\)</span>, <span class="math inline">\(G^{\pi (2)} (x)\)</span>, ...., <span class="math inline">\(G^{\pi (n)} (x)\)</span>. We can get an estimate <span class="math inline">\(\hat{V^{\pi}} (x)\)</span> of <span class="math inline">\(V^{\pi} (x)\)</span> by taking the average of the sample average:</p>
<p><span class="math display">\[\hat{V^{\pi}} (x) = \frac{1}{n} \sum^{n}_{i=1} \hat{G}^{\pi(i)} (x)\]</span></p>
<span id="more"></span>
<p><img src="/images/RL/mc/mc_3.png"></p>
<p>This follows by the <code>weak law of large number</code>, we can also estimate this expectation using Stochastic Approximation (SA) procedure to obtain an online fashion update:</p>
<p><span class="math display">\[ \hat{V^{\pi}_{t+1}} (x) \leftarrow (1 - \alpha_t) \hat{V^{\pi}_{t}} (x) + \alpha_t G^{\pi (t)} (x)\]</span></p>
<p><img src="/images/RL/mc/mc_2.png"></p>
<h2 id="first-visit-and-every-visit-mc">First Visit and Every Visit MC</h2>
<p>Above two algorithms are examples of first visit MC method. Each occurrence of state <span class="math inline">\(x\)</span> in an episode is called a visit to <span class="math inline">\(x\)</span>. Of course, <span class="math inline">\(x\)</span> may be visited multiple times in the same episode; let us call the first time it is visited in an episode the first visit to <span class="math inline">\(x\)</span>. The <code>first-visit MC method</code> estimates <span class="math inline">\(V^{\pi} (x)\)</span> as the average of the returns following first visits to <span class="math inline">\(x\)</span>, whereas the <code>every-visit MC method</code> averages the returns following all visits to <span class="math inline">\(x\)</span>.</p>
<h1 id="mc-control">MC Control</h1>
<h2 id="exploring-start">Exploring Start</h2>
<p>The general idea of MC control is to use some version of Policy Iteration. If we run many rollouts from each state-action pair <span class="math inline">\((x, a)\)</span>, we can define <span class="math inline">\(\hat{Q^{\pi}_t}\)</span> that converges to <span class="math inline">\(Q^{\pi}\)</span>. If we wait for an infinite time:</p>
<p><span class="math display">\[Q^{\pi}_{\infty} = lim_{t \rightarrow \infty} \hat{Q^{\pi}_{t}} = Q^{\pi}\]</span></p>
<p>We can then choose:</p>
<p><span class="math display">\[\pi^{\prime} \rightarrow \pi_g (\hat{Q^{\pi}_{\infty}})\]</span></p>
<p>Then we repeat this process until convergence.</p>
<p>However, we do not need to have a very accurate estimation of <span class="math inline">\(Q^{\pi_k}\)</span> before performing the policy improvement step. We can perform MC for a finite number of rollouts from each state, and then perform the improvement step. The below algorithms are MC control with Exploring Start, which assumes that for every state action pairs <span class="math inline">\((x, a)\)</span>, we have positive probability that we start at this state action pair.</p>
<p><img src="/images/RL/mc/mc_1.png"></p>
<p>or online version using exploring start:</p>
<p><img src="/images/RL/mc/mc_5.png"></p>
<p>We can see that all returns are cumulated and averaged irrespective which policy they follow, however, the algorithm can still converge to <span class="math inline">\(Q^{*}\)</span>:</p>
<p><img src="/images/RL/mc/mc_6.png"></p>
<h2 id="without-exploring-start">Without Exploring Start</h2>
<p>Even though we are guaranteed to converge optimal action value function using MC with exploring start, however, this assumption of exploring start is unlike especially when state space and action space are large. To avoid this unlikely assumption, we can replace exploring start with <span class="math inline">\(\epsilon\)</span>-soft policies to ensure sufficient exploration or using off-policy algorithms.</p>
<p><img src="/images/RL/mc/mc_7.png"></p>
<h1 id="further">Further</h1>
<p>In this post, we have some basic understanding of generic MC methods and basic framework of MC Policy evaluation and control. Next, we will explore some popular MC methods for solving control problems. We will see that MC methods can be generalized to both on-policy sampling scenario and off-policy sampling scenario.</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>MC</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>MC</tag>
        <tag>Tabular Methods</tag>
      </tags>
  </entry>
  <entry>
    <title>Measure Integral and Real Analysis (3)</title>
    <url>/2022/03/14/mira-3/</url>
    <content><![CDATA[<h1 id="measure-integral-and-real-analysis-3">Measure Integral and Real Analysis (3)</h1>
<h2 id="banach-spaces">Banach Spaces</h2>
<h3 id="metric-spaces">Metric Spaces</h3>
<h4 id="definition-6.1-metric-space">Definition 6.1: Metric Space</h4>
<p>A <strong>metric</strong> oon a nonempty set <span class="math inline">\(V\)</span> is a function <span class="math inline">\(d: V \times V \rightarrow [0, \infty)\)</span> s.t:</p>
<ul>
<li><span class="math inline">\(d(f, f) = 0, \; \forall f \in V\)</span>.</li>
<li>If <span class="math inline">\(f, g \in V\)</span> and <span class="math inline">\(d(f, g) = 0\)</span>, then <span class="math inline">\(f = g\)</span>.</li>
<li><span class="math inline">\(d(f, g) = d(g, f), \; \forall f, g \in V\)</span>.</li>
<li><span class="math inline">\(d(f, h) \leq d(f, g) + f(g, h), \; \forall f, g, h \in V\)</span>. (Triangle inequality)</li>
</ul>
<p>A <strong>metric space</strong> is a pair <span class="math inline">\((V, d)\)</span>, where <span class="math inline">\(V\)</span> is a nonempty set adn <span class="math inline">\(d\)</span> is a metric on <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<h4 id="definition-6.3-open-ball-bf-r-closed-ball-barbf-r">Definition 6.3: Open Ball; <span class="math inline">\(B(f, r)\)</span>; Closed Ball <span class="math inline">\(\bar{B}(f, r)\)</span></h4>
<p>Suppose <span class="math inline">\((V, d)\)</span> is a metric space, <span class="math inline">\(f \in V\)</span> and <span class="math inline">\(r &gt; 0\)</span>:</p>
<ul>
<li>The <strong>open ball</strong> centered at <span class="math inline">\(f\)</span> with radius <span class="math inline">\(r\)</span> is denoted <span class="math inline">\(B(f, r)\)</span> and is defined by: <span class="math display">\[B(f, r) = \{g \in V: d(f, g) &lt;  r\}\]</span></li>
<li>The <strong>closed ball</strong> centered at <span class="math inline">\(f\)</span> with radius <span class="math inline">\(r\)</span> is denoted <span class="math inline">\(\bar{B}(f, r)\)</span> and is defined by: <span class="math display">\[\bar{B}(f, r) = \{g \in V: d(f, g) \leq r\}\]</span></li>
</ul>
<p><br></p>
<h4 id="definition-6.4-open">Definition 6.4: Open</h4>
<p>A subset <span class="math inline">\(G\)</span> of a metric space <span class="math inline">\(V\)</span> is called <strong>open</strong> if for every <span class="math inline">\(f \in G\)</span>, there exists <span class="math inline">\(r &gt; 0\)</span> s.t <span class="math inline">\(B(f, r) \subseteq G\)</span>.</p>
<p><br></p>
<h4 id="theorem-6.5-open-balls-are-open">Theorem 6.5: Open balls are Open</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a metric space, <span class="math inline">\(f \in V\)</span>, and <span class="math inline">\(r &gt; 0\)</span>. Then <span class="math inline">\(B(f, r)\)</span> is an open subset of <span class="math inline">\(V\)</span>.</p>
<h5 id="proof-of-theorem-6.5">Proof of Theorem 6.5:</h5>
<p>Suppose <span class="math inline">\(g \in B(f, r)\)</span>. We need to show there exists an open ball centered at <span class="math inline">\(g\)</span> with radius <span class="math inline">\(k\)</span> s.t <span class="math inline">\(B(g, k) \subseteq B(f, r)\)</span>. Let <span class="math inline">\(k = r - d(f, g)\)</span>, and <span class="math inline">\(h \in B(g, r - d(f, g))\)</span>, then:</p>
<p><span class="math display">\[d(f, h) \leq d(f, g) + d(g, h) &lt; d(f, g) + r - d(f, g) = r\]</span></p>
<p>Thus, <span class="math inline">\(h \in B(f, r), \; \forall h \in B(g, k)\)</span>, so <span class="math inline">\(B(f, r)\)</span> is open.</p>
<p><br></p>
<h4 id="definition-6.6-closed">Definition 6.6: Closed</h4>
<p>A subset of a metric space <span class="math inline">\(V\)</span> is called <strong>closed</strong> if its complement in <span class="math inline">\(V\)</span> is open.</p>
<p><br></p>
<h4 id="definition-6.7-closure-bare">Definition 6.7: Closure; <span class="math inline">\(\bar{E}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a metric space and <span class="math inline">\(E \subseteq V\)</span>. The <strong>closure</strong> of <span class="math inline">\(E\)</span>, denoted <span class="math inline">\(\bar{E}\)</span>, is defined by:</p>
<p><span class="math display">\[\bar{E} = \{g \in V: B(g, \epsilon) \cap E \neq \emptyset \; \forall \epsilon &gt; 0\}\]</span></p>
<p><br></p>
<h4 id="definition-6.8-limit-in-metric-space-lim_k-rightarrow-infty-f_k">Definition 6.8: Limit in Metric Space; <span class="math inline">\(\lim_{k \rightarrow \infty} f_k\)</span></h4>
<p>Suppose <span class="math inline">\((V, d)\)</span> is a metric space, <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence in <span class="math inline">\(V\)</span>, and <span class="math inline">\(f \in V\)</span>. Then:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} f_k = f\]</span></p>
<p>means</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} d(f, f_k) = 0\]</span></p>
<p><br></p>
<span id="more"></span>
<h4 id="theorem-6.9-closure">Theorem 6.9: Closure</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a metric space and <span class="math inline">\(E \subseteq V\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(\bar{E} = \{g \in V: \text{there exist $f_1, f_2, ...$ in $E$ s.t $\lim_{k \rightarrow \infty} f_k = g$}\}\)</span></li>
<li><span class="math inline">\(\bar{E}\)</span> is the intersection of all closed subsets of <span class="math inline">\(V\)</span> that contains <span class="math inline">\(E\)</span>.</li>
<li><span class="math inline">\(\bar{E}\)</span> is a closed subset of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(E\)</span> is closed if and ony if <span class="math inline">\(\bar{E} = E\)</span>.</li>
<li><span class="math inline">\(E\)</span> is closed if and only if <span class="math inline">\(E\)</span> contains the limit of every convergent sequence of elements of <span class="math inline">\(E\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-6.10-continuous">Definition 6.10: Continuous</h4>
<p>Suppose <span class="math inline">\((V, d_v)\)</span> and <span class="math inline">\((W, d_w)\)</span> are metric spaces and <span class="math inline">\(T: V \rightarrow W\)</span> is a function.</p>
<ul>
<li><p>For <span class="math inline">\(f \in V\)</span>, the function <span class="math inline">\(T\)</span> is called <strong>continuous</strong> at <span class="math inline">\(f\)</span> if for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t: <span class="math display">\[d_w (T(f), T(g)) &lt; \epsilon\]</span></p>
<p>for all <span class="math inline">\(g \in V\)</span> amd <span class="math inline">\(d_v(f, g) &lt; \epsilon\)</span>.</p></li>
<li><p>The function <span class="math inline">\(T\)</span> is called <strong>continuous</strong> if <span class="math inline">\(T\)</span> is continuous at <span class="math inline">\(f\)</span> for every <span class="math inline">\(f \in V\)</span>.</p></li>
</ul>
<p><br></p>
<h4 id="theorem-6.11-equivalent-conditions-for-continuity">Theorem 6.11: Equivalent Conditions for Continuity</h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are metric spaces and <span class="math inline">\(T: V \rightarrow W\)</span> is a function. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is continuous.</li>
<li><span class="math inline">\(\lim_{k \rightarrow \infty} f_k = f \in V \implies \lim_{k \rightarrow \infty} T(f_k) = T(f) \in W\)</span>.</li>
<li><span class="math inline">\(T^{-1} (G)\)</span> is an open subset of <span class="math inline">\(V\)</span> for every open set <span class="math inline">\(G \subseteq W\)</span>.</li>
<li><span class="math inline">\(T^{-1} (F)\)</span> is a closed subset of <span class="math inline">\(V\)</span> for every closed set <span class="math inline">\(F \subseteq W\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-6.12-cauchy-sequence">Definition 6.12: Cauchy Sequence</h4>
<p>A sequence <span class="math inline">\(f_1, f_2, ...\)</span> in a metric space <span class="math inline">\((V, d)\)</span> is called a <strong>Cauchy sequence</strong> if for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(n \in \mathbb{Z}^+\)</span> s.t <span class="math inline">\(d(f_i, f_k) &lt; \epsilon\)</span> for all integers <span class="math inline">\(j \geq n\)</span> and <span class="math inline">\(k \geq n\)</span>.</p>
<p><br></p>
<h4 id="theorem-6.13-every-convergent-sequence-is-a-cauchy-sequence">Theorem 6.13: Every Convergent Sequence is a Cauchy Sequence</h4>
<p>Every convergent sequence in a metric space is a Cauchy seqeunce.</p>
<p><br></p>
<h4 id="definition-6.14-complete-metric-space">Definition 6.14: Complete Metric Space</h4>
<p>A metric space <span class="math inline">\(V\)</span> is called <strong>complete</strong> if every Cauchy sequence in <span class="math inline">\(V\)</span> converges to some element of <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<h4 id="theorem-6.16-connection-between-complete-and-closed">Theorem 6.16: Connection Between Complete and Closed</h4>
<ol type="a">
<li>A complete subset of a metric space is closed.</li>
<li>A closed subset of a complete metric space is complete.</li>
</ol>
<h5 id="proof-of-theorem-6.16">Proof of Theorem 6.16:</h5>
<p>To prove a, assume <span class="math inline">\(U \subseteq V\)</span> is a complete subset of a metric space <span class="math inline">\((V, d)\)</span>, then for convergent sequence <span class="math inline">\(f_1, f_2, ... \in U\)</span>, we have the limit <span class="math inline">\(f \in V\)</span>, which implies the set is closed.</p>
<p>To prove b, assume <span class="math inline">\(U \subseteq V\)</span> is a closed subset of a complete metric space <span class="math inline">\(V\)</span>, then for cauchy sequence <span class="math inline">\(f_1, f_2, ... \in U\)</span>, we also have <span class="math inline">\(f_1, f_2, ... \in V\)</span>. Since <span class="math inline">\(V\)</span> is complete, <span class="math inline">\(f_1, f_2, ..\)</span> has a limit <span class="math inline">\(f \in V\)</span>, since <span class="math inline">\(U\)</span> is closed, <span class="math inline">\(f \in U\)</span>.</p>
<p><br></p>
<h3 id="vector-spaces">Vector Spaces</h3>
<p>If <span class="math inline">\(z_1, z_2, ...\)</span> is a sequence of complex numbers and <span class="math inline">\(L \in \mathbb{C}\)</span>, then:</p>
<p><span class="math display">\[\lim_{k \rightarrow} z_k = L \implies \lim_{k \rightarrow \infty} |z_k - L| = 0\]</span></p>
<p>IFF</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} Re(z_k) = Re(L), \quad \quad \lim_{k\rightarrow \infty} Im(z_k) = Im(L)\]</span></p>
<h4 id="definition-6.19-measurable-complex-valued-function">Definition 6.19: Measurable Complex-Valued Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space. A function <span class="math inline">\(f: X \rightarrow \mathbb{C}\)</span> is called <span class="math inline">\(S\)</span>-measurable if <span class="math inline">\(Re(f)\)</span> and <span class="math inline">\(Im(f)\)</span> are both <span class="math inline">\(S\)</span>-measurable functions.</p>
<p>The following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable.</li>
<li><span class="math inline">\(f^{-1}(G) \in S\)</span> for every open set <span class="math inline">\(G \in \mathbb{R}^2\)</span>.</li>
<li><span class="math inline">\(f^{-1}(B) \in S\)</span> for every Borel set <span class="math inline">\(B \in \mathbb{B}_2\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-6.20-fp-is-measurable-if-f-is-measurable">Theorem 6.20: <span class="math inline">\(|f|^p\)</span> is Measurable If <span class="math inline">\(f\)</span> is Measurable</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space, <span class="math inline">\(f: X \rightarrow \mathbb{C}\)</span> is an <span class="math inline">\(S\)</span>-measurable function, and <span class="math inline">\(0 &lt; p &lt; \infty\)</span>. Then <span class="math inline">\(|f|^p\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p><br></p>
<h4 id="definition-6.21-integral-of-a-complex-valued-function-int-f-dmu">Definition 6.21: Integral of a Complex-valued Function; <span class="math inline">\(\int f d\mu\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow \mathbb{C}\)</span> is an <span class="math inline">\(S\)</span>-mearuable function with <span class="math inline">\(\int |f| d\mu &lt; \infty\)</span> (<span class="math inline">\(f \in L^1(\mu)\)</span>) Then <span class="math inline">\(\int f d\mu\)</span> is defined by:</p>
<p><span class="math display">\[\int f d\mu = \int (Re(f)) d\mu + i\int (Im (f)) d\mu\]</span></p>
<p>And</p>
<p><span class="math display">\[\int (f + g) d\mu = \int f d\mu + \int g d\mu\]</span></p>
<p><span class="math display">\[\int \alpha f d\mu = \alpha \int f d\mu\]</span></p>
<p>where <span class="math inline">\(f, g\)</span> are S-measurable complex valued functions s.t the integrals are defined, and <span class="math inline">\(\alpha \in \mathbb{C}\)</span>.</p>
<p><br></p>
<h4 id="theorem-6.22-bound-on-the-absolute-value-of-an-integral">Theorem 6.22: Bound on the Absolute Value of an Integral</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow \mathbb{C}\)</span> is an <span class="math inline">\(S\)</span>-measurable function s.t <span class="math inline">\(\int |f| d\mu &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[|\int f d\mu| \leq \int |f| d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-6.24-integral-of-complex-conjugate-of-a-function">Theorem 6.24: Integral of Complex Conjugate of a Function</h4>
<p><span class="math display">\[\int \bar{f} d\mu = \overline{\int f d\mu}\]</span></p>
<p>for every measure <span class="math inline">\(\mu\)</span> and every <span class="math inline">\(f \in L^1 (\mu)\)</span></p>
<p><br></p>
<h3 id="normed-vector-space">Normed Vector Space</h3>
<h4 id="definition-6.32-mathbbfx">Definition 6.32: <span class="math inline">\(\mathbb{F}^X\)</span></h4>
<p><span class="math inline">\(\mathbb{F}^X\)</span> denotes the space of all functions that maps from <span class="math inline">\(X \rightarrow \mathbb{F}\)</span>, this is a vector space.</p>
<p><br></p>
<h4 id="definition-6.33-norm-normed-vector-space">Definition 6.33: Norm; Normed Vector Space</h4>
<p>A <strong>norm</strong> on a vector space <span class="math inline">\(V\)</span> over $ $ is a function <span class="math inline">\(\|\cdot\|: V \rightarrow [0, \infty)\)</span> s.t:</p>
<ul>
<li><span class="math inline">\(\|f\| = 0\)</span> IFF <span class="math inline">\(f = 0\)</span> (<strong>positive definite</strong>)</li>
<li><span class="math inline">\(\|\alpha f\| = |\alpha| \|f\|\)</span> (<strong>Homogeneity</strong>)</li>
<li><span class="math inline">\(\|f + g\| \leq \|f\| + \|g\|, \; \forall f,g \in V\)</span> (<strong>Triangle Inequality</strong>)</li>
</ul>
<p>A <strong>normed vector space</strong> is a pair <span class="math inline">\((V, \|\cdot\|)\)</span>, where <span class="math inline">\(V\)</span> is a vector space and <span class="math inline">\(\|\cdot\|\)</span> is a norm on <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<h4 id="definition-6.34-norm-equivalence">Definition 6.34: Norm Equivalence</h4>
<p>We say two norms <span class="math inline">\(F, G\)</span> on <span class="math inline">\(V\)</span> are <strong>equivalent</strong> if there is a <span class="math inline">\(\lambda &lt; \infty\)</span> s.t:</p>
<p><span class="math display">\[\lambda^{-1}G(x) \leq F(x) \leq \lambda G(x)\]</span></p>
<p>for all <span class="math inline">\(x \in V\)</span></p>
<p><br></p>
<h4 id="theorem-6.35-any-two-norms-on-a-finite-dimensional-space-are-equivalent">Theorem 6.35: Any Two Norms on a Finite-Dimensional Space are Equivalent</h4>
<p>Any two norms on a finite-dimensional vector space are equivalent.</p>
<p><br></p>
<h4 id="theorem-6.36-normed-vector-spaces-are-metric-spaces">Theorem 6.36: Normed Vector Spaces are Metric Spaces</h4>
<p>Suppose <span class="math inline">\((V, \|\cdot\|)\)</span> is a normed vector space. Define <span class="math inline">\(d: V \times V \rightarrow [0, \infty)\)</span> by:</p>
<p><span class="math display">\[d(f, g) = \|f - g\|\]</span></p>
<p>Then <span class="math inline">\(d\)</span> is a metric on <span class="math inline">\(V\)</span>.</p>
<p>So in the context of normed vector space:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} f_k = f \Longleftrightarrow \lim_{k \rightarrow \infty} \|f_k - f\| = 0\]</span></p>
<p>A sequence <span class="math inline">\(f_1, f_2, ...\)</span> in a normed vector space <span class="math inline">\((V, \|\cdot\|)\)</span> is a Cauchy sequence if for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exits <span class="math inline">\(n \in \mathbb{Z}^+\)</span> s.t <span class="math inline">\(\forall k, j \in \mathbb{Z}^+ \geq n\)</span>, <span class="math inline">\(\|f_k - f_j\| &lt; \epsilon\)</span>.</p>
<p><br></p>
<h4 id="definition-6.37-banach-space">Definition 6.37: Banach Space</h4>
<p>A complete normed vector space is called a <strong>Banach space</strong>.</p>
<p>In other words, a normed vector space is a Banach space, if every cauchy sequence in <span class="math inline">\(V\)</span> converges to some element of <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<h4 id="definition-6.40-infinite-sum-in-a-normed-vector-space">Definition 6.40: Infinite Sum in a Normed Vector Space</h4>
<p>Suppose <span class="math inline">\(g_1, g_2, ...\)</span> is a sequence in a normed vector space <span class="math inline">\(V\)</span>. Then <span class="math inline">\(\sum^{\infty}_{k=1} g_k\)</span> is defined by:</p>
<p><span class="math display">\[\sum^{\infty}_{k=1} g_k = \lim_{n \rightarrow \infty} \sum^n_{k=1} g_k\]</span></p>
<p>If this limit exists, in which case the infinite series is said to <strong>converge</strong>.</p>
<p><br></p>
<h4 id="theorem-6.41">Theorem 6.41:</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a normed vector space. Then <span class="math inline">\(V\)</span> is a banach space IFF <span class="math inline">\(\sum^{\infty}_{k=1} g_k\)</span> converges for every sequence <span class="math inline">\(g_1, g_2, ...\)</span> in <span class="math inline">\(V\)</span> s.t <span class="math inline">\(\sum^{\infty}_{k=1} \|g_k\| &lt; \epsilon\)</span></p>
<p><br></p>
<h4 id="definition-6.43-bounded-linear-map-t-bv-w">Definition 6.43: Bounded Linear Map; <span class="math inline">\(\|T\|\)</span>; <span class="math inline">\(B(V, W)\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are normed vector spaces over the same field <span class="math inline">\(\mathbb{F}\)</span> and <span class="math inline">\(T: V \rightarrow W\)</span> is a linear map.</p>
<ul>
<li>The norm of <span class="math inline">\(T\)</span>, denoted <span class="math inline">\(\|T\|\)</span>, is defined by: <span class="math display">\[\|T\| = \sup\{\|T(f)\|: f\in V, \; \|f\| \leq 1\}\]</span></li>
<li><span class="math inline">\(T\)</span> is called <strong>bounded</strong> if <span class="math inline">\(\|T\| &lt; \infty\)</span>.</li>
<li>The set of bounded linear maps from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is denoted <span class="math inline">\(B(V, W)\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-6.46-cdot-is-a-norm-on-bv-w">Theorem 6.46: <span class="math inline">\(\|\cdot\|\)</span> is a Norm on <span class="math inline">\(B(V, W)\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are normed vector spaces, <span class="math inline">\(\|\cdot\|\)</span> is defined above. Then <span class="math inline">\(\forall S, T \in B(V, W), \alpha \in \mathbb{F}\)</span>:</p>
<ul>
<li><span class="math inline">\(\|S + T\| \leq \|S\| + \|T\|\)</span></li>
<li><span class="math inline">\(\|\alpha T\| = |\alpha|\|T\|\)</span> Furthermore, the function <span class="math inline">\(\|\cdot\|\)</span> is a norm on <span class="math inline">\(B(V, W)\)</span></li>
</ul>
<p><br></p>
<h4 id="theorem-6.471-equivalence-conditions-for-norm-of-linear-maps">Theorem 6.47(1): Equivalence Conditions For Norm of Linear Maps</h4>
<p>All Definitions below are equivalent for normed vector spaces <span class="math inline">\(V, W\)</span>, <span class="math inline">\(V \neq \{0\}\)</span>, <span class="math inline">\(T: V \rightarrow W\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\|T\| = \sup\{\|T(f)\|: f\in V, \; \|f\| \leq 1\}\)</span></li>
<li><span class="math inline">\(\|T\| = \sup\{\|T(f)\|: f\in V, \; \|f\| = 1\}\)</span></li>
<li><span class="math inline">\(\|T\| = \inf \{c \in [0, \infty): \|T(f)\| \leq c\|f\|, \forall f \in V\}\)</span></li>
<li><span class="math inline">\(\|T\| = \sup\{\frac{\|T(f)\|}{\|f\|}: f \in V, \; f \neq 0\}\)</span></li>
</ol>
<p>This conditions implies that:</p>
<p><span class="math display">\[\|T(f)\| \leq \|T\|\|f\|, \; \forall f\in V\]</span></p>
<p><br></p>
<h4 id="theorem-6.47-bv-w-is-a-banach-space-if-w-is-a-banach-space">Theorem 6.47: <span class="math inline">\(B(V, W)\)</span> is a Banach Space IF <span class="math inline">\(W\)</span> is a Banach Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a normed vector space and <span class="math inline">\(W\)</span> is a Banach Space. Then <span class="math inline">\(B(V, W)\)</span> is a Banach space.</p>
<p><br></p>
<h4 id="theorem-6.48-continuity-is-equivalent-to-boundedness-for-linear-maps">Theorem 6.48: Continuity is Equivalent to Boundedness for Linear Maps</h4>
<p>A linear map from one normed vector space to another normed vector space is continuous IFF its bounded.</p>
<p><br></p>
<h4 id="theorem-6.49-a-linear-map-from-a-finite-dimensional-space-is-always-continuous">Theorem 6.49: A Linear Map from a Finite-Dimensional Space is Always Continuous</h4>
<p>A linear map from a finite-dimensional space is always continuous.</p>
<p><br></p>
<h3 id="linear-functions">Linear Functions</h3>
<h4 id="theorem-6.52-bounded-linear-functionals">Theorem 6.52: Bounded Linear Functionals</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a normed vector space and <span class="math inline">\(\varphi: V \rightarrow \mathbb{F}\)</span> is a linear functional that is not identically 0. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(\varphi\)</span> is a bounded linear functional.</li>
<li><span class="math inline">\(\varphi\)</span> is a continuous linear functional.</li>
<li><span class="math inline">\(\text{null } \varphi\)</span> is a closed subspace of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(\overline{\text{null $\varphi$}} \neq V\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-6.53-family">Definition 6.53: Family</h4>
<p>A <strong>family</strong> <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> in a set <span class="math inline">\(V\)</span> is a function <span class="math inline">\(e\)</span> from a set <span class="math inline">\(\Gamma\)</span> to <span class="math inline">\(V\)</span> with the value of the function <span class="math inline">\(e\)</span> at <span class="math inline">\(k \in \Gamma\)</span> denoted by <span class="math inline">\(e_k\)</span>.</p>
<p>In other words, <span class="math inline">\(e: \Gamma \rightarrow V\)</span> is defined as:</p>
<p><span class="math display">\[e(k) = e_k, \forall k \in \Gamma\]</span></p>
<p>The range of the function <span class="math inline">\(e\)</span> is a subset of <span class="math inline">\(V\)</span>:</p>
<p><span class="math display">\[range(e) = \{e_k\}_{k \in \Gamma}\]</span></p>
<p>A subset <span class="math inline">\(\Gamma\)</span> of a vector space <span class="math inline">\(V\)</span>, can be thought as a family in <span class="math inline">\(V\)</span> by considering <span class="math inline">\(\{e_f\}_{f\in\Gamma}, e_f = f\)</span>.</p>
<p>We can think of <span class="math inline">\(\{e_k\}\)</span> as a list.</p>
<p><br></p>
<h4 id="definition-6.54-linearly-independent-span-finite-dimensional-basis">Definition 6.54: Linearly independent; Span; Finite-dimensional; Basis</h4>
<p>Suppose <span class="math inline">\(\{e_k\}_{k\in\Gamma}\)</span> is a family in a vector space <span class="math inline">\(V\)</span>.</p>
<ul>
<li><span class="math inline">\(\{e_k\}_{k\in\Gamma}\)</span> is called <strong>linearly independent</strong> if there does not exist a finite nonempty subset <span class="math inline">\(\Omega\)</span> of <span class="math inline">\(\Gamma\)</span> and a family <span class="math inline">\(\{\alpha_j\}_{j \in \Omega}\)</span> in <span class="math inline">\(F / \{0\}\)</span> s.t: <span class="math display">\[\sum_{j \in \Omega} \alpha_j e_j = 0\]</span></li>
<li>The <strong>span</strong> of <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is denoted by <strong><span class="math inline">\(span(\{e_k\}_{k \in \Gamma})\)</span></strong> and is defined to be the <strong>set</strong> of all sums of the form: <span class="math display">\[\sum_{j \in \Omega} \alpha_j e_j\]</span></li>
<li>A vector space <span class="math inline">\(V\)</span> is called <strong>finite-dimensional</strong> if there exists a finite set <span class="math inline">\(\Gamma\)</span> and a family <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> in <span class="math inline">\(V\)</span> s.t <span class="math inline">\(span(\{e_K\}_{k \in \Gamma}) = V\)</span>.</li>
<li>A vector space is called <strong>infinite-dimensional</strong> if it is not finite-dimensional.</li>
<li>A family in <span class="math inline">\(V\)</span> is called <strong>basis (Hamel basis, which only finite sums are under consideration)</strong> of <span class="math inline">\(V\)</span> if it is linearly independent and its span equals <span class="math inline">\(V\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-6.55-maximal-element">Definition 6.55: Maximal Element</h4>
<p>Suppose <span class="math inline">\(A\)</span> is a collection of subsets of a set <span class="math inline">\(V\)</span>. A set <span class="math inline">\(\Gamma \in A\)</span> is called a <strong>maximal element</strong> of <span class="math inline">\(A\)</span> if there does not exist <span class="math inline">\(\Gamma^\prime \in A\)</span> s.t <span class="math inline">\(\Gamma \subset \Gamma^\prime\)</span>.</p>
<p><br></p>
<h4 id="theorem-6.57-bases-as-maximal-elements">Theorem 6.57: Bases as Maximal Elements</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a vector space. Then a subset of <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V\)</span> IFF, it is a maximal element of the collection of linearly independent subsets of <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<h4 id="definition-6.58-chain">Definition 6.58: Chain</h4>
<p>A collection <span class="math inline">\(C\)</span> of subsets of a set <span class="math inline">\(V\)</span> is called a <strong>chain</strong> if <span class="math inline">\(\Omega, \Gamma \in C \implies \Omega \subseteq \Gamma\)</span> or <span class="math inline">\(\Gamma \subseteq \Omega\)</span>.</p>
<p><br></p>
<h4 id="theorem-6.60-zorns-lemma">Theorem 6.60: Zorn's Lemma</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a set and <span class="math inline">\(A\)</span> is a collection of subsets of <span class="math inline">\(V\)</span> with the property that the union of all the sets in <span class="math inline">\(C\)</span> is in <span class="math inline">\(A\)</span> for every chain <span class="math inline">\(C \subseteq A\)</span>. Then <span class="math inline">\(A\)</span> contains a maximal element.</p>
<p><br></p>
<h4 id="theorem-6.61-bases-exist">Theorem 6.61: Bases Exist</h4>
<p>Every vector space has basis.</p>
<p><br></p>
<h4 id="theorem-6.62-discontinuous-linear-functionals">Theorem 6.62: Discontinuous Linear Functionals</h4>
<p>Every infinite-dimensional normed vector space has a discontinuous linear functional.</p>
<p><br></p>
<h4 id="theorem-6.63-extension-lemma">Theorem 6.63: Extension Lemma</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real normed vector space, <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>, and <span class="math inline">\(\psi: U \rightarrow \mathbb{R}\)</span> is a bounded linear functional. Suppose <span class="math inline">\(h \in V / U\)</span>. Then <span class="math inline">\(\psi\)</span> can be extended to a bounded linear functional <span class="math inline">\(\varphi: U + \mathbb{R}h \rightarrow \mathbb{R}\)</span> s.t <span class="math inline">\(\|\varphi\| = \|\psi\|\)</span>.</p>
<p>Where <span class="math inline">\(V / U = \{v + u: \forall v \in V, u \in U\}\)</span> is a quotient space, and <span class="math inline">\(U + \mathbb{R}h = \{f + \alpha h: f \in U, \alpha \in \mathbb{R}\}\)</span>.</p>
<p><br></p>
<h4 id="definition-6.67-graph">Definition 6.67: Graph</h4>
<p>Suppose <span class="math inline">\(T: V \rightarrow W\)</span> is a function from a set <span class="math inline">\(V\)</span> to a set <span class="math inline">\(W\)</span>. Then the <strong>graph</strong> of <span class="math inline">\(T\)</span> is denoted <span class="math inline">\(graph(T)\)</span> and is the subset of <span class="math inline">\(V \times W\)</span> defined by:</p>
<p><span class="math display">\[graph(T) = \{(f, T(f)) \in V \times W: f \in V\}\]</span></p>
<p>Formally, a function from a set <span class="math inline">\(V\)</span> to a set <span class="math inline">\(W\)</span> equals its graph.</p>
<p><br></p>
<h4 id="theorem-6.68-function-properties-in-terms-of-graphs">Theorem 6.68: Function Properties in Terms of Graphs</h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are normed vector spaces and <span class="math inline">\(T: V \rightarrow W\)</span> is a function:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is a linear map IFF <span class="math inline">\(graph(T)\)</span> is a subspace of <span class="math inline">\(V \times W\)</span>.</li>
<li>Suppose <span class="math inline">\(U \subseteq V\)</span> and <span class="math inline">\(S: U \rightarrow W\)</span> is a function. Then <span class="math inline">\(T\)</span> is an extension of <span class="math inline">\(S\)</span> IFF <span class="math inline">\(graph(S) \subseteq graph(T)\)</span>.</li>
<li>If <span class="math inline">\(T: V \rightarrow W\)</span> is a linear map and <span class="math inline">\(c \in [0, \infty)\)</span>, then <span class="math inline">\(\|T\| \leq c\)</span> IFF <span class="math inline">\(\|g\| \leq c \|f\|\)</span> for all <span class="math inline">\((f, g) \in graph(T)\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-6.69-hahn-banach-theorem">Theorem 6.69: Hahn-Banach Theorem</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a normed vector space, <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>, and <span class="math inline">\(\psi: U \rightarrow \mathbb{F}\)</span> is a bounded linear functional. Then <span class="math inline">\(\psi\)</span> can be extended to a bounded linear functional on <span class="math inline">\(V\)</span> whose norm equals <span class="math inline">\(\|\psi\|\)</span>.</p>
<p><br></p>
<h4 id="definition-6.71-dual-space-vprime">Definition 6.71: Dual Space; <span class="math inline">\(V^{\prime}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a normed vector space. THen the <strong>dual space</strong> of <span class="math inline">\(V\)</span>, denoted <span class="math inline">\(V^{\prime}\)</span> is the normed vector space consisting of the bounded linear functional on <span class="math inline">\(V\)</span>. In other words, <span class="math inline">\(V^{\prime} = B(V, \mathbb{F})\)</span></p>
<p><br></p>
<h4 id="theorem-6.72-f-max_varphi-1varphif-varphi-in-vprime">Theorem 6.72: <span class="math inline">\(\|f\| = \max_{\|\varphi\| = 1}\{|\varphi(f)|: \varphi \in V^{\prime}\}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a normed vector space and <span class="math inline">\(f \in V / \{0\}\)</span>. Then there exists <span class="math inline">\(\varphi \in V^{\prime}\)</span> s.t <span class="math inline">\(\|\varphi\| = 1\)</span> and <span class="math inline">\(\|f\| = \varphi (f)\)</span>.</p>
<p><br></p>
<h2 id="lp-spaces"><span class="math inline">\(L^p\)</span> Spaces</h2>
<p><span class="math inline">\(L^p(E)\)</span> where <span class="math inline">\(E\)</span> is a Borel or Lebesgue subset of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(0 &lt; p \leq \infty\)</span>, then <span class="math inline">\(L^p(E)\)</span> means <span class="math inline">\(L^p(\lambda_E)\)</span>, where <span class="math inline">\(\lambda_E\)</span> is the lebesgue measure restricted to Borel or Lebesgue subsets contained in <span class="math inline">\(E\)</span>.</p>
<h3 id="lp-mu"><span class="math inline">\(L^p (\mu)\)</span></h3>
<h4 id="definition-7.1-f_p-essential-supremum">Definition 7.1: <span class="math inline">\(\|f\|_p\)</span>; Essential Supremum</h4>
<p>Suppose that <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(0 &lt; p &lt; \infty\)</span>, and <span class="math inline">\(f: X \rightarrow \mathbb{F}\)</span> is <span class="math inline">\(S\)</span>-measurable. Then the <strong><span class="math inline">\(p\)</span>-norm</strong> of <span class="math inline">\(f\)</span> is denoted by <span class="math inline">\(\|f\|_p\)</span> and is defined by:</p>
<p><span class="math display">\[\|f\|_p = (\int |f|^p d\mu)^{\frac{1}{p}}\]</span></p>
<p>Also, <span class="math inline">\(\|f\|_{\infty}\)</span> which is called the <strong>essential supremum</strong> of <span class="math inline">\(f\)</span>, is defined by:</p>
<p><span class="math display">\[\|f\|_{\infty} = \inf\{t &gt; 0: \mu(\{x \in X: |f(x)| &gt; t\}) = 0\}\]</span></p>
<p>The terminology <span class="math inline">\(p\)</span>-norm is convenient, even though it is not necessarily a norm, for example If there exists a nonempty set <span class="math inline">\(E \in S\)</span> s.t <span class="math inline">\(\mu(E) = 0\)</span>, then <span class="math inline">\(\|\chi_E\|_p = 0\)</span>, even if <span class="math inline">\(\chi_E \neq 0\)</span>.</p>
<p>We can think of <span class="math inline">\(\|f\|_{\infty}\)</span> as the smallest that you can make the supremum of <span class="math inline">\(|f|\)</span> after modifications on sets of measure <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h4 id="definition-7.3-lebesgue-space-lp-mu">Definition 7.3: Lebesgue Space; <span class="math inline">\(L^p (\mu)\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 &lt; p \leq \infty\)</span>. The <strong>Lebesgue space</strong> <span class="math inline">\(L^p(\mu)\)</span>, sometimes denoted <span class="math inline">\(L^p(X, S, \mu)\)</span> is defined to be the set of <span class="math inline">\(S\)</span>-measurable functions <span class="math inline">\(f: X \rightarrow \mathbb{F}\)</span> s.t <span class="math inline">\(\|f\|_p &lt; \infty\)</span>.</p>
<blockquote>
<h5 id="example-lp">Example <span class="math inline">\(l^p\)</span></h5>
<p>When <span class="math inline">\(\mu\)</span> is counting measure on <span class="math inline">\(\mathbb{Z}^+\)</span>, the set <span class="math inline">\(L^p(\mu)\)</span> is often denoted by <span class="math inline">\(l^p\)</span>. Thus if <span class="math inline">\(0 &lt; p &lt; \infty\)</span>, then: <span class="math display">\[l^p = \{(a_1, a_2, ...)\}: \text{ each } a_k \in \mathbb{F}, \; \sum^{\infty}_{k=1} |a_k|^p &lt; \infty\}\]</span> <span class="math display">\[l^\infty = \{(a_1, a_2, ...): \text{ each } a_k \in \mathbb{F}, \; \sup_{k \in \mathbb{Z}^+} |a_k| &lt; \infty\}\]</span></p>
</blockquote>
<p><br></p>
<h4 id="theorem-7.5-lpmu-is-a-vector-space">Theorem 7.5: <span class="math inline">\(L^p(\mu)\)</span> is a Vector Space</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 &lt; p &lt; \infty\)</span>. Then:</p>
<ol type="a">
<li><p><span class="math display">\[\|f + g\|^p_p \leq 2^p (\|f\|^p_p + \|g\|^p_p)\]</span></p></li>
<li><p><span class="math display">\[\|\alpha f\|_p = |\alpha| \|f\|_p\]</span></p></li>
</ol>
<p>for all <span class="math inline">\(f, g \in L^p(\mu)\)</span> and all <span class="math inline">\(\alpha \in \mathbb{F}\)</span>. Furthermore, with the usual operations of addition and scalar multiplication of functions, <span class="math inline">\(L^p(\mu)\)</span> is a vector space.</p>
<h5 id="proof-of-theorem-7.5">Proof of Theorem 7.5:</h5>
<p>Suppose <span class="math inline">\(f, g \in L^p (\mu)\)</span>. If <span class="math inline">\(x \in X\)</span>, then:</p>
<p><span class="math display">\[|f(x) - g(x)|^p \leq (|f(x)| + |g(x)|)^p \leq (2 \max{|f(x)|, |g(x)|}^p) \leq 2^p (|f(x)|^p, |g(x)|^p)\]</span></p>
<p>Take the integral over both sides we have:</p>
<p><span class="math display">\[\int |f(x) - g(x)|^p d\mu \leq \int 2^p (|f(x)|^p, |g(x)|^p) d\mu \implies \|f + g\|^p_p \leq 2^p (\|f\|^p_p + \|g\|^p_p)\]</span></p>
<p>From this we can see that <span class="math inline">\(f, g \in L^p(\mu) \implies \|f + g\|_p &lt; \infty \in L^p(\mu)\)</span></p>
<p>The scalar multiplication is straight forward, since <span class="math inline">\(0 \in L^p(\mu)\)</span> and <span class="math inline">\(L^p(\mu)\)</span> is closed under scalar multiplication and addition, it is a vector space and subspace of <span class="math inline">\(\mathbb{F}^X\)</span>.</p>
<p><br></p>
<h4 id="definition-7.6-dual-exponent-pprime">Definition 7.6: Dual Exponent; <span class="math inline">\(p^{\prime}\)</span></h4>
<p>For <span class="math inline">\(1 \leq p \leq \infty\)</span>, the <strong>dual exponent</strong> of <span class="math inline">\(p\)</span> is denoted by <span class="math inline">\(p^\prime\)</span> and is the element of <span class="math inline">\([1, \infty]\)</span> s.t</p>
<p><span class="math display">\[\frac{1}{p} + \frac{1}{p^{\prime}} = 1\]</span></p>
<blockquote>
<h5 id="example-7.7">Example 7.7</h5>
<p><span class="math display">\[1^{\prime} = \infty, \quad \infty^{\prime} = 1, \quad 2^{\prime} = 2, \quad 4^{\prime} = \frac{4}{3}\]</span></p>
</blockquote>
<p><br></p>
<h4 id="theorem-7.8-youngs-inequality">Theorem 7.8: Young's Inequality</h4>
<p>Suppose <span class="math inline">\(1 &lt; p &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[ab \leq \frac{a^p}{p} + \frac{b^{p^{\prime}}}{p^{\prime}}\]</span></p>
<p><br></p>
<h4 id="theorem-7.9-holders-inequality">Theorem 7.9: Holder's Inequality</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(1 \leq p \leq \infty\)</span>, and <span class="math inline">\(f, h: X \rightarrow \mathbb{F}\)</span> are <span class="math inline">\(S\)</span>-measurable. Then:</p>
<p><span class="math display">\[\|fh\|_1 \leq \|f\|_p\|h\|_{p^{\prime}}\]</span></p>
<p><br></p>
<h4 id="theorem-7.10-lqmu-subseteq-lpmu-if-mux-infty">Theorem 7.10: <span class="math inline">\(L^q(\mu) \subseteq L^p(\mu)\)</span> IF <span class="math inline">\(\mu(X) &lt; \infty\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a finite measure space and <span class="math inline">\(0 &lt; p &lt; q &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[\|f\|_p \leq \mu(X)^{\frac{q - p}{pq}}\|f\|_q\]</span></p>
<p>for all <span class="math inline">\(f \in L^q(\mu)\)</span>. Furthermore, <span class="math inline">\(L^q(\mu) \subseteq L^p(\mu)\)</span>.</p>
<p><br></p>
<h4 id="theorem-7.12-formula-for-f_p">Theorem 7.12: Formula for <span class="math inline">\(\|f\|_p\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(1 \leq p &lt; \infty\)</span>, and <span class="math inline">\(f \in L^p(\mu)\)</span>. Then:</p>
<p><span class="math display">\[\|f\|_p = \sup\{|\int fhd\mu|: h \in L^{p^{\prime}}(\mu), \|h\|_{p^{\prime}} \leq 1\}\]</span></p>
<p>This result hold for <span class="math inline">\(p = \infty\)</span>, if <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\sigma\)</span>-finite measure.</p>
<p><br></p>
<h4 id="theorem-7.14-minkowskis-inequality">Theorem 7.14: Minkowski's Inequality</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(1 \leq p \leq \infty\)</span>, and <span class="math inline">\(f, g \in L^p(\mu)\)</span>. Then:</p>
<p><span class="math display">\[\|f + g\|_p \leq \|f\|_p + \|g\|_p\]</span></p>
<p><br></p>
<h3 id="mathbflpmu"><span class="math inline">\(\mathbf{L}^p(\mu)\)</span></h3>
<p>Mathematicians often pretend that elements of <span class="math inline">\(L^p(\mu)\)</span> are functions, where two functions are considered to be equal if they differ only on a set of <span class="math inline">\(\mu\)</span>-measure <span class="math inline">\(0\)</span>.</p>
<h4 id="definition-7.15-zmu-tildef">Definition 7.15: <span class="math inline">\(Z(\mu)\)</span>; <span class="math inline">\(\tilde{f}\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 &lt; p \leq \infty\)</span>.</p>
<ul>
<li><span class="math inline">\(Z(\mu)\)</span> denotes the set of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{F}\)</span> that equal <span class="math inline">\(0\)</span> almost everywhere (zero everywhere except for the set with zero measure). So <span class="math inline">\(Z(\mu)\)</span> is a subspace of <span class="math inline">\(L^p(\mu)\)</span>.</li>
<li>For <span class="math inline">\(f \in L^p(\mu)\)</span>, let <span class="math inline">\(\tilde{f}\)</span> be a subset of <span class="math inline">\(L^p(\mu)\)</span> defined by: <span class="math display">\[\tilde{f} = \{f + z: z \in Z(\mu)\}\]</span></li>
<li>If <span class="math inline">\(f, F \in L^p(\mu)\)</span>, then <span class="math inline">\(\tilde{f} = \tilde{F}\)</span> IFF <span class="math inline">\(f(x) = F(x)\)</span> for almost every <span class="math inline">\(x \in X\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-7.16-mathbflp-mu">Definition 7.16: <span class="math inline">\(\mathbf{L}^p (\mu)\)</span></h4>
<p>Suppose <span class="math inline">\(\mu\)</span> is a measure and <span class="math inline">\(0 &lt; p \leq \infty\)</span>.</p>
<ul>
<li>Let <span class="math inline">\(\mathbf{L}^p(\mu)\)</span> denote the collection of subsets of <span class="math inline">\(L^p(\mu)\)</span> defined by: <span class="math display">\[\mathbf{L}^p(\mu) = \{\tilde{f}: f \in L^p(\mu)\}\]</span></li>
<li>For <span class="math inline">\(\tilde{f}, \tilde{g} \in \mathbf{L}^p(\mu)\)</span> and <span class="math inline">\(\alpha \in \mathbb{F}\)</span>, define <span class="math inline">\(\tilde{f} + \tilde{g}\)</span> and <span class="math inline">\(\alpha \tilde{f}\)</span> by: <span class="math display">\[\tilde{f} + \tilde{g} = \widetilde{(f + g)} \quad \quad \alpha \tilde{f} = \widetilde{(\alpha f)}\]</span></li>
<li><span class="math inline">\(\mathbf{L}^p(\mu) = L^p(\mu) / Z(\mu)\)</span></li>
<li>We can think of elements of <span class="math inline">\(L^p (\mu)\)</span> as equivalence classes of function in <span class="math inline">\(L^p(\mu)\)</span>, where two functions are equivalent if they agree almost everywhere.</li>
</ul>
<p><br></p>
<h4 id="definition-7.17-cdot_p-on-mathbflp-mu">Definition 7.17: <span class="math inline">\(\|\cdot\|_p\)</span> on <span class="math inline">\(\mathbf{L}^p (\mu)\)</span></h4>
<p>Suppose <span class="math inline">\(\mu\)</span> is a measure and <span class="math inline">\(0 &lt; p \leq \infty\)</span>. Define <span class="math inline">\(\|\cdot\|_p\)</span> on <span class="math inline">\(\mathbf{L}^p (\mu)\)</span> by:</p>
<p><span class="math display">\[\|\tilde{f}\|_p = \|f\|_p\]</span></p>
<p>for <span class="math inline">\(f \in L^p(\mu)\)</span></p>
<p><br></p>
<h4 id="definition-7.18-mathbflp-mu-is-a-normed-vector-space">Definition 7.18: <span class="math inline">\(\mathbf{L}^p (\mu)\)</span> is a Normed Vector Space</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(1 \leq p \leq \infty\)</span>. Then <span class="math inline">\(\mathbf{L}^p (\mu)\)</span> is a vector space and <span class="math inline">\(\|\cdot\|_p\)</span> is a norm on <span class="math inline">\(\mathbf{L}^p (\mu)\)</span>.</p>
<p><br></p>
<h4 id="theorem-7.18.1-lp-lpmu-mathbflpmu">Theorem 7.18.1: <span class="math inline">\(l^p = L^p(\mu) = \mathbf{L}^p(\mu)\)</span></h4>
<p>If <span class="math inline">\(\mu\)</span> is counting measure on <span class="math inline">\(\mathbb{Z}^+\)</span>, then: <span class="math display">\[l^p = L^p(\mu) = \mathbf{L}^p(\mu)\]</span></p>
<p>Because the counting measure has no sets of measure <span class="math inline">\(0\)</span> other thant the empty set.</p>
<p><br></p>
<h4 id="definition-7.19-mathbflpe-for-e-subseteq-mathbbr">Definition 7.19: <span class="math inline">\(\mathbf{L}^p(E)\)</span> for <span class="math inline">\(E \subseteq \mathbb{R}\)</span></h4>
<p>If <span class="math inline">\(E\)</span> is a Borel or Lebesgue measurable subset of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(0 &lt; p \leq \infty\)</span>, then <span class="math inline">\(\mathbf{L}^p(E)\)</span> means <span class="math inline">\(\mathbf{L}^p(\lambda_E)\)</span>, where <span class="math inline">\(\lambda_E\)</span> denotes Lebesgue measure <span class="math inline">\(\lambda\)</span> restricted to the Borel or Lebesgue measurable subsets of <span class="math inline">\(\mathbb{R}\)</span> that are contained in <span class="math inline">\(E\)</span>.</p>
<p><br></p>
<h4 id="theorem-7.20-cauchy-sequences-in-lpmu-converges">Theorem 7.20: Cauchy Sequences in <span class="math inline">\(L^p(\mu)\)</span> Converges</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(1 \leq p \leq \infty\)</span>. Suppose <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of functions in <span class="math inline">\(L^p(\mu)\)</span> s.t for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(n \in \mathbb{Z}^+\)</span> s.t: <span class="math display">\[\|f_j - f_k\|_p &lt; \epsilon\]</span></p>
<p>for all <span class="math inline">\(j \geq n\)</span> and <span class="math inline">\(k \geq n\)</span>. Then there exists <span class="math inline">\(f \in L^p(\mu)\)</span> s.t: <span class="math display">\[\lim_{k \rightarrow \infty} \|f_k - f\|_p = 0\]</span></p>
<p><br></p>
<h4 id="theorem-7.23-convergent-sequences-in-lp-have-pointwise-convergent-subsequences">Theorem 7.23: Convergent Sequences in <span class="math inline">\(L^p\)</span> have Pointwise Convergent Subsequences</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(1 \leq p \leq \infty\)</span>. Suppose <span class="math inline">\(f \in L^p(\mu)\)</span> and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of functions in <span class="math inline">\(L^p(\mu)\)</span> s.t <span class="math inline">\(\lim_{k\rightarrow \infty} \|f_k - f\|_{p} = 0\)</span>, then there exists a subsequence <span class="math inline">\(f_{k_1}, f_{k_2}, ....\)</span> s.t: <span class="math display">\[\lim_{m\rightarrow \infty} f_{k_m} (x) = f(x)\]</span></p>
<p>for almost every <span class="math inline">\(x \in X\)</span>.</p>
<p><br></p>
<h4 id="theorem-7.24-mathbflpmu-is-a-banach-space">Theorem 7.24: <span class="math inline">\(\mathbf{L}^p(\mu)\)</span> is a Banach Space</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, and <span class="math inline">\(1 \leq p \leq \infty\)</span>. Then, <span class="math inline">\(\mathbf{L}^p(\mu)\)</span> is a Banach Space.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Logistic Regression</title>
    <url>/2021/07/19/logistic-regression/</url>
    <content><![CDATA[<h1 id="logistic-regression">Logistic Regression</h1>
<p>Suppose we have training examples <span class="math inline">\(D = \{(\mathbf{x}_1, y_1), ...., (\mathbf{x}_N, y_N); \; \mathbf{x}_i \in \mathbb{R}^d\}\)</span>, our goal is to make decision about the class of new input <span class="math inline">\(\mathbf{x}\)</span>. The logistic regression does this by learning from a training set, a vector of bias and a matrix of weights.</p>
<h2 id="binary-class">Binary-Class</h2>
<p>In binary class problem, our target <span class="math inline">\(Y\)</span> takes values <span class="math inline">\(\{0, 1\}\)</span>. To model the distribution <span class="math inline">\(P(Y | \mathbf{X}; \; \mathbf{w}, b)\)</span>, we apply sigmoid function on the dot product of weights and inputs which transform the output to a value between <span class="math inline">\([0, 1]\)</span> (one criteria for probability):</p>
<p><span class="math display">\[z = \mathbf{x}^T \mathbf{w} + b\]</span></p>
<p><span class="math display">\[y = \sigma(z)\]</span></p>
<p>To make sure that class random variable <span class="math inline">\(Y\)</span>'s conditional pmf sums to 1:</p>
<p><span class="math display">\[P(Y=1 | X=\mathbf{x} ;\; \mathbf{w}, b) = \frac{1}{1 + e^{-z}} = p\]</span></p>
<p><span class="math display">\[P(Y=0 | X=\mathbf{x} ;\; \mathbf{w}, b) = 1 - \frac{1}{1 + e^{-z}} = \frac{e^{-z}}{1 + e^{-z}} = 1 - p\]</span></p>
<p>Then, it is equivalently to express this conditional pmf as Bernoulli pmf:</p>
<p><span class="math display">\[p_{Y|\mathbf{X}} (y | \mathbf{x}; \; \mathbf{w}, b) = p^y + (1 - p)^{1 - y}\]</span></p>
<p>If we have the conditional pmf of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X= \mathbf{x}\)</span>, then we can use simple decision rule to make decisions:</p>
<p><span class="math display">\[
\hat{y} =
\begin{cases}
P(Y=1 | X=\mathbf{x}) &gt; 0.5, \quad 1\\
P(Y=1 | X=\mathbf{x}) \leq 0.5, \quad 0
\end{cases}
\]</span></p>
<span id="more"></span>
<h3 id="learning-parameters">Learning Parameters</h3>
<p>Given the dataset <span class="math inline">\(D\)</span>, the conditional likelihood function can be written as:</p>
<p><span class="math display">\[L(\boldsymbol{\theta}; \; D) = \prod^{N}_{i=1} P( y_i | \mathbf{x}_i ; \; \mathbf{\theta})\]</span></p>
<p>Where <span class="math inline">\(\boldsymbol{\theta} = &lt;\mathbf{w}, b&gt;\)</span>. In general, we could absorb <span class="math inline">\(b\)</span> in <span class="math inline">\(\mathbf{w}\)</span> by having an extra <span class="math inline">\(w_0\)</span> term and append <span class="math inline">\(1\)</span> as one feature at the beginning of each feature vector <span class="math inline">\(\mathbf{x}_i\)</span>. Our log likelihood becomes:</p>
<span class="math display">\[\begin{aligned}
l(\boldsymbol{\theta}; \; D) &amp;= \sum^{N}_{i=1} y_i\log (p_i) + (1 - y_i) \log(1 - p_i)\\
&amp;= \sum^{N}_{i=1} y_i\log (\frac{1}{1 + e^{-z_i}}) + (1 - y_i) \log(\frac{e^{-z_i}}{1 + e^{-z_i}})\\
&amp;= \sum^{N}_{i=1} -y_i\log (1 + e^{-z}) + (1 - y_i)z_i - \log(1 + e^{-z_i}) + y_i\log (1 + e^{-z})\\
&amp;= \sum^{N}_{i=1} y_i \mathbf{w}^T\mathbf{x}_i - \log (1 + e^{\mathbf{w}^T\mathbf{x}_i})
\end{aligned}\]</span>
<p>By taking the negative sign in front of this log-likelihood, we have <code>cross-entropy loss</code> of logistic regression.</p>
<p>The partial derivative is then:</p>
<p><span class="math display">\[\frac{l(\boldsymbol{\theta}; \; D)}{\partial w_j} = \sum^{N}_{i=1}(y_i - p_i) x_{ij}\]</span></p>
<p><strong>We are not going to solve for the parameters by taking gradient and setting it to zero because the equations are non-linear in <span class="math inline">\(\mathbf{w}\)</span></strong>. Thus, one way to do this is to apply gradient decent on the negative of log likelihood (cross-entropy loss).</p>
<h2 id="multi-class">Multi-Class</h2>
<p>In multi-class case, we have <span class="math inline">\(Y = \{1, ...., K\}\)</span>. Instead with one set of parameters <span class="math inline">\(\boldsymbol \theta = \mathbf{w}\)</span>, we now have one set of parameters for each class (total <span class="math inline">\(K-1\)</span>) <span class="math inline">\(\;\)</span> <span class="math inline">\(\boldsymbol \theta = W_{[K \times d]}\)</span>. Then we can define the condition pmf for <span class="math inline">\(i\)</span>th sample using softmax function as:</p>
<p><span class="math display">\[P(Y=y_i | \mathbf{X} = \mathbf{x}_i) = \frac{e^{z_{iy_i}}}{\sum^{K}_{j=1} e^{z_{ij}}} = p_{iy_i}, \quad 1 \leq y_i \leq K\]</span></p>
<p>This is equivalent to the pmf of multinomial distribution with <span class="math inline">\(n=1\)</span>, which is the categorical distribution:</p>
<p><span class="math display">\[p_{Y | \mathbf{x}}(y_i | \mathbf{x}_i) = \prod^{K}_{j=1} p_{iy_i}^{I[y_i = j]}\]</span></p>
<p>Then the log likelihood is:</p>
<p><span class="math display">\[l(\boldsymbol{\theta}; \; D) = \sum^{N}_{i=1} \sum^{K}_{j=1} I[y_i = j] \log (p_{iy_i})\]</span></p>
<p>By taking the negative sign in front of this log-likelihood, we have <code>multi-class cross-entropy loss</code> of logistic regression.</p>
<p>If we are using the one-hot encoding for the class <span class="math inline">\(y_i\)</span>, then we can replace the log likelihood by:</p>
<p><span class="math display">\[l(\boldsymbol{\theta}; \; D) = \sum^{N}_{i=1} y_i \log (p_{iy_i})\]</span></p>
<p>The partial derivative is then:</p>
<p><span class="math display">\[\frac{l(\boldsymbol{\theta}; \; D)}{\partial w_{jd}} = \sum^{N}_{i=1} (I[y_i = j] - p_{iy_i}) x_{id}\]</span></p>
<h1 id="implementation">Implementation</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, optimizer, c=<span class="number">1</span>, max_iter=<span class="number">2000</span>, lr=<span class="number">0.01</span>, tor=<span class="number">0.0000001</span>, verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.c = c</span><br><span class="line">        self.max_iter = max_iter</span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self.tor = tor</span><br><span class="line">        self.verbose = verbose</span><br><span class="line"></span><br><span class="line">        self.weights = <span class="literal">None</span></span><br><span class="line">        self.k = <span class="literal">None</span></span><br><span class="line">        self.d = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x_train, y_train</span>):</span></span><br><span class="line">        n_y, self.k = y_train.shape</span><br><span class="line">        x_train = np.column_stack([np.ones(n_y), x_train])</span><br><span class="line">        n_x, self.d = x_train.shape</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.weights:</span><br><span class="line">            self.weights = np.random.randn(self.d, self.k)</span><br><span class="line"></span><br><span class="line">        opt = self.optimizer(lr=self.lr, model_vars=[self.weights])</span><br><span class="line"></span><br><span class="line">        prev_matrix = <span class="number">0</span></span><br><span class="line">        dif = np.linalg.norm(self.weights - prev_matrix)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.k &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">while</span> (i &lt;= self.max_iter) <span class="keyword">and</span> (dif &gt;= self.tor):</span><br><span class="line">                prev_matrix = self.weights</span><br><span class="line">                <span class="keyword">if</span> self.verbose <span class="keyword">and</span> (i % self.verbose == <span class="number">0</span>):</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&#x27;iteration: <span class="subst">&#123;i&#125;</span>, loss: <span class="subst">&#123;self._cal_train_loss(x_train, y_train)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                self.weights = opt([self._mc_ce_grad(x_train, y_train)])[<span class="number">0</span>]</span><br><span class="line">                dif = np.linalg.norm(self.weights - prev_matrix)</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_test</span>):</span></span><br><span class="line">        x_test = np.column_stack([np.ones(x_test.shape[<span class="number">0</span>]), x_test])</span><br><span class="line">        pred = [np.argmax(self._cal_softmax(x_i)) <span class="keyword">for</span> x_i <span class="keyword">in</span> x_test]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_mc_ce_grad</span>(<span class="params">self, x, labels</span>):</span></span><br><span class="line">        n = x.shape[<span class="number">0</span>]</span><br><span class="line">        output_g = np.zeros((self.d, self.k))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, x_i <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">            soft_max = self._cal_softmax(x_i)</span><br><span class="line">            temp_g = np.repeat(x_i.reshape(-<span class="number">1</span>, <span class="number">1</span>), self.k, axis=<span class="number">1</span>) * (soft_max - labels[i])</span><br><span class="line">            output_g += temp_g</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (output_g + self.c * self.weights)/ n</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_cal_softmax</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        bot = <span class="number">0</span></span><br><span class="line">        top = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">            ea = np.exp(np.dot(self.weights[:, k], x))</span><br><span class="line">            bot += ea</span><br><span class="line">            top.append(ea)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.array(top / bot)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span>(<span class="params">y_pred, y_true</span>):</span></span><br><span class="line">        loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(y_true):</span><br><span class="line">            y_pred_i = np.log(y_pred[i])</span><br><span class="line">            loss += np.dot(y_pred_i, v.T)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> -loss / <span class="built_in">len</span>(y_true)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_cal_train_loss</span>(<span class="params">self, x_train, y_train</span>):</span></span><br><span class="line">        y_pred = self._cal_softmax(x_train[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> x_train[<span class="number">1</span>:]:</span><br><span class="line">            y_pred = np.row_stack([y_pred, self._cal_softmax(i)])</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> self.cross_entropy(y_pred, y_train)</span><br></pre></td></tr></table></figure>
<h1 id="ref">Ref</h1>
<p>https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf</p>
<p>https://web.stanford.edu/~jurafsky/slp3/5.pdf</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Momentum</title>
    <url>/2021/07/29/momentum/</url>
    <content><![CDATA[<h1 id="momentum">Momentum</h1>
<p>While SGD remains a very popular optimization strategy, learning with it can be slow. The method of momentum is designed to accelerate learning, especially in the face of <strong>high curvature</strong> (large change of direction of the curve in small amount time), <strong>small but consistent gradients</strong> (flat surface) or <strong>noisy gradients</strong> (with high variance). The momentum algorithm accumulates an exponentially decaying moving average of past gradients and continues to move in their direction.</p>
<p><br></p>
<p>The momentum algorithm introduces several variables:</p>
<ol type="1">
<li>A vector <span class="math inline">\(\mathbf{v}\)</span> that plays a role of velocity (with direction and speed). The velocity is set to an exponentially decaying average of the negative gradient.</li>
<li>A hyparameter <span class="math inline">\(\alpha \in [0, 1)\)</span> determins how quickly the contributions of previous gradients exponentially decay.</li>
</ol>
<p>The update rule is given by:</p>
<p><span class="math display">\[\mathbf{v} \leftarrow \alpha \mathbf{v} - \epsilon \nabla_{\boldsymbol{\theta}} (\frac{1}{N} \sum^{N}_{i=1} L(\mathbf{f} (\mathbf{x}_i; \; \boldsymbol{\theta}), \mathbf{y}_i))\]</span></p>
<p><span class="math display">\[\boldsymbol{\theta} \rightarrow \boldsymbol{\theta} + \mathbf{v}\]</span></p>
<p>Previously, in SGD, the size of the step was simply the norm of the gradient multiplied by the learning rate:</p>
<p><span class="math display">\[\epsilon \nabla_{\boldsymbol{\theta}} (\frac{1}{N} \sum^{N}_{i=1} L(\mathbf{f} (\mathbf{x}_i; \; \boldsymbol{\theta}), \mathbf{y}_i))\]</span></p>
<p>Now the size of the step depends on <strong>how large and how aligned a sequence of gradients</strong> are. The step size is <strong>largest</strong> when many successive gradients point in exactly the same direction. If the momentum algorithm always observe gradient <span class="math inline">\(\mathbf{g}\)</span>, then it will accelerate in the direction of <span class="math inline">\(-\mathbf{g}\)</span>:</p>
<p><span class="math display">\[\mathbf{v}_1 \leftarrow - \epsilon \mathbf{g}\]</span></p>
<p><span class="math display">\[\mathbf{v}_2 \leftarrow -\mathbf{g} \epsilon(\alpha + 1)\]</span></p>
<p><span class="math display">\[\mathbf{v}_N \leftarrow -\mathbf{g} \epsilon \sum^{N-1}_{i=0} \alpha^i\]</span></p>
<p><span class="math display">\[\implies \|\mathbf{v}_{\infty}\| = \frac{\epsilon \|\mathbf{g}\|}{1 - \alpha}\]</span></p>
<p>The terminal velocity will have speed <span class="math inline">\(\frac{\epsilon \|\mathbf{g}\|}{1 - \alpha} \gg \epsilon \|\mathbf{g}\|\)</span>. This makes sense because if we receive consistent small gradients, we would like to take larger steps because we are confident we are in the right direction. One the other hand, consistently changing direction gradients (high curvature) would cause the gradient to be small to allow convergence.</p>
<p><img src='/images/ML/momentum_1.png' width="600"></p>
<h2 id="nesterov-momentum">Nesterov Momentum</h2>
<p>Nesterov Momentum is inspired by Nesterov's accelerated gradient method, the update rules in this case are given by:</p>
<p><span class="math display">\[\mathbf{v} \leftarrow \alpha \mathbf{v} - \epsilon \nabla_{\boldsymbol{\theta}} (\frac{1}{N} \sum^{N}_{i=1} L(\mathbf{f} (\mathbf{x}_i; \; \boldsymbol{\theta} + \alpha \mathbf{v}), \mathbf{y}_i))\]</span></p>
<p><span class="math display">\[\boldsymbol{\theta} \rightarrow \boldsymbol{\theta} + \mathbf{v}\]</span></p>
<p>This is similar to momentum, but before taking the gradient, we first take one step forward using previous velocity, then we take the gradient there and adjust velocity accordingly. We can also think of this as attempting to add a <strong>correlation factor</strong> to the standard method of momentum.</p>
<p><img src='/images/ML/momentum_2.png' width="600"></p>
<h1 id="implementation">Implementation</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SGD</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, lr, model_vars</span>):</span></span><br><span class="line">        self.model_vars = model_vars</span><br><span class="line">        self.lr = lr</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, grad</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.model_vars):</span><br><span class="line">            self.model_vars[i] = v - self.lr * grad[i]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.model_vars</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Momentum</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, lr, model_vars, alpha=<span class="number">0.9</span></span>):</span></span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.model_vars = model_vars</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.v = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, grad</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.model_vars):</span><br><span class="line">            self.v = self.v * self.alpha - self.lr * grad[i]</span><br><span class="line">            self.model_vars[i] = self.model_vars[i] + self.v</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.model_vars</span><br></pre></td></tr></table></figure>
<h1 id="ref">Ref</h1>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>Measure Integral and Real Analysis (1)</title>
    <url>/2022/02/13/mira/</url>
    <content><![CDATA[<h1 id="measure-integral-and-real-analysis-1">Measure Integral and Real Analysis (1)</h1>
<p><span class="math inline">\(X / A\)</span> means that the difference between set <span class="math inline">\(X\)</span> and <span class="math inline">\(A\)</span>.</p>
<h2 id="fields">Fields</h2>
<h3 id="complete-ordered-fields">Complete Ordered Fields</h3>
<h4 id="definition-0.1-field">Definition 0.1: Field</h4>
<p>A <strong>field</strong> is a set <span class="math inline">\(\mathbb{F}\)</span> along with <strong>closed</strong> operations of addition and multiplication on <span class="math inline">\(\mathbb{F}\)</span> that have the following properties:</p>
<ol type="1">
<li><strong>Commutativity</strong>: <span class="math display">\[a + b = b + a, \quad ab = ba \quad \forall a, b \in \mathbb{F}\]</span></li>
<li><strong>Associativity</strong>: <span class="math display">\[(a + b) + c  = a + (b + c) \quad (ab)c = a(bc) \quad \forall a,b,c \in \mathbb{F}\]</span></li>
<li><strong>Distributive Property</strong>: <span class="math display">\[a(b + c) = ab + ac \quad \forall a, b, c \in \mathbb{F}\]</span></li>
<li><strong>Additive Identity</strong>: There exists an element <span class="math inline">\(0 \in \mathbb{F}\)</span> s.t. <span class="math inline">\(a + 0 = a, \forall a \in \mathbb{F}\)</span></li>
<li><strong>Additive Inverse</strong>: For each <span class="math inline">\(a \in \mathbb{F}\)</span>, there exists an element <span class="math inline">\(-a \in \mathbb{F}\)</span> such that <span class="math inline">\(a + (-a) = 0\)</span>.</li>
<li><strong>Multiplicative Identity</strong>: There exists an element <span class="math inline">\(1 \in \mathbb{F}\)</span> s.t <span class="math inline">\(1 \neq 0\)</span> and <span class="math inline">\(a1 = a, \forall a \in \mathbb{F}\)</span>.</li>
<li><strong>Multiplicative Inverse</strong>: For each <span class="math inline">\(a \in \mathbb{F}\)</span> with <span class="math inline">\(a \neq 0\)</span>, there exists an element <span class="math inline">\(a^{-1} \in \mathbb{F}\)</span> s.t <span class="math inline">\(aa^{-1} = 1\)</span></li>
</ol>
<blockquote>
<p><span class="math inline">\(\mathbb{Q}, \mathbb{R}, \mathbb{C}, \{0, 1\}\)</span> with usual operation of addition and multiplication are fields.</p>
</blockquote>
<p><br></p>
<span id="more"></span>
<h4 id="definition-0.5-ordered-field-positive">Definition 0.5: Ordered Field, Positive</h4>
<p>An <strong>ordered field</strong> is a field <span class="math inline">\(\mathbb{F}\)</span> along with a subset <span class="math inline">\(P\)</span> of <span class="math inline">\(\mathbb{F}\)</span>, called the <strong>positive</strong> subset with the following properties:</p>
<ol type="1">
<li>If <span class="math inline">\(a \in \mathbb{F}\)</span>, then <span class="math inline">\(a \in P\)</span> or <span class="math inline">\(a = 0\)</span> or <span class="math inline">\(-a \in P\)</span>.</li>
<li>If <span class="math inline">\(a \in P\)</span>, then <span class="math inline">\(-a \notin P\)</span>.</li>
<li>If <span class="math inline">\(a, b \in P\)</span>, then <span class="math inline">\(a + b \in P\)</span> and <span class="math inline">\(ab \in P\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-0.6-the-positive-subset-is-closed-under-multiplicative-inverse">Theorem 0.6: The Positive Subset is Closed under Multiplicative Inverse</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field with positive subset <span class="math inline">\(P\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(1 \in P\)</span></li>
<li><span class="math inline">\(a^{-1} \in P, \forall a \in P\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-0.7-less-than-greater-than">Definition 0.7: Less Than, Greater Than</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field with positive subset <span class="math inline">\(P\)</span>. Suppose <span class="math inline">\(a, b \in \mathbb{F}\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(a &lt; b\)</span> is defined to mean <span class="math inline">\(b - a \in P\)</span>.</li>
<li><span class="math inline">\(a \leq b\)</span> is defined to mean <span class="math inline">\(a &lt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
<li><span class="math inline">\(a &gt; b\)</span> is defined to mean <span class="math inline">\(a - b \in P\)</span>.</li>
<li><span class="math inline">\(a \geq b\)</span> is defined to mean <span class="math inline">\(a &gt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
</ol>
<p>The statement <span class="math inline">\(0 &lt; b\)</span> is equivalent to the statement <span class="math inline">\(b \in P\)</span>.</p>
<p><br></p>
<h4 id="theorem-0.8-transitivity">Theorem 0.8: Transitivity</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field and <span class="math inline">\(a, b, c \in \mathbb{F}\)</span>. If <span class="math inline">\(a &lt; b\)</span> and <span class="math inline">\(b &lt; c\)</span>, then <span class="math inline">\(a &lt; c\)</span>.</p>
<p><br></p>
<h4 id="definition-0.9-absolute-value">Definition 0.9: Absolute Value</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field and <span class="math inline">\(b \in \mathbb{F}\)</span>. The <strong>absolute value</strong> of <span class="math inline">\(b\)</span>, denoted <span class="math inline">\(|b|\)</span>, is defined by:</p>
<p><span class="math display">\[
|b| =
\begin{cases}
b, \quad \text{if} b \geq 0\\
-b, \quad \text{if} b &lt; 0
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="theorem-0.10-a-b-leq-a-b">Theorem 0.10: <span class="math inline">\(|a + b| \leq |a| + |b|\)</span></h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field and <span class="math inline">\(a, b \in \mathbb{F}\)</span>. Then:</p>
<p><span class="math display">\[|a + b| \leq |a| + |b|\]</span></p>
<p><br></p>
<h3 id="completeness">Completeness</h3>
<h4 id="definition-0.19-complete-ordered-field">Definition 0.19: Complete Ordered Field</h4>
<p>An ordered field <span class="math inline">\(\mathbb{F}\)</span> is called <strong>complete</strong> if every nonempty subset of <span class="math inline">\(\mathbb{F}\)</span> that has an upper bound has a least upper bound.</p>
<p><br></p>
<h4 id="definition-0.20-mathbbr-the-field-of-real-numbers">Definition 0.20: <span class="math inline">\(\mathbb{R}\)</span>, The Field of Real Numbers</h4>
<p>The symbol <span class="math inline">\(\mathbb{R}\)</span> denotes a complete ordered field. This field is called real numbers.</p>
<p><br></p>
<h4 id="definition-0.35-supremum-and-infimum">Definition 0.35: Supremum and Infimum</h4>
<p>Suppose <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The <strong>supremum</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\sup A\)</span>, is defined as:</p>
<p><span class="math display">\[
\sup A =
\begin{cases}
\text{The Least Upper Bound}, \quad \text{if $A$ has an upper bound and $A \neq \emptyset$}\\
\infty, \quad \text{if $A$ does not have an upper bound}\\
-\infty, \quad \text{if $A = \emptyset$}
\end{cases}
\]</span></p>
<p>The <strong>Infimum</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\inf A\)</span>, is defined as:</p>
<p><span class="math display">\[
\inf A =
\begin{cases}
\text{The Greatest Lower Bound}, \quad \text{if $A$ has a lower bound and $A \neq \emptyset$}\\
-\infty, \quad \text{if $A$ does not have a lower bound}\\
\infty, \quad \text{if $A = \emptyset$}
\end{cases}
\]</span></p>
<h3 id="intervals">Intervals</h3>
<p>Sometimes it is useful to consider a set consisting of <span class="math inline">\(\mathbb{R}\)</span> and two additional elements called <span class="math inline">\(\infty\)</span> and <span class="math inline">\(-\infty\)</span>. We define it as <span class="math inline">\(\mathbb{R} \cup \{\infty, -\infty\}\)</span>.</p>
<h4 id="definition-0.40-ordering-on-mathbbr-cup-infty--infty">Definition 0.40: Ordering on <span class="math inline">\(\mathbb{R} \cup \{\infty, -\infty\}\)</span></h4>
<ul>
<li>The ordering <span class="math inline">\(&lt;\)</span> on <span class="math inline">\(\mathbb{R}\)</span> is extended to <span class="math inline">\(\mathbb{R} \cup \{\infty, -\infty\}\)</span> as follows:
<ul>
<li><span class="math inline">\(a &lt; \infty, \;\forall a \in \mathbb{R} \cup \{-\infty\}\)</span></li>
<li><span class="math inline">\(-\infty &lt; a, \;\forall a \in \mathbb{R} \cup \{\infty\}\)</span></li>
</ul></li>
<li>For <span class="math inline">\(a, b \in \mathbb{R}\cup \{\infty, -\infty\}\)</span>,
<ul>
<li>The notation <span class="math inline">\(a \leq b\)</span> means that <span class="math inline">\(a &lt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
<li>The notation <span class="math inline">\(a &gt; b\)</span> means that <span class="math inline">\(b &lt; a\)</span>.</li>
<li>The notation <span class="math inline">\(a \geq b\)</span> means that <span class="math inline">\(a &gt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
</ul></li>
</ul>
<p><br></p>
<h4 id="definition-0.41-interval-notation">Definition 0.41: Interval Notation</h4>
<p>Suppose <span class="math inline">\(a, b \in \mathbb{R} \cup \{\infty, -\infty\}\)</span>. Then:</p>
<ul>
<li><span class="math inline">\((a, b) = \{t\in\mathbb{R}: a &lt; t &lt; b\}\)</span></li>
<li><span class="math inline">\([a, b] = \{t \in \mathbb{R} \cup \{\infty, -\infty\}: a \leq t \leq b\}\)</span></li>
<li><span class="math inline">\((a, b] = \{t \in \mathbb{R} \cup \{\infty\}: a &lt; t \leq b\}\)</span></li>
<li><span class="math inline">\([a, b) = \{t \in \mathbb{R} \cup \{-\infty\}: a \leq t &lt; b\}\)</span></li>
</ul>
<p>If <span class="math inline">\(a &gt; b\)</span> then all sets are empty ses. If <span class="math inline">\(a = b\)</span>, then <span class="math inline">\([a, b]\)</span> is the set of <span class="math inline">\(\{a\}\)</span>, all others are empty sets. The definition implies that:</p>
<ol type="1">
<li><span class="math inline">\((-\infty, \infty) = \mathbb{R}\)</span></li>
<li><span class="math inline">\([-\infty, \infty] = \mathbb{R} \cup \{\infty, \infty\}\)</span>, this is not a subset of <span class="math inline">\(\mathbb{R}\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-0.42-interval">Definition 0.42: Interval</h4>
<ul>
<li>A subset of <span class="math inline">\([-\infty, \infty]\)</span> is called an <strong>interval</strong> if it contains all numbers that are between pairs of its elements.</li>
<li>In other words, a set <span class="math inline">\(I \subset [-\infty, \infty]\)</span> is called an <strong>interval</strong> if <span class="math inline">\(c, d \in I\)</span> implies <span class="math inline">\((c, d) \in I\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-0.43-description-of-intervals">Theorem 0.43: Description of Intervals</h4>
<p>Suppose <span class="math inline">\(I \subset [-\infty, \infty]\)</span> is an interval. Then <span class="math inline">\(I\)</span> is one of the following sets for some <span class="math inline">\(a,b \in [-\infty, \infty]\)</span>:</p>
<p><span class="math display">\[(a, b), [a, b], (a, b], [a, b)\]</span></p>
<p><br></p>
<h3 id="open-and-closed-subsets-of-mathbbrn">Open and Closed Subsets of <span class="math inline">\(\mathbb{R}^n\)</span></h3>
<h4 id="definition-0.44-mathbbrn">Definition 0.44: <span class="math inline">\(\mathbb{R^n}\)</span></h4>
<p>^n is the set of all ordered <span class="math inline">\(n-tuples\)</span> of real numbers:</p>
<p><span class="math display">\[\mathbb{R}^n = \{(x_1, ..., x_n): x_1, ..., x_n \in \mathbb{R}\}\]</span></p>
<p><br></p>
<h4 id="definition-0.45-cdot-cdot_infty">Definition 0.45: <span class="math inline">\(\|\cdot\|, \|\cdot\|_{\infty}\)</span></h4>
<p>For <span class="math inline">\((x_1, ..., x_n) \in \mathbb{R}^n\)</span>, let:</p>
<p><span class="math display">\[\|(x_1, ..., x_n)\| = \sqrt{x_1^2 + ... + x_n^2}\]</span></p>
<p>and</p>
<p><span class="math display">\[\|(x_1, ..., x_n)\|_{\infty} = \max\{|x_1|, ..., |x_n|\}\]</span></p>
<p><br></p>
<h4 id="definition-0.46-limit">Definition 0.46: Limit</h4>
<p>Suppose <span class="math inline">\(a_1, a_2, ... \in\mathbb{R}^n\)</span> and <span class="math inline">\(L \in \mathbb{R}^n\)</span>. Then <span class="math inline">\(L\)</span> is called a limit of the sequence <span class="math inline">\(a_1, a_2, ...\)</span> and we write:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} a_k = L\]</span></p>
<p>If for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(m \in \mathbb{Z}^+\)</span> s.t:</p>
<p><span class="math display">\[\|a_k - L\|_\infty &lt; \epsilon\]</span></p>
<p>for all integers <span class="math inline">\(k \geq m\)</span>.</p>
<p><br></p>
<h4 id="definition-0.47-converge-convergent">Definition 0.47: Converge, Convergent</h4>
<p>A sequence in <span class="math inline">\(\mathbb{R}^n\)</span> is said to <strong>converge</strong> and to be a <strong>convergent sequence</strong> if it has a limit.</p>
<p><br></p>
<h4 id="theorem-0.48-coordinatewise-limits">Theorem 0.48: Coordinatewise Limits</h4>
<p>Suppose <span class="math inline">\(a_1, a_2, .... \in \mathbb{R}^n\)</span> and <span class="math inline">\(L \in \mathbb{R}^n\)</span>. For <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, let:</p>
<p><span class="math display">\[(a_{k, 1}, ...., a_{k, n}) = a_k\]</span></p>
<p>and let <span class="math inline">\((L_1, ..., L_n) = L\)</span>. Then, <span class="math inline">\(\lim_{k \rightarrow \infty} a_k = L\)</span> IFF:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} a_{k, j} = L_j\]</span></p>
<p>For each <span class="math inline">\(j \in \{1, ..., n\}\)</span></p>
<p><strong>Thus, questions about convergence of sequences in <span class="math inline">\(\mathbb{R}^n\)</span> can often be reduced to questions about convergence of sequences in <span class="math inline">\(\mathbb{R}\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-0.49-open-cube">Definition 0.49: Open Cube</h4>
<p>For <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(\delta &gt; 0\)</span>, the <strong>open cube</strong> <span class="math inline">\(B(x, \delta)\)</span> is defined by:</p>
<p><span class="math display">\[B(x, \delta) = \{y \in \mathbb{R}^n: \|y - x\|_{\infty} &lt; \delta\}\]</span></p>
<p><br></p>
<h4 id="definition-0.51-open-interval">Definition 0.51: Open Interval</h4>
<p>A subset of <span class="math inline">\(\mathbb{R}\)</span> of the form <span class="math inline">\((a, b)\)</span> for some <span class="math inline">\(a, b \in [-\infty, \infty]\)</span> is called an <strong>open interval</strong>.</p>
<p>If <span class="math inline">\(n = 1\)</span>, then <span class="math inline">\(B(x, \delta) = (x - \delta, x + \delta)\)</span></p>
<p><br></p>
<h4 id="definition-10.52-open-subset-of-mathbbrn">Definition 10.52: Open Subset of <span class="math inline">\(\mathbb{R}^n\)</span></h4>
<ul>
<li>A subset <span class="math inline">\(G\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>open</strong> if for every <span class="math inline">\(x \in G\)</span>, there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(B(x, \delta) \subseteq G\)</span>.</li>
<li>Equivalently, a subset <span class="math inline">\(G\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>open</strong> if every element of <span class="math inline">\(G\)</span> is contained in an open cube that is contained in <span class="math inline">\(G\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-0.55-union-and-intersection-of-open-sets">Theorem 0.55: Union and Intersection of Open Sets</h4>
<ol type="a">
<li>The union of every collection of open subsets of <span class="math inline">\(\mathbb{R}^n\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
<li>The intersection of every finite collection of open subset of <span class="math inline">\(\mathbb{R}^n\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-0.56-countable-uncountable">Definition 0.56: Countable, Uncountable</h4>
<ul>
<li>A set <span class="math inline">\(C\)</span> is called <strong>countable</strong> if <span class="math inline">\(C = \emptyset\)</span> or if <span class="math inline">\(C = \{c_1 c_2, ...\}\)</span> for some sequence <span class="math inline">\(c_1, c_2, ...\)</span> of element of <span class="math inline">\(C\)</span>.</li>
<li>A set is called <strong>uncountable</strong> if it is not countable.</li>
</ul>
<p><br></p>
<h4 id="definition-0.58-disjoint">Definition 0.58: Disjoint</h4>
<p>A sequence <span class="math inline">\(E_1, E_2, ...\)</span> of sets is called disjoint if <span class="math inline">\(E_j \cap E_k = \emptyset\)</span> whenever <span class="math inline">\(j \neq k\)</span>.</p>
<p><br></p>
<h4 id="theorem-0.59-open-subset-of-mathbbr-is-countable-disjoint-union-of-open-intervals">Theorem 0.59: Open Subset of <span class="math inline">\(\mathbb{R}\)</span> is Countable Disjoint Union of Open Intervals</h4>
<p>A subset of <span class="math inline">\(\mathbb{R}\)</span> is open iFF it is the union of a disjoint sequence of open interval.</p>
<p><br></p>
<h4 id="definition-0.60-set-difference-complement">Definition 0.60: Set Difference, Complement</h4>
<ul>
<li>If <span class="math inline">\(S, A\)</span> are sets, then the <strong>set difference</strong> <span class="math inline">\(S \ A\)</span> is defined to be the set of elements of <span class="math inline">\(S\)</span> that are not in <span class="math inline">\(A\)</span>. In other words, <span class="math inline">\(S \ A = \{s \in S: s \neq A\}\)</span>.</li>
<li>If <span class="math inline">\(A \subseteq S\)</span>, then <span class="math inline">\(S \ A\)</span> is the <strong>complement</strong> of <span class="math inline">\(A\)</span> in <span class="math inline">\(S\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-0.61-closed-subset-of-mathbbrn">Definition 0.61: Closed Subset of <span class="math inline">\(\mathbb{R}^n\)</span></h4>
<p>A subset of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>closed</strong> if its complement in <span class="math inline">\(\mathbb{R}^n\)</span> is open.</p>
<p><strong>a subset of <span class="math inline">\(\mathbb{R}^n\)</span> need not be either open or closed. For example <span class="math inline">\((6, 16]\)</span> is neither open nor closed</strong></p>
<p><br></p>
<h4 id="theorem-0.62-characterization-of-closed-sets">Theorem 0.62: Characterization of Closed Sets</h4>
<p>A subset of <span class="math inline">\(\mathbb{R}^n\)</span> is closed IFF it contains the limit of every convergent sequence of elements of the set.</p>
<p><br></p>
<h4 id="theorem-0.63-de-morgans-laws">Theorem 0.63: De Morgan's Laws</h4>
<p>Suppose <span class="math inline">\(A\)</span> is a collection of subsets of some set <span class="math inline">\(X\)</span>. Then:</p>
<p><span class="math display">\[X /\ \bigcup_{E \in A} E = \bigcap_{E \in A} (X /\ E)\]</span></p>
<p>and</p>
<p><span class="math display">\[X /\ \bigcap_{E \in A} E = \bigcup_{E \in A} (X /\ E)\]</span></p>
<p><br></p>
<h4 id="theorem-0.65-sets-that-are-both-open-and-closed">Theorem 0.65: Sets that are Both Open and Closed</h4>
<p>The only subsets of <span class="math inline">\(\mathbb{R}^n\)</span> that are both open and closed are <span class="math inline">\(\emptyset\)</span> and <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<p><br></p>
<h2 id="riemann-integral">Riemann Integral</h2>
<h3 id="riemann-integral-review">Riemann Integral Review</h3>
<h4 id="definition-1.1-partition">Definition 1.1: Partition</h4>
<p>Suppose <span class="math inline">\(a, b \in \mathbb{R}\)</span> with <span class="math inline">\(a &lt; b\)</span>. A partition of <span class="math inline">\([a, b]\)</span> is a finite list of the form <span class="math inline">\(x_0, x_1, ...., x_n\)</span>, where:</p>
<p><span class="math display">\[a = x_0 &lt; x_1 &lt; .... &lt; x_n = b\]</span></p>
<p><br></p>
<h4 id="definition-1.2-notation-for-infimum-and-supremum-of-a-function">Definition 1.2: Notation for Infimum and Supremum of a Function</h4>
<p>If <span class="math inline">\(f\)</span> is a real-valued function and <span class="math inline">\(A\)</span> is a subset of the domain of <span class="math inline">\(f\)</span>, then:</p>
<p><span class="math display">\[\inf_A f = \inf\{f(x): x \in A\} \quad \quad \sup_A f = \sup\{f(x): x \in A\}\]</span></p>
<p><br></p>
<h4 id="definition-1.3-lower-and-upper-riemann-sums">Definition 1.3: Lower and Upper Riemann Sums</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function and <span class="math inline">\(P\)</span> is a partition <span class="math inline">\(x_0 ,...., x_n\)</span> of <span class="math inline">\([a, b]\)</span>. The <strong>lower Riemann sum</strong> <span class="math inline">\(L(f, P, [a, b])\)</span> and the <strong>upper Riemann sum</strong> <span class="math inline">\(U(f, P, [a, b])\)</span> are defined by:</p>
<p><span class="math display">\[L(f, P, [a, b]) = \sum^n_{j=1}(x_j - x_{j-1}) \inf_{[x_{j-1}, x_j]} f\]</span></p>
<p>and</p>
<p><span class="math display">\[U(f, P, [a, b]) = \sum^n_{j=1}(x_j - x_{j-1}) \sup_{[x_{j-1}, x_j]} f\]</span></p>
<p><br></p>
<h4 id="theorem-1.5-inequalities-with-riemann-sums">Theorem 1.5: Inequalities with Riemann Sums</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function and <span class="math inline">\(P, P^{\prime}\)</span> are partitions of <span class="math inline">\([a, b]\)</span>, such that the list defining <span class="math inline">\(P\)</span> is a sublist of the list defining <span class="math inline">\(P^{\prime}\)</span>. Then:</p>
<p><span class="math display">\[L(f, P, [a, b]) \leq L(f, P^{\prime}, [a, b]) \leq U(f, P^{\prime}, [a, b]) \leq U(f, P, [a, b])\]</span></p>
<h5 id="proof-of-theorem-1.5">Proof of Theorem 1.5:</h5>
<p>Let <span class="math inline">\(P\)</span> be the partition <span class="math inline">\(x_0, ..., x_n\)</span> and <span class="math inline">\(P^{\prime}\)</span> be the partition <span class="math inline">\(x^{\prime}_0, ..., x^{\prime}_N\)</span> of <span class="math inline">\([a, b]\)</span>. Then for each <span class="math inline">\(j = 1, ..., n\)</span>, there exists <span class="math inline">\(k \in \{0, ..., N-1\}\)</span> and a positive integer <span class="math inline">\(m\)</span> s.t <span class="math inline">\(x_{j-1} = x^{\prime}_k &lt; ... &lt; x^{\prime}_{k+m} = x_j\)</span>, in other words, the interval <span class="math inline">\([x_{j-1}, x_j]\)</span> contains several smaller intervals <span class="math inline">\([x^{\prime}_{k}, x^{\prime}_{k+1}], ...., [x^{\prime}_{k+m -1}, x^{\prime}_{k+m}]\)</span>. Then:</p>
<p><span class="math display">\[(x_j - x_{j-1}) \inf_{[x_{j-1}, x_j]} f = \sum^{m}_{i=1} (x^{\prime}_{k+i} - x^{\prime}_{k+i - 1})\inf_{[x_{j-1}, x_j]} f \leq \sum^{m}_{i=1} (x^{\prime}_{k+i} - x^{\prime}_{k+i - 1})\inf_{[x^{\prime}_{k+i - 1}, x^{\prime}_{k+i}]} f\]</span></p>
<p>Which implies the first inequality. The second and third are similar.</p>
<p><br></p>
<h4 id="theorem-1.6-lower-riemann-sums-leq-upper-riemann-sums">Theorem 1.6: Lower Riemann Sums <span class="math inline">\(\leq\)</span> Upper Riemann Sums</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function and <span class="math inline">\(P, P^{\prime}\)</span> are partitions of <span class="math inline">\([a, b]\)</span>. Then:</p>
<p><span class="math display">\[L(f, P, [a, b]) \leq U(f, P^{\prime}, [a, b])\]</span></p>
<h5 id="proof-of-theorem-1.6">Proof of Theorem 1.6:</h5>
<p>Let <span class="math inline">\(P^{\prime\prime}\)</span> be the partition of <span class="math inline">\([a, b]\)</span> obtained by merging the lists that define <span class="math inline">\(P, P^{\prime}\)</span>, then by <code>theorem 1.5</code>, we have:</p>
<p><span class="math display">\[L(f, P, [a, b]) \leq L(f, P^{\prime\prime}, [a, b]) \leq U(f, P^{\prime\prime}, [a, b]) \leq U(f, P^{\prime}, [a, b])\]</span></p>
<p>For any <span class="math inline">\(P, P^{\prime}\)</span>.</p>
<p><br></p>
<h4 id="definition-1.7-lower-and-upper-riemann-integrals">Definition 1.7: Lower and Upper Riemann Integrals</h4>
<p>Suppose <span class="math inline">\(f:[a, b] \rightarrow \mathbb{R}\)</span> is a bounded function. The <strong>lower</strong> Riemann integral <span class="math inline">\(L(f, [a, b])\)</span> and the <strong>upper</strong> Riemann integral <span class="math inline">\(U(f, [a, b])\)</span> of <span class="math inline">\(f\)</span> are defined by:</p>
<p><span class="math display">\[L(f, [a, b]) = \sup_{P} L(f, P, [a, b])\]</span></p>
<p>and</p>
<p><span class="math display">\[U(f, [a, b]) = \inf_P U(f, P, [a, b])\]</span></p>
<p>Where the supremum and infimum above are taken over all partitions <span class="math inline">\(P\)</span> of <span class="math inline">\([a, b]\)</span>.</p>
<p><br></p>
<h4 id="theorem-1.8-lower-riemann-integral-leq-upper-riemann-integral">Theorem 1.8: Lower Riemann Integral <span class="math inline">\(\leq\)</span> Upper Riemann Integral</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function. Then:</p>
<p><span class="math display">\[L(f, [a, b]) \leq U(f, [a, b])\]</span></p>
<p><br></p>
<h4 id="definition-1.9-riemann-integrable-riemann-integral">Definition 1.9: Riemann Integrable; Riemann Integral</h4>
<ul>
<li>A <strong>bounded</strong> function on a <strong>closed bounded interval</strong> is called <strong>Riemann integrable</strong> if its lower Riemann integral equals its upper Riemann integral.</li>
<li>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is Riemann integrable, then the <strong>Riemann integral <span class="math inline">\(\int^a_b f\)</span></strong> is defined by: <span class="math display">\[\int^b_a f = L(f, [a, b]) = U(f, [a, b])\]</span></li>
</ul>
<p><br></p>
<h4 id="theorem-1.11-continuous-functions-are-riemann-integrable">Theorem 1.11: Continuous Functions are Riemann Integrable</h4>
<p>Every continuous real-valued function on each closed bounded interval is Riemann integrable.</p>
<p><br></p>
<h4 id="theorem-1.13-bounds-on-riemann-integral">Theorem 1.13: Bounds on Riemann Integral</h4>
<p>Suppose <span class="math inline">\(f:[a, b] \rightarrow \mathbb{R}\)</span> is Riemann integrable. Then:</p>
<p><span class="math display">\[(b - a) \inf_{[a, b]}f \leq \int^b_a f \leq (b - a) \sup_{[a, b]} f\]</span></p>
<p><br></p>
<h3 id="riemann-integral-is-not-good-enough">Riemann Integral Is not Good Enough</h3>
<p>The Riemann integral has several deficiencies:</p>
<ol type="1">
<li>Riemann integration does not handle functions with many discontinuities.</li>
<li>Riemann integration does not handle unbounded functions.</li>
<li>Riemann integration does not work well with limits.</li>
</ol>
<p><br></p>
<h2 id="measures">Measures</h2>
<h3 id="outer-measure-on-mathbbr">Outer Measure on <span class="math inline">\(\mathbb{R}\)</span></h3>
<h4 id="definition-2.1-length-of-open-interval-li">Definition 2.1: Length of Open Interval: <span class="math inline">\(l(I)\)</span></h4>
<p>The <strong>length</strong> <span class="math inline">\(l(I)\)</span> of an <strong>open</strong> interval <span class="math inline">\(I\)</span> is defined by:</p>
<p><span class="math display">\[
l(I) =
\begin{cases}
b - a, \quad \text{if $I = (a, b)$ for some $a, b \in \mathbb{R}$ with $a &lt; b$}\\
0, \quad \text{if $I = \emptyset$}\\
\infty, \quad \text{if $I = (-\infty, a)$ or $I = (a, \infty)$ for some $a \in \mathbb{R}$}\\
\infty, \quad \text{if $I = (-\infty, \infty)$}
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="definition-2.2-outer-measure-a">Definition 2.2: Outer Measure: <span class="math inline">\(|A|\)</span></h4>
<p>The <strong>outer measure</strong> <span class="math inline">\(|A|\)</span> of a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is defined by:</p>
<p><span class="math display">\[|A| = \inf\{\sum^{\infty}_{k=1} l(I_k): I_1, I_2, ... \text{ are open intervals such that $A \subseteq \bigcup_{k=1}^{\infty} I_k$}\}\]</span></p>
<blockquote>
<h4 id="example-2.3-finite-sets-have-outer-measure-0">Example 2.3: Finite sets have outer measure 0</h4>
<p>Suppose <span class="math inline">\(A = \{a_1, ..., a_n\}\)</span> is a finite set of real numbers. Suppose <span class="math inline">\(\epsilon &gt; 0\)</span>. Define a sequence <span class="math inline">\(I_1, I_2, ...\)</span> of open intervals by:</p>
<p><span class="math display">\[
I_k =
\begin{cases}
(a_k - \epsilon, a_k + \epsilon), \quad \text{if $k \leq n$}\\
\emptyset, \quad \text{if $k &gt; n$}\\
\end{cases}
\]</span></p>
<p>Then <span class="math inline">\(I_1, I_2, ...\)</span> is a sequence of open interval whose union contains <span class="math inline">\(A\)</span>. Clearly <span class="math inline">\(\sum^{\infty}_{k=1}l(I_k) = 2\epsilon n \implies |A| \leq 2\epsilon n\)</span>, since <span class="math inline">\(\epsilon &gt; 0\)</span> is an arbitrary positive number, this implies that <span class="math inline">\(|A| = 0\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.4-countable-sets-have-outer-measure-0">Theorem 2.4: Countable Sets Have Outer Measure <span class="math inline">\(0\)</span></h4>
<p>Every countable subset of <span class="math inline">\(\mathbb{R}\)</span> has outer measure <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.5-outer-measure-preserves-order">Theorem 2.5: Outer Measure Preserves Order</h4>
<p>Suppose <span class="math inline">\(A, B\)</span> are subsets of <span class="math inline">\(\mathbb{R}\)</span> with <span class="math inline">\(A \subseteq B\)</span>. Then <span class="math inline">\(|A| \leq |B|\)</span>.</p>
<p><br></p>
<h4 id="definition-2.6-translation-t-a">Definition 2.6: Translation, <span class="math inline">\(t + A\)</span></h4>
<p>If <span class="math inline">\(t \in \mathbb{R}\)</span> and <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, then the <strong>translation</strong> <span class="math inline">\(t + A\)</span> is defined by:</p>
<p><span class="math display">\[t + A = \{t + a: a \in A\}\]</span></p>
<p>If <span class="math inline">\(t \in \mathbb{R}, a, b \in [-\infty, \infty]\)</span>, then <span class="math inline">\(t + (a, b) = (t + a, t + b)\)</span> and <span class="math inline">\(t + \infty = \infty\)</span> and <span class="math inline">\(t + -\infty = -\infty\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.7-outer-measure-is-translation-invariant">Theorem 2.7: Outer Measure is Translation Invariant</h4>
<p>Suppose <span class="math inline">\(t \in \mathbb{R}\)</span> and <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then <span class="math inline">\(|t + A| = |A|\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.8-countable-subadditivity-of-outer-measure">Theorem 2.8: Countable Subadditivity of Outer Measure</h4>
<p>Suppose <span class="math inline">\(A_1, A_2, ...\)</span> is a sequence of subsets of <span class="math inline">\(\mathbb{R}\)</span>. Then:</p>
<p><span class="math display">\[|\bigcup_{k=1}^{\infty} A_k| \leq \sum^{\infty}_{k=1} |A_k|\]</span></p>
<p>In other words:</p>
<p><span class="math display">\[|A_1 \cup A_2 \cup ... | \leq |A_1| + |A_2| + ... \]</span></p>
<h5 id="proof-of-theorem-2.8">Proof of Theorem 2.8</h5>
<p>Assume <span class="math inline">\(|A_k| &lt; \infty\)</span> for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span>. Let <span class="math inline">\(\epsilon &gt; 0\)</span> and for each <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, let <span class="math inline">\(I_{1, k}, I_{2, k}, ...\)</span> be a sequence of open intervals whose union contains <span class="math inline">\(A_k\)</span> s.t:</p>
<p><span class="math display">\[\sum^{\infty}_{j=1} l(I_{j, k}) \leq \frac{\epsilon}{2^k} + |A_k|\]</span></p>
<p>This makes sense because <span class="math inline">\(|A| = \inf\{\sum^{\infty}_{j=1} l(I_{j, k})\}\)</span> and <span class="math inline">\(|A| + \epsilon \geq \inf\{\sum^{\infty}_{j=1} l(I_{j, k})\}\)</span>.</p>
<p>Sum both side over <span class="math inline">\(k\)</span>, we have:</p>
<p><span class="math display">\[\sum^{\infty}_{k=1}\sum^{\infty}_{j=1} l(I_{j, k}) \leq \epsilon + \sum^{\infty}_{k=1}|A_k|\]</span></p>
<p>The union of left hand side open intervals is the set $A_1 A_2 ... $, Thus, we have:</p>
<p><span class="math display">\[|A_1 \cup A_2 \cup ... | \leq \sum^{\infty}_{k=1}\sum^{\infty}_{j=1} l(I_{j, k}) \leq \epsilon + \sum^{\infty}_{k=1}|A_k|\]</span></p>
<p>Since <span class="math inline">\(\epsilon\)</span> is any positive real number, we have desired result.</p>
<p><br></p>
<h4 id="definition-2.10-open-cover-finite-subcover">Definition 2.10: Open Cover, Finite Subcover</h4>
<p>Suppose <span class="math inline">\(A \subseteq \mathbb{R}\)</span>:</p>
<ul>
<li>A collection <span class="math inline">\(C\)</span> of open subsets of <span class="math inline">\(\mathbb{R}\)</span> is called an <strong>open cover</strong> of <span class="math inline">\(A\)</span> if <span class="math inline">\(A\)</span> is contained in the union of all the sets in <span class="math inline">\(C\)</span>.</li>
<li>An open cover <span class="math inline">\(C\)</span> of <span class="math inline">\(A\)</span> is said to have a <strong>finite subcover</strong> if <span class="math inline">\(A\)</span> is contained in the union of some finite list of sets in <span class="math inline">\(C\)</span>.</li>
</ul>
<blockquote>
<h4 id="example-2.11">Example 2.11</h4>
<p>The collection <span class="math inline">\(\{(k, k+2): k \in \mathbb{Z}^+\}\)</span> is an open cover of <span class="math inline">\([2, 5]\)</span> because <span class="math inline">\([2, 5] \subseteq \bigcup^{\infty}_{k=1} (k, k+2)\)</span>. This open cover has finite subcover because <span class="math inline">\([2, 5] \subseteq (1, 3) \cup (2, 4) \cup (3, 5) \cup (4, 6)\)</span>.</p>
<p>The collection above is an open cover of <span class="math inline">\([2, \infty)\)</span> but does not have a finite subcover.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.12-heine-borel-theorem">Theorem 2.12: Heine-Borel Theorem</h4>
<p>Every open cover of a closed bounded subset of <span class="math inline">\(\mathbb{R}\)</span> has a finite subcover.</p>
<p><br></p>
<h4 id="theorem-2.14-outer-measure-of-a-closed-interval">Theorem 2.14: Outer Measure of a Closed Interval</h4>
<p>Suppose <span class="math inline">\(a, b \in \mathbb{R}\)</span> with <span class="math inline">\(a &lt; b\)</span>. Then <span class="math inline">\(|[a, b]| = b - a\)</span></p>
<p><br></p>
<h4 id="theorem-2.17-nontrivial-intervals-are-uncountable">Theorem 2.17: Nontrivial Intervals are Uncountable</h4>
<p>Every interval in <span class="math inline">\(\mathbb{R}\)</span> that contains at least two distinct elements is uncountable.</p>
<h5 id="proof-of-theorem-2.17">Proof of Theorem 2.17:</h5>
<p>Suppose <span class="math inline">\(I\)</span> is an interval that contains <span class="math inline">\(a, b \in \mathbb{R}\)</span> and <span class="math inline">\(b &gt; a\)</span>, then <span class="math inline">\([a, b] \subseteq I\)</span>, then by <code>theorem 2.5</code>, we have:</p>
<p><span class="math display">\[|I| \geq |[a, b]|\]</span></p>
<p>and</p>
<p><span class="math display">\[|[a, b]| = b - a &gt; 0\]</span></p>
<p><br></p>
<h4 id="theorem-2.18-nonadditivity-of-outer-measure">Theorem 2.18: Nonadditivity of Outer Measure</h4>
<p>There exist disjoint subsets <span class="math inline">\(A, B\)</span> of <span class="math inline">\(\mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[|A \cup B| \neq |A| + |B|\]</span></p>
<p><br></p>
<h3 id="measurable-spaces-and-functions">Measurable Spaces and Functions</h3>
<h4 id="theorem-2.22-nonexistence-of-extension-of-length-to-all-subsets-of-mathbbr">Theorem 2.22: Nonexistence of Extension of Length to All Subsets of <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>There does not exists a function <span class="math inline">\(\mu\)</span> with all the following properties:</p>
<ol type="a">
<li><span class="math inline">\(\mu\)</span> is a function from the set of subsets of <span class="math inline">\(\mathbb{R}\)</span> to <span class="math inline">\([0, \infty]\)</span>.</li>
<li><span class="math inline">\(\mu(I) = l(I)\)</span> for every open interval <span class="math inline">\(I\)</span> of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\mu (\sum^{\infty}_{k=1} A_k) = \sum^{\infty}_{k=1} \mu(A_k)\)</span> for every disjoint sequence <span class="math inline">\(A_1, A_2, ...\)</span> of subsets of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\mu(t + A) = \mu(A)\)</span> for every <span class="math inline">\(A \subseteq \mathbb{R}\)</span> and every <span class="math inline">\(t \in \mathbb{R}\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-2.23-sigma-algebra">Definition 2.23: <span class="math inline">\(\sigma\)</span>-algebra</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(S\)</span> is a set of subsets of <span class="math inline">\(X\)</span>. Then <span class="math inline">\(S\)</span> is called a <strong><span class="math inline">\(\sigma\)</span>-algebra</strong> on <span class="math inline">\(X\)</span> if the following three conditions are satisfied:</p>
<ul>
<li><span class="math inline">\(\emptyset \in S\)</span>.</li>
<li>If <span class="math inline">\(E \in S\)</span>, then <span class="math inline">\(X / E \in S\)</span>.</li>
<li>If <span class="math inline">\(E_1, E_2, ...\)</span> is a sequence of elements of <span class="math inline">\(S\)</span>, then <span class="math inline">\(\bigcup^{\infty}_{k=1} E_k \in S\)</span>.</li>
</ul>
<blockquote>
<p>{, X} is <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>. The set of all subsets of <span class="math inline">\(X\)</span> is <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.25-sigma-algebras-are-closed-under-countable-intersection">Theorem 2.25: <span class="math inline">\(\sigma\)</span>-algebras are Closed Under Countable Intersection</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on a set <span class="math inline">\(X\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(X \in S\)</span>.</li>
<li>If <span class="math inline">\(D, E \in S\)</span>, then <span class="math inline">\(D \cup E \in S\)</span> and <span class="math inline">\(D \cap E \in S\)</span> and <span class="math inline">\(D / E \in S\)</span>.</li>
<li>If <span class="math inline">\(E_1, E_2, ....\)</span> is a sequence of elemnts of <span class="math inline">\(S\)</span>, then <span class="math inline">\(\bigcap^{\infty}_{k=1} E_k \in S\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-2.26-measurable-space-measurable-set">Definition 2.26: Measurable Space, Measurable Set</h4>
<ul>
<li>A <strong>measurable space</strong> is an ordered pair <span class="math inline">\((X, S)\)</span>, where <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra on <span class="math inline">\(X\)</span>.</li>
<li>An element of <span class="math inline">\(S\)</span> is called an <strong><span class="math inline">\(S\)</span>-measurable set</strong> or just a <strong>measurable set</strong> if <span class="math inline">\(S\)</span> is clear from the context.</li>
</ul>
<blockquote>
<p><span class="math inline">\(X = \mathbb{R}\)</span> and <span class="math inline">\(S\)</span> is the set of all subsets of <span class="math inline">\(\mathbb{R}\)</span> that are countable or have a countable complement, then the ordered pair <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(\mathbb{Q} \in S\)</span> is <span class="math inline">\(S\)</span>-measurable set.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.27-smallest-sigma-algebra-containing-a-collection-of-subsets">Theorem 2.27: Smallest <span class="math inline">\(\sigma\)</span>-algebra Containing a Collection of Subsets</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(A\)</span> is a set of subsets of <span class="math inline">\(X\)</span>. Then the intersection of all <span class="math inline">\(\sigma-\)</span>algebras on <span class="math inline">\(X\)</span> that contain <span class="math inline">\(A\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra on <span class="math inline">\(X\)</span>.</p>
<p>Using the <strong>smallest</strong> for the intersection of all <span class="math inline">\(\sigma\)</span>-algebras that contain as set <span class="math inline">\(A\)</span> of subset of <span class="math inline">\(X\)</span> makes sense, because the smallest <span class="math inline">\(\sigma\)</span>-algebra will be one of those <span class="math inline">\(\sigma\)</span>-algebra that contains <span class="math inline">\(A\)</span>. If <span class="math inline">\(A\)</span> is already <span class="math inline">\(\sigma\)</span>-algebra, then the interaction is just <span class="math inline">\(A\)</span>.</p>
<p><br></p>
<h4 id="definition-2.29-borel-set">Definition 2.29: Borel Set</h4>
<p>The smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> containing all open subsets of <span class="math inline">\(\mathbb{R}\)</span> is called <strong>the collection of Borel subsets</strong> of <span class="math inline">\(\mathbb{R}\)</span>. An element of this <span class="math inline">\(\sigma-algebra\)</span> is called a <strong>Borel set</strong>.</p>
<p>We can also define the collection of Borel subsets to be the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> containing all the <strong>open intervals</strong>. Because every open subset of <span class="math inline">\(\mathbb{R}\)</span> is the union of a sequence of open intervals.</p>
<p><strong>The set contains every open sets, closed sets, countable union, intersection of open, closed sets. There exists subsets of <span class="math inline">\(\mathbb{R}\)</span> that are not Borel sets, but any subset of <span class="math inline">\(\mathbb{R}\)</span> that you can write down in a concrete fashion is a Borel set.</strong></p>
<p><br></p>
<h4 id="definition-2.31-inverse-image-f-1-a">Definition 2.31: Inverse Image: <span class="math inline">\(f^{-1} (A)\)</span></h4>
<p>If <span class="math inline">\(f: X \rightarrow Y\)</span> is a function and <span class="math inline">\(A \subseteq Y\)</span>, then the set <span class="math inline">\(f^{-1} (A)\)</span> is defined by:</p>
<p><span class="math display">\[f^{-1} (A) = \{x \in X: f(x) \in A\}\]</span></p>
<p><br></p>
<h4 id="theorem-2.33-algebra-of-inverse-images">Theorem 2.33: Algebra of Inverse Images</h4>
<p>Suppose <span class="math inline">\(f: X \rightarrow Y\)</span> is a function. Then:</p>
<ol type="a">
<li><span class="math inline">\(f^{-1} (Y / A) = X / f^{-1}(A), \; \forall A \subseteq Y\)</span></li>
<li><span class="math inline">\(f^{-1} (\bigcap_{A \in \mathbf{A}} A) = \bigcap_{A \in \mathbb{A}} f^{-1}(A)\)</span>, for every set <span class="math inline">\(\mathbf{A}\)</span> of subsets of <span class="math inline">\(Y\)</span>.</li>
<li><span class="math inline">\(f^{-1} (\bigcup_{A \in \mathbf{A}} A) = \bigcup_{A \in \mathbb{A}} f^{-1}(A)\)</span>, for every set <span class="math inline">\(\mathbf{A}\)</span> of subsets of <span class="math inline">\(Y\)</span>.</li>
</ol>
<p>In other words, the inverse image of union or intersection of any subsets of <span class="math inline">\(Y\)</span>, is the same as the union or intersection of inverse image of these subsets of <span class="math inline">\(Y\)</span>.</p>
<h5 id="proof-of-theorem-2.33">Proof of Theorem 2.33:</h5>
<p>Suppose <span class="math inline">\(A \subseteq Y\)</span>. For <span class="math inline">\(x \in X\)</span>, we have:</p>
<p><span class="math display">\[x \in f^{-1} (Y / A) \Longleftrightarrow  f(x) \in Y / A \Longleftrightarrow f(x) \notin A \Longleftrightarrow x \notin f^{-1}(A) \implies x \in X / f^{-1}(A) \]</span></p>
<p>Let <span class="math inline">\(\mathbf{A}\)</span> be a set of subsets of <span class="math inline">\(Y\)</span>, then:</p>
<p><span class="math display">\[x \in f^{-1} (\bigcap_{A \in \mathbf{A}} A) \Longleftrightarrow f(x) \in \bigcap_{A \in \mathbf{A}} A\]</span></p>
<p>This implies that <span class="math inline">\(f(x)\)</span> is in every subset <span class="math inline">\(A \in \mathbf{A}\)</span>, thus, we have:</p>
<p><span class="math display">\[x \in f^{-1}(A) \; \forall A \in \mathbf{A} \implies x \in \bigcap_{A \in \mathbf{A}} f^{-1}(A)\]</span></p>
<p>The proof is similar for union.</p>
<p><br></p>
<h4 id="theorem-2.34-inverse-image-of-a-composition">Theorem 2.34: Inverse Image of a Composition</h4>
<p>Suppose <span class="math inline">\(f: X \rightarrow Y\)</span> and <span class="math inline">\(g: Y \rightarrow W\)</span> are functions. Then:</p>
<p><span class="math display">\[(g \circ f)^{-1} (A) = f^{-1} (g^{-1} (A))\]</span></p>
<p>for every <span class="math inline">\(A \subseteq W\)</span></p>
<h5 id="proof-of-theorem-2.34">Proof of Theorem 2.34:</h5>
<p>Suppose <span class="math inline">\(A \subseteq W\)</span>, <span class="math inline">\(x \in X\)</span>, then we have:</p>
<p><span class="math inline">\(x \in (g \circ f)^{-1} (A) \Longleftrightarrow g \circ f (x) \in A \Longleftrightarrow g(f(x)) \in A \Longleftrightarrow f(x) \in g^{-1} (A) \Longleftrightarrow x \in f^{-1}(g^{-1} (A))\)</span></p>
<p><br></p>
<h4 id="definition-2.35-measurable-function">Definition 2.35: Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space. A function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is called <strong><span class="math inline">\(S\)</span>-measurable</strong> (or just <strong>measurable</strong> if <span class="math inline">\(S\)</span> is clear from the context)</p>
<p>if:</p>
<p><span class="math display">\[f^{-1}(B) \in S\]</span></p>
<p>for every Borel set <span class="math inline">\(B \in \mathbb{R}\)</span>.</p>
<blockquote>
<h5 id="example-2.36-measurable-functions">Example 2.36: Measurable Functions</h5>
<p>If <span class="math inline">\(S = \{\emptyset, X\}\)</span>, then the only <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X\)</span> to <span class="math inline">\(\mathbb{R}\)</span> are the constant functions, because otherwise each <span class="math inline">\(x \in X\)</span> will have multiple <span class="math inline">\(f(x)\)</span>, which will violate the definition of function.</p>
<p>If <span class="math inline">\(S\)</span> is the set of all subsets of <span class="math inline">\(X\)</span>, then every function from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> is <span class="math inline">\(S\)</span>-measurable.</p>
<p>If <span class="math inline">\(S = \{\emptyset, (-\infty, 0), [0, \infty), \mathbb{R}\}\)</span>, then a function <span class="math inline">\(f:\mathbb{R} \rightarrow \mathbb{R}\)</span> is <span class="math inline">\(S\)</span>-measurable IFF <span class="math inline">\(f\)</span> is constant on <span class="math inline">\((-\infty, 0)\)</span> and <span class="math inline">\(f\)</span> is constant on <span class="math inline">\([0, \infty)\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="definition-2.37-characteristic-function-chi_e">Definition 2.37: Characteristic Function; <span class="math inline">\(\chi_E\)</span></h4>
<p>Suppose <span class="math inline">\(E\)</span> is a subset of a set <span class="math inline">\(X\)</span>. The <strong>characteristic function</strong> of <span class="math inline">\(E\)</span> is the function <span class="math inline">\(\chi_E: X \rightarrow \mathbb{R}\)</span> defined by:</p>
<p><span class="math display">\[
\chi_E (x) =
\begin{cases}
1, \quad \text{if} \; x \in E\\
0, \quad \text{if} \; x \notin E
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="theorem-2.39-condition-for-measurable-function">Theorem 2.39: Condition for Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is a function such that:</p>
<p><span class="math display">\[f^{-1} ((a, \infty)) \in S\]</span></p>
<p>for all <span class="math inline">\(a \in \mathbb{R}\)</span>. Then <span class="math inline">\(f\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p>Where:</p>
<p><span class="math display">\[f^{-1}((a, \infty)) = \{x \in X: f(x) &gt; a\}\]</span></p>
<p><strong>We can replace the collection of sets <span class="math inline">\(\{(a, \infty): a\in \mathbb{R}\}\)</span> by any collection of subsets of <span class="math inline">\(\mathbb{R}\)</span> s.t the smallest <span class="math inline">\(\sigma\)</span>-algebra containing that collection contains the Borel subset of <span class="math inline">\(\mathbb{R}\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-2.40-borel-measurable-function">Definition 2.40: Borel Measurable Function</h4>
<p>Suppose <span class="math inline">\(X \subseteq \mathbb{R}\)</span>. A function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is called <strong>Borel Measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Borel set for every Borel set <span class="math inline">\(B \subseteq \mathbb{R}\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> is a Borel subset of <span class="math inline">\(\mathbb{R}\)</span>, then <span class="math inline">\(S\)</span> might be the set of Borel sets contained in <span class="math inline">\(X\)</span>, in which case the phrase Borel Measurable is the same as <span class="math inline">\(S\)</span>-measuable.</p>
<p><strong>If <span class="math inline">\(X \subseteq \mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> is Borel measurable implies that <span class="math inline">\(X\)</span> is a borel set.</strong></p>
<p><strong>If <span class="math inline">\(X \subseteq \mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> is Borel measurable IFF <span class="math inline">\(f^{-1}((a, \infty))\)</span> is a borel set for all <span class="math inline">\(a \in \mathbb{R}\)</span>. Most of the proofs of Borel measurable function involves this result.</strong></p>
<p><br></p>
<h4 id="definition-2.41-every-continuous-function-is-borel-measurable">Definition 2.41: Every Continuous Function is Borel Measurable</h4>
<p>Every continuous real-valued function defined on a Borel subset of <span class="math inline">\(\mathbb{R}\)</span> is a Borel measurable function.</p>
<p><br></p>
<h4 id="definition-2.42-increasing-function-strictly-increasing">Definition 2.42: Increasing Function; Strictly Increasing</h4>
<p>Suppose <span class="math inline">\(X \subseteq \mathbb{R}\)</span> and <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is a function:</p>
<ul>
<li><span class="math inline">\(f\)</span> is called <strong>increasing</strong> if <span class="math inline">\(f(x) \leq f(y)\)</span> for all <span class="math inline">\(x, y \in X\)</span> with <span class="math inline">\(x &lt; y\)</span>.</li>
<li><span class="math inline">\(f\)</span> is called <strong>strictly increasing</strong> if <span class="math inline">\(f(x) &lt; f(y)\)</span>, for all <span class="math inline">\(x, y \in X\)</span> with <span class="math inline">\(x &lt; y\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-2.43-every-increasing-function-is-borel-measurable">Theorem 2.43: Every Increasing Function is Borel Measurable</h4>
<p>Every increasing function defined on a Borel subset is Borel measurable.</p>
<p><strong>similar results for decreasing function</strong>.</p>
<h5 id="proof-of-theorem-2.43">Proof of Theorem 2.43:</h5>
<p>Let <span class="math inline">\(X \subseteq \mathbb{R}\)</span> be a borel set, let <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> be an increasing function. Then:</p>
<p>Let <span class="math inline">\(b = \inf f^{-1}((a, \infty))\)</span>. So we can write it as:</p>
<p><span class="math display">\[f^{-1}((a, \infty)) = [b, \infty) \cap X\]</span></p>
<p>Thus, we have <span class="math inline">\(f^{-1}((a, \infty))\)</span> is a borel set which implies that <span class="math inline">\(f\)</span> is borel measurable.</p>
<p><br></p>
<h4 id="theorem-2.44-composition-of-measurable-functions">Theorem 2.44: Composition of Measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is an <span class="math inline">\(S\)</span>-measurable function. Suppose <span class="math inline">\(g\)</span> is a real-valued Borel measurable function defined on a subset of <span class="math inline">\(\mathbb{R}\)</span> that includes the range of <span class="math inline">\(f\)</span>. Then <span class="math inline">\(g \circ f: X \rightarrow \mathbb{R}\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<blockquote>
<h5 id="example-2.45">Example 2.45</h5>
<p>If <span class="math inline">\(f\)</span> is measurable, then so are <span class="math inline">\(-f, |f|, f^2\)</span>.</p>
<p>Since <span class="math inline">\(g(x) = -x\)</span>, <span class="math inline">\(g(x) = |x|\)</span>, <span class="math inline">\(g(x) = x^2\)</span> are all continuous functions defined on <span class="math inline">\(\mathbb{R}\)</span>, which is a borel subset of <span class="math inline">\(\mathbb{R}\)</span>, so <span class="math inline">\(g(f(x))\)</span> is measurable.</p>
</blockquote>
<h4 id="theorem-2.46-algebraic-operations-with-measurable-functions">Theorem 2.46: Algebraic Operations with Measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f, g: X \rightarrow \mathbb{R}\)</span> are <span class="math inline">\(S\)</span>-measurable. Then:</p>
<ol type="a">
<li><span class="math inline">\(f + g\)</span>, <span class="math inline">\(f - g\)</span>, and <span class="math inline">\(fg\)</span> are <span class="math inline">\(S-measurable\)</span> functions.</li>
<li>If <span class="math inline">\(g(x) \neq 0\)</span> for all <span class="math inline">\(x \in X\)</span>, then <span class="math inline">\(\frac{f}{g}\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</li>
</ol>
<p><br></p>
<h4 id="theorem-2.48-limit-of-s-measurable-functions">Theorem 2.48: Limit of <span class="math inline">\(S\)</span>-Measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>. Suppose <span class="math inline">\(\lim_{k \rightarrow \infty} f_k (x)\)</span> exists for each <span class="math inline">\(x \in X\)</span>. Define <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> by:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} f_k (x)\]</span></p>
<p>Then, <span class="math inline">\(f\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p><br></p>
<h4 id="definition-2.50-borel-subsets-of--infty-infty-extended-definition-of-borel-subset-to-mathbbr-cup--infty-infty">Definition 2.50: Borel Subsets of <span class="math inline">\([-\infty, \infty]\)</span> (Extended definition of borel subset to <span class="math inline">\(\mathbb{R} \cup \{-\infty, \infty\}\)</span>)</h4>
<p>A subset of <span class="math inline">\([-\infty, \infty]\)</span> is called a <strong>Borel set</strong> if its intersection with <span class="math inline">\(\mathbb{R}\)</span> is a Borel Set.</p>
<blockquote>
<p><span class="math inline">\([-\infty, \infty]\)</span> is a borel set because <span class="math inline">\([-\infty, \infty] \cap \mathbb{R} = \mathbb{R}\)</span> is a borel set.</p>
</blockquote>
<p><br></p>
<h4 id="definition-2.51-measurable-function">Definition 2.51: Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space. A function <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is called <span class="math inline">\(S\)</span>-measurable if:</p>
<p><span class="math display">\[f^{-1}(B) \in S\]</span></p>
<p><br></p>
<h4 id="theorem-2.52-condition-for-measurable-function">Theorem 2.52: Condition for Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is a function s.t:</p>
<p><span class="math display">\[f^{-1} ((a, \infty]) \in S\]</span></p>
<p>for all <span class="math inline">\(a \in \mathbb{R}\)</span>. Then <span class="math inline">\(f\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p><br></p>
<h4 id="theorem-2.53-infimum-and-supremum-of-a-sequence-of-s-measurable-functions">Theorem 2.53: Infimum and Supremum of a Sequence of <span class="math inline">\(S\)</span>-measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X\)</span> to <span class="math inline">\([-\infty, \infty]\)</span>. Define <span class="math inline">\(g, h: X \rightarrow [-\infty, \infty]\)</span>. Define <span class="math inline">\(g, h: X \rightarrow [-\infty, \infty]\)</span> by:</p>
<p><span class="math display">\[g(x) = \inf\{f_k (x): k \in \mathbb{Z}^+\}\]</span></p>
<p>and</p>
<p><span class="math display">\[h(x) = \sup\{f_k (x): k \in \mathbb{Z}^+\}\]</span></p>
<p>Then <span class="math inline">\(g, h\)</span> are <span class="math inline">\(S\)</span>-measurable functions.</p>
<h5 id="proof-of-theorem-2.53">Proof of Theorem 2.53:</h5>
<p>Suppose <span class="math inline">\(a \in \mathbb{R}\)</span>, The definition of the supremum implies that:</p>
<p><span class="math display">\[h^{-1} ((a, \infty]) = \{x; h(x) &gt; a\}\]</span></p>
<p>Since,</p>
<p><span class="math display">\[\{x; h(x) &gt; a\} \subseteq \bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\}\]</span></p>
<p>On the other hand, for all <span class="math inline">\(x \in \bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\}\)</span>, we have <span class="math inline">\(\sup_k f_k (x) &gt; a\)</span>, thus:</p>
<p><span class="math display">\[\bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\}\subseteq \{x; h(x) &gt; a\} \]</span></p>
<p>This implies that:</p>
<p><span class="math display">\[h^{-1} ((a, \infty]) = \{x; h(x) &gt; a\} = \bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\} = \bigcup_{k=1}^{\infty} f^{-1}_k ((a, \infty])\]</span></p>
<p>Since <span class="math inline">\(f^{-1}_k ((a, \infty]) \in S\)</span> by assumption, we have:</p>
<p><span class="math display">\[h^{-1} ((a, \infty]) \in S\]</span></p>
<p>Note that:</p>
<p><span class="math display">\[g(x) = - \sup\{-f_k (x): k \in \mathbb{Z}^+\}\]</span></p>
<p>for all <span class="math inline">\(x \in X\)</span>. The result about supremum implies that <span class="math inline">\(g\)</span> is <span class="math inline">\(S\)</span>-measurable.</p>
<p><br></p>
<h3 id="measures-and-their-properties">Measures and Their Properties</h3>
<p>The word <strong>measure</strong> allows us to use a single word instead of repeating theorems for length, area and volume.</p>
<h4 id="definition-2.54-measure">Definition 2.54: Measure</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>. A <strong>measure</strong> on <span class="math inline">\((X, S)\)</span> is a function <span class="math inline">\(\mu: S \rightarrow [0, \infty]\)</span> s.t <span class="math inline">\(\mu(\emptyset) = 0\)</span> and:</p>
<p><span class="math display">\[\mu(\bigcup_{k=1}^{\infty} E_k) = \sum^{\infty}_{k=1} \mu(E_k)\]</span></p>
<p>for every disjoint sequence <span class="math inline">\(E_1, E_2, ...\)</span> of sets in <span class="math inline">\(S\)</span>.</p>
<p>Notice that countable additivity implies finite additivity by constructing disjoint sequence <span class="math inline">\(E_1, E_2, ..., E_n, \emptyset, \emptyset, ...\)</span></p>
<p><br></p>
<h4 id="definition-2.56-measure-space">Definition 2.56: Measure Space</h4>
<p>A <strong>measure space</strong> is an ordered triple <span class="math inline">\((X, S, \mu)\)</span>, where <span class="math inline">\(X\)</span> is a set, <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>, and <span class="math inline">\(\mu\)</span> is a measure on <span class="math inline">\((X, S)\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.57-measure-preserves-order-measure-of-a-set-difference">Theorem 2.57: Measure Preserves Order; Measure of a Set Difference</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(D, E \in S\)</span> are such that <span class="math inline">\(D \subseteq E\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(\mu(D) \leq \mu(E)\)</span></li>
<li><span class="math inline">\(\mu(E / D) = \mu(E) - \mu(D)\)</span> provided that <span class="math inline">\(\mu(D) &lt; \infty\)</span></li>
</ol>
<h5 id="proof-of-theorem-2.57">Proof of Theorem 2.57:</h5>
<p>Suppose <span class="math inline">\(D \subseteq E\)</span>, then <span class="math inline">\(E = D \cup (E / D)\)</span> and these two sets are disjoint, that is:</p>
<p><span class="math display">\[\mu(E) = \mu(D \cup (E / D)) = \mu(D) + \mu(E / D) \geq \mu(D)\]</span></p>
<p>given that <span class="math inline">\(\mu(D) &lt; \infty\)</span> subtract both sides by <span class="math inline">\(\mu(D)\)</span>, we have b.</p>
<p><br></p>
<h4 id="theorem-2.58-countable-subadditivity">Theorem 2.58: Countable Subadditivity</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1, E_2, ... \in S\)</span>. Then:</p>
<p><span class="math display">\[\mu(\bigcup^{\infty}_{k=1} E_k) \leq \sum^{\infty}_{k=1}\mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-2.59-measure-of-an-increasing-union">Theorem 2.59: Measure of an Increasing Union</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1 \subseteq E_2 \subseteq ...\)</span> is an increasing sequence of sets in <span class="math inline">\(S\)</span>. Then:</p>
<p><span class="math display">\[\mu(\bigcup^\infty_{k=1} E_k) = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<h5 id="proof-theorem-2.59">Proof Theorem 2.59</h5>
<p>If <span class="math inline">\(\mu(E_k) = \infty\)</span> for some <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, then the equation above holds because both sides equals <span class="math inline">\(\infty\)</span>:</p>
<p><span class="math display">\[\mu(\bigcup^{\infty}_{k=1} E_k) \geq \mu(E_k) = \infty = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<p>Thus, we consider only the case where <span class="math inline">\(\mu(E_k) &lt; \infty\)</span> for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span>.</p>
<p>Let <span class="math inline">\(E_0 = \emptyset\)</span>. Then:</p>
<p><span class="math display">\[\bigcup^{\infty}_{k=1} E_k = E_1 \cup (E_2 / E_1) \cup (E_3 / E_2) \cup ... = \bigcup^{\infty}_{j=1} E_{j} / E_{j-1}\]</span></p>
<p>And the union on the right hand side is disjoint, that is:</p>
<p><span class="math display">\[\mu(\bigcup^{\infty}_{j=1} E_{j} / E_{j-1}) = \sum^{\infty}_{j=1} \mu(E_{j} / E_{j-1}) = \lim_{k\rightarrow \infty} \sum^{k}_{j=1} \mu(E_{j} / E_{j-1})\]</span></p>
<p>Since <span class="math inline">\(E_{j-1} &lt; \infty\)</span>, we have:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} \sum^{k}_{j=1} \mu(E_{j} / E_{j-1}) = \lim_{k\rightarrow \infty} \sum^{k}_{j=1} \mu(E_{j}) - \mu(E_{j-1}) = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-2.60-measure-of-a-decreasing-intersection">Theorem 2.60: Measure of a Decreasing Intersection</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1 \supseteq E_2 \supseteq ...\)</span> is a decreasing sequence of sets in <span class="math inline">\(S\)</span>, with <span class="math inline">\(\mu(E_1) &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[\mu(\bigcap^{\infty}_{k=1}E_k) = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-2.61-measure-of-a-union">Theorem 2.61: Measure of a Union</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(D, E \in S\)</span>, with <span class="math inline">\(\mu(D \cap E) &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[\mu(D \cup E) = \mu(D) + \mu(E) - \mu(D \cap E)\]</span></p>
<p><br></p>
<h3 id="lebesgue-measure">Lebesgue Measure</h3>
<p>The main goal of this section is to prove that outer measure when restrict to borel sets is a measure.</p>
<h4 id="theorem-2.62-additivity-of-outer-measure-if-one-of-the-sets-is-open">Theorem 2.62: Additivity of Outer Measure If One of the Sets is Open</h4>
<p>Suppose <span class="math inline">\(A, G\)</span> are disjoint subsets of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(G\)</span> is open. Then:</p>
<p><span class="math display">\[|A \cup G| = |A| + |G|\]</span></p>
<p><br></p>
<h4 id="theorem-2.63-additivity-of-outer-measure-iff-the-sets-is-closed">Theorem 2.63: Additivity of Outer Measure IFF the Sets is Closed</h4>
<p>Suppose <span class="math inline">\(A, F\)</span> are disjoint subsets of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(\mathbb{F}\)</span> is closed. Then:</p>
<p><span class="math display">\[|A \cup F| = |A| + |F|\]</span></p>
<p><br></p>
<h4 id="theorem-2.65-approximation-of-borel-sets-from-below-by-closed-sets">Theorem 2.65: Approximation of Borel Sets from Below by Closed Sets</h4>
<p>Suppose <span class="math inline">\(B \subseteq \mathbb{R}\)</span> is a Borel set. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq B\)</span> s.t <span class="math inline">\(|B / F| &lt; \epsilon\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.66-additivity-of-outer-measure-if-one-of-the-sets-is-a-borel-set">Theorem 2.66: Additivity of Outer Measure If One of the Sets is a Borel Set</h4>
<p>Suppose <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are disjoint subsets of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(B\)</span> is a Borel set. Then:</p>
<p><span class="math display">\[|A \cup B| = |A| + |B|\]</span></p>
<p><br></p>
<h4 id="theorem-2.67-existence-of-a-subset-of-mathbbr-that-is-not-a-borel-set">Theorem 2.67: Existence of a Subset of <span class="math inline">\(\mathbb{R}\)</span> that is not a Borel Set</h4>
<p>There exists a set <span class="math inline">\(B \subseteq \mathbb{R}\)</span> s.t <span class="math inline">\(|B| &lt; \infty\)</span> and <span class="math inline">\(B\)</span> is not a Borel set.</p>
<h5 id="proof-of-theorem-2.67">Proof of Theorem 2.67:</h5>
<p>From <code>Theorem 2.18</code>, we know that there exists disjoint set <span class="math inline">\(A, B \subseteq \mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[|A \cup B| \neq |A| + |B|\]</span></p>
<p>Then, according to <code>Theorem 2.66</code>, if all subsets of <span class="math inline">\(\mathbb{R}\)</span> are Borel sets, we would have violated <code>Theorem 2.18</code>.</p>
<p><br></p>
<h4 id="theorem-2.68-outer-measure-is-a-measure-on-borel-sets">Theorem 2.68: Outer Measure is a Measure on Borel Sets</h4>
<p>Outer measure is a measure on <span class="math inline">\((\mathbb{R}, \mathbb{B})\)</span>, where <span class="math inline">\(\mathbb{B}\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra of Borel subsets of <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p><br></p>
<h4 id="definition-2.69-lebesgue-measure-on-mathbbb">Definition 2.69: Lebesgue Measure (on <span class="math inline">\(\mathbb{B}\)</span>)</h4>
<p><strong>Lebesgue Measure</strong> is the measure on <span class="math inline">\((\mathbb{R}, \mathbb{B})\)</span>, where <span class="math inline">\(\mathbb{B}\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra of Borel subsets of <span class="math inline">\(\mathbb{R}\)</span>, that assigns to each Borel set its outer measure.</p>
<p>In other words, the <strong>Lebesgue measure</strong> of a set is the same as its outer measure except it should not be applied to arbitrary sets but only to Borel sets.</p>
<p><br></p>
<h3 id="lebesgue-measurable-sets">Lebesgue Measurable Sets</h3>
<h4 id="definition-2.70-lebesgue-meaurable-set">Definition 2.70: Lebesgue Meaurable Set</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is called <strong>Lebesgue measurable</strong> if there exists a Borel set <span class="math inline">\(B \subseteq A\)</span> s.t <span class="math inline">\(|A / B| = 0\)</span>.</p>
<p>This definition implies that all Borel set is Lebesgue measurable because if <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is a Borel set, then we can take <span class="math inline">\(B = A\)</span>. If <span class="math inline">\(A\)</span> is a set with outer measure <span class="math inline">\(0\)</span>, then <span class="math inline">\(A\)</span> is Lebesgue measurable because we can take <span class="math inline">\(B = \emptyset\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.71-equivalences-for-being-a-lebesgue-measurable-set">Theorem 2.71: Equivalences for Being a Lebesgue Measurable Set</h4>
<p>Suppose <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(A\)</span> is Lebesgue measurable.</li>
<li>For each <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq A\)</span> with <span class="math inline">\(|A / F| \leq \epsilon\)</span>.</li>
<li>There exists closed sets <span class="math inline">\(F_1, F_2, ...\)</span> contained in <span class="math inline">\(A\)</span> s.t <span class="math inline">\(|A / \bigcup^{\infty}_{k=1} F_k| = 0\)</span>.</li>
<li>There exists a Borel set <span class="math inline">\(B \subseteq A\)</span> s.t <span class="math inline">\(|A / B| = 0\)</span>.</li>
<li>For each <span class="math inline">\(\epsilon &gt; 0\)</span>. There exists an open set <span class="math inline">\(G \supseteq A\)</span> s.t <span class="math inline">\(|G / A| &lt; \epsilon\)</span>.</li>
<li>There exists open sets <span class="math inline">\(G_1, G_2, ...\)</span> containing <span class="math inline">\(A\)</span> s.t <span class="math inline">\(|(\bigcap^{\infty}_{k=1})G_k / A| = 0\)</span>.</li>
<li>There exists a Borel set <span class="math inline">\(B \subseteq A\)</span> s.t <span class="math inline">\(|B / A| = 0\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-2.72-outer-measure-is-a-measure-on-lebesgue-measurable-sets">Theorem 2.72: Outer Measure is a Measure on Lebesgue Measurable Sets</h4>
<ol type="a">
<li>The set <span class="math inline">\(L\)</span> of Lebesgue measurable subsets of <span class="math inline">\(\mathbb{R}\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>Outer measure is a measure on <span class="math inline">\((\mathbb{R}, L)\)</span>.</li>
</ol>
<p>b implies that there are sets in <span class="math inline">\(\mathbb{R}\)</span> that is not Lebesgue measurable.</p>
<h5 id="proof-of-theorem-2.72">Proof of Theorem 2.72:</h5>
<p>We know that from <code>theorem 2.71</code> that a and b are equivalent, that is, let <span class="math inline">\(L\)</span> be the set that contains all <span class="math inline">\(A\)</span> that satisfies b, we can show that <span class="math inline">\(L\)</span> is <span class="math inline">\(\sigma\)</span>-algebra.</p>
<p>To show b, let <span class="math inline">\(A_1, A_2, ... \in L\)</span> be a disjoint sequence of Lebesgue measurable sets, then by definition, we have Borel set <span class="math inline">\(B_k \subseteq A_k\)</span> s.t</p>
<p><span class="math display">\[|A_k / B_k| = 0\]</span></p>
<p>for all <span class="math inline">\(k\)</span>. Then, <span class="math inline">\(B_1, B_2, ..\)</span> is a sequence of disjoint Borel sets.</p>
<p>Then we have:</p>
<p><span class="math display">\[|\bigcup^{\infty}_{k=1} A_k| \geq |\bigcup^{\infty}_{k=1} B_k| = \sum^{\infty}_{k=1} |B_k|\]</span></p>
<p>Since <span class="math inline">\(|A_k| = |B_k \cup (A_k / B_k)| \leq |B_k| + |A_k / B_k| = |B_k|\)</span>, we have:</p>
<p><span class="math display">\[|\bigcup^{\infty}_{k=1} A_k| \geq \sum^{\infty}_{k=1} |B_k| \geq \sum^{\infty}_{k=1} |A_k|\]</span></p>
<p><br></p>
<h4 id="definition-2.73-lebesgue-measure-more-general-on-l">Definition 2.73: Lebesgue Measure (More general, on <span class="math inline">\(L\)</span>)</h4>
<p><strong>Lebesgue measure</strong> is the measure on <span class="math inline">\((\mathbb{R}, L)\)</span>, where <span class="math inline">\(L\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra of Lebesgue measurable subsets of <span class="math inline">\(\mathbb{R}\)</span>, that assigns to each Lebesgue measurable set its outer measure.</p>
<p><strong>Every Lebesgue measurable set differs from a Borel set by a set with outer measure <span class="math inline">\(0\)</span>.</strong></p>
<p><strong>The two definitions differ only on the domain, which will be specified unless it is irrelevant.</strong></p>
<p><br></p>
<h4 id="definition-2.74-cantor-set">Definition 2.74: Cantor Set</h4>
<p>The <strong>Cantor set</strong> <span class="math inline">\(C\)</span> is <span class="math inline">\([0, 1] / (\bigcup^{\infty}_{n=1}) G_n\)</span>, where <span class="math inline">\(G_1 = (\frac{1}{3}, \frac{2}{3})\)</span> and <span class="math inline">\(G_n\)</span> for <span class="math inline">\(n &gt; 1\)</span> is the union of the middle-third open intervals in the intervals of <span class="math inline">\([0, 1] / \bigcup^{n-1}_{j=1}G_j\)</span>.</p>
<p>One way to envision the Cantor set <span class="math inline">\(C\)</span> is to start with the interval <span class="math inline">\([0, 1]\)</span> and then consdier the process that removes at each step the middle-third open intervals of all intervals left from the previous step.</p>
<p><br></p>
<h4 id="theorem-2.76-c-is-closed-has-measure-0-and-contains-no-nontrivial-intervals">Theorem 2.76: <span class="math inline">\(C\)</span> is Closed, has Measure <span class="math inline">\(0\)</span>, and Contains no nontrivial Intervals</h4>
<ol type="a">
<li>The Cantor set is a closed subset of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>The Cantor set has Lebesgue measure <span class="math inline">\(0\)</span>.</li>
<li>The Cantor set contains no interval with more than one element.</li>
</ol>
<p><br></p>
<h3 id="convergence-of-measurable-functions">Convergence of Measurable Functions</h3>
<h4 id="definition-2.82-pointwise-and-uniform-convergence">Definition 2.82: Pointwise and Uniform Convergence</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set, <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>, and <span class="math inline">\(f\)</span> is a function from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>.</p>
<ul>
<li><p>The sequence <span class="math inline">\(f_1, f_2, ...\)</span> <strong>converges pointwise</strong> on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span>, if:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} f_k (x) = f(x)\]</span></p>
<p>for each <span class="math inline">\(x \in X\)</span>. In other words, <span class="math inline">\(f_1, f_2, ...\)</span> converges pointwise on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span> if for each <span class="math inline">\(x \in X\)</span> and every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(n &gt; \mathbb{Z}^+\)</span> s.t <span class="math display">\[|f_k(x) - f(x)| &lt; \epsilon\]</span> for all integers <span class="math inline">\(k \geq n\)</span>.</p></li>
<li><p>The sequence <span class="math inline">\(f_1, f_2, ...\)</span> <strong>converges uniformly</strong> on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span> if for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(n \in \mathbb{Z}^+\)</span> s.t <span class="math inline">\(|f_k (x) - f(x)| &lt; \epsilon\)</span>, forall integers <span class="math inline">\(k \geq n\)</span> and for all <span class="math inline">\(x \in X\)</span>.</p></li>
</ul>
<p><br></p>
<h4 id="theorem-2.84-uniform-limit-of-continuous-function-is-continuous">Theorem 2.84: Uniform Limit of Continuous Function is Continuous</h4>
<p>Suppose <span class="math inline">\(B \subseteq \mathbb{R}\)</span> and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of functions from <span class="math inline">\(B \rightarrow \mathbb{R}\)</span> that converges uniformly on <span class="math inline">\(B\)</span> to a function <span class="math inline">\(f: B \rightarrow \mathbb{R}\)</span>. Suppose <span class="math inline">\(b \in B\)</span> and <span class="math inline">\(f_k\)</span> is continuous at <span class="math inline">\(b\)</span> for each <span class="math inline">\(k \in \mathbb{Z}^+\)</span>. Then <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(b\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.85-egorovs-theorem">Theorem 2.85: Egorov's Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space with <span class="math inline">\(\mu(X) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> that converges pointwise on <span class="math inline">\(X\)</span> to a function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a set <span class="math inline">\(E \subseteq S\)</span> s.t <span class="math inline">\(\mu(X / E) &lt; \epsilon\)</span> and <span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(E\)</span>.</p>
<h5 id="proof-of-theorem-2.85">Proof of Theorem 2.85:</h5>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space with <span class="math inline">\(\mu(X) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> that converges pointwise on <span class="math inline">\(X\)</span> to a function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span>.</p>
<p>We want to prove that:</p>
<ol type="1">
<li><span class="math inline">\(E = \bigcap^{\infty}_{n=1} A_{m_n, n} \in S\)</span>.</li>
<li><span class="math inline">\(\mu(X / E) &lt; \epsilon\)</span>.</li>
<li><span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(E\)</span>.</li>
</ol>
<p>Suppose <span class="math inline">\(\epsilon &gt; 0\)</span>, then for any <span class="math inline">\(n \in \mathbb{Z}^+\)</span>, the definition of pointwise convergence implies that for some <span class="math inline">\(k\)</span> for some <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[|f_k (x) - f(x)| &lt; \frac{1}{n}\]</span></p>
<p>then:</p>
<p><span class="math display">\[\bigcap^{\infty}_{k=1}\{x \in X: |f_k (x) - f(x)| &lt; \frac{1}{n}\} = X\]</span></p>
<p><span class="math display">\[\bigcup^{\infty}_{m=1}\bigcap^{\infty}_{k=m}\{x \in X: |f_k (x) - f(x)| &lt; \frac{1}{n}\} = X\]</span></p>
<p>For <span class="math inline">\(m \in \mathbb{Z}^+\)</span>, let:</p>
<p><span class="math display">\[A_{m, n} = \bigcap^{\infty}_{k=m}\{x \in X: |f_k (x) - f(x)| &lt; \frac{1}{n}\}\]</span></p>
<p>Since <span class="math inline">\(f_1, f_2, ...\)</span> is <span class="math inline">\(S\)</span>-measurable, by <code>theorem 2.48</code>, <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable, by <code>theorem 2.46</code> <span class="math inline">\(f_k - f\)</span> is <span class="math inline">\(S\)</span>-measurable, this implies that:</p>
<p><span class="math display">\[(f_k - f)^{-1} ((-\frac{1}{n}, \frac{1}{n})) \in S\]</span></p>
<p>So <span class="math inline">\(A_{m, n} \in S\)</span> <strong>which proves 1.</strong></p>
<p>We can clearly see that <span class="math inline">\(A_{1, n} \subseteq A_{2, n} \subseteq ...\)</span> is an increasing sequence of sets, and by <code>theorem 2.59</code>:</p>
<p><span class="math display">\[\lim_{m \rightarrow \infty} \mu(\bigcup^{\infty}_{m=1} A_{m, n}) = \mu(X)\]</span></p>
<p>Thus, by sequence convergence theorem, there exists <span class="math inline">\(m_n \in \mathbb{Z}^+\)</span> s.t:</p>
<p><span class="math display">\[\mu(X) - \mu(A_{m_n, n}) &lt; \frac{\epsilon}{2^n}\]</span></p>
<p>Let <span class="math inline">\(E = \bigcap^{\infty}_{n=1} A_{m_n, n}\)</span>, then:</p>
<p><span class="math display">\[\mu(X / E) = \mu(X /  \bigcap^{\infty}_{n=1} A_{m_n, n}) = \mu(\bigcup^{\infty}_{n=1}(X / A_{m_n, n})) \leq \sum^{\infty}_{n=1}\mu(X / A_{m_n, n}) = \sum^{\infty}_{n=1}\mu(X) - \mu(A_{m_n, n})\]</span></p>
<p>Since <span class="math inline">\(\sum^{\infty}_{n=1} \epsilon (\frac{1}{2})^n = (\sum^{\infty}_{n=0} \epsilon (\frac{1}{2})^n) - \epsilon = \epsilon\)</span>, we have:</p>
<p><span class="math display">\[\mu(X / E) &lt; \epsilon\]</span></p>
<p><strong>which proves 2.</strong></p>
<p>Now, suppose <span class="math inline">\(\epsilon^\prime &gt; 0\)</span> and let <span class="math inline">\(n\)</span> be such that <span class="math inline">\(\frac{1}{n} &lt; \epsilon^\prime\)</span>. Then <span class="math inline">\(E \subseteq A_{m_n, n}\)</span>, which implies that:</p>
<p><span class="math display">\[|f_k (x) - f(x)| &lt; \frac{1}{n} &lt; \epsilon^\prime\]</span></p>
<p>for all <span class="math inline">\(k \geq m_n\)</span> and <span class="math inline">\(x \in E\)</span>, thus, <strong>we have proved 3.</strong></p>
<p><br></p>
<h4 id="definition-2.88-simple-function">Definition 2.88: Simple Function</h4>
<p>A function is called <strong>simple</strong> if it takes only finite many values.</p>
<p>Let <span class="math inline">\(f = c_1\chi_{E_1} + .... + c_n \chi_{E_n}\)</span>, where <span class="math inline">\(E_k = f^{-1}(\{c_k\})\)</span>, then <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable IFF <span class="math inline">\(E_1, ..., E_n \in S\)</span></p>
<p>The representation of the simple function <span class="math inline">\(f\)</span> is not unique. By requiring <span class="math inline">\(c_1, ..., c_n\)</span> to be distinct and <span class="math inline">\(E_1, ...., E_n\)</span> to be nonempty and disjoint with <span class="math inline">\(E_1 \cup .... \cup E_n = X\)</span> produces what is called the <strong>standard representation</strong> of a simple function (taking <span class="math inline">\(E_k = f^{-1} (\{c_k\})\)</span> where <span class="math inline">\(c_1, c_2, ..., c_n\)</span> are distinct values of <span class="math inline">\(f\)</span>)</p>
<p><br></p>
<h4 id="theorem-2.89-approximation-by-simple-function">Theorem 2.89: Approximation by Simple Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable. Then there exists a sequence <span class="math inline">\(f_1, f_2, ...\)</span> of functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> s.t:</p>
<ol type="a">
<li>Each <span class="math inline">\(f_k\)</span> is simple <span class="math inline">\(S\)</span>-measurable function.</li>
<li><span class="math inline">\(|f_k(x)| \leq |f_{k+1}(x)| \leq |f(x)|\)</span> for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span> and all <span class="math inline">\(x \in X\)</span>.</li>
<li><span class="math inline">\(\lim_{k \rightarrow \infty} f_k (x) = f(x)\)</span> for every <span class="math inline">\(x \in X\)</span>.</li>
<li><span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span> if <span class="math inline">\(f\)</span> is bounded.</li>
</ol>
<p><br></p>
<h4 id="theorem-2.91-luzins-theorem">Theorem 2.91: Luzin's Theorem</h4>
<p>Suppose <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> is a Borel measurable function. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq \mathbb{R}\)</span> s.t <span class="math inline">\(|\mathbb{R} / F| &lt; \epsilon\)</span> and <span class="math inline">\(g|_{F}\)</span> is a continuous function on <span class="math inline">\(F\)</span>.</p>
<p>In other words, if <span class="math inline">\(g\)</span> is Borel measurable function, then there exists a closed set <span class="math inline">\(F \subseteq \mathbb{R}\)</span>, s.t the outer measure of the complement of <span class="math inline">\(F\)</span> is arbitrarily large and <span class="math inline">\(g|_F\)</span> is continuous on this arbitrarily small open set. <strong><span class="math inline">\(g|_F\)</span> is continuous on <span class="math inline">\(F\)</span> is not the same as <span class="math inline">\(g\)</span> is continuous at every point of <span class="math inline">\(B\)</span>.</strong></p>
<blockquote>
<p><span class="math inline">\(\chi_\mathbb{Q}\)</span> is discontinuous as every point of <span class="math inline">\(\mathbb{R}\)</span>, however, <span class="math inline">\(\chi_{\mathbb{Q}} |_{\mathbb{R} / \mathbb{Q}}\)</span> is continuous everywhere on <span class="math inline">\(\mathbb{R} / \mathbb{Q}\)</span> because they are all 0.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.92-continuous-extensions-of-continuous-functions">Theorem 2.92: Continuous Extensions of Continuous Functions</h4>
<ul>
<li>Every continuous function on a closed subset of <span class="math inline">\(\mathbb{R}\)</span> can be extended to a continuous function on all of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>More precisely, if <span class="math inline">\(F \in \mathbb{R}\)</span> is closed and <span class="math inline">\(g: F \rightarrow \mathbb{R}\)</span> is continuous, then there exists a continuous function <span class="math inline">\(h: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t <span class="math inline">\(h|_F = g\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-2.93-luzins-theorem-second-version">Theorem 2.93: Luzin's Theorem, Second Version</h4>
<p>Suppose <span class="math inline">\(E \subseteq \mathbb{R}\)</span> and <span class="math inline">\(g: E \rightarrow \mathbb{R}\)</span> is a Borel measurable function. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq E\)</span> and a continuous function <span class="math inline">\(h: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t <span class="math inline">\(|E / F| &lt; \epsilon\)</span> and $h|_{F} = g |_F $.</p>
<p><br></p>
<h4 id="definition-2.94-lebesgue-measurable-function">Definition 2.94: Lebesgue Measurable Function</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, where <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, is called <strong>Lebesgue measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Lebesgue measurable set for every Borel set <span class="math inline">\(B \subseteq \mathbb{R}\)</span>.</p>
<p><strong>The definition implies that if <span class="math inline">\(A\)</span> is Lebesgue measurable then <span class="math inline">\(A\)</span> is a Lebesgue measurable subset of <span class="math inline">\(\mathbb{R}\)</span>. If <span class="math inline">\(A\)</span> is a Lebesgue measurable subset of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra of all Lebesgue measurable subsets of <span class="math inline">\(A\)</span>, then <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable</strong>.</p>
<p><br></p>
<h4 id="theorem-2.95-every-lebesgue-measurable-function-is-almost-borel-measurable">Theorem 2.95 Every Lebesgue Measurable Function is Almost Borel Measurable:</h4>
<p>Suppose <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is a Lebesgue measurable function. Then there exists a Borel measurable function <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[|\{x \in \mathbb{R}: g(x) \neq f(x)\}| = 0\]</span></p>
<p><br></p>
<h4 id="review-2.96">Review 2.96</h4>
<ul>
<li>A <strong>Borel set</strong> is an element of the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> that contains all the open subsets of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>A <strong>Lebesgue measurable set</strong> is an element of the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> that contains all the open subsets of <span class="math inline">\(\mathbb{R}\)</span> and all the subsets of <span class="math inline">\(\mathbb{R}\)</span> with outer measure <span class="math inline">\(0\)</span>.</li>
<li>Every Lebesgue measurable set differs from a Borel set by a set with outer measure <span class="math inline">\(0\)</span>.</li>
<li>Outer measure restricted to the <span class="math inline">\(\sigma\)</span>-algebra of Borel sets or Lebesgue measurable sets is called <strong>Lebesgue measure</strong>.</li>
<li>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is called <strong>Borel measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Borel set for every Borel set <span class="math inline">\(B \in \mathbb{B}\)</span>.</li>
<li>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is called <strong>Lebesgue measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Lebesgue measurable set for every Borel set <span class="math inline">\(B \in \mathbb{B}\)</span>.</li>
</ul>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Naive Bayes</title>
    <url>/2021/07/19/naive-bayes/</url>
    <content><![CDATA[<h1 id="naive-bayes">Naive Bayes</h1>
<p>Suppose our training set consists of data samples <span class="math inline">\(D = \{(\mathbf{x}_1, y_1), ...., (\mathbf{x}_N, y_N)\}, \; \mathbf{x_i} \in \mathbb{R}^d\)</span>, where <span class="math inline">\(D = \{(\mathbf{x}_i, y_i)\}\)</span> are realizations of a random sample that follows unknown joint distribution <span class="math inline">\(P(\mathbf{X}, Y)\)</span>.</p>
<p><strong>Assumptions</strong>:</p>
<ol type="1">
<li><p><strong>Features are conditionally independent (Naive bayes assumption)</strong>: <span class="math display">\[P(\mathbf{X} | Y) = \prod^{d}_{j=1} P(X_j | Y)\]</span></p></li>
<li><p><strong>MLE assumption</strong>: Random sample is identically distributed.</p></li>
<li><p><strong>Positional independence</strong>: The position of features does not matter (used in Multinomial case).</p></li>
</ol>
<p>By applying bayes rule (applying on distribution <span class="math inline">\(P (\cdot)\)</span> to make things general), we have:</p>
<p><span class="math display">\[P(Y | \mathbf{X}) = \frac{P(\mathbf{X}, Y)}{P(\mathbf{X})} = \frac{P(\mathbf{X} | Y) P(Y)}{P(\mathbf{X})}\]</span></p>
<p>By substituting the assumption:</p>
<p><span class="math display">\[P(Y | \mathbf{X}) = \frac{\prod^{d}_{j=1} P(X_j | Y)P(Y)}{P(\mathbf{X})}\]</span></p>
<p>Since the probability distribution <span class="math inline">\(P(\mathbf{X})\)</span> characterised by <span class="math inline">\(F_{\mathbf{X}}(\mathbf{x})\)</span> is constant for any given <span class="math inline">\(\mathbf{x}\)</span>, we can drop it from the equation because it only changes <span class="math inline">\(P(Y | \mathbf{X})\)</span> by a proportion:</p>
<p><span class="math display">\[P(Y | \mathbf{X}) \propto P(Y) \prod^{d}_{j=1} P(X_j | Y)\]</span></p>
<p>Our goal is to find a class <span class="math inline">\(\hat{y}\)</span> that maximize the probability given input <span class="math inline">\(\mathbf{X} = \mathbf{x}\)</span>:</p>
<span class="math display">\[\begin{aligned}
\hat{y} = \underset{y}{\arg\max} \sum^{d}_{j=1} \log P_{X_j|Y}(x_j | y) + \log P_{Y}(y)
\end{aligned}\]</span>
<span id="more"></span>
<h2 id="bernoulli-naive-bayes">Bernoulli Naive Bayes</h2>
<p>In order to solve for <span class="math inline">\(\hat{y}\)</span>, we need to first find <span class="math inline">\(\log P(X_i | Y)\)</span> and <span class="math inline">\(\log P(Y)\)</span>. Assume that our features are discrete and takes values <span class="math inline">\(X_{j} \in \{0, 1\}\)</span> and we have <span class="math inline">\(k\)</span> classes, <span class="math inline">\(Y \in \{0, ..., k\}\)</span>. Then it is nature to also assume that the conditional distribution of one feature <span class="math inline">\(X_{j}\)</span> given <span class="math inline">\(Y=y\)</span> follows a bernoulli distribution with unknown parameters <span class="math inline">\(\mu_{jy}\)</span>. That is, for <span class="math inline">\(i\)</span>th input (<span class="math inline">\(\mathbf{x}_i, y_i\)</span>) the pmf of <span class="math inline">\(j\)</span>th feature given <span class="math inline">\(y_i\)</span> can be written as:</p>
<p><span class="math display">\[p_{X_j | Y} (x_{ij} | y_i; \mu_{j y_{i}}) = \mu_{j y_{i}}^{x_{ij}} (1 - \mu_{j y_{i}})^{1 - x_{ij}}\]</span></p>
<p>Besides parameter <span class="math inline">\(\mu_{jy_i}\)</span>, we have parameter <span class="math inline">\(\pi_{y_i}\)</span> which is defined as the prior probability of class <span class="math inline">\(y_i\)</span> (This is valid because this is part of the joint distribution):</p>
<p><span class="math display">\[\pi_{y_i} = P(Y=y_i)\]</span></p>
<p>Then, the likelihood function can be written as <span class="math inline">\(\boldsymbol{\theta} = &lt;\boldsymbol{\mu, \; \pi}&gt;\)</span>:</p>
<p><span class="math display">\[L(\boldsymbol{\theta}; D) = \prod^{N}_{i=1} P(\mathbf{X}, Y; \; \boldsymbol{\theta}) = \prod^{N}_{i=1} \pi_{y_i} \prod^{d}_{j=1} \mu_{j y_{i}}^{x_{ij}} (1 - \mu_{j y_{i}})^{1 - x_{ij}}\]</span></p>
<p>subject to constraint <span class="math inline">\(\sum^{K}_{i=1} \pi_{i} = 1\)</span></p>
<p>Then the log likelihood function:</p>
<p><span class="math display">\[l(\boldsymbol{\theta}; D) = \sum^{N}_{i=1} [\log (\pi_{y_i}) \sum^{d}_{j=1} x_{ij} \log (\mu_{j y_{i}}) + (1 - x_{ij})\log (1 - \mu_{j y_{i}})]\]</span></p>
<p>subject to constraint <span class="math inline">\(\sum^{K}_{i=1} \pi_{i} = 1\)</span></p>
<p>Taking partial derivative w.r.t <span class="math inline">\(\mu_{jk}\)</span>:</p>
<span class="math display">\[\begin{aligned}
\frac{\partial l(\boldsymbol{\theta}; D)}{\partial \mu_{jk}} &amp;= 0\\
\implies \sum^{n}_{i=1} I[y_i = k] (\frac{x_{ij}}{\mu_{jk}} - \frac{1 - x_{ij}}{1 - \mu_{jk}}) &amp;= 0\\
\implies \sum^{n}_{i=1} I[y_i = k] \frac{x_{ij}}{\mu_{jk}} &amp;= \sum^{n}_{i=1} I[y_i = k] \frac{1 - x_{ij}}{1 - \mu_{jk}}\\
\implies \sum^{n}_{i=1} I[y_i = k] (1 - \mu_{jk}) x_{ij} &amp;= \sum^{n}_{i=1} I[y_i = k] (1 - x_{ij}) \mu_{jk}\\
\implies \hat{\mu}_{jk} &amp;= \frac{\sum^{N}_{i=1} I[x_{ij} = 1 \text{ and } y_i = k]}{\sum^{N}_{i=1} I[y_i = k]}
\end{aligned}\]</span>
<p>Taking partial derivative w.r.t <span class="math inline">\(\pi_{k}\)</span> and constraint <span class="math inline">\(\sum^{K}_{i=1} \pi_{i} = 1\)</span> (Lagrange multiplier):</p>
<p><span class="math display">\[\frac{\partial l(\boldsymbol{\theta}; D)}{\partial \pi_{k}} + \lambda \frac{\partial \sum^{K}_{i=1} \pi_{i}}{\partial \pi_{k}} = 0\]</span></p>
<p><span class="math display">\[\implies \lambda = - \sum^{N}_{i=1} \frac{I[y_i = k]}{\pi_k}\]</span></p>
<p><span class="math display">\[\implies \pi_k = - \sum^{N}_{i=1} \frac{I[y_i = k]}{\lambda}\]</span></p>
<p>By substituting <span class="math inline">\(\lambda\)</span> with <span class="math inline">\(\sum^{N}_{i=1} \pi_i = 1 \implies \lambda = -N\)</span>:</p>
<p><span class="math display">\[\hat{\pi}_k = \sum^{N}_{i=1} \frac{I[y_i = k]}{N}\]</span></p>
<p>The result is same if we assume <span class="math inline">\(Y\)</span> follows Multinomial distribution with constraint on <span class="math inline">\(p\)</span> and <span class="math inline">\(n = 1\)</span>.</p>
<h2 id="multinomial-naive-bayes">Multinomial Naive Bayes</h2>
<p>In multinomial case, our features are counts <span class="math inline">\(X_j \in \{0, ....., M\}\)</span>.</p>
<p>The derivation of Multinomial NB is similar to Bernoulli case, the only difference is that, in multinomial, we assume the conditional distribution of <span class="math inline">\(\mathbf{X}\)</span> given <span class="math inline">\(Y=y\)</span> follows a multinomial distribution. That is, the conditional pmf for <span class="math inline">\(i\)</span>th input <span class="math inline">\((\mathbf{x}_i | y_i)\)</span> is defined as:</p>
<p><span class="math display">\[p_{\mathbf{X} | Y} (\mathbf{x}_i | y_i) = \frac{M_i!}{x_{i1}! .... x_{id}!} \prod^{d}_{j=1} \mu^{x_{ij}}_{jy_i}\]</span></p>
<p>Where, <span class="math inline">\(M_{i}\)</span> represents the total counts for sample <span class="math inline">\(i\)</span>.</p>
<p>By positional independence:</p>
<p><span class="math display">\[p_{\mathbf{X} | Y} (\mathbf{x}_i | y_i) = \prod^{d}_{j=1} \mu^{x_{ij}}_{jy_i}\]</span></p>
<p>Then, we can write the likelihood function as:</p>
<p><span class="math display">\[L(\boldsymbol{\theta}; D) = \prod^{N}_{i=1} P(\mathbf{X}, Y; \; \boldsymbol{\theta}) = \prod^{N}_{i=1} \pi_{y_i} \prod^{d}_{j=1} \mu^{x_{ij}}_{jy_i}\]</span></p>
<p>subject to constraints:</p>
<p><span class="math display">\[\sum^{K}_{i=1} \pi_i = 1\]</span></p>
<p><span class="math display">\[\sum^{d}_{j=1} \mu_{jk} = 1\]</span></p>
<p><span class="math display">\[\sum^{d}_{j=1} x_{ij} = M_i\]</span></p>
<p>By solving the contrained maximization problem, we have the estimates:</p>
<p><span class="math display">\[\hat{\mu}_{jk} = \frac{\sum^{N}_{i=1} I[y_i = k]x_{ij} + l}{\sum^{N}_{i=1} I[y_i = k] \sum^{d}_{\beta=1} x_{i\beta} + ld}\]</span></p>
<p><span class="math display">\[\hat{\pi}_k = \sum^{N}_{i=1} \frac{I[y_i = k]}{N}\]</span></p>
<h2 id="categorical-naive-bayes">Categorical Naive Bayes</h2>
<p>In some cases, features <span class="math inline">\(X_j \in \{1, ...., K_{j}\}\)</span> are nominal and have no explicit meaning for their numerical values. Thus, in this case, we can model the pmf of <span class="math inline">\(j\)</span>th feature of <span class="math inline">\(i\)</span>th example given <span class="math inline">\(Y=y_i\)</span> by categorical pmf:</p>
<p><span class="math display">\[p_{X_j|Y} (x_{ij} | y_i) = \prod^{K_{j}}_{k=1} \mu_{jy_i k}^{I[x_{ij} = k]}\]</span></p>
<p>The likelihood function is therefore:</p>
<p><span class="math display">\[L(\boldsymbol{\theta}; D) = \prod^{N}_{i=1} P(\mathbf{X}, Y; \; \boldsymbol{\theta}) = \prod^{N}_{i=1} \pi_{y_i} \prod^{d}_{j=1}\prod^{K_{j}}_{k=1} \mu_{jy_i k}^{I[x_{ij} = k]}\]</span></p>
<p>subject to constraints:</p>
<p><span class="math display">\[\sum^{K}_{i=1} \pi_i = 1\]</span></p>
<p><span class="math display">\[\sum^{K_{j}}_{k=1} \mu_{ijk} = 1\]</span></p>
<p>The estimates are:</p>
<p><span class="math display">\[\hat{\mu}_{jck} = \frac{\sum^{N}_{i=1} I[y_i = c] I[x_{ij} = k] + l}{\sum^{N}_{i=1} I[y_i = c] + lK_{j}}\]</span></p>
<h2 id="gaussian-naive-bayes">Gaussian Naive Bayes</h2>
<p>Suppose features are continuously distributed <span class="math inline">\(X_j \in \mathbb{R}\)</span>, then we can use gaussian distribution to model the conditional distribution of feature:</p>
<p><span class="math display">\[f_{X_{j} | Y} (x_{ij} | Y=y_i ;\; \mu_{jy_i}, \sigma_{jy_i}) = N(\mu_{jy_i}, \sigma_{jy_i})\]</span></p>
<p>Then by following similar procedure, we have ML estimates:</p>
<p><span class="math display">\[\hat{\mu}_{jk} = \frac{1}{n_k} \sum^{N}_{i=1} I[y_i = k] x_{ij}\]</span></p>
<p><span class="math display">\[\hat{\sigma}^2_{jk} = \frac{1}{n_k} \sum^{N}_{i=1} I[y_i = k] (x_{ij} - \hat{\mu}_{jk})^2\]</span></p>
<p>Where <span class="math inline">\(n_c = \frac{1}{n_k} \sum^{N}_{i=1} I[y_i = k]\)</span></p>
<h2 id="naive-bayes-as-linear-classifier">Naive Bayes as Linear Classifier</h2>
<h1 id="implementation">Implementation</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultinomialNB</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha=<span class="number">1</span></span>):</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.theta = <span class="literal">None</span></span><br><span class="line">        self.class_prior = <span class="literal">None</span></span><br><span class="line">        self.class_map = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, pd.DataFrame):</span><br><span class="line">            X = X.values</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(y, pd.Series):</span><br><span class="line">            y = y.values</span><br><span class="line"></span><br><span class="line">        c_ = np.unique(y)</span><br><span class="line">        n_c = c_.size</span><br><span class="line">        NT, N_d = X.shape</span><br><span class="line"></span><br><span class="line">        self.theta = np.zeros((n_c, N_d))</span><br><span class="line">        self.class_prior = np.array(np.unique(y, return_counts=<span class="literal">True</span>), dtype=np.float64).T</span><br><span class="line">        self.class_prior[:, <span class="number">1</span>] = self.class_prior[:, <span class="number">1</span>] / NT</span><br><span class="line">        self.class_map = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> index, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(c_):</span><br><span class="line">            N_c = X[y == c].<span class="built_in">sum</span>()</span><br><span class="line">            self.class_map[index] = c</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N_d):</span><br><span class="line">                N_ci = X[y == c, i].<span class="built_in">sum</span>()</span><br><span class="line">                self.theta[index, i] = np.log((N_ci + self.alpha) / (N_c + self.alpha * N_d))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, pd.DataFrame):</span><br><span class="line">            X = X.values</span><br><span class="line"></span><br><span class="line">        pred_results = np.zeros(X.shape[<span class="number">0</span>])</span><br><span class="line">        class_size = <span class="built_in">len</span>(self.class_map)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> index, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(X):</span><br><span class="line">            temp_lst = np.zeros(class_size)</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(class_size):</span><br><span class="line">                temp_lst[c] = np.log(self.class_prior[:, <span class="number">1</span>][c])</span><br><span class="line">                <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>]):</span><br><span class="line">                    temp_lst[c] = temp_lst[c] + self.theta[c][d] * i[d]</span><br><span class="line"></span><br><span class="line">            pred_results[index] = self.class_map[np.argmax(temp_lst)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pred_results</span><br></pre></td></tr></table></figure>
<h1 id="ref">Ref</h1>
<p>http://www.cs.toronto.edu/~zemel/documents/2515/Tutorial4-2515-nb-gbc.pdf</p>
<p>https://mattshomepage.com/articles/2016/Jun/26/multinomial_nb/</p>
<p>https://classes.cec.wustl.edu/~SEAS-SVC-CSE517A/sp20/lecturenotes/06_lecturenote_NB.pdf</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>natural-actor-critic</title>
    <url>/2021/06/03/natural-actor-critic/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>overfeat</title>
    <url>/2021/06/25/overfeat/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>off-policy-actor-critic</title>
    <url>/2021/06/03/off-policy-actor-critic/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Measure Integral and Real Analysis (4)</title>
    <url>/2022/03/30/mira-4/</url>
    <content><![CDATA[<h1 id="measure-integral-and-real-analysis-4">Measure Integral and Real Analysis (4)</h1>
<h2 id="hilbert-spaces">Hilbert Spaces</h2>
<h3 id="inner-product-spaces">Inner Product Spaces</h3>
<h4 id="definition-8.1-inner-product-inner-product-space">Definition 8.1: Inner Product; Inner Product Space</h4>
<p>An <strong>inner product</strong> on a vector space <span class="math inline">\(V\)</span> is a function that takes each ordered pair <span class="math inline">\(f, g\)</span> of elements of <span class="math inline">\(V\)</span> to a number <span class="math inline">\(&lt;f, g&gt; \in \mathbb{F}\)</span> and has the following properties:</p>
<ul>
<li><strong>Positivity</strong>: <span class="math display">\[&lt;f, f&gt; \in [0, \infty), \; \forall f \in V\]</span></li>
<li><strong>Definiteness</strong>: <span class="math display">\[&lt;f, f&gt; = 0 \text{ IFF } f = 0\]</span></li>
<li><strong>Linearity in first slot</strong>: <span class="math display">\[&lt;f + g, h&gt; = &lt;f, h&gt; + &lt;g, h&gt;, \quad &lt;\alpha f, g&gt; = \alpha&lt;f, g&gt;, \quad \forall f,g,h \in V, \alpha \in \mathbb{F}\]</span></li>
<li><strong>Conjugate Symmetry</strong>: <span class="math display">\[&lt;f, g&gt; = \overline{&lt;g, f&gt;}, \; \forall f, g \in V\]</span></li>
</ul>
<p>A vector space with inner product is called an <strong>inner product space</strong>.</p>
<p>If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the complex conjugate can be ignored as the symmetry property.</p>
<p><br></p>
<h4 id="theorem-8.3-basic-properties-of-an-inner-product">Theorem 8.3: Basic Properties of an Inner Product</h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner product space. Then:</p>
<ol type="a">
<li><span class="math inline">\(&lt;0, g&gt; = &lt;g, 0&gt; = 0, \; \forall g \in V\)</span></li>
<li><span class="math inline">\(&lt;f, g + h&gt; = &lt;f, g&gt; + &lt;f, h&gt;, \; \forall f, g, h \in V\)</span></li>
<li><span class="math inline">\(&lt;f, \alpha g&gt; = \bar{\alpha} &lt;f, g&gt;, \; \forall \alpha \in \mathbb{F}, f, g \in V\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-8.4-norm-associated-with-an-inner-product-cdot">Definition 8.4: Norm Associated with an Inner Product; <span class="math inline">\(\|\cdot\|\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner product space. For <span class="math inline">\(f \in V\)</span>, define the <strong>norm</strong> of <span class="math inline">\(f\)</span>, denoted <span class="math inline">\(\|f\|\)</span>, by:</p>
<p><span class="math display">\[\|f\| = \sqrt{&lt;f, f&gt;}\]</span></p>
<p><br></p>
<h4 id="theorem-8.6-homogeneity-of-the-norm">Theorem 8.6: Homogeneity of the Norm</h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner product space, <span class="math inline">\(f \in V\)</span>, and <span class="math inline">\(\alpha \in \mathbb{F}\)</span>. Then:</p>
<p><span class="math display">\[\|\alpha f\| = |\alpha|\|f\|\]</span></p>
<p><br></p>
<h4 id="definition-8.7-orthogonal">Definition 8.7: Orthogonal</h4>
<p>Two elements of an inner product space are called <strong>orthogonal</strong> if their inner product equals <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h4 id="definition-8.24-distance-from-a-point-to-a-set">Definition 8.24: Distance from a Point to a Set</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a nonempty subset of a normed vector space <span class="math inline">\(V\)</span> and <span class="math inline">\(f \in V\)</span>. The <strong>distance</strong> from <span class="math inline">\(f\)</span> to <span class="math inline">\(U\)</span>, denoted <span class="math inline">\(distance(f, U)\)</span>, is defined by:</p>
<p><span class="math display">\[distance(f, U) = \inf\{\|f - g\|: g \in U\}\]</span></p>
<p><br></p>
<span id="more"></span>
<h4 id="definition-8.25-convex">Definition 8.25: Convex</h4>
<ul>
<li>A subset of a vector space is called <strong>convex</strong> if the subset contains the line segment connecting each pair of the points in it.</li>
<li>More precisely, suppose <span class="math inline">\(V\)</span> is a vector space and <span class="math inline">\(U \subseteq V\)</span>. Then <span class="math inline">\(U\)</span> is called <strong>convex</strong> if: <span class="math display">\[(1 - t) f + t g \in U, \; \forall t \in [0, 1], f, g \in U\]</span></li>
</ul>
<p><br></p>
<h4 id="theorem-8.28-distance-to-a-closed-convex-set-is-attained-in-a-hilbert-space">Theorem 8.28: Distance to a Closed Convex Set is Attained in a Hilbert Space</h4>
<ul>
<li>The distance from an element of a Hilbert space to a nonempty closed convex set is attained by a unique element of the nonempty closed convex set.</li>
<li>More specifically, suppose <span class="math inline">\(V\)</span> is a <strong>Hilbert space</strong>, <span class="math inline">\(f \in V\)</span>, and <span class="math inline">\(U\)</span> is a nonempty closed convex subset of <span class="math inline">\(V\)</span>. Then there exists a unique <span class="math inline">\(g \in U\)</span> s.t: <span class="math display">\[\|f - g\| = distance(f, U)\]</span></li>
</ul>
<p><br></p>
<h4 id="definition-8.34-orthogonal-projection-p_u">Definition 8.34: Orthogonal Projection; <span class="math inline">\(P_U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a nonempty closed convex subset of a <strong>Hilbert space</strong> <span class="math inline">\(V\)</span>. Then <strong>orthogonal projection</strong> of <span class="math inline">\(V\)</span> onto <span class="math inline">\(U\)</span> is the function <span class="math inline">\(P_U: V \rightarrow V\)</span> defined by setting <span class="math inline">\(P_U(f)\)</span> equal to the unique element of <span class="math inline">\(U\)</span> that is closest to <span class="math inline">\(f\)</span>.</p>
<p>This definition only makes sense because of <code>theorem 8.28</code>.</p>
<p><br></p>
<h4 id="theorem-8.37-orthogonal-projection-onto-closed-subspace">Theorem 8.37: Orthogonal Projection onto Closed Subspace</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a closed subspace of <strong>Hilbert space</strong> <span class="math inline">\(V\)</span> and <span class="math inline">\(f \in V\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(f - P_U(f)\)</span> is orthogonal to <span class="math inline">\(g\)</span> for every <span class="math inline">\(g \in U\)</span>.</li>
<li>If <span class="math inline">\(h \in U\)</span> and <span class="math inline">\(f - h\)</span> is orthogonal to <span class="math inline">\(g\)</span> for every <span class="math inline">\(g \in U\)</span>, then <span class="math inline">\(h = P_U(f)\)</span>.</li>
<li><span class="math inline">\(P_U: V \rightarrow V\)</span> is a linear map.</li>
<li><span class="math inline">\(\|P_U (f)\| \leq \|f\|\)</span>, with equality IFF <span class="math inline">\(f \in U\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-8.38-orthogonal-complement-uperp">Definition 8.38: Orthogonal Complement; <span class="math inline">\(U^\perp\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subset of an <strong>inner product space</strong> <span class="math inline">\(V\)</span>. The <strong>orthogonal complement</strong> of <span class="math inline">\(U\)</span> is denoted by <span class="math inline">\(U^\perp\)</span> and is defined by:</p>
<p><span class="math display">\[U^{\perp} = \{h \in V: &lt;g, h&gt; = 0, \; \forall g \in U\}\]</span></p>
<p>In other words, the orthogonal complement of a subset <span class="math inline">\(U\)</span> of an inner product space <span class="math inline">\(V\)</span> is the set of elements of <span class="math inline">\(V\)</span> that are orthogonal to every element of <span class="math inline">\(U\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.40-properties-of-orthogonal-complement">Theorem 8.40: Properties of Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subset of an <strong>inner product space</strong> <span class="math inline">\(V\)</span>. Then</p>
<ol type="a">
<li><span class="math inline">\(U^\perp\)</span> is a closed subspace of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(U \cap U^\perp \subseteq \{0\}\)</span>.</li>
<li>If <span class="math inline">\(W \subseteq U\)</span>, then <span class="math inline">\(U^\perp \subseteq W^\perp\)</span>.</li>
<li><span class="math inline">\(\bar{U}^{\perp} = U^{\perp}\)</span></li>
<li><span class="math inline">\(U \subseteq (U^{\perp})^\perp\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-8.41-orthogonal-complement-of-the-orthogonal-complement">Theorem 8.41: Orthogonal Complement of the Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of a Hilbert space <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\overline{U} = (U^\perp)^\perp\]</span></p>
<p>As a special case, if <span class="math inline">\(U\)</span> is a closed subspace of a Hilbert space <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[U = (U^\perp)^\perp\]</span></p>
<p><br></p>
<h4 id="theorem-8.42-necessary-and-sufficient-condition-for-a-subspace-to-be-dense">Theorem 8.42: Necessary and Sufficient Condition for a Subspace to be Dense</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of a Hilbert space <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\overline{U} = V\]</span></p>
<p>IFF</p>
<p><span class="math display">\[U^\perp = \{0\}\]</span></p>
<p><br></p>
<h4 id="theorem-8.43-orthogonal-decomposition">Theorem 8.43: Orthogonal Decomposition</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a <strong>closed subspace</strong> of a Hilbert space <span class="math inline">\(V\)</span>. Then every element <span class="math inline">\(f \in V\)</span> can be uniquely written in the form:</p>
<p><span class="math display">\[f = g + h\]</span></p>
<p>where <span class="math inline">\(g \in U\)</span> and <span class="math inline">\(h \in U^\perp\)</span>. Furthermore, <span class="math inline">\(g = P_U (f)\)</span> and <span class="math inline">\(h = f - P_U(f)\)</span>.</p>
<p><br></p>
<h4 id="definition-8.44-identity-map-i">Definition 8.44: Identity Map; <span class="math inline">\(I\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a vector space. The <strong>identity map</strong> <span class="math inline">\(I\)</span> is the linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(V\)</span> defined by:</p>
<p><span class="math display">\[I(f) = f\]</span></p>
<p>for <span class="math inline">\(f \in V\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.45-range-and-null-space-of-orthogonal-projections">Theorem 8.45: Range and Null Space of Orthogonal Projections</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a closed subspace of a Hilbert space <span class="math inline">\(V\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(\text{range}(P_U) = U\)</span> and <span class="math inline">\(\text{null}(P_U) = U^\perp\)</span>.</li>
<li><span class="math inline">\(\text{range}(P_{U^\perp}) = U^\perp\)</span> and <span class="math inline">\(\text{null}(P_{U^\perp}) = U\)</span>.</li>
<li><span class="math inline">\(P_{U^\perp} = I - P_U\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-8.47-riesz-representation-theorem">Theorem 8.47: Riesz Representation Theorem</h4>
<p>Suppose <span class="math inline">\(\varphi\)</span> is a bounded linear functional on a Hilbert space <span class="math inline">\(V\)</span>. Then there exists a unique <span class="math inline">\(h \in V\)</span> s.t:</p>
<p><span class="math display">\[\varphi(f) = &lt;f, h&gt;\]</span></p>
<p>for all <span class="math inline">\(f \in V\)</span>. Furthermore, <span class="math inline">\(\|\varphi\| = \|h\|\)</span>.</p>
<p><br></p>
<h3 id="orthonormal-bases">Orthonormal Bases</h3>
<h4 id="definition-8.50-orthonormal-family">Definition 8.50: Orthonormal Family</h4>
<p>A family <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> in an inner product space is called an <strong>orthonormal family</strong> if:</p>
<p><span class="math display">\[
&lt;e_j, e_k&gt; =
\begin{cases}
0, \quad \text{if } j \neq k\\
1, \quad \text{if } j = k
\end{cases}
\]</span></p>
<p>for all <span class="math inline">\(j, k \in \Gamma\)</span></p>
<p>in other words, a family is an orthonormal family if <span class="math inline">\(e_j, e_k\)</span> are orthogonal for all distinct <span class="math inline">\(j, k \in \Gamma\)</span> and <span class="math inline">\(\|e_k\| = 1\)</span> for all <span class="math inline">\(k \in \Gamma\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.52-finite-orthonormal-families">Theorem 8.52: Finite Orthonormal Families</h4>
<p>Suppose <span class="math inline">\(\Omega\)</span> is a finite set and <span class="math inline">\(\{e_j\}_{j \in \Omega}\)</span> is an orthonormal family in an inner product space. Then:</p>
<p><span class="math display">\[\|\sum_{j \in \Omega} \alpha_j e_j\|^2 = \sum_{j \in \Omega} |\alpha_j|^2\]</span></p>
<p>for every family <span class="math inline">\(\{\alpha_j\}_{j \in \Omega}\)</span> in <span class="math inline">\(\mathbb{F}\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.53-unordered-sum-sum_k-in-gamma-f_k">Theorem 8.53: Unordered Sum; <span class="math inline">\(\sum_{k \in \Gamma} f_k\)</span></h4>
<p>Suppose <span class="math inline">\(\{f_k\}_{k \in \Gamma}\)</span> is a family in a normed vector space <span class="math inline">\(V\)</span>. Then <strong>unordered sum</strong> <span class="math inline">\(\sum_{k \in \Gamma} f_k\)</span> is said to be <strong>converge</strong> if there exists <span class="math inline">\(g \in V\)</span> s.t for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a finite subset <span class="math inline">\(\Omega \subseteq \Gamma\)</span> s.t:</p>
<p><span class="math display">\[\|g - \sum_{j \in \Omega^\prime} f_j\| &lt; \epsilon\]</span></p>
<p>For all finite sets <span class="math inline">\(\Omega^\prime\)</span> with <span class="math inline">\(\Omega \subseteq \Omega^\prime \subseteq \Gamma\)</span>. If this happens, we set <span class="math inline">\(\sum_{k \in \Gamma} f_k = g\)</span>. If there is no such <span class="math inline">\(g \in V\)</span>, then <span class="math inline">\(\sum_{k \in \Gamma} f_k\)</span> is left undefined.</p>
<ul>
<li><p>Suppose <span class="math inline">\(\{a_k\}_{k \in \Gamma}\)</span> is a family in <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(a_k \geq 0\)</span> for each <span class="math inline">\(k \in \Gamma\)</span>. Then the unordered sum <span class="math inline">\(\sum_{k \in \Gamma} a_k\)</span> converges IFF: <span class="math display">\[\sup\{\sum_{j \in \Omega} a_j: \Omega \text{ is a finite subset of $\Gamma$}\} &lt; \infty\]</span></p>
<p>If the sum converges then it is the supremum above.</p></li>
<li><p>Suppose <span class="math inline">\(\{a_k\}_{k \in \Gamma}\)</span> is a family in <span class="math inline">\(\mathbb{R}\)</span>, then the unordered sum converges IFF: <span class="math display">\[\sum_{k \in \Gamma} |a_k| &lt; \infty\]</span></p></li>
</ul>
<p><br></p>
<h4 id="theorem-8.54-linear-combinations-of-an-orthonormal-family">Theorem 8.54: Linear Combinations of an Orthonormal Family</h4>
<p>Suppose <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is an orthonormal family in a Hilbert space <span class="math inline">\(V\)</span>. Suppose <span class="math inline">\(\{\alpha_k\}_{k \in \Gamma}\)</span> is a family in <span class="math inline">\(\mathbb{F}\)</span>. Then:</p>
<ol type="a">
<li>The unordered sum <span class="math inline">\(\sum_{k \in \Gamma} a_k e_k\)</span> converges <span class="math inline">\(\Longleftrightarrow \sum_{k \in \Gamma} |a_k|^2 &lt; \infty\)</span></li>
</ol>
<p>Furthermore, if <span class="math inline">\(\sum_{k \in \Gamma} a_ke_k\)</span> converges, then:</p>
<ol start="2" type="a">
<li><span class="math inline">\(\|\sum_{k \in \Gamma} a_k e_k\|^2 = \sum_{k \in \Gamma} |a_k|^2\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-8.57-bessels-inequality">Theorem 8.57: Bessel's Inequality</h4>
<p>Suppose <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is an orthonormal family in an inner product space <span class="math inline">\(V\)</span> and <span class="math inline">\(f \in V\)</span>. Then:</p>
<p><span class="math display">\[\sum_{k \in \Gamma} |&lt;f, e_k&gt;|^2 \leq \|f\|^2\]</span></p>
<p><br></p>
<h4 id="theorem-8.58-closure-of-the-span-of-an-orthonormal-family">Theorem 8.58: Closure of the Span of an Orthonormal Family</h4>
<p>Suppose <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is an orthonormal family in a Hilbert space <span class="math inline">\(V\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(\overline{span(\{e_k\}_{k \in \Gamma})} = \{\sum_{k \in \Gamma} \alpha_k e_k: \{\alpha_k\}_{k \in \Gamma} \text{ is a family in $\mathbb{F}$ and } \sum_{k \in \Gamma} |a_k|^2 &lt; \infty\}\)</span>.</li>
<li><span class="math inline">\(f = \sum_{k \in \Gamma} &lt;f, e_k&gt; e_k\)</span>, for every <span class="math inline">\(f \in \overline{span(\{e_k\}_{k \in \Gamma})}\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-8.61-orthonormal-basis">Definition 8.61: Orthonormal Basis</h4>
<p>An orthonormal family <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> in a Hilbert space <span class="math inline">\(V\)</span> is called an <strong>orthonormal basis</strong> of <span class="math inline">\(V\)</span> if:</p>
<p><span class="math display">\[\overline{span(\{e_k\}_{k \in \Gamma})} = V\]</span></p>
<p><strong>An important point to keep in mind is that despite the terminology, an orthonormal basis is not necessarily a basis in sense of <code>theorem 6.54</code></strong>. In fact, if <span class="math inline">\(\Gamma\)</span> is infinite set (uncountable) and <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is an orthonormal basis of <span class="math inline">\(V\)</span>, then it is not a basis of <span class="math inline">\(V\)</span> (ie. <span class="math inline">\(span(\{e_k\}_{k \in \Gamma}) \neq V\)</span>)</p>
<p><br></p>
<h4 id="theorem-8.63-parsevals-identity">Theorem 8.63: Parseval's Identity</h4>
<p>Suppose <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is an orthonormal basis of a Hilbert space <span class="math inline">\(V\)</span> and <span class="math inline">\(f, g \in V\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(f = \sum_{k \in \Gamma} &lt;f, e_k&gt; e_k\)</span>.</li>
<li><span class="math inline">\(&lt;f, g&gt; = \sum_{k \in \Gamma} &lt;f, e_k&gt; \overline{&lt;g, e_k&gt;}\)</span>.</li>
<li><span class="math inline">\(\|f\|^2 = \sum_{k \in \Gamma} |&lt;f, e_k&gt;|^2\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-8.64-separable">Definition 8.64: Separable</h4>
<p>A normed vector space is called <strong>separable</strong> if it has a countable subset whose closure equals the whole space.</p>
<p>A normed vector space <span class="math inline">\(V\)</span> is separable if and only if there exists a countable subset <span class="math inline">\(C\)</span> of <span class="math inline">\(V\)</span> such that every open ball in <span class="math inline">\(V\)</span> contains at least one element of <span class="math inline">\(C\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.67-existence-of-orthonormal-bases-for-separable-hilbert-spaces">Theorem 8.67: Existence of Orthonormal Bases for Separable Hilbert Spaces</h4>
<p>Every separable Hilbert space has an orthonormal basis.</p>
<p><br></p>
<h4 id="theorem-8.71-orthogonal-projection-in-terms-of-an-orthonormal-basis">Theorem 8.71: Orthogonal Projection in Terms of an Orthonormal Basis</h4>
<p>Suppose that <span class="math inline">\(U\)</span> is a closed subspace of a Hilbert space <span class="math inline">\(V\)</span> and <span class="math inline">\(\{e_k\}_{k \in \Gamma}\)</span> is an orthonormal basis of <span class="math inline">\(U\)</span>. Then:</p>
<p><span class="math display">\[P_U(f) = \sum_{k \in \Gamma} &lt;f, e_k&gt; e_k\]</span></p>
<p><br></p>
<h4 id="theorem-8.75-existence-of-orthonormal-bases-for-all-hilbert-spaces">Theorem 8.75: Existence of Orthonormal Bases for All Hilbert Spaces</h4>
<p>Every Hilbert space has an orthonormal basis.</p>
<p><br></p>
<h3 id="reproducing-kernel-hilbert-space">Reproducing Kernel Hilbert Space</h3>
<h4 id="definition-8.80-kernel">Definition 8.80: Kernel</h4>
<p>Let <span class="math inline">\(X\)</span> be a non-empty set. A function <span class="math inline">\(k: X \times X \rightarrow \mathbb{R}\)</span> is called a <strong>kernel</strong> If there exists an <span class="math inline">\(\mathbb{R}\)</span>-Hilbert space <span class="math inline">\(H\)</span> and a map, <span class="math inline">\(\phi: X \rightarrow H\)</span> s.t <span class="math inline">\(\forall x, x^{\prime} \in X\)</span>: <span class="math display">\[k(x, x^{\prime}) := &lt;\phi(x), \phi(x^{\prime})&gt;_H\]</span></p>
<p><br></p>
<h4 id="definition-8.81-positive-definite-functions">Definition 8.81: Positive Definite Functions</h4>
<p>A symmetric function <span class="math inline">\(k: X \times X \rightarrow \mathbb{R}\)</span> is <strong>positive definite</strong> if <span class="math inline">\(\forall n \geq 1\)</span>, <span class="math inline">\(\forall (a_1, ...., a_n) \in \mathbb{R}^n\)</span>, <span class="math inline">\(\forall (x_1, ..., x_n) \in X^{n}\)</span>,</p>
<p><span class="math display">\[\sum^n_{i=1}\sum^n_{j=1} a_ia_j k(x_i, x_j) \geq 0\]</span></p>
<p>The function <span class="math inline">\(k(\cdot, \cdot)\)</span> is <strong>strictly</strong> positive definite if for mutually distinct <span class="math inline">\(x_i\)</span>, the equality holds only when all <span class="math inline">\(a_i\)</span> are zero.</p>
<p><br></p>
<h4 id="theorem-8.82-every-kernel-is-a-positive-definite-function">Theorem 8.82: Every Kernel is a Positive Definite Function</h4>
<p>Let <span class="math inline">\(H\)</span> be any Hilbert space, <span class="math inline">\(X\)</span> is a non-empty set and <span class="math inline">\(\phi: X \rightarrow H\)</span>. Then <span class="math inline">\(k(x, y) := &lt;\phi(x), \phi(y)&gt;_H\)</span> is a <strong>positive definite</strong> function. The reverse also holds. A positive definite function is guaranteed to be the inner product in a Hilbert space <span class="math inline">\(H\)</span> between features <span class="math inline">\(\phi(x)\)</span>.</p>
<p><strong>Thus, we also call a positive definite function kernel function</strong>.</p>
<p><br></p>
<h4 id="theorem-8.83-sums-of-kernels-are-kernels">Theorem 8.83: Sums of Kernels are Kernels</h4>
<p>Given <span class="math inline">\(\alpha &gt; 0\)</span>, and <span class="math inline">\(k, k_1, k_2\)</span> are all kernels on <span class="math inline">\(X\)</span>, then <span class="math inline">\(\alpha k\)</span> and <span class="math inline">\(k_1 + k_2\)</span> are all kernels on <span class="math inline">\(X\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.84-mapping-between-spaces">Theorem 8.84: Mapping Between Spaces</h4>
<p>Let <span class="math inline">\(X, \tilde{X}\)</span> be sets, and define a map <span class="math inline">\(A: X \rightarrow \tilde{X}\)</span>. Define the kernel <span class="math inline">\(k\)</span> on <span class="math inline">\(\tilde{X}\)</span>. Then the kernel <span class="math inline">\(k(A(x), A(x^{\prime}))\)</span> is a kernel on <span class="math inline">\(X\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.85-products-of-kernels-are-kernels">Theorem 8.85: Products of Kernels are Kernels</h4>
<p>Given <span class="math inline">\(k_1\)</span> on <span class="math inline">\(X_1\)</span> and <span class="math inline">\(k_2\)</span> on <span class="math inline">\(X_2\)</span>, then <span class="math inline">\(k_1 \times k_2\)</span> is a kernel on <span class="math inline">\(X_1 \times X_2\)</span>. If <span class="math inline">\(X_1 = X_2 = X\)</span>, then <span class="math inline">\(k := k_1 \times k_2\)</span> is a kernel on <span class="math inline">\(X\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.86">Theorem 8.86:</h4>
<p>For any function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span>, the expression <span class="math inline">\(\tilde{k}:= f(x)k(x, y)f(y)\)</span> defines a kernel. In particular:</p>
<p><span class="math display">\[k(x, y) := f(x) f(y)\]</span></p>
<p>is a kernel.</p>
<h4 id="definition-8.87-reproducing-kernel-hilbert-space-first-definition">Definition 8.87: Reproducing Kernel Hilbert Space (First Definition)</h4>
<p>Let <span class="math inline">\(H\)</span> be a Hilbert space of <span class="math inline">\(\mathbb{R}\)</span>-valued functions defined on a non-empty set <span class="math inline">\(X\)</span> (that is the elements of <span class="math inline">\(H\)</span> are <span class="math inline">\(\mathbb{R}^X\)</span> functions, that is <span class="math inline">\(\phi: X \rightarrow \mathbb{R}^X\)</span>). A function <span class="math inline">\(k: X \times X \rightarrow \mathbb{R}\)</span> is called a <strong>reproduce kernel</strong> of <span class="math inline">\(H\)</span> and <span class="math inline">\(H\)</span> is a reproducing kernel Hilbert space, if <span class="math inline">\(k\)</span> satisfies:</p>
<ul>
<li><span class="math inline">\(\forall x \in X\)</span>, <span class="math inline">\(k(\cdot, x) \in H\)</span>. (The function <span class="math inline">\(k_x (\cdot) = k(\cdot, x)\)</span> is an element of <span class="math inline">\(H\)</span>, so every element <span class="math inline">\(x \in X\)</span> is being mapped to <span class="math inline">\(k_x \in H\)</span>).</li>
<li>Reproducing Kernel Hilbert Space is a function space which is a set of all possible linear combination of <span class="math inline">\(k_{x}, \forall x \in X\)</span>. <span class="math display">\[H:=\overline{span\{k_x: x \in X\}}\]</span></li>
<li><span class="math inline">\(\forall x \in X\)</span>, <span class="math inline">\(\forall f \in H\)</span>, <span class="math inline">\(&lt;f, k(\cdot, x)&gt;_H = f(x)\)</span> (<strong>THE REPRODUCING PROPERTY</strong>)</li>
</ul>
<p>In particular:</p>
<p><span class="math display">\[k(x, y) = &lt;k_x, k_y&gt;\]</span></p>
<p>where <span class="math inline">\(\phi(x) = k_x\)</span></p>
<p>Given <span class="math inline">\(f = \sum^n_{i=1} \alpha_i k(\cdot, x_i), g = \sum^n_{j=1} \beta_j k(\cdot, x_j)\)</span> The inner product <span class="math inline">\(&lt;f, g&gt;_H\)</span> is defined as:</p>
<p><span class="math display">\[&lt;f, g&gt;_H  = \sum^n_{i=1}\sum^{n}_{j=1} \alpha_i\beta_j k(x_i, y_j)\]</span></p>
<p><br></p>
<h4 id="theorem-8.88-uniqueness-of-reproduce-kernel">Theorem 8.88: Uniqueness of Reproduce Kernel</h4>
<p>Given a kernel, the corresponding RKHS is unique up to isometric isomorphisms. Given an RKHS, the corresponding kernel is unique. In other words, each kernel generates a new RKHS.</p>
<p><br></p>
<h4 id="theorem-8.89-dirac-evaluation-functional">Theorem 8.89: Dirac Evaluation Functional</h4>
<p>For a Hilbert space <span class="math inline">\(H\)</span> of real-valued functions on <span class="math inline">\(X\)</span>, and for any point <span class="math inline">\(x \in X\)</span>, the <strong>evaluation functional at <span class="math inline">\(x\)</span></strong> is defined as the map <span class="math inline">\(\delta_x: H \rightarrow \mathbb{R}\)</span> s.t for all functions <span class="math inline">\(f \in H\)</span>:</p>
<p><span class="math display">\[\delta_x (f) = f(x)\]</span></p>
<p><br></p>
<h4 id="theorem-8.90-reproducing-kernel-hilbert-space-second-definition">Theorem 8.90: Reproducing kernel Hilbert Space (second definition)</h4>
<p>Let <span class="math inline">\(H\)</span> be a Hilbert space of functions <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span>. Then the evaluation functionals <span class="math inline">\(\delta_x\)</span> are bounded and continuous functionals IFF <span class="math inline">\(H\)</span> has a reproducing kernel <span class="math inline">\(k\)</span>.</p>
<p><br></p>
<h2 id="fourier-analysis">Fourier Analysis</h2>
<ul>
<li><span class="math inline">\(\sin (x)\cos (y) = \frac{\sin(x - y) + \sin (x + y)}{2}\)</span></li>
<li><span class="math inline">\(\sin (x) \sin(y) = \frac{\cos(x - y) - \cos(x + y)}{2}\)</span></li>
<li><span class="math inline">\(\cos(x)\cos(y) = \frac{\cos(x - y) + \cos(x + y)}{2}\)</span></li>
<li><span class="math inline">\(e^{it} = \cos(t) + i \sin(t)\)</span></li>
<li><span class="math inline">\(\overline{e^{it}} = e^{-it}\)</span></li>
<li><span class="math inline">\(z^n = e^{int}\)</span>, this is a function on <span class="math inline">\(\partial \mathbf{D}\)</span>.</li>
<li><span class="math inline">\(\overline{z^n} = e^{-int}\)</span></li>
</ul>
<h3 id="fourier-series-and-poisson-integral">Fourier Series and Poisson Integral</h3>
<h4 id="definition-11.3-mathbfd-partial-mathbfd">Definition 11.3: <span class="math inline">\(\mathbf{D}, \partial \mathbf{D}\)</span></h4>
<ul>
<li><span class="math inline">\(\mathbf{D}\)</span> denotes the open unit disk in the complex plane: <span class="math display">\[\mathbf{D} = \{w \in \mathbb{C}: |w| &lt; 1\}\]</span></li>
<li><span class="math inline">\(\partial \mathbf{D}\)</span> is the unit circle in the complex plane: <span class="math display">\[\partial \mathbf{D} = \{z \in \mathbb{C}: \|z\| = 1\}\]</span></li>
</ul>
<p><span class="math inline">\(e^{it} = \cos(t) + i \sin(t)\)</span> is a one to one map of <span class="math inline">\((-\pi, \pi]\)</span> onto <span class="math inline">\(\partial \mathbf{D}\)</span>.</p>
<p><br></p>
<h4 id="definition-11.4-measurable-subsets-of-partial-mathbfd-sigma">Definition 11.4: Measurable Subsets of <span class="math inline">\(\partial \mathbf{D}\)</span>; <span class="math inline">\(\sigma\)</span></h4>
<ul>
<li>A subset <span class="math inline">\(E\)</span> of <span class="math inline">\(\partial \mathbf{D}\)</span> is <strong>measurable</strong> if <span class="math inline">\(\{t \in (-\pi, \pi]: e^{it} \in E\}\)</span> is a Borel subset of <span class="math inline">\(\mathbb{R}\)</span> or <span class="math inline">\((e^{it})^{-1}(E) \subseteq B(\mathbb{R})\)</span>.</li>
<li><span class="math inline">\(\sigma\)</span> is the measureon the measurable subsets of <span class="math inline">\(\partial \mathbf{D}\)</span> obtained by transferring Lebesgue measure from <span class="math inline">\((-\pi, \pi]\)</span> to <span class="math inline">\(\partial \mathbf{D}\)</span>, normalized so that <span class="math inline">\(\sigma(\partial \mathbf{D}) = 1\)</span>. In other words, if <span class="math inline">\(E \subseteq \partial \mathbf{D}\)</span> is measurable, then: <span class="math display">\[\sigma(E) = \frac{|\{t \in (-\pi, \pi]: e^{it} \in E\}|}{2\pi}\]</span></li>
</ul>
<p>So we can write the Lebesgue integral on <span class="math inline">\(\partial \mathbf{D}\)</span>:</p>
<p><span class="math display">\[\int_{\partial \mathbf{D}} f d\sigma = \int^\pi_{-\pi} f(e^{it}) \frac{dt}{2\pi}\]</span></p>
<p>for all measurable functions <span class="math inline">\(f: \partial \mathbf{D} \rightarrow \mathbb{C}\)</span> that above integrals make sense.</p>
<p><br></p>
<h4 id="definition-11.5-lp-partial-mathbfd">Definition 11.5: <span class="math inline">\(L^p (\partial \mathbf{D})\)</span></h4>
<p>For <span class="math inline">\(1 \leq p \leq \infty\)</span>, define <span class="math inline">\(L^p(\partial \mathbf{D})\)</span> to mean the complex version of <span class="math inline">\(L^p(\sigma)\)</span>.</p>
<p><br></p>
<h4 id="theorem-11.6-orthonormal-family-in-l2-partial-mathbfd">Theorem 11.6: Orthonormal Family in <span class="math inline">\(L^2 (\partial \mathbf{D})\)</span></h4>
<p><span class="math inline">\(\{z^n\}_{n \in \mathbb{Z}}\)</span> is an orthonormal family in <span class="math inline">\(L^2(\partial \mathbf{D})\)</span>.</p>
<p><br></p>
<h4 id="definition-11.7-fourier-coefficient-hatfn-fourier-seires">Definition 11.7: Fourier Coefficient; <span class="math inline">\(\hat{f}(n)\)</span>; Fourier Seires</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\partial \mathbf{D})\)</span></p>
<ul>
<li>For <span class="math inline">\(n \in \mathbb{Z}\)</span>, the <span class="math inline">\(n\)</span>th <strong>Fourier coefficient</strong> of <span class="math inline">\(f\)</span> is denoted <span class="math inline">\(\hat{f}(n)\)</span> and is defined by: <span class="math display">\[\hat{f}(n) = \int_{\partial \mathbf{D}} f(z) \bar{z^n} d\sigma(z) = \int^\pi_{-\pi} f(e^{it}) e^{-int} \frac{dt}{2\pi}\]</span></li>
<li>The <strong>Fourier Series</strong> of <span class="math inline">\(f\)</span> is the formal sum: <span class="math display">\[\sum^\infty_{n=-\infty} \hat{f}(n) z^n\]</span></li>
</ul>
<p><br></p>
<h4 id="theorem-11.9-algebraic-properties-of-fourier-coefficients">Theorem 11.9: Algebraic Properties of Fourier Coefficients</h4>
<p>Suppose <span class="math inline">\(f, g \in L^1(\partial \mathbf{D})\)</span> and <span class="math inline">\(n \in \mathbb{Z}\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(\widehat{f + g}(n) = \hat{f}(n) + \widehat{g}(n)\)</span></li>
<li><span class="math inline">\(\widehat{\alpha f}(n) = \alpha \hat{f}(n)\)</span> for all <span class="math inline">\(\alpha \in \mathbb{C}\)</span></li>
<li><span class="math inline">\(|\hat{f}(n)| \leq \|f\|_1\)</span></li>
</ol>
<p>from <span class="math inline">\(a, b\)</span>, we can say that for each <span class="math inline">\(n \in \mathbb{Z}\)</span>, the function that maps from <span class="math inline">\(L^1(\partial \mathbf{D}) \rightarrow \mathbb{R} := f \mapsto \hat{f}(n)\)</span> is a linear functional.</p>
<p><br></p>
<h4 id="theorem-11.10-riemann-lebesgue-lemma">Theorem 11.10: Riemann-Lebesgue Lemma</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\partial \mathbf{D})\)</span>, then:</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} \hat{f}(n) = 0\]</span></p>
<p><br></p>
<h4 id="definition-11.241-periodic-function">Definition 11.24(1): Periodic Function</h4>
<p>A function <span class="math inline">\(f\)</span> is said to be periodic with period <span class="math inline">\(T\)</span> if:</p>
<p><span class="math display">\[f(x) = f(x + T)\]</span></p>
<p><br></p>
<h4 id="theorem-11.242-derivative-of-a-periodic-function">Theorem 11.24(2): Derivative of a Periodic Function</h4>
<p>The derivative of a periodic function is periodic.</p>
<p><br></p>
<h4 id="definition-11.24-tildef-k-times-continuously-differentiable-fk">Definition 11.24: <span class="math inline">\(\tilde{f}\)</span>; <span class="math inline">\(k\)</span> times continuously differentiable; <span class="math inline">\(f^{[k]}\)</span></h4>
<p>Suppose <span class="math inline">\(f: \partial \mathbf{D} \rightarrow \mathbb{C}\)</span> is a complex-valued function on <span class="math inline">\(\partial \mathbf{D}\)</span> and <span class="math inline">\(k \in \mathbb{Z}^+ \cup \{0\}\)</span>.</p>
<ul>
<li><p>Define <span class="math inline">\(\tilde{f}: \mathbb{R} \rightarrow \mathbb{C}\)</span> by <span class="math inline">\(\tilde{f}(t) = f(e^{it})\)</span> (This is similar to <span class="math inline">\(g: \mathbb{R} \rightarrow \partial \mathbf{D}\)</span>, <span class="math inline">\(g(t) = e^{it}\)</span>, <span class="math inline">\(\tilde{f} = f \circ g\)</span>).</p></li>
<li><p><span class="math inline">\(f\)</span> is called <span class="math inline">\(k\)</span> times <strong>continuously differentiable</strong> if <span class="math inline">\(\tilde{f}\)</span> is <span class="math inline">\(k\)</span> times differentiable everywhere on <span class="math inline">\(\mathbb{R}\)</span> and its <span class="math inline">\(k\)</span>th-derivative <span class="math inline">\(\tilde{f}^{(k)}: \mathbb{R} \rightarrow \mathbb{C}\)</span> is continuous.</p></li>
<li><p>If <span class="math inline">\(f\)</span> is <span class="math inline">\(k\)</span>-times continuously differentiable, then <span class="math inline">\(f^[k]: \partial \mathbf{D} \rightarrow \mathbb{C}\)</span> is defined by: <span class="math display">\[f^{[k]}(e^{it}) = \tilde{f}^{(k)}(t)\]</span></p>
<p>for <span class="math inline">\(t \in \mathbb{R}\)</span>. Here <span class="math inline">\(\tilde{f}^{(0)}\)</span> is defined to be <span class="math inline">\(\tilde{f}\)</span>, which means that <span class="math inline">\(f^{[0]} = f\)</span></p></li>
</ul>
<p><br></p>
<h4 id="theorem-11.26-fourier-coefficients-of-differentiable-functions">Theorem 11.26: Fourier Coefficients of Differentiable Functions</h4>
<p>Suppose <span class="math inline">\(k \in \mathbb{Z}^+\)</span> and <span class="math inline">\(f: \partial \mathbf{D} \rightarrow \mathbb{C}\)</span> is <span class="math inline">\(k\)</span> times continuously differentiable. Then:</p>
<p><span class="math display">\[\widehat{f^{[k]} (n)} = i^kn^k \widehat{f}(n)\]</span></p>
<p>for every <span class="math inline">\(n \in \mathbb{Z}\)</span></p>
<p><br></p>
<h4 id="theorem-11.27-fourier-series-of-twice-continuous-differentiable-functions-converge">Theorem 11.27: Fourier Series of Twice Continuous Differentiable Functions Converge</h4>
<p>Suppose <span class="math inline">\(f: \partial \mathbf{D} \rightarrow \mathbb{C}\)</span> is twice continuously differentiable. Then:</p>
<p><span class="math display">\[f(z) = \sum^\infty_{n = -\infty} \widehat{f}(n) z^n\]</span></p>
<p>for all <span class="math inline">\(z \in \partial \mathbf{D}\)</span>. Furthermore, the partial sum <span class="math inline">\(\sum^{M}_{n = -K} \widehat{f}(n) z^n\)</span> converge uniformly on <span class="math inline">\(\partial \mathbf{D}\)</span> to <span class="math inline">\(f\)</span> as <span class="math inline">\(K, M \rightarrow \infty\)</span></p>
<p><br></p>
<h3 id="fourier-series-and-lp-of-unit-circle">Fourier Series and <span class="math inline">\(L^p\)</span> of Unit Circle</h3>
<h4 id="theorem-11.30-orthonormal-basis-of-l2partial-mathbfd">Theorem 11.30: Orthonormal Basis of <span class="math inline">\(L^2(\partial \mathbf{D})\)</span></h4>
<p>The family <span class="math inline">\(\{z^n\}_{n \in \mathbb{Z}}\)</span> is an orthonormal basis of <span class="math inline">\(L^2(\partial \mathbf{D})\)</span>.</p>
<p><br></p>
<h4 id="theorem-11.31-convergence-of-fourier-series-in-the-norm-of-l2partial-mathbfd">Theorem 11.31: Convergence of Fourier Series in the Norm of <span class="math inline">\(L^2(\partial \mathbf{D})\)</span></h4>
<p>Suppose <span class="math inline">\(f \in L^2(\partial \mathbf{D})\)</span>. Then:</p>
<p><span class="math display">\[f = \sum^\infty_{n=-\infty} \widehat{f}(n)z^n\]</span></p>
<p>where the infinite sum converges to <span class="math inline">\(f\)</span> in the norm of <span class="math inline">\(L^2(\partial \mathbf{D})\)</span>.</p>
<p><br></p>
<h3 id="fourier-transform">Fourier Transform</h3>
<h4 id="definition-11.47-fourier-transform-hatf">Definition 11.47: Fourier Transform; <span class="math inline">\(\hat{f}\)</span></h4>
<p>For <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>, the <strong>Fourier transform</strong> of <span class="math inline">\(f\)</span> is the function <span class="math inline">\(\hat{f}: \mathbb{R} \rightarrow \mathbb{C}\)</span> defined by:</p>
<p><span class="math display">\[\hat{f}(t) = \int^{\infty}_{-\infty} f(x) e^{-2\pi itx} dx = \int_{\mathbb{R}} g d\lambda\]</span></p>
<p>where <span class="math inline">\(g(x) = f(x)e^{-2\pi itx}\)</span>. The <span class="math inline">\(2\pi\)</span> in <span class="math inline">\(e^{-2\pi itx}\)</span> is a normalization constant, without it, we will not have <span class="math inline">\(\|\hat{f}\|_2 = \|f\|_2\)</span>.</p>
<p><br></p>
<h4 id="theorem-11.49-riemann-lebesgue-lemma">Theorem 11.49: Riemann-Lebesgue Lemma</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>. Then <span class="math inline">\(\hat{f}\)</span> is uniformly continuous on <span class="math inline">\(\mathbb{R}\)</span>. Furthermore:</p>
<p><span class="math display">\[\|\hat{f}\|_{\infty} \leq \|f\|_1\]</span></p>
<p>and</p>
<p><span class="math display">\[\lim_{t \rightarrow \pm \infty} \hat{f}(t) = 0\]</span></p>
<p><br></p>
<h4 id="theorem-11.50-derivative-of-a-fourier-transform">Theorem 11.50: Derivative of a Fourier Transform</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>. Define <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{C}\)</span> by <span class="math inline">\(g(x) = x f(x)\)</span>. If <span class="math inline">\(g \in L^1(\mathbb{R})\)</span>, then <span class="math inline">\(\hat{f}\)</span> is a continuously differentiable function on <span class="math inline">\(\mathbb{R}\)</span> amd</p>
<p><span class="math display">\[(\hat{f})^\prime(t) = -2\pi i \hat{g}(t)\]</span></p>
<p>for all <span class="math inline">\(t \in \mathbb{R}\)</span>.</p>
<p><br></p>
<h4 id="theorem-11.54-fourier-transform-of-a-derivative">Theorem 11.54: Fourier Transform of a Derivative</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span> is a continuously differentiable function and <span class="math inline">\(f^\prime \in L^1(\mathbb{R})\)</span>. If <span class="math inline">\(t \in \mathbb{R}\)</span>, then:</p>
<p><span class="math display">\[\hat{(f^{\prime})}(t) = 2 \pi it \hat{f}(t)\]</span></p>
<p><br></p>
<h4 id="theorem-11.55-fourier-transforms-of-translations-rotations-and-dilations">Theorem 11.55: Fourier Transforms of Translations, Rotations and Dilations</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>, <span class="math inline">\(b \in \mathbb{R}, t \in \mathbb{R}\)</span>.</p>
<ol type="a">
<li>If <span class="math inline">\(g(x) = f(x - b) \; \forall x \in \mathbb{R}\)</span>, then <span class="math inline">\(\hat{g} (t) = e^{-2\pi ibt} \hat{f}(t)\)</span></li>
<li>If <span class="math inline">\(g(x) = e^{2\pi ibx} f(x) \; \forall x \in \mathbb{R}\)</span>, then <span class="math inline">\(\hat{g}(t) = \hat{f} (t - b)\)</span></li>
<li>If <span class="math inline">\(b \neq 0\)</span> and <span class="math inline">\(g(x) = f(bx)\; \forall x \in \mathbb{R}\)</span>, then <span class="math inline">\(\hat{g}(t) = \frac{1}{|b|} \hat{f}(\frac{t}{b})\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-11.59-integral-of-a-function-times-a-fourier-transform">Theorem 11.59: Integral of a function times a Fourier Transform</h4>
<p>Suppose <span class="math inline">\(f, g \in L^1(\mathbb{R})\)</span>. Then:</p>
<p><span class="math display">\[\int^\infty_{-\infty} \hat{f(t)}g(t) dt = \int^{\infty}_{-\infty} f(t) \hat{g}(t) dt\]</span></p>
<p><br></p>
<h4 id="theorem-11.76-fourier-inversion-formula">Theorem 11.76: Fourier Inversion Formula</h4>
<p>Suppose <span class="math inline">\(f, \hat{f} \in L^1 (\mathbb{R})\)</span>. Then:</p>
<p><span class="math display">\[f(x) = \int^\infty_{-\infty} \hat{f}(t) e^{2\pi ixt} dt\]</span></p>
<p>for almost every <span class="math inline">\(x \in \mathbb{R}\)</span>. In other words:</p>
<p><span class="math display">\[f(x) = \hat{(\hat{f})} (-x)\]</span></p>
<p>This theorem also implies that <span class="math inline">\(f\)</span> can be modified on a set of measure zero to become a uniformly continuous function on <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p><br></p>
<h4 id="theorem-11.80-functions-are-determined-by-their-fourier-transforms">Theorem 11.80: Functions are Determined by Their Fourier Transforms</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span> and <span class="math inline">\(\hat{f}(t) = 0\)</span> for every <span class="math inline">\(t \in \mathbb{R}\)</span>. Then <span class="math inline">\(f = 0\)</span>. In other words, the function that maps <span class="math inline">\(f \mapto \hat{f}\)</span> is one to one.</p>
<p><br></p>
<h4 id="theorem-11.82-plancherels-theorem">Theorem 11.82: Plancherel's Theorem</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R}) \cap L^2(\mathbb{R})\)</span>. Then <span class="math inline">\(\|\hat\|_2 = \|f\|_2\)</span>, which also implies that <span class="math inline">\(\hat{f} \in L^2(\mathbb{R})\)</span>.</p>
<p><br></p>
<h2 id="ref">REF</h2>
<h3 id="rkhs">RKHS</h3>
<p>https://www.math.unipd.it/~demarchi/TAA1718/RKHS_presentazione.pdf</p>
<p>https://people.eecs.berkeley.edu/~bartlett/courses/281b-sp08/7.pdf</p>
<p>https://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf</p>
<p>https://arxiv.org/pdf/2106.08443.pdf</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>PCA</title>
    <url>/2021/07/19/pca/</url>
    <content><![CDATA[<h1 id="principal-component-analysis">Principal Component Analysis</h1>
<p>Let <span class="math inline">\([\mathbf{X}_1 ... \mathbf{X}_N]\)</span> be a <span class="math inline">\(p \times N\)</span> matrix of random sample where <span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^p\)</span>. The sample mean <span class="math inline">\(\mathbf{M}\)</span> of the random sample is defined as:</p>
<p><span class="math display">\[\mathbf{M} = \frac{1}{N} \sum^{N}_{i=1} \mathbf{X}_{i}\]</span></p>
<p>Let <span class="math inline">\(\hat{\mathbf{X}}_k\)</span> be the centered random vector for <span class="math inline">\(k = 1, ...., N\)</span>:</p>
<p><span class="math display">\[\hat{\mathbf{X}}_k = \mathbf{X}_k - \mathbf{M}\]</span></p>
<p>Then we can defined the centered random sample matrix as:</p>
<p><span class="math display">\[B = [\hat{\mathbf{X}}_1 ... \hat{\mathbf{X}}_N]_{[p\times N]}\]</span></p>
<p>The sample covariance matrix <span class="math inline">\(S\)</span> is then:</p>
<p><span class="math display">\[S = [\frac{1}{N} BB^T]_{[p\times p]}\]</span></p>
<p>We can easily show that <span class="math inline">\(S\)</span> is positive semi-definite. Assume that <span class="math inline">\(\mathbf{x} &gt; 0\)</span>:</p>
<span class="math display">\[\begin{aligned}
BB^T \mathbf{x} &amp;= \lambda \mathbf{x}\\
\implies \mathbf{x}^T BB^T \mathbf{x} &amp;= \lambda \mathbf{x}^T \mathbf{x}\\
\implies \frac{\mathbf{x}^T BB^T \mathbf{x}}{\mathbf{x}^T \mathbf{x}} &amp;= \lambda
\end{aligned}\]</span>
<p>Let <span class="math inline">\(\mathbf{A} = B^T\mathbf{x}\)</span>, then:</p>
<p><span class="math display">\[\frac{\mathbf{A}^T \mathbf{A}}{\mathbf{x}^T \mathbf{x}} = \lambda\]</span></p>
<p>Since, <span class="math inline">\(\mathbf{A}^T \mathbf{A} \geq 0\)</span> for any vector <span class="math inline">\(A\)</span>, similar for <span class="math inline">\(\mathbf{x}^T \mathbf{x}\)</span>, then:</p>
<p><span class="math display">\[\lambda \geq 0\]</span></p>
<p>Since, <span class="math inline">\(S\)</span> is symmetric and <span class="math inline">\(\lambda \geq 0\)</span> for all eigenvalues of <span class="math inline">\(S\)</span>, we can conclude that <span class="math inline">\(S\)</span> is <strong>positive semi-definite</strong>.</p>
<p>The <strong>total variance</strong> in the data is:</p>
<p><span class="math display">\[tr(S)\]</span></p>
<h2 id="pca">PCA</h2>
<p><strong>The goal of PCA is to find an orthogonal <span class="math inline">\(p \times p\)</span> matrix <span class="math inline">\(P = [\mathbf{u}_1 .... \mathbf{u}_p]\)</span> that determines a change of variable, <span class="math inline">\(\mathbf{X} = P\mathbf{Y}\)</span> with the property that the features of <span class="math inline">\(\mathbf{Y}\)</span> are uncorrelated and are arranged in order of decreasing variance.</strong></p>
<p>Assume the <span class="math inline">\(\mathbf{X}\)</span> is already being centered, that is <span class="math inline">\(B = [\mathbf{X}_1 .... \mathbf{X}_N]\)</span>, then <span class="math inline">\(\mathbf{Y}\)</span> is also centered since <span class="math inline">\(P \neq 0\)</span>:</p>
<p><span class="math display">\[E[\mathbf{X}] = P\cdot E[\mathbf{Y}] = 0\]</span></p>
<p>Then the sample covariance matrix of <span class="math inline">\(\mathbf{Y}\)</span> is:</p>
<p><span class="math display">\[S_Y = \frac{1}{N-1}[P^{-1}\mathbf{X}_1 .... P^{-1}\mathbf{X}_N] [P^{-1}\mathbf{X}_1 .... P^{-1}\mathbf{X}_N]^T\]</span></p>
<p><span class="math display">\[\implies S_{\mathbf{Y}} = \frac{1}{N-1} P^{T}BB^{T}P = P^{T} S_{\mathbf{X}} P\]</span></p>
<p>So the desired orthogonal matrix is the one that makes <span class="math inline">\(\hat{Cov}[Y_i, Y_j] = 0, \; \forall i \neq j\)</span> (features are uncorrelated), which means that the we want the sample covariance matrix <span class="math inline">\(S_Y\)</span> to be diagonal.</p>
<p><br></p>
<p>Let <span class="math inline">\(D\)</span> be a diagonal matrix with eigenvalues of <span class="math inline">\(S_{\mathbf{X}}\)</span>, <span class="math inline">\(\lambda_1 ,...., \lambda_p\)</span> on the diagonal s.t <span class="math inline">\(\lambda_1 \geq \lambda_2 \geq ..... \lambda_p \geq 0\)</span>, let <span class="math inline">\(P\)</span> be an orthogonal matrix whose columns are the corresponding unit eigenvectors <span class="math inline">\(\mathbf{u}_1, ....., \mathbf{u}_p\)</span> (Symmetric matrices have property that the eigenspaces are mutually orthogonal, in the sense that eigenvectors corresponding to different eigenvalues are orthogonal). Then, we can use <span class="math inline">\(P\)</span> and <span class="math inline">\(\mathbf{X}\)</span> to represent <span class="math inline">\(Y\)</span>, and the sample covariance matrix is:</p>
<p><span class="math display">\[S_{\mathbf{X}} = PDP^T \implies P^{-1} S_{\mathbf{X}} P = D\]</span></p>
<p>Thus, <span class="math inline">\(S_{\mathbf{Y}} = D\)</span>.</p>
<p>Then, the eigenvectors <span class="math inline">\(\mathbf{u}_1, ...., \mathbf{u}_p\)</span> are called <code>Principal Components</code> of the data. The first PC is the eigenvector corresponding to the largest eigenvalue of <span class="math inline">\(S_{\mathbf{X}}\)</span>.</p>
<p>The result transformation is defiend as:</p>
<p><span class="math display">\[P^{T} \mathbf{X} = \mathbf{Y}\]</span></p>
<p><span class="math display">\[
\mathbf{Y} = 
\begin{bmatrix}
\mathbf{u}^T_1 \mathbf{X} \\
.\\
.\\
.\\
\mathbf{u}^T_p \mathbf{X}\\
\end{bmatrix}
\]</span></p>
<h2 id="total-variance">Total Variance</h2>
<p>It can be shown that the PCA transformation does not change the total variance of the data, that is the total variance of the data is the sum of eigenvalues:</p>
<p><span class="math display">\[tr(S_{\mathbf{Y}}) = tr(D)\]</span></p>
<p>This is only true when we are dealing with sample covariance matrix,</p>
<h1 id="implementation">Implementation</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca</span>(<span class="params">X, k=<span class="number">2</span></span>):</span></span><br><span class="line">    u, s, vt = np.linalg.svd(X, full_matrices=<span class="literal">False</span>)</span><br><span class="line">    xv = u * s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> xv[:, :k]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">X</span>):</span></span><br><span class="line">    n, d = X.shape</span><br><span class="line">    x_trans = X.copy()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(d):</span><br><span class="line">        <span class="comment"># normalization</span></span><br><span class="line">        x_trans[:, j] = (X[:, j] - X[:, j].mean()) / X[:, j].std()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x_trans</span><br></pre></td></tr></table></figure>
<h1 id="ref">Ref</h1>
<p>https://stats.stackexchange.com/questions/266864/why-is-the-sum-of-eigenvalues-of-a-pca-equal-to-the-original-variance-of-the-dat</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Policy Gradient (3)</title>
    <url>/2021/06/05/policy-gradient-3/</url>
    <content><![CDATA[<h1 id="policy-search-methods-reinforce">Policy Search Methods (REINFORCE)</h1>
<p>We already now that, if we have sampled from the correct distribution and have an estimate for <span class="math inline">\(Q^{\pi_{\theta}} (X, A)\)</span>, we have an unbiased sample of the policy gradient (Discounted Setting):</p>
<p><span class="math display">\[\gamma^{k} \nabla \log \pi_{\theta}(A | X) Q^{\pi_{\theta}} (X, A)\]</span></p>
<p>The remaining issue is the computation of <span class="math inline">\(Q^{\pi_{\theta}} (X, A)\)</span>. This is essentially a Policy Evaluation problem, and we may use various action-value function estimators.</p>
<h2 id="reinforce">REINFORCE</h2>
<p>A simple approach uses MC estimates to estimate <span class="math inline">\(Q^{\pi_{\theta}} (X, A)\)</span>. This would lead to what is known as the REINFORCE algorithm:</p>
<p>In the on-policy setting when agent follows <span class="math inline">\(\pi_{\theta}\)</span>:</p>
<ul>
<li>It generates the sequence <span class="math inline">\(X_1, A_1, R_1\)</span> with <span class="math inline">\(A_{t} \sim \pi_{\theta} (\cdot | X_t), X_t \sim \rho^{\pi_{\theta}}\)</span>.</li>
<li>Then <span class="math inline">\(G_{t}^{\pi_{\theta}} = \sum_{k \geq t} \gamma^{k - t} R_{k}\)</span> is an unbiased estimator of <span class="math inline">\(Q^{\pi_{\theta}} (X_t, A_t)\)</span>.</li>
<li>We replace the action-value function with the estimate.</li>
<li>The return however has high variance even though it is unbiased.</li>
<li>We can use a state dependent baseline function (usually the value function) to reduce the variance.</li>
</ul>
<p><img src='/images/RL/pg/pg_5.png' width="600"></p>
<h2 id="implementation">Implementation</h2>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Continuous Action Space</tag>
        <tag>Policy Search</tag>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Policy Gradient (2)</title>
    <url>/2021/05/30/policy-gradient-2/</url>
    <content><![CDATA[<h1 id="policy-search-methods-policy-gradient">Policy Search Methods (Policy Gradient)</h1>
<p><span style="color:red"><em>All <span class="math inline">\(\nabla\)</span> refer to <span class="math inline">\(\nabla_{\theta}\)</span> for simplicity.</em></span></p>
<p>From <a href="/2021/05/23/policy-gradient/" title="introduction">introduction</a> blog, our goal:</p>
<p><span class="math display">\[\underset{\pi_{\theta}}{\operatorname{maximize}} J_\rho(\pi_\theta) = \underset{\theta}{\operatorname{maximize}} J_\rho(\pi_\theta)\]</span></p>
<p>By taking the gradient w.r.t <span class="math inline">\(\theta\)</span>, we have:</p>
<span class="math display">\[\begin{aligned}
\nabla J_\rho(\pi_\theta) &amp;= \nabla E_{X_1 \sim \rho} [V^{\pi_\theta} (X_1)]\\
&amp;= \nabla \int_{x_1}\int_{a} [r(x_1, a) \pi_{\theta} (a | x_1) da dx_1 + \int_{x^{\prime}} P(x^{\prime} | x_1, a) \pi_{\theta}(a | x_1) V^{\pi_\theta}(x^{\prime})dx^{\prime} da dx_1]\\
&amp;= \nabla \int_{a} \int_{x_1} \int_{x^{\prime}} \pi_{\theta}(a | x_1) [r(x_1, a) + P(x^{\prime} | x_1, a) V^{\pi_\theta}(x^{\prime})]dx^{\prime} da dx_1 \\
&amp;= \int_{x_1} \int_{a} \int_{x^{\prime}} \nabla [\pi_{\theta}(a | x_1) (r(x_1, a) + P(x^{\prime} | x_1, a) V^{\pi_\theta}(x^{\prime}))]dx^{\prime} da dx_1 \\
\end{aligned}\]</span>
<p>We can swap integral and derivative as long as <span class="math inline">\(V^{\pi_{\theta}}\)</span> is a continuous function of <span class="math inline">\(\theta\)</span>, the estimator of this expectation is called <code>pathwise derivative estimator</code> or <code>stochastic backpropagation estimator</code> (more details in <a href="/2021/05/27/stochastic-graph/" title="Stochastic Graph">Stochastic Graph</a>).</p>
<p>This <span class="math inline">\(\nabla J_\rho(\pi_\theta)\)</span> is called the <strong>Policy Gradient</strong>. In ideal case, if we know the policy gradient (i.e if we know the environment dynamics <span class="math inline">\(P, R\)</span>), we can use gradient ascent to update the parameters <span class="math inline">\(\theta\)</span>.</p>
<span id="more"></span>
<p><strong>The question is, how can we approximate this gradient in reality using samples?</strong></p>
<h2 id="immediate-reward-problem-easy-case">Immediate Reward Problem (Easy Case)</h2>
<p>First, let's consider an immediate reward problem:</p>
<p><img src='/images/RL/pg/pg_1.png' width="600"></p>
<p>In this setting, our <span class="math inline">\(J_\rho(\pi_\theta)\)</span> is:</p>
<span class="math display">\[\begin{aligned}
J_\rho(\pi_\theta) &amp;= \int_{x_1} V^{\pi_\theta} \rho(x_1) dx_1 \\
&amp;= \int_{x_1} \int_{a} r(x_1, a) \pi_{\theta}(a | x_1) \rho(x_1) da dx_1 \\
\end{aligned}\]</span>
<p>The value function <span class="math inline">\(V^{\pi_\theta}\)</span> in this setting is the same as <span class="math inline">\(r^{\pi_{\theta}}\)</span>, and the action space is continuous.</p>
<p>Then, the policy gradient <span class="math inline">\(\nabla J_\rho(\pi_\theta)\)</span> can be written as:</p>
<p><span class="math display">\[\nabla J_\rho(\pi_\theta) = \int_{x_1} \int_{a} r(x_1, a) \rho(x_1) \nabla \pi_{\theta}(a | x_1) da dx_1\]</span></p>
<p><strong>How can we compute <span class="math inline">\(\nabla J_\rho(\pi_\theta)\)</span> ?</strong></p>
<p>Recall that, <span class="math inline">\(\frac{\partial log (\theta)}{ \partial \theta} = \frac{1}{\theta}\)</span>:</p>
<span class="math display">\[\begin{aligned}
\nabla J_\rho(\pi_\theta) &amp;= \int_{x_1} \int_{a} r(x_1, a) \rho(x_1) \nabla \pi_{\theta}(a | x_1) da dx_1\\
&amp;= \int_{x_1} \int_{a} r(x_1, a) \rho(x_1) \pi_{\theta}(a | x_1) \frac{\nabla \pi_{\theta}(a | x_1)}{\pi_{\theta}(a | x_1)}  da dx_1\\
&amp;= \int_{x_1} \int_{a} \rho(x_1) \pi_{\theta}(a | x_1) r(x_1, a)  \nabla log (\pi_{\theta}(a | x_1))  da dx_1\\
&amp;= E_{X_1 \sim \rho, A \sim \pi_{\theta}(\cdot | X_1)} [r(X_1, A)  \nabla log (\pi_{\theta}(A | X_1))]
\end{aligned}\]</span>
<p>Then, we can draw samples from this expectation:</p>
<p><span class="math display">\[r(X_1, A)  \nabla log (\pi_{\theta}(A | X_1))\]</span></p>
<p>These samples are called <code>REINFORCE</code> or <code>Score function</code> estimators. These samples are unbiased samples of the policy gradient <span class="math inline">\(\nabla J_\rho(\pi_\theta)\)</span>. We can use these unbiased but noisy samples to update parameters. This makes it <strong>Stochastic Gradient Ascent</strong>.</p>
<h3 id="baseline">Baseline</h3>
<p>We know that above sample is unbiased sample of the policy gradient, but, how about its variance?</p>
<p>There are two source of variance:</p>
<ol type="1">
<li>Variance that comes from sampling <span class="math inline">\(X_1 \sim \rho\)</span> and use this sample to estimate the expectation.</li>
<li>Variance that comes from sampling <span class="math inline">\(A \sim \pi_{\theta}(a | X_1)\)</span> and use this sample to estimate the expectation.</li>
</ol>
<p>Recall the total variance formula:</p>
<p><span class="math display">\[Var[Y] = E_X[Var[Y | X]] + Var_X[E[Y | X]]\]</span></p>
<p>One can show that the variance for <strong><span class="math inline">\(i\)</span>th dimension</strong> of <span class="math inline">\(\nabla J_\rho(\pi_\theta)\)</span>:</p>
<p><span class="math display">\[Var[r(X_1, A)  \frac{\partial}{\partial \theta_i} log (\pi_{\theta}(A | X_1))] = E_{X_1} [Var_{A}[r(X_1, A)  \frac{\partial}{\partial \theta_i}  log (\pi_{\theta}(A | X_1)) | X_1]] + Var_{X_1} [E_A[r(X_1, A)  \frac{\partial}{\partial \theta_i} log (\pi_{\theta}(A | X_1)) | X_1]]\]</span></p>
<p>To see this more clearly, let's define:</p>
<p><span class="math display">\[g(x; \theta) = E_{A \sim \pi_{\theta}(\cdot | x)} [r(x, A)  \nabla log (\pi_{\theta}(A | x))]\]</span></p>
<p>This function <span class="math inline">\(g: X \times \Theta \rightarrow \mathbb{R}^{p}\)</span> is the policy gradient at a particular starting state <span class="math inline">\(x\)</span>, and it is a <span class="math inline">\(p\)</span>-dimensional vector (Assuming <span class="math inline">\(\theta\)</span> is <span class="math inline">\(p\)</span>-dimensional). Then we have:</p>
<p><span class="math display">\[Var[r(X_1, A)  \frac{\partial}{\partial \theta_i} log (\pi_{\theta}(A | X_1))] = E_{X_1} [Var_{A}[r(X_1, A)  \frac{\partial}{\partial \theta_i}  log (\pi_{\theta}(A | X_1)) | X_1]] + Var_{X_1} [g_i(X_1; \theta)]\]</span></p>
<p>These two sources of variance make our estimate of the gradient inaccurate. We can reduce them using a <code>baseline</code>.</p>
<p>Consider the variance of estimating <span class="math inline">\(g(x; \theta)\)</span> using a single sample <span class="math inline">\(r(x, A) \nabla log (\pi_{\theta}(A | x))\)</span> with <span class="math inline">\(A \sim \pi_\theta(\cdot | x)\)</span>. For each dimension <span class="math inline">\(i\)</span>, we have:</p>
<span class="math display">\[\begin{aligned} 
E_{A}[ (r(x, A) -  b(x))  \frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x)) \; |\; x] &amp;= \int_a (r(x, a) - b(x)) \pi_{\theta}(a | x)  \frac{\partial}{\partial \theta_i} log (\pi_{\theta}(a | x)) da\\
&amp;= \int_a r(x, a) \frac{\partial}{\partial \theta_i} \pi_{\theta}(a | x) da  - b(x) \int_a \frac{\partial}{\partial \theta_i} \pi_{\theta}(a | x) da\\
&amp;=  \int_a r(x, a) \frac{\partial}{\partial \theta_i} \pi_{\theta}(a | x) da - b(x) \frac{\partial}{\partial \theta_i} \underbrace{\int_a \pi_{\theta}(a | x) da}_{1} \\
&amp;=  \int_a r(x, a) \frac{\partial}{\partial \theta_i} \pi_{\theta}(a | x) da - b(x) \frac{\partial}{\partial \theta_i} (1)\\
&amp;=  \int_a r(x, a) \frac{\partial}{\partial \theta_i} \pi_{\theta}(a | x) da\\
&amp;= E_{A}[ (r(x, A) -  b(x))  \frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x))\; |\; x]
\end{aligned}\]</span>
<p><br/></p>
<p>This shows that, if we add a state dependent function <span class="math inline">\(b(x)\)</span> to <span class="math inline">\(r(x, a)\)</span>, the expectation won't change. But, this may change the variance! We can formulate this idea to be an optimization problem and find a function <span class="math inline">\(b: X \rightarrow \mathbb{R}^{p}\)</span> such that for all <span class="math inline">\(x \in X\)</span> (for each <span class="math inline">\(b_i\)</span>):</p>
<p><span class="math display">\[\min_{b_i} \sum^{p}_{i=1} Var[(r(x, A) + b_i (x))  \frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x)) \; |\; x]\]</span></p>
<p>by solving this optimization problem, we have:</p>
<p><span class="math display">\[b_i (x) = \frac{-E_A[r(x, A) (\frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x)))^2 \; |\; x]}{E_A [(\frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x)))^2 | x]}\]</span></p>
<p>We can also choose single scalar function <span class="math inline">\(b: X \rightarrow \mathbb{R}\)</span> instead：</p>
<p><span class="math display">\[b (x) = \frac{-E_A[r(x, A) \|\frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x))\|^2_2 \; |\; x]}{E_A [\|\frac{\partial}{\partial \theta_i}log (\pi_{\theta}(A | x))\|^2_2 | x]}\]</span><br/></p>
<h2 id="policy-gradient-general-case">Policy Gradient (General Case)</h2>
<p>Recall that:</p>
<p><span class="math display">\[P^{\pi} (\cdot | y)= \int_{x \in X} \int_a P(x | y, a) \pi(a | y) da dx\]</span></p>
<h3 id="average-reward-setting">Average Reward Setting</h3>
<p>The difference with the immediate reward case, where we only need initial distribution <span class="math inline">\(\rho\)</span>, in average reward case, we depend on the environment transition distribution <span class="math inline">\(P^{\pi_{\theta}}\)</span> too. As we update <span class="math inline">\(\theta\)</span>, we obtain a different policy <span class="math inline">\(\pi_{\theta}\)</span>, that is, we have a different dynamics transition distribution <span class="math inline">\(P^{\pi_{\theta}}\)</span>.</p>
<p>Recall that in average reward setting, the quality of a policy is measured as the long term expected reward or average rate reward or simply average reward following <span class="math inline">\(\pi_\theta\)</span> <code>independent of starting state</code> (<strong><span class="math inline">\(x_1\)</span> in the expectation is used to emphasize that the Expected reward is <span class="math inline">\(t\)</span> step</strong>):</p>
<span class="math display">\[\begin{aligned}
J (\pi_\theta) &amp;= \lim_{n \rightarrow \infty}\frac{1}{n}E[R_1 + R_2, .... \; |\; A_{1}, A_{2}, ... \sim \pi_{\theta}, x_1]\\
&amp;= \lim_{n \rightarrow \infty}\frac{1}{n} \sum^{n}_{t=1} E[R_t \; |\; A_{1}, A_{2}, ... \sim \pi_{\theta}, x_1]\\
&amp;= \lim_{n \rightarrow \infty}\frac{1}{n} \sum^{n}_{t=1} \int_{x, a} P^{\pi_{\theta}} (X_t = x | x_1; t) \pi(a | x) R(x, a) da dx\\
&amp;= \int_{x, a} \lim_{n \rightarrow \infty}\frac{1}{n} \sum^{n}_{t=1} P^{\pi_{\theta}} (X_t = x | x_1; t) \pi(a | x) R(x, a) da dx\\
&amp;= \int_{x} \rho^{\pi_{\theta}} (x) \int_a \pi_{\theta} (a | x) R(x, a) da dx\\
\end{aligned}\]</span>
<p><br/></p>
<p>Where <span class="math inline">\(\rho^{\pi_{\theta}} (x) = \lim_{n \rightarrow \infty}\frac{1}{n} \sum^{n}_{t=1} P^{\pi_{\theta}} (X_t = x | x_1; t) = \lim_{t \rightarrow \infty} P^{\pi_{\theta}} (X_t = x | x_1; t)\)</span>.</p>
<h4 id="stationary-distribution">Stationary Distribution</h4>
<p><span class="math inline">\(\rho^{\pi_{\theta}}\)</span> above is the <code>stationary distribution</code> under <span class="math inline">\(\pi_\theta\)</span> which is assumed to exist (when the markov chain is <code>ergodic</code>) and independent of starting state (<strong><span class="math inline">\(x_1\)</span> here is used to emphasize that this is <span class="math inline">\(t\)</span> step transition probability</strong>).</p>
<p>In general, let <span class="math inline">\(\sum^{N}_{n=1}I\{X_n = j | X_0=i \}\)</span> be the number of visits to state <span class="math inline">\(j\)</span> in <span class="math inline">\(N\)</span> steps starting from <span class="math inline">\(i\)</span>. Then the expected visits to state <span class="math inline">\(j\)</span> is:</p>
<p><span class="math display">\[E[\sum^{N}_{n=1}I\{X_n = j | X_0=i\}] = \sum^{N}_{n=1} E[I\{X_n = j\} | X_0=i] = \sum^{N}_{n=1} P(X_n=j | X_0=i)\]</span><br/></p>
<p>The <code>expected proportion of visits</code> is then:</p>
<p><span class="math display">\[\frac{\sum^{N}_{n=1} P(X_n=j | X_0=i)}{N}\]</span><br/></p>
<p>The <code>stationary distribution</code> can be interpreted as the long run expected proportion of time that the chain spends for each state over the state space, so it is defined as <span class="math inline">\(\pi = (\pi_0, \pi_1, ...)\)</span> over the state space <span class="math inline">\(X\)</span>:</p>
<span class="math display">\[\begin{aligned}
\pi_j &amp;= \lim_{n \rightarrow \infty}\frac{1}{n}\sum^{n}_{m=1} E[I\{X_m=j | X_0=i\}] \;\;\;\;\;\;\;\;\; \forall \text{ initial states } i\\
&amp;= \lim_{n \rightarrow \infty} \frac{\sum^{n}_{m=1} P(X_m=j | X_0=i)}{n}\\
&amp;= \lim_{n \rightarrow \infty} P(X_m=j)
\end{aligned}\]</span>
<p><br/></p>
<p><img src='/images/RL/pg/pg_3.png'> <img src='/images/RL/pg/pg_4.png' width="700"></p>
<p>So <span class="math inline">\(\rho^{\pi_{\theta}} (\cdot)\)</span> is the special distribution in which if you select actions according to <span class="math inline">\(\pi_\theta\)</span>, you end up in the same distribution:</p>
<p><span class="math display">\[\int_{x} \rho^{\pi_{\theta}} (x) \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) dx^{\prime} da dx = \rho^{\pi_{\theta}} (x^{\prime})\]</span></p>
<p><strong>We can easily sample states from this distribution by following <span class="math inline">\(\pi_{\theta}\)</span></strong>.</p>
<h3 id="discounted-setting">Discounted Setting</h3>
<p>In discounted setting, the objective is defined as long term discounted return starting from initial state distribution <span class="math inline">\(X_1 \sim \rho\)</span> following <span class="math inline">\(\pi_{\theta}\)</span>:</p>
<p><span class="math display">\[J_{\rho} (\pi_\theta) = E_{X_1 \sim \rho} [V^{\pi_{\theta}} (X_1)]\]</span></p>
<p>Recall that <span class="math inline">\(P^{\pi_{\theta}} (\cdot | x; k) = P^{\pi_{\theta}} (\cdot | x)^k\)</span> is the <span class="math inline">\(k\)</span> step transition distribution:</p>
<p><span class="math display">\[\sum^{\infty}_{k=0} \gamma^k P^{\pi_{\theta}} (X_{k + 1}=x | x_{1}) = P^{\pi_{\theta}}(X_{1} = x | x_{1}) + \gamma P^{\pi_{\theta}}(X_{2} = x | x_{1}) + ...\]</span></p>
<p>By taking the expected value over initial state we have:</p>
<span class="math display">\[\begin{aligned}
E_{x_1} [\sum^{\infty}_{k=0} \gamma^k P^{\pi_{\theta}} (X_{k + 1}=x | x_{1})] &amp;= E_{x_1} [P^{\pi_{\theta}}(X_{1} = x | x_{1})] + \gamma E_{x_1} [P^{\pi_{\theta}}(X_{2} = x | x_{1})] \; + ...\\
&amp;= \rho(x) + \gamma \sum_{x_1} P^{\pi_{\theta}}(X_{2} = x | x_{1}) \rho(x_1) \; + ...\\
&amp;= \rho(x) + \gamma P^{\pi_{\theta}}(X_{2} = x) \; + ...\\
&amp;= Pr(X_1 = x) + \gamma Pr(X_{2} = x) \; + ... \\
\end{aligned}\]</span>
<p>This is the <strong>expected number of time steps spend in state <span class="math inline">\(x\)</span> discounted by <span class="math inline">\(\gamma^k\)</span></strong> given we start at state <span class="math inline">\(X_1 \sim \rho\)</span>.</p>
<p>Let's now define the <code>discounted future state distribution</code> (similar to stationary distribution but with discount and depend on initial state)starting from state <span class="math inline">\(x_1 \in X\)</span> following <span class="math inline">\(\pi_{\theta}\)</span>:</p>
<p><span class="math display">\[\rho^{\pi}_{\gamma} (\cdot | x_1) \triangleq (1 - \gamma) \sum^{\infty}_{k=0} \gamma^k P^{\pi_{\theta}} (\cdot | x_1; k)\]</span></p>
<p>Where , and <span class="math inline">\(1 - \gamma\)</span> is the normalization term. We can easily verify that this is a valid distribution. <strong>One interpretation of this distribution is that the agent starts at <span class="math inline">\(x_1\)</span> and at each time step <span class="math inline">\(t\)</span> terminate with probability <span class="math inline">\(1 - \gamma\)</span>. This accounts for the discounted factor inside the average counts. That is, we can sample from the state stationary distribution and terminate at each step with probability <span class="math inline">\(1 - \gamma\)</span>. Or instead, we could weight each samples by <span class="math inline">\(\gamma^k\)</span> to account for the termination.</strong></p>
<p>We can also define the <code>discounted future-state distribution</code> of starting from <span class="math inline">\(\rho\)</span> and following <span class="math inline">\(\pi\)</span> as:</p>
<p><span class="math display">\[\rho^{\pi}_{\gamma} (\cdot) = \int_{x_1} \rho^{\pi}_{\gamma} (\cdot | x_1) \rho (x_1) dx_1\]</span></p>
<p><span class="math display">\[\rho^{\pi}_{\gamma} (x) = (1 - \gamma) E_{x_1} [\sum^{\infty}_{k=0} \gamma^k P^{\pi} (X_{k + 1}=x | x_{1})] = (1 - \gamma)(Pr(X_1 = x) + \gamma Pr(X_{2} = x) \; + ...) \]</span></p>
<p><br></p>
<h3 id="expected-reward-and-discounted-return">Expected Reward and Discounted Return</h3>
<p>We can see the connection between expected reward and discounted return:</p>
<span class="math display">\[\begin{aligned}
V^{\pi} (x) &amp;= E^{\pi}[\sum^{\infty}_{t = 1} \gamma^{t - 1} R_{t} \; |\; X_1 = x]\\
&amp;= \sum^{\infty}_{t = 1} \gamma^{t - 1} E^{\pi}[R_{t} \; |\; X_1 = x]\\
&amp;= \sum^{\infty}_{t = 1} \gamma^{t - 1} \int_{x^{\prime}, a} P^{\pi}(X_t=x^{\prime} | x; t) \pi(a | x^{\prime})R(x^{\prime}, a)da dx^{\prime}\\
&amp;= \frac{1}{1 - \gamma} \int_{x^{\prime}, a} \rho^{\pi}_{\gamma} ( x^{\prime}| x) \pi(a | x^{\prime}) R(x^{\prime}, a) dadx^{\prime}\\
&amp;= \frac{1}{1 - \gamma}E_{X^{\prime} \sim \rho^{\pi}_{\gamma} (\cdot | x), A \sim \pi(\cdot | X^{\prime})} [R(X^{\prime}, A)]\\
\end{aligned}\]</span>
<p>We can interchange summation and infinity sum because the sum is finite. Here <span class="math inline">\(R(\cdot)\)</span> represents the realization of random variable <span class="math inline">\(R\)</span>. This tells us that the value function at a state <span class="math inline">\(x\)</span> is the expected reward when <span class="math inline">\(X^{\prime}\)</span> is distributed according to <span class="math inline">\(\rho^{\pi}_{\gamma} (\cdot | x)\)</span> and following <span class="math inline">\(\pi\)</span>.</p>
<h3 id="policy-gradient-theorem">Policy Gradient Theorem</h3>
<p><img src='/images/RL/pg/pg_2.png' width="600"></p>
<h4 id="proof-average-reward-setting">Proof: Average Reward Setting</h4>
<p>In average reward setting, <span class="math inline">\(d^{\pi} (x) = \rho^{\pi_{\theta}} (x),\; \; \rho = J (\pi_\theta)\)</span> and <span class="math inline">\(Q^{\pi} (x, a)\)</span> is defined as:</p>
<p><span class="math display">\[Q^{\pi} (x, a) = r(x, a) - J(\pi_\theta) +  \int_{x^{\prime}} P(x^{\prime} | x, a) V^{\pi_{\theta}} (x^{\prime}) dx^{\prime}\]</span></p>
<p>Recall that,</p>
<span class="math display">\[\begin{aligned}
\nabla V^{\pi_{\theta}} (x) &amp;= \int_{a} \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da \;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \forall x \in X\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \nabla Q^{\pi_{\theta}} (x, a) da\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \nabla (r(x, a) - J(\pi_\theta) +  \int_{x^{\prime}} P(x^{\prime} | x, a) V^{\pi_{\theta}} (x^{\prime})dx^{\prime}) da\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) (- \nabla J(\pi_\theta) +  \int_{x^{\prime}} P(x^{\prime} | x, a) \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime}) da\\
\end{aligned}\]</span>
<p><br/></p>
<p>That is:</p>
<p><span class="math display">\[\nabla J(\pi_\theta) \underbrace{\int_a \pi_{\theta}(a | x) da}_{1} =  \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime} da - \nabla V^{\pi_{\theta}} (x)\]</span> <br/></p>
<p>Weighting both sides by (taking expectation) <span class="math inline">\(\rho^{\pi_{\theta}} (x)\)</span> and remember the property of stationary distribution <span class="math inline">\(\int_{x} \rho^{\pi_{\theta}} (x) \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) dx^{\prime} da dx = \rho^{\pi_{\theta}} (x^{\prime})\)</span>:</p>
<span class="math display">\[\begin{aligned}
\underbrace{\int_{x} \rho^{\pi_{\theta}} (x) dx}_{1} \nabla J(\pi_\theta)  &amp;= \int_{x} \rho^{\pi_{\theta}} (x) \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da dx + \int_{x} \rho^{\pi_{\theta}} (x) \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime} da dx- \int_{x} \rho^{\pi_{\theta}} (x) \nabla V^{\pi_{\theta}} (x) dx \\
\nabla J(\pi_\theta)  &amp;= \int_{x} \rho^{\pi_{\theta}} (x) \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da dx + \int_{x} \rho^{\pi_{\theta}} (x) \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime} da dx- \int_{x} \rho^{\pi_{\theta}} (x) \nabla V^{\pi_{\theta}} (x) dx \\
&amp;= \int_{x} \rho^{\pi_{\theta}} (x) \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da dx + \int_{x^{\prime}}  \rho^{\pi_{\theta}} (x^{\prime}) \nabla V^{\pi_{\theta}} (x^{\prime})dx- \int_{x} \rho^{\pi_{\theta}} (x) \nabla V^{\pi_{\theta}} (x) dx \\
&amp;= \int_{x} \rho^{\pi_{\theta}} (x) \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da dx \\
\end{aligned}\]</span>
<p><br/></p>
<h4 id="proof-discounted-return-setting">Proof: Discounted Return Setting</h4>
<p>In discounted return setting, <span class="math inline">\(d^{\pi} (x) = \rho^{\pi_{\theta}} (x),\; \; \rho = J_{\rho} (\pi_\theta)\)</span>.</p>
<p>Recall that,</p>
<span class="math display">\[\begin{aligned}
\nabla V^{\pi_{\theta}} (x) &amp;= \int_{a} \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da \;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \forall x \in X\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \nabla Q^{\pi_{\theta}} (x, a) da\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \nabla (r(x, a) +  \int_{x^{\prime}} P(x^{\prime} | x, a) \gamma V^{\pi_{\theta}} (x^{\prime})dx^{\prime}) da\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) \gamma \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime} da\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_a \pi_{\theta}(a | x) \int_{x^{\prime}} P(x^{\prime} | x, a) \gamma \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime} da\\
&amp;= \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da + \int_{x^{\prime}} P^{\pi_{\theta}}(x^{\prime} | x) \gamma \nabla V^{\pi_{\theta}} (x^{\prime})dx^{\prime}\\
\end{aligned}\]</span>
<p><br/></p>
<p>Now we expand <span class="math inline">\(V^{\pi_{\theta}} (x^{\prime})\)</span> likewise, we will end up with the recursive relation:</p>
<p><span class="math display">\[\nabla V^{\pi_{\theta}} (x) = \int_{x^{\prime}} \sum^{\infty}_{k = 0}\gamma^k P^{\pi_\theta} (x^{\prime} | x; k) \int_{a^{\prime}} \nabla \pi_{\theta}(a^{\prime} | x^{\prime}) Q^{\pi_{\theta}} (x^{\prime}, a^{\prime}) da^{\prime} dx^{\prime}\]</span></p>
<p>Then, we can make this an expectation by adding normalization term:</p>
<span class="math display">\[\begin{aligned}
\nabla V^{\pi_{\theta}} (x) &amp;= \frac{1}{1 - \gamma}\int_{x^{\prime}} (1 - \gamma) \sum^{\infty}_{k = 0}\gamma^k P^{\pi_\theta} (x^{\prime} | x; k) \int_{a^{\prime}} \nabla \pi_{\theta}(a^{\prime} | x^{\prime}) Q^{\pi_{\theta}} (x^{\prime}, a^{\prime}) da^{\prime} dx^{\prime}\\
&amp;= \frac{1}{1 - \gamma} \int_{x^{\prime}} \rho^{\pi_{\theta}} (x^{\prime} | x) \int_{a^{\prime}} \nabla \pi_{\theta}(a^{\prime} | x^{\prime}) Q^{\pi_{\theta}} (x^{\prime}, a^{\prime}) da^{\prime} dx^{\prime}\\
\end{aligned}\]</span>
<p><br/></p>
<p>Then <span class="math inline">\(\nabla J_{\rho} (\pi_\theta) = E_{X \sim \rho}[\nabla V^{\pi_{\theta}} (X)]\)</span> can be expressed as:</p>
<span class="math display">\[\begin{aligned}
\nabla J_{\rho} (\pi_\theta) &amp;= \frac{1}{1 - \gamma} \int_{x_1} \int_{x^{\prime}} \rho(x_1) \rho^{\pi_{\theta}} (x^{\prime} | x_1) \int_{a^{\prime}} \nabla \pi_{\theta}(a^{\prime} | x^{\prime}) Q^{\pi_{\theta}} (x^{\prime}, a^{\prime}) da^{\prime} dx^{\prime} dx_1\\
&amp;= \frac{1}{1 - \gamma} \int_{x^{\prime}}  \rho^{\pi_{\theta}} (x^{\prime}) \int_{a^{\prime}} \nabla \pi_{\theta}(a^{\prime} | x^{\prime}) Q^{\pi_{\theta}} (x^{\prime}, a^{\prime}) da^{\prime} dx^{\prime}\\
\end{aligned}\]</span>
<p><br/></p>
<h2 id="policy-gradients-as-expectations">Policy Gradients as Expectations</h2>
<p>Recall that, the <code>score function estimator</code> :</p>
<p><span class="math display">\[\frac{\partial}{\partial \theta} E_{X \sim p(\cdot ; \theta)}[f(X)] = \int_x \frac{\frac{\partial}{\partial\theta} p(x; \theta)}{p(x; \theta)} p(x; \theta) f(x)dx = E_{X \sim p(\cdot ; \theta)}[f(X) \frac{\partial}{\partial\theta} \log p(X; \theta)]\]</span></p>
<p>Thus, the results above can be written as:</p>
<ul>
<li><p>Average Reward Setting:</p>
<span class="math display">\[\begin{aligned}
  \nabla J(\pi_\theta) &amp;= \int_{x} \rho^{\pi_{\theta}} (x) \int_{a} \nabla \pi_{\theta}(a | x) Q^{\pi_{\theta}} (x, a) da dx \\
  &amp;= E_{X \sim \rho^{\pi_{\theta}} (\cdot)} [ \int_{a} \frac{\pi_{\theta}(a | X)}{\pi_{\theta}(a | X)}\nabla \pi_{\theta}(a | X) Q^{\pi_{\theta}} (X, a) da]\\
  &amp;= E_{X \sim \rho^{\pi_{\theta}} (\cdot)} [ \int_{a} \frac{\nabla \pi_{\theta}(a | X)}{\pi_{\theta}(a | X)}\pi_{\theta}(a | X) Q^{\pi_{\theta}} (X, a) da]\\   
  &amp;= E_{X \sim \rho^{\pi_{\theta}} (\cdot)} [ \int_{a} \pi_{\theta}(a | X)  \nabla \log \pi_{\theta}(a | X) Q^{\pi_{\theta}} (X, a) da]\\
  &amp;= E_{X \sim \rho^{\pi_{\theta}} (\cdot), A \sim \pi_{\theta} (\cdot | X)} [\nabla \log \pi_{\theta}(A | X) Q^{\pi_{\theta}} (X, A)]\\
  \end{aligned}\]</span>
<p><br/></p></li>
<li><p>Discounted Return Setting:</p>
<p><span class="math display">\[\nabla J_{\rho}(\pi_\theta) \propto E_{X \sim \rho^{\pi_{\theta}} (\cdot), A \sim \pi_{\theta} (\cdot | X)} [\nabla \log \pi_{\theta}(A | X) Q^{\pi_{\theta}} (X, A)]\]</span></p></li>
</ul>
<p>Now we have nice expectation over state distribution or discounted future state distribution, we can use samples to estimate the gradient.</p>
<h2 id="sampling-from-expectations">Sampling from Expectations</h2>
<h3 id="average-reward-setting-1">Average Reward Setting</h3>
<p>In average reward setting or in episodic tasks when we have <span class="math inline">\(\gamma = 1\)</span>, sampling from the expectation is straight forward. We can directly sample trajectories following <span class="math inline">\(\pi_{\theta}\)</span>, then the states would be samples from the stationary state distribution and actions would be samples from the policy.</p>
<h3 id="discounted-return-setting">Discounted Return Setting</h3>
<p>In discounted return setting, however, sampling is a little tricky.</p>
<ol type="1">
<li>The agent starts an episode from <span class="math inline">\(X_1 \sim \rho\)</span> and follows <span class="math inline">\(\pi_\theta\)</span></li>
<li>We get a sequence of states <span class="math inline">\(X_1, ...\)</span></li>
</ol>
<p>However, these samples are from the stationary state distribution but <span style="color:red"><strong>not</strong> </span>from the discounted future state distribution. In order to sample from the correct distribution, we either:</p>
<ol type="1">
<li>Interpret <span class="math inline">\(\gamma\)</span> as termination, terminate at each time step with probability <span class="math inline">\(1 - \gamma\)</span>.</li>
<li>Add a weight <span class="math inline">\(\gamma^k\)</span> which depends on the current time step to account for the discounting.</li>
</ol>
<p>If we have sampled from the correct distribution and have an estimate for <span class="math inline">\(Q^{\pi_{\theta}} (X, A)\)</span>, we have an unbiased sample of the policy gradient:</p>
<p><span class="math display">\[\gamma^{k} \nabla \log \pi_{\theta}(A | X) Q^{\pi_{\theta}} (X, A)\]</span></p>
<p><strong>We can now use these samples in an SG scheme to improve the policy.</strong></p>
<h2 id="next-reinforece-and-a2c">Next: REINFORECE and A2C</h2>
<h1 id="reference">Reference</h1>
<p>Amir-massoud Farahmand. Introduction to Reinforcement Learning (Spring 2021) Lecture 6</p>
<p>Sham M. Kakade. On the sample complexity of reinforcement learning. 2003. https://homes.cs.washington.edu/~sham/papers/thesis/sham_thesis.pdf</p>
<p>Thomas, P.. (2014). Bias in Natural Actor-Critic Algorithms. Proceedings of the 31st International Conference on Machine Learning, in PMLR 32(1):441-448</p>
<p>Sutton, R. S., McAllester, D. A., Singh, S. P., and Man- sour, Y. (1999). Policy gradient methods for reinforce- ment learning with function approximation. In Neural Information Processing Systems 12, pages 1057–1063.</p>
<p>Sutton &amp; Barto's "Reinforcement Learning: An Introduction", 2nd edition</p>
<p>https://stats.stackexchange.com/questions/400087/how-deriving-the-formula-for-the-on-policy-distribution-in-episodic-tasks</p>
<p>MC:</p>
<p>http://wwwf.imperial.ac.uk/~ejm/M3S4/NOTES3.pdf</p>
<p>A First Look at Stochastic Processes https://www.worldscientific.com/worldscibooks/10.1142/11488</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Continuous Action Space</tag>
        <tag>Policy Search</tag>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Policy Gradient (1)</title>
    <url>/2021/05/23/policy-gradient/</url>
    <content><![CDATA[<h1 id="policy-search-methods-introduction">Policy Search Methods (Introduction)</h1>
<p>So far, we have encountered methods for computing the optimal policy based on the computation of the value function. In this case, only value function was explicitly represented. There are also methods based on explicit representation of the policy and optimizing the performance of the agent by searching in the space of policies. These methods are called <strong>policy search methods</strong>.</p>
<p>Consider a stochastic policy <span class="math inline">\(\pi_\theta: X \rightarrow M(A)\)</span> that maps state space to distribution defined over actions and parameterized by a <span class="math inline">\(\theta \in \Theta\)</span>. The set <span class="math inline">\(\Theta\)</span> is the parameter space. The space of all parameterized policies can be described as:</p>
<p><span class="math display">\[\prod_\Theta = \{\pi_\theta: X \rightarrow M(A): \theta \in \Theta\}\]</span></p>
<p>This space depends on the mapping <span class="math inline">\(\pi_\theta\)</span> and <span class="math inline">\(\Theta\)</span></p>
<p>One example how we can parameterize policy by softmax distribution. Given a function mapping <span class="math inline">\(f_{\theta}: X \times A \rightarrow \mathbb{R}\)</span>, the probability of choosing action <span class="math inline">\(a\)</span> at state <span class="math inline">\(x\)</span> is:</p>
<p><span class="math display">\[\pi_{\theta} (a | x) = \frac{exp(f_{\theta} (x, a))}{\sum_{a^{\prime}} exp(f_{\theta} (x, a^{\prime}))}\]</span></p>
<p>or a normal distribution defined by <span class="math inline">\(\mu_\theta (x), \Sigma_\theta(x)\)</span>:</p>
<p><span class="math display">\[\pi_{\theta} (\cdot | x) = N(\mu_\theta(x), \Sigma_{\theta} (x))\]</span></p>
<span id="more"></span>
<h2 id="why-parameterize-policy">Why Parameterize Policy?</h2>
<p>Explicit parameterization of policy allows us to easily choose a continuous action. For example, if the policy is normal distribution defined over actions, we can just sample actions according to this distribution. For value based methods, this can be challenging:</p>
<ul>
<li>Even if we know <span class="math inline">\(Q^{*}\)</span>, computing the greedy policy is impossible over continuous action space.</li>
<li>VI and PI requires repeated calculation of the greedy policy.</li>
</ul>
<h2 id="how-can-we-compare-policies">How Can We Compare Policies?</h2>
<p>The performance can be measured in various ways. In VFA, we have bellman residuals, bellman errors, projected bellman errors and etc (But the ideas are all based on maximizing the expected return). In policy gradient methods, we also maximize the expected return following <span class="math inline">\(\pi_\theta\)</span>, at the same time, we incorporate the variance or some other risk measures.</p>
<p><strong>Our goal is to find a policy that maximize this performance measure within the space of <span class="math inline">\(\prod_\Theta\)</span>.</strong></p>
<h3 id="reasonable-choice-of-performance-measure">Reasonable Choice of Performance Measure</h3>
<p>Assume that we only care about the performance at state <span class="math inline">\(x \in X\)</span> (We only care about one state). Then the goal of policy search:</p>
<p><span class="math display">\[argmax_{\pi \in \prod_{\Theta}} V^{\pi} (x) = argmax_{\theta \in \Theta} V^{\pi_{\theta}} (x)\]</span></p>
<p>In this case, we are interested only in state <span class="math inline">\(x\)</span>, its performance, measured according to its expected return, is maximized. We may want to find a policy that is only good at our starting state <span class="math inline">\(x\)</span> and ignore the performance at other states. The obtained policy is going to be initial-state-dependent. If we change <span class="math inline">\(x\)</span> to another state <span class="math inline">\(x^{\prime} \neq x\)</span>, we get a different optimal policy (according to this performance measure).</p>
<p>Recall that, the optimal value function <span class="math inline">\(V^{*}\)</span> is optimal at every state. The optimal policy <span class="math inline">\(\pi^{*}\)</span> not only maximizes the value function at this particular state <span class="math inline">\(x\)</span>, but also at any other <span class="math inline">\(x^{\prime} \in X\)</span>. So, Instead of this extreme case of considering only the initial state <span class="math inline">\(x\)</span>, we can consider when the initial state is distributed according to some distribution <span class="math inline">\(\rho \sim M(X)\)</span> (This formulation is emphasized in the <a href="/2021/05/03/MDP/" title="MDP">MDP</a> blog, where trajectory starts by sampling from this initial distribution).</p>
<p>The <strong>performance measure</strong> would be the average of following <span class="math inline">\(\pi_\theta\)</span> over initial state distribution <span class="math inline">\(X_1 \sim \rho\)</span>:</p>
<p><span class="math display">\[J(\pi_\theta) = J_\rho(\pi_\theta) \triangleq \int_{x_1} V^{\pi_{\theta}} (x_1) d\rho(x_1) = E_{X_1 \sim \rho}[V^{\pi_{\theta}}(X_1)]\]</span></p>
<p>In this case:</p>
<ul>
<li>The optimal policy maximizes <span class="math inline">\(J_\rho\)</span></li>
<li><span class="math inline">\(J_\rho (\pi^*) \leq J_\rho (\pi^\theta)\)</span> for any <span class="math inline">\(\pi_{\theta} \in \prod_{\Theta}\)</span></li>
<li>If <span class="math inline">\(\pi^{*} \notin \prod_{\Theta}\)</span>, then <span class="math inline">\(J_\rho (\pi^*) &gt; J_\rho (\pi^\theta)\)</span> for any <span class="math inline">\(\pi_{\theta} \in \prod_{\Theta}\)</span></li>
</ul>
<h2 id="goal">Goal</h2>
<p>So, in policy search methods, we aim to find the policy that maximizes the performance measure within <span class="math inline">\(\prod_{\Theta}\)</span>:</p>
<p><span class="math display">\[\bar{\pi} = argmax_{\pi_{\theta} \in \prod_{\Theta}} J_{\rho} (\pi_{\theta})\]</span></p>
<ul>
<li>The maximizer is denoted as <span class="math inline">\(\bar{\pi}\)</span> because the optimal policy <span class="math inline">\(\pi^{*}\)</span> may not lie in the space of <span class="math inline">\(\prod_{\Theta}\)</span></li>
<li>For different <span class="math inline">\(\rho\)</span>, we may get different maximizes. However, if <span class="math inline">\(\pi^{*} \in \prod_{\Theta}\)</span>, <span class="math inline">\(\rho\)</span> does not matter.</li>
<li>To emphasis the dependence of <span class="math inline">\(\bar{\pi}\)</span> on <span class="math inline">\(\rho\)</span>, <span class="math inline">\(\bar{\pi}_{\rho}\)</span> may be used.</li>
<li>Sometimes, <span class="math inline">\(J(\pi(\theta))\)</span> or <span class="math inline">\(J_{\rho}(\pi_{\theta})\)</span> is denoted as <span class="math inline">\(J_{\rho} (\theta)\)</span> for simplification.</li>
</ul>
<h2 id="next-how-can-we-solve-for-barpi_rho">Next: How can we solve for <span class="math inline">\(\bar{\pi}_{\rho}\)</span>?</h2>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Continuous Action Space</tag>
        <tag>Policy Search</tag>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Prioritized Experience Replay</title>
    <url>/2021/05/20/prior-exp-replay/</url>
    <content><![CDATA[<h1 id="prioritized-experience-replay">Prioritized Experience Replay</h1>
<h2 id="introduction">Introduction</h2>
<p>In simplest form, RL agents observe a stream of experience and discard incoming data immediately, after a single update. Two issues with this are:</p>
<ol type="1">
<li>Strongly correlated updates that break the i.i.d assumptions of most stochastic-gradient-based algorithms</li>
<li>The rapid forgetting of possibly rare experiences that would be useful later on (ie. some rare actions, rare states etc)</li>
</ol>
<p>Experience replay addresses both of these issues. In general, it can reduce the amount of experience required to learn, and replace it with more computation and more memory.</p>
<p>However, RL gant can learn more effectively from some transitions than from others. Transitions may be more or less surprising, redundant, or task-relevant. Some transitions may not be immediately useful to the agent but might become so when the agent competence increases. Prioritized replay memory liberates agents from considering transitions uniformly. In particular, the authers propose to more frequently reply transitions with high <strong>expected learning progress</strong>, as measured by the magnitude of their TD error (on expectation, it is the <strong>BR</strong>). The bias will be corrected with importance sampling, loss of diversity will be alleviated with stochastic optimization.</p>
<p>Using a replay memory leads to design choices at two levels: which experiences to store, and which experiences to replay (and how to do so). This paper addresses only the latter: <code>making the most effective use of the replay memory for learning</code>.</p>
<span id="more"></span>
<h2 id="prioritized-replay">Prioritized Replay</h2>
<h3 id="prioritizing-with-td-error">Prioritizing with TD Error</h3>
<p>The central component of prioritized replay is the criterion by which the importance of each transition is measured. One idealised criterion would be the amount the RL agent can learn from a transition in its current state (expected learning progress). While this measure is not directly accessible, a reasonable proxy is the magnitude of a transition's TD error <span class="math inline">\(\delta\)</span> (remember the <span class="math inline">\(E[\delta] = BR\)</span>, so <span class="math inline">\(\delta\)</span> is an unbiased estimate of BR). Which indicates how 'surprising' or unexpected the transition is, in order words, how far the value is from its next-step bootstrap estimate (i.e <span class="math inline">\(\hat{T} V\)</span>). However, TD-error can have high variance in some circumstances. Some possible alternatives for TD error:</p>
<ol type="1">
<li></li>
<li></li>
<li></li>
</ol>
<h3 id="greedy-td-error-prioritization">Greedy TD Error Prioritization</h3>
<p>This algorithm stores the last encountered TD error along with each transition in the replay memory. The transition with the largest absolute TD error is replayed from the meomory. A Q-learning update is applied to this transition, which updates the weights in proportion to the TD error. New trains arrive without a known TD-error, so they put them at maximal priority in order to guarantee that all experience is seen at least once.</p>
<p>Some issues:</p>
<ol type="1">
<li>TD errors are only updated for the transitions that are replayed or sampled from the memory. (to avoid expensive sweeps over the entire replay memory)</li>
<li>The transitions that have a low TD error on first visit may not be replayed for a long time or never because they will have low priority.</li>
<li>It is sensitive to noise spikes, which can be exacerbated by bootstrapping (a large update to <span class="math inline">\(Q(s, a)\)</span> may result in large updates in some other preceding states). When approximate error (<span class="math inline">\(\|Q^{\pi} - Q\|\)</span>) appear as another source of noise.</li>
<li>Errors shrink slowly because the initally high error transitions get replayed frequently. This lack of diversity that makes the system prone to over-fitting to specific training transitions.</li>
</ol>
<h3 id="stochastic-prioritization">Stochastic Prioritization</h3>
<p>To overcome these drawbacks, a stochastic sampling method that interpolates between pure greedy prioritization and uniform random sampling is introduced by the authors. like epsilon greedy policy, this method ensures that the probability of being sampled is monotonic in a transition's priority, while guaranteeing a non-zero probability even for the lowest-priority transition. The probability of sampling transition <span class="math inline">\(i\)</span> is defined as:</p>
<p><span class="math display">\[P(i) = \frac{p^{\alpha}_i}{\sum_{k} p^{\alpha}_k}\]</span></p>
<p>where <span class="math inline">\(p_i &gt; 0\)</span> is the priority of transition <span class="math inline">\(i\)</span>. The exponent <span class="math inline">\(\alpha\)</span> determines how much prioritization is used, which <span class="math inline">\(\alpha = 0\)</span> corresponding to the uniform case.</p>
<p>There are several choice of priority measure <span class="math inline">\(p_i\)</span>:</p>
<ol type="1">
<li>absolute TD error: <span class="math inline">\(p_i = | \delta_i | + \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is a small positive constant that prevents the edge-case of transitions not being revisited once their error is 0.</li>
<li>rank based: <span class="math inline">\(p_i = \frac{1}{rank(i)}\)</span>, where <span class="math inline">\(rank(i)\)</span> is the rank of transition <span class="math inline">\(i\)</span> when the replay memory is sorted according to <span class="math inline">\(|\delta_i|\)</span>. In this case, <span class="math inline">\(P\)</span> becomes a power law distribution with exponent <span class="math inline">\(\alpha\)</span>.</li>
</ol>
<p>Both distributions are monotonic in <span class="math inline">\(|\delta_i|\)</span>, but the latter is likely to be more robust because it is not sensitive to outliers.</p>
<h3 id="implementation">Implementation</h3>
<p>To efficiently sample from the distribution, the complexity cannot depend on <span class="math inline">\(N\)</span>. For a rank-based variant, we can approximate the cumulative density function with a piecewise linear function with <span class="math inline">\(k\)</span> segments of equal probability. The segment boundaries can be precomputed. At runtime, we can sample a segment and then sample uniformly among the transitions within it. This works particularly well with mini-batch based learning algorithm. Choose <span class="math inline">\(k\)</span> to be the size of the mini-batch the sample one transition from each segment (stratified sampling). The proportional variant is different, it is based on sum-tree data structure which can be efficiently updated and sampled from.</p>
<p><img src="/images/RL/papers/prm_1.png"></p>
<h2 id="importance-sampling-to-correct-bias">Importance Sampling to Correct Bias</h2>
<p>The estimation of the expected value with stochastic updates relies on those updates corresponding to the same distribution as its expectation <strong>(I think they are talking about the DQN loss, <span class="math inline">\(E[\| \hat{T}Q_{k} - Q\|]\)</span>, where transitions are sampled from the replay memory, since the priority of transitions changes, the underlying distribution changes, in order to fix this, we need to remove some effect of the priority on the shift of distribution)</strong>. Prioritized replay introduces bias because it changes this distribution in an uncontrolled fashion, and therefore changes the solution that the estimates will converge to (even if the policy and state distribution are fixed). We can correct this bias by using importance-sampling (IS) weights:</p>
<p><span class="math display">\[w_i = \frac{1}{N} \frac{1}{P(i)}\]</span></p>
<p>Thus, if we have large <span class="math inline">\(P(i)\)</span>, we should make it smaller, so the distribution is uniform.</p>
<p>These weights can be folded into the Q-learning update by using <span class="math inline">\(w_i \delta_i\)</span> instead of <span class="math inline">\(\delta\)</span>, for stability, they also normalize weights by <span class="math inline">\(\frac{1}{max_i w_i}\)</span></p>
<h1 id="ref">Ref</h1>
<p>https://danieltakeshi.github.io/2019/07/14/per/#:~:text=Prioritized%20replay%20introduces%20bias%20because,%2Dsampling%20(IS)%20weights.</p>
]]></content>
      <categories>
        <category>RL</category>
      </categories>
      <tags>
        <tag>Replay Memory</tag>
      </tags>
  </entry>
  <entry>
    <title>probability (2)</title>
    <url>/2021/05/11/probability-2/</url>
    <content><![CDATA[<h1 id="probability-background-2">Probability Background (2)</h1>
<h2 id="distribution-of-two-random-variables">Distribution of Two Random Variables</h2>
<p>Intuitive Example:</p>
<blockquote>
<p>Let our experiment be flipping a coin 3 times. Then our sample space <span class="math inline">\(\Omega = \{HHH, THH, TTH, TTT, THT, HTH, HTT, HHT\}\)</span>. Let <span class="math inline">\(X_1\)</span> be the number of head on the first two tosses and <span class="math inline">\(X_2\)</span> be the number of heads on all three tosses. Then, our interest can be represented by the pair of random variables <span class="math inline">\((X_1, X_2)\)</span>, for example <span class="math inline">\((X_1 (HTH), X_2(HTH)) = (1, 2)\)</span>. Continuing this way, <span class="math inline">\(X_1, X_2\)</span> are real-valued functions defined on the sample space <span class="math inline">\(\Omega\)</span>, which take the outcome and map from sample space to ordered number pairs: <span class="math display">\[\mathbb{D} = \{(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3)\}\]</span></p>
<p>One the other hand, we can regard this ordered pair of functions as a vector function <span class="math inline">\(f: \Omega \rightarrow \mathbb{D} \subset \mathbb{R}^2\)</span> defined by <span class="math inline">\(f(x) = &lt;X_1(x), \; X_2(x)&gt;, \quad x \in \Omega\)</span>.</p>
</blockquote>
<p><img src="/images/RL/background/prob_33.png" width="600"></p>
<p>We often denote random vectors using vector notations <span class="math inline">\(\mathbf{X} = (X_1, X_2)^{\prime}\)</span> as a column vector.</p>
<p>Let <span class="math inline">\(\mathbb{D}\)</span> be the range space of <span class="math inline">\((X_1, X_2)\)</span>. Let <span class="math inline">\(A\)</span> be a subset of <span class="math inline">\(\mathbb{D}\)</span>. We can uniquely define the distribution of this random vector <span class="math inline">\(P_{X_1, X_2}\)</span> in terms of the <code>CDF</code>:</p>
<p><span class="math display">\[F_{X_1, X_2} (x_1, x_2) = P_{X_1, X_2}((X_1 \leq x_1) \cap (X_2 \leq x_2)) = P_{X_1, X_2}(X_1 \leq x_1, \; X_2 \leq x_2)\]</span></p>
<p>For all <span class="math inline">\((x_1, x_2) \in \mathbb{R}^2\)</span>. At the same time:</p>
<p><span class="math display">\[P_{X_1, X_2}(a_1 &lt; X_1 \leq b_1, \; a_2 &lt; X_2 \leq b_2) = F_{X_1, X_2} (b_1, b_2) -  F_{X_1, X_2} (a_1, b_2) -  F_{X_1, X_2} (b_1, a_2) +  F_{X_1, X_2} (a_1, a_2)\]</span></p>
<p>Hence, all induced probabilities can be formulated in terms of the cdf. We often call this cdf the <code>joint cumulative distribution</code>.</p>
<span id="more"></span>
<p><br></p>
<h3 id="discrete-random-vector">Discrete Random Vector</h3>
<p>A random vector <span class="math inline">\((X_1, X_2)\)</span> is <code>discrete random vector</code> if its range space <span class="math inline">\(\mathbb{D}\)</span> is finite or countable. Hence, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are <strong>both discrete</strong>. The <code>joint probability mass function</code> of <span class="math inline">\((X_1, X_2)\)</span> <span class="math inline">\(p_{X_1, X_2}\)</span> is defined by:</p>
<p><span class="math display">\[p_{X_1, X_2} (x_1, x_2) = P(\{c_1: X_1 (c_1) = x_1\} \cap \{c_2: X_2 (c_2) = x_2\}) = P(X_1 = x_1, X_2 = x_2)\]</span></p>
<p>for all <span class="math inline">\((x_1, x_2) \in \mathbb{D}\)</span>. The pmf uniquely defines the cdf, it also is characterized by the two properties:</p>
<p><span class="math display">\[0 \leq p_{X_1, X_2} (x_1, x_2) \leq 1, \quad \quad \underset{D}{\sum \sum} p_{X_1, X_2} (x_1, x_2) = 1\]</span></p>
<p>For an event <span class="math inline">\(B \subset \mathbb{D}\)</span>, we have:</p>
<p><span class="math display">\[P_{X_1, X_2} (B) = P((X_1, X_2) \in B) = \underset{B}{\sum \sum} p_{x_1, X_2} (x_1, x_2)\]</span></p>
<p>The <code>support</code> of a discrete random vector <span class="math inline">\((X_1, X_2)\)</span> is defined as all points <span class="math inline">\((x_1, x_2)\)</span> in the range space of <span class="math inline">\((X_1, X_2)\)</span> such that <span class="math inline">\(p_{X_1, X_2} (x_1, x_2) &gt; 0\)</span>.</p>
<p><br></p>
<h3 id="continuous-random-vector">Continuous Random Vector</h3>
<p>We say a random vector <span class="math inline">\((X_1, X_2)\)</span> with range space <span class="math inline">\(\mathbb{D}\)</span> is of the <code>continuous</code> type if its cdf <span class="math inline">\(F_{X_1, X_2} (x_1, x_2)\)</span> is continuous:</p>
<p><span class="math display">\[F_{X_1, X_2} (x_1, x_2) = \int^{x_1}_{-\infty} \int^{x_2}_{-\infty} f_{X_1, X_2} (w_1, w_2) dw_1 dw_2\]</span></p>
<p>For all <span class="math inline">\((x_1, x_2) \in \mathbb{R}^2\)</span>. We call <span class="math inline">\(f_{X_1, X_2}\)</span> the <code>joint probability density function</code> of <span class="math inline">\((X_1, X_2)\)</span>. Then:</p>
<p><span class="math display">\[\frac{\partial^2 F_{X_1, X_2} (x_1, x_2)}{\partial x_1 \partial x_2} = f_{X_1, X_2} (x_1, x_2)\]</span></p>
<p>The pdf is essentially characterized by the two properties:</p>
<p><span class="math display">\[0 \leq f_{X_1, X_2} (x_1, x_2), \quad \quad \int^{\infty}_{-\infty} \int^{\infty}_{-\infty}  f_{X_1, X_2} (x_1, x_2) dx_1dx_2= 1\]</span></p>
<p>Then, the probability distribution <span class="math inline">\(P_{X_1, X_2}\)</span> is defined as:</p>
<p><span class="math display">\[P_{X_1, X_2} (A) = P((X_1, X_2) \in A) = \underset{A}{\int \int} f_{X_1, X_2} (x_1, x_2) dx_1dx_2\]</span></p>
<p>Note that <span class="math inline">\(P((X_1, X_2) \in A)\)</span> is just the volumn under the surface (graph) <span class="math inline">\(z = f_{X_1, X_2} (x_1, x_2)\)</span> over the set <span class="math inline">\(A\)</span> (uncountable).</p>
<p>For continuous random vector the <code>support</code> of <span class="math inline">\((X_1, X_2)\)</span> contains all points <span class="math inline">\((x_1, x_2)\)</span> for which <span class="math inline">\(f(x_1, x_2) &gt; 0\)</span></p>
<h3 id="marginal-distributions">Marginal Distributions</h3>
<p>Let <span class="math inline">\((X_1, X_2)\)</span> be a random vector, we can obtain their individual distributions in terms of the joint distribution.</p>
<p>Consider events which defined the cdf of <span class="math inline">\(X_1\)</span> at <span class="math inline">\(x_1\)</span> is <span class="math inline">\(\{X_1 \leq x_1\}\)</span>, in scenario of random vector, this is the same as no limitation on <span class="math inline">\(X_2\)</span>:</p>
<p><span class="math display">\[\{X_1 \leq x_1\} \cap \{-\infty &lt; X_2 &lt; \infty\}\]</span></p>
<p>Taking the joint probability:</p>
<p><span class="math display">\[P(\{X_1 \leq x_1\} \cap \{-\infty &lt; X_2 &lt; \infty\}) = F_{X_1} (x_1) = \lim_{x_2 \rightarrow \infty} F_{X_1, X_2} (x_1, x_2)\]</span></p>
<p>For all <span class="math inline">\(x_1 \in \mathbb{R}\)</span>.</p>
<h4 id="marginal-pmf">Marginal PMF</h4>
<p>Now, we have the relationship between the cdfs. Let <span class="math inline">\(\mathbb{D}_1\)</span> be the support of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(w_1 \in \mathbb{D}_1\)</span>, let <span class="math inline">\(\mathbb{D}_2\)</span> be the support of <span class="math inline">\(X_2\)</span> and <span class="math inline">\(x_2 \in \mathbb{D}_2\)</span>, we can extend pmf:</p>
<p><span class="math display">\[P(\{X_1 \leq x_1\} \cap \{-\infty &lt; X_2 &lt; \infty\}) = \sum_{w_1 \leq x_1} \sum_{x_2 \in \mathbb{D}_2} p_{X_1, X_2} (w_1, x_2)\]</span></p>
<p>Then, by <strong>the uniqueness of cdfs</strong>, the quantity <span class="math inline">\(\sum_{x_2 \in \mathbb{D}_2} p_{X_1, X_2} (w_1, x_2)\)</span> is the pmf of <span class="math inline">\(X_1\)</span> evaluated at <span class="math inline">\(w_1\)</span>:</p>
<p><span class="math display">\[p_{X_1}(x_1) = \sum_{x_2 \in \mathbb{D}_2} p_{X_1, X_2} (x_1, x_2)\]</span></p>
<p>For all <span class="math inline">\(x_1 \in \mathbb{D}_{1}\)</span>.</p>
<p>That is, to find <span class="math inline">\(p_{X_1}(x_1)\)</span> we can fix <span class="math inline">\(x_1\)</span> and sum <span class="math inline">\(p_{X_1, X_2}\)</span> over all the values of <span class="math inline">\(x_2\)</span>. Same is for <span class="math inline">\(X_2\)</span>. These individual pmfs are called the <code>marginal pmfs</code>.</p>
<h4 id="marginal-pdf">Marginal PDF</h4>
<p>For continuous <code>case</code>:</p>
<p><span class="math display">\[P(\{X_1 \leq x_1\} \cap \{-\infty &lt; X_2 &lt; \infty\}) = \int^{x_1}_{-\infty} \int^{\infty}_{-\infty} f_{X_1, X_2} (w_1, x_2) dx_2 dw_1\]</span></p>
<p>Then, by <strong>the uniqueness of cdfs</strong>, the quantity in braces must be the pdf of <span class="math inline">\(X_1\)</span>, evaluated at <span class="math inline">\(w_1\)</span>:</p>
<p><span class="math display">\[f_{X_1} (x_1) = \int^{\infty}_{-\infty} f_{X_1, X_2} (x_1, x_2) dx_2\]</span></p>
<p>That is, in the continuous case the <code>marginal pdf</code> of <span class="math inline">\(X_1\)</span> is found by integrating out <span class="math inline">\(x_2\)</span>. Same is for <span class="math inline">\(X_2\)</span></p>
<h3 id="expectation">Expectation</h3>
<p>Let <span class="math inline">\((X_1, X_2)\)</span> be continuous random vector, let <span class="math inline">\(Y = g(X_1, X_2)\)</span> where <span class="math inline">\(g: \mathbb{R}^2 \rightarrow \mathbb{R}\)</span>. Then the expectation of <span class="math inline">\(Y\)</span>, <span class="math inline">\(E[Y]\)</span> exists if:</p>
<p><span class="math display">\[\int^{\infty}_{-\infty}\int^{\infty}_{-\infty} |g(x_1, x_2)| f_{X_1, X_2} (x_1, x_2) dx_1 dx_2 &lt; \infty\]</span></p>
<p>Then,</p>
<p><span class="math display">\[E[Y] = \int^{\infty}_{-\infty}\int^{\infty}_{-\infty} g(x_1, x_2) f_{X_1, X_2} (x_1, x_2) dx_1 dx_2\]</span></p>
<p>Likewise, if <span class="math inline">\((X_1, X_2)\)</span> is discrete, then:</p>
<p><span class="math display">\[E[Y] = \sum_{x_1} \sum_{x_2} g(x_1, x_2) p_{X_1, X_2} (x_1, x_2)\]</span></p>
<p><br></p>
<p><img src="/images/RL/background/prob_34.png" width="600"></p>
<p><br></p>
<p>The expectation of function of individual random variable <span class="math inline">\(X_1\)</span> can be found in two ways:</p>
<p><span class="math display">\[E[g(X_1)] = \int^{\infty}_{-\infty}\int^{\infty}_{-\infty} g(x_1) f_{X_1, X_2} (x_1, x_2) dx_1 dx_2 = \int^{\infty}_{-\infty} g(x_1) f_{X_1} (x_1) dx_1\]</span></p>
<p><br></p>
<p><img src="/images/RL/background/prob_35.png" width="600"></p>
<p><br></p>
<p>If <code>moment generating function</code> exists, then it uniquely determines the distribution of random vector <span class="math inline">\(\mathbf{X}\)</span>. Let <span class="math inline">\(\mathbf{t} = (t_1, t_2)^{\prime}\)</span>, then the moment generating function can be rewritten as:</p>
<p><span class="math display">\[M_{X_1, X_2} (\mathbf{t}) = E[e^{\mathbf{t^{\prime}} \mathbf{X}}]\]</span></p>
<p>With <span class="math inline">\(t_2 = 0\)</span> or <span class="math inline">\(t_1 = 0\)</span>, we recover the MGFs for individual random variables.</p>
<p><br></p>
<p><img src="/images/RL/background/prob_36.png" width="600"></p>
<p>This is saying that, the expectation of a random vector is a vector function of expectation.</p>
<h3 id="transformation-bivariate-random-variables">Transformation: Bivariate Random Variables</h3>
<p>Let <span class="math inline">\(X_1, X_2\)</span> denote random variables of the discrete type, which have the joint pmf <span class="math inline">\(p_{X_1, X_2} (x_1, x_2)\)</span> that is positive on the support set <span class="math inline">\(S\)</span>. Let <span class="math inline">\(y_1 = u_1(x_1, x_2)\)</span> and <span class="math inline">\(y_2 = u_2(x_1, x_2)\)</span> define a one-to-one transformation that maps <span class="math inline">\(S\)</span> onto <span class="math inline">\(T\)</span>. The joint pmf of the two new random variables <span class="math inline">\(Y_1 = u_1 (X_1, X_2)\)</span> and <span class="math inline">\(Y_2 = u_2(X_1, X_2)\)</span> is given by:</p>
<p><span class="math display">\[
p_{Y_1, Y_2}(y_1, y_2)=
\begin{cases}
p_{X_1, X_2} (w_1(y_1, y_2), w_2 (y_1, y_2)), \quad &amp;(y_1, y_2) \in T\\
0, \quad &amp;o.w
\end{cases}
\]</span></p>
<p>Where <span class="math inline">\(w_1(y_1, y_2) = x_1\)</span>, <span class="math inline">\(w_2(y_1, y_2) = x_2\)</span> is the single-valued inverse of <span class="math inline">\(y_1 = u_1(x_1, x_2)\)</span> and <span class="math inline">\(y_2 = u_2 (x_1, x_2)\)</span> (form function of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> using <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span>).</p>
<h3 id="conditional-distributions-and-expectations">Conditional Distributions and Expectations</h3>
<h4 id="discrete-conditional-pmf">Discrete Conditional PMF</h4>
<p>Let <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> denote random variables of the discrete type, which have the joint pmf defined to be <span class="math inline">\(p_{X_1, X_2} (x_1, x_2)\)</span> that is positive on the support set <span class="math inline">\(S\)</span> and is zero elsewhere. Let <span class="math inline">\(p_{X_1} (x_1)\)</span> and <span class="math inline">\(p_{X_2} (x_2)\)</span> denote, respectively the marginal probability mass function of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. Let <span class="math inline">\(x_1\)</span> be a point in the support of <span class="math inline">\(X_1\)</span>, then <span class="math inline">\(p_{X_1} (x_1) &gt; 0\)</span>. We have:</p>
<p><span class="math display">\[P(X_2 = x_2 | X_1 = x_1) = \frac{P(X_1=x, X_2=x_2)}{P(X_1 = x_1)} = \frac{p_{X_1, X_2}(x_1, x_2)}{p_{X_1}(x_1)}\]</span></p>
<p>For all <span class="math inline">\(x_2\)</span> in the support of <span class="math inline">\(S_{X_2}\)</span>. Then we define this function as:</p>
<p><span class="math display">\[p_{X_2 | X_1} (x_2 | x_1) = \frac{p_{X_1, X_2}(x_1, x_2)}{p_{X_1}(x_1)}, \quad x_2 \in S_{X_2}\]</span></p>
<p>For any fixed <span class="math inline">\(x_1\)</span> with <span class="math inline">\(p_{X_1} (x_1) &gt; 0\)</span>, this function has the conditions of being a pmf of the discrete type becuase:</p>
<ol type="1">
<li><p><span class="math inline">\(p_{X_2 | X_1} (x_2 | x_1)\)</span> is non-negative: <span class="math display">\[p_{X_1} (x_1) &gt; 0, \quad p_{X_1, X_2} (x_1, x_2) &gt; 0, \; \forall (x_1, x_2) \in (S_{X_1} \times S_{X_2})\]</span></p></li>
<li><p><span class="math inline">\(\sum_{x_2} p_{X_2 | X_1} (x_2 | x_1) = \sum_{x_2} \frac{p_{X_1, X_2}(x_1, x_2)}{p_{X_1}(x_1)} = \frac{\sum_{x_2}p_{X_1, X_2}(x_1, x_2)}{p_{X_1}(x_1)} = 1\)</span></p></li>
</ol>
<p>We call <span class="math inline">\(p_{X_2 | X_1} (x_2 | x_1)\)</span> the <code>conditional pmf</code> of discrete type of random variable <span class="math inline">\(X_2\)</span> given the discrete type of random variable <span class="math inline">\(X_1 = x_1\)</span>. Similar formula can be derived for conditional pmf of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2 = x_2\)</span>.</p>
<p><br></p>
<h4 id="continuous-conditional-pmf">Continuous Conditional PMF</h4>
<p>Now, let <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> be random variables of continuous type and have the joint pdf defined as <span class="math inline">\(f_{X_1, X_2} (x_1, x_2)\)</span> and the marginal pdf defined as <span class="math inline">\(f_{X_1}(x_1)\)</span> and <span class="math inline">\(f_{X_2} (x_2)\)</span>. When <span class="math inline">\(f_{X_1}(x_1) &gt; 0\)</span>, we defined the function <span class="math inline">\(f_{X_1, X_2}\)</span> as:</p>
<p><span class="math display">\[f_{X_2 | X_1} (x_2 | x_1) = \frac{f_{X_1, X_2}(x_1, x_2)}{f_{X_1}(x_1)}\]</span></p>
<p>Then, this function has the conditions of being a pdf of the continuous type becuase:</p>
<ol type="1">
<li><p><span class="math inline">\(f_{X_2 | X_1} (x_2 | x_1)\)</span> is non-negative: <span class="math display">\[f_{X_1} (x_1) &gt; 0, \quad f_{X_1, X_2} (x_1, x_2) &gt; 0, \; \forall (x_1, x_2) \in (S_{X_1} \times S_{X_2})\]</span></p></li>
<li><p><span class="math inline">\(\int^{\infty}_{-\infty} f_{X_2 | X_1} (x_2 | x_1) dx_2 = \int^{\infty}_{-\infty} \frac{p_{X_1, X_2}(x_1, x_2)}{p_{X_1}(x_1)} dx_2 = \frac{\int^{\infty}_{-\infty} f_{X_1, X_2}(x_1, x_2) dx_2}{f_{X_1}(x_1)} = 1\)</span></p></li>
</ol>
<p>That is, this function is called <code>conditional pdf</code> of the continuous type of random variable <span class="math inline">\(X_2\)</span>, given that the continuous type of random variable <span class="math inline">\(X_1=x_1\)</span>. Similar formula can be derived for conditional pdf of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2 = x_2\)</span>.</p>
<p>Since each of the pdfs <span class="math inline">\(f_{X_2 | X_1} (x_2 | x_1), f_{X_1 | X_2} (x_1 | x_2)\)</span> is a pdf of one variable, each has all the propertiees of such a pdf. Thus we can compute probabilities and mathmetical expectations. If the random variables are of the continuous type, the probability:</p>
<p><span class="math display">\[P(a &lt; X_2 &lt; b | X_1 = x_1) = \int^{b}_{a} f_{X_2 | X_1} (x_2 | x_1) dx_2\]</span></p>
<p>This is called <strong>the conditional probability that <span class="math inline">\(a &lt; X_2 &lt; b\)</span>, given that <span class="math inline">\(X_1 = x_1\)</span></strong></p>
<h4 id="conditional-expectation-and-variance">Conditional Expectation and Variance</h4>
<p>If <span class="math inline">\(u(X_2)\)</span> is a function of <span class="math inline">\(X_2\)</span>, the <code>conditional expectation (continuous case)</code> of <span class="math inline">\(u(X_2)\)</span>, given that <span class="math inline">\(X_1=x_1\)</span>, if it exists, is given by:</p>
<p><span class="math display">\[E_{X_2 | X_1}[u(X_2) | X_1=x_1] = \int^{\infty}_{-\infty} u(x_2) f_{X_2 | X_2} (x_2 | x_1) dx_2\]</span></p>
<p>Notice that, the conditional expectation <span class="math inline">\(E_{X_2 | X_1}[X_2 | X_1=x_1]\)</span> is function of <span class="math inline">\(x_1\)</span>. If they do exist, then <span class="math inline">\(E_{X_2 | X_1}[X_2 | X_1=x_1]\)</span> is the mean and:</p>
<p><span class="math display">\[Var(X_2 | x_1) = E_{X_2 | X_1}[(X_2 - E_{X_2 | X_1}[X_2 | X_1=x_1])^2 | X_1 = x_1]\]</span></p>
<p>is the <code>conditional variance</code> of the conditional distribution of <span class="math inline">\(X_2\)</span>, given <span class="math inline">\(X_1 = x_1\)</span>.</p>
<p>The similar rule holds for conditional variance:</p>
<p><span class="math display">\[Var(X_2 | x_1) = E_{X_2 | X_1}[X_2^2 | X_1=x_1]- (E_{X_2 | X_1}[X_2 | X_1=x_1])^2\]</span></p>
<h4 id="double-expectation">Double Expectation</h4>
<p><img src="/images/RL/background/mprob_2_3_1.png" width="600"></p>
<p>Proof:</p>
<blockquote>
<span class="math display">\[\begin{aligned}
E[X_2] &amp;= \int^{\infty}_{-\infty} f_{X_2} (x_2) x_2 dx_2\\
&amp;= \int^{\infty}_{-\infty} \int^{\infty}_{-\infty}  x_2 f_{X_2, X_1} (x_2, x_1)dx_1 dx_2\\
&amp;= \int^{\infty}_{-\infty} \int^{\infty}_{-\infty} x_2 f_{X_2, X_1} (x_2, x_1) dx_2 dx_1\\
&amp;= \int^{\infty}_{-\infty}\int^{\infty}_{-\infty} x_2 f_{X_2 | X_1} (x_2 | x_1) f_{x_1} (x_1) dx_2 dx_1\\
&amp;= \int^{\infty}_{-\infty} E_{X_2 | X_1}[X_2 | x_1] f_{x_1} (x_1) dx_2 dx_1\\
&amp;= E_{X_1}[E_{X_2 | X_1}[X_2 | X_1]]
\end{aligned}\]</span>
</blockquote>
<p>Intuitively, this result could have this useful interpretation. Both the random variables <span class="math inline">\(X_2\)</span> and <span class="math inline">\(E[X_2 | X_1]\)</span> have the same mean <span class="math inline">\(\mu\)</span>. If we did not know <span class="math inline">\(\mu\)</span>, we can use either of the two random variables to guess. Since however, <span class="math inline">\(Var[X_2] \geq Var[E[X_2 | X_1]]\)</span>, we would put more reliance in <span class="math inline">\(E[X_2 | X_1]\)</span> as a guess. That is, if we observe the pair <span class="math inline">\((x_1, x_2)\)</span>, we would prefer to use <span class="math inline">\(E[X_2 | x_1]\)</span> over <span class="math inline">\(x_2\)</span> to estimate <span class="math inline">\(\mu\)</span>.</p>
<h3 id="independent-random-variables">Independent Random Variables</h3>
<p>Let <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> denote the random variables of the continuous type that have the joint pdf <span class="math inline">\(f(x_1, x_2)\)</span> and marginal probability density functions defined as <span class="math inline">\(f_1 (x_1)\)</span> and <span class="math inline">\(f_2 (x_2)\)</span> respectively. Suppose we have an instance where <span class="math inline">\(f_{X_2 | X_1} (x_2 | x_1)\)</span> does not depend upon <span class="math inline">\(x_1\)</span>. Then the marginal pdf of <span class="math inline">\(X_2\)</span> is</p>
<span class="math display">\[\begin{aligned}
f_{X_2} (x_2) &amp;= \int^{\infty}_{-\infty} f_{X_2, X_1} f(x_2, x_1) dx_1 \\
&amp;= \int^{\infty}_{-\infty} f_{X_2 | X_1} f(x_2 | x_1) f_{X_1}(x_1) dx_1 \\
&amp;= f_{X_2 | X_1} f(x_2 | x_1) \int^{\infty}_{-\infty} f_{X_1}(x_1) dx_1 \\
&amp;= f_{X_2 | X_1} f(x_2 | x_1)
\end{aligned}\]</span>
<p>Then the joint pdf is:</p>
<p><span class="math display">\[f_{X_2, X_1} f(x_2, x_1) = f_{X_2 | X_1} f(x_2 | x_1) f_{X_1} (x_1) = f_{X_2} (x_2) f_{X_1} (x_1)\]</span></p>
<p><img src="/images/RL/background/mprob_2_4_1.png" width="600"></p>
<p><br></p>
<p><code>Theorem 2.4.1</code></p>
<blockquote>
<p>Let random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> have supports <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively, and have the joint pdf <span class="math inline">\(f(x_1, x_2)\)</span>. Then <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent if and only if <span class="math inline">\(f(x_1, x_2)\)</span> can be written as a product of a nonnegative function of <span class="math inline">\(x_1\)</span> and a nonnegative function of <span class="math inline">\(x_2\)</span>. That is: <span class="math display">\[f(x_1, x_2) \equiv g(x_1) h(x_2)\]</span></p>
<p>Where <span class="math inline">\(g(x_1) &gt; 0 \; \forall x_1 \in S_{1}\)</span> and <span class="math inline">\(h(x_2) &gt; 0, \; \forall x_2 \in S_{2}\)</span>, 0 elsewhere.</p>
</blockquote>
<p><img src="/images/RL/background/mprob_2_4_2.png" width="600"></p>
<p><img src="/images/RL/background/mprob_2_4_3.png" width="600"></p>
<p><img src="/images/RL/background/mprob_2_4_4.png" width="600"></p>
<p><img src="/images/RL/background/mprob_2_4_5.png" width="600"></p>
<h3 id="correlation-coefficient">Correlation Coefficient</h3>
<p>Let <span class="math inline">\((X, Y)\)</span> denote a random vector. How do we know the correlation between them? There are many measures of dependence, we investigate a parameter <span class="math inline">\(\rho\)</span> of the joint distribution of <span class="math inline">\((X, Y)\)</span> which measures linearity between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p><img src="/images/RL/background/mprob_2_5_1.png" width="600"></p>
<p>It follows by the linearity of expectation, that the covariance of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can be expressed as:</p>
<p><span class="math display">\[Cov(X, Y) = E[XY - \mu_2 X - \mu_1 Y + \mu_1\mu_2] = E[XY] - \mu_1\mu_2\]</span></p>
<p><img src="/images/RL/background/mprob_2_5_2.png" width="600"></p>
<p><img src="/images/RL/background/mprob_2_5_3.png" width="600"></p>
<p><img src="/images/RL/background/mprob_2_5_4.png" width="600"></p>
<p><strong>The converse is not true</strong> (i.e if <span class="math inline">\(Cov(X, Y) = 0 \implies X, Y\)</span> are independent). However, the contrapositive is true:</p>
<blockquote>
<p>If <span class="math inline">\(\rho \neq 0\)</span>, then <span class="math inline">\(X, Y\)</span> are dependent.</p>
</blockquote>
<h2 id="extension-to-several-random-variables">Extension to Several Random Variables</h2>
<p><img src="/images/RL/background/mprob_2_6_1.png" width="600"></p>
<p>We denote the random vector by n-dimensional column vector <span class="math inline">\(\mathbf{X}\)</span> and the observed values (realization) of random vector by <span class="math inline">\(\mathbf{x}\)</span>. The joint cdf is defined to be:</p>
<p><span class="math display">\[F_{\mathbf{X}} (\mathbf{x}) = P[X_1 \leq x_1 ,....., X_n \leq x_n]\]</span></p>
<p>We say that the <span class="math inline">\(n\)</span> random variables <span class="math inline">\(X_1\)</span>, ...., <span class="math inline">\(X_n\)</span> are of the discrete type or of the continuous type and have a distribution of that type according to whether the joint cdf can be expressed as:</p>
<p><span class="math display">\[F_{\mathbf{X}} (\mathbf{x}) = \sum_{w_1 \leq x_1} .... \sum_{w_n \leq x_n} p_{\mathbf{X}}(w_1, ....., w_n)\]</span></p>
<p>or</p>
<p><span class="math display">\[F_{\mathbf{X}} (\mathbf{x}) = \int^{x_1}_{-\infty} .... \int^{x_n}_{-\infty} f(w_1, ....., w_n)dw_n .... dw_1\]</span></p>
<p>For continuous case:</p>
<p><span class="math display">\[\frac{\partial^n}{\partial x_1, ...., x_n} F_{\mathbf{X}} (\mathbf{x}) = f(\mathbf{x})\]</span></p>
<p>For the discrete case, the support set <span class="math inline">\(S\)</span> of a random vector is all points in <span class="math inline">\(\mathbb{D}\)</span> that have positive mass while for the continuous case these would be all points in <span class="math inline">\(\mathbb{D}\)</span> that have positive mass that can be embedded in an open set of positive probability.</p>
<h3 id="expectation-1">Expectation</h3>
<p>Let <span class="math inline">\(\mathbf{X}\)</span> be a <span class="math inline">\(n\)</span> dimensional column random vector, let <span class="math inline">\(Y = u(\mathbf{X})\)</span> for some function <span class="math inline">\(u\)</span>. As in the bivariate case, the expected value of a continuous random variable exists if the <span class="math inline">\(n\)</span>-fold integral exists:</p>
<p><span class="math display">\[\int^{\infty}_{-\infty} .... \int^{\infty}_{-\infty} |u(\mathbf{x})|f(x_1, ....., x_n)dx_n .... dx_1\]</span></p>
<p>The expected value of a discrete random variable exists if the <span class="math inline">\(n\)</span>-fold sum exists:</p>
<p><span class="math display">\[\sum_{x_1} .... \sum_{x_n} |u(\mathbf{x})|p_{\mathbf{X}}(x_1, ....., x_n)\]</span></p>
<p>Then the expectation is:</p>
<ol type="1">
<li><p>Discrete case: <span class="math display">\[E[Y] = \sum_{x_1} .... \sum_{x_n} u(\mathbf{x})p_{\mathbf{X}}(x_1, ....., x_n)\]</span></p></li>
<li><p>Continuous case: <span class="math display">\[E[Y] = \int^{\infty}_{-\infty} .... \int^{\infty}_{-\infty} u(\mathbf{x})f(x_1, ....., x_n)dx_n .... dx_1\]</span></p></li>
</ol>
<h3 id="marginal-distribution">Marginal Distribution</h3>
<p>By an argument similar to the two-variable case, we have:</p>
<p><span class="math display">\[f_{X_1} (x_1) = \int^{\infty}_{-\infty} .... \int^{\infty}_{-\infty} f(x_1, ....., x_n)dx_n .... dx_2\]</span></p>
<p><span class="math display">\[p_{X_1} (x_1) = \sum_{x_2} .... \sum_{x_n} p_{\mathbf{X}}(x_1, ....., x_n)\]</span></p>
<p>Now, if we take subset of <span class="math inline">\(k\)</span> where <span class="math inline">\(k &lt; n\)</span> from <span class="math inline">\(\mathbf{X}\)</span>, then we can define the <code>Marginal pdf of subset of k</code> variables.</p>
<h3 id="conditional-distribution">Conditional Distribution</h3>
<p>Similarly, we can extend the definition of a conditional distribution from bivariate conditional distribution.</p>
<p>Suppose, <span class="math inline">\(f_{X_1} (x_1) &gt; 0\)</span>. Then we define the symbol <span class="math inline">\(f_{X_2,....,X_n | X_1} (x_2,.....,x_n | x_1)\)</span> by the relation:</p>
<p><span class="math display">\[f_{X_2,....,X_n | X_1} (x_2,.....,x_n | x_1) = \frac{f_{\mathbf{X}} (\mathbf{x})}{f_{X_1} (x_1)}\]</span></p>
<p>Then <span class="math inline">\(f_{X_2,....,X_n | X_1} (x_2,.....,x_n | x_1)\)</span> is called the <code>joint conditional pdf</code> of <span class="math inline">\(X_2, ...., X_n\)</span> given <span class="math inline">\(X_1 = x_1\)</span>.</p>
<p>More general, <strong>the joint conditional pdf of <span class="math inline">\(n - k\)</span> of the random variables, for given values of the remaining <span class="math inline">\(k\)</span> variables, is defined as the joint pdf of the <span class="math inline">\(n\)</span> variables divided by the marginal pdf of the particular subset group of <span class="math inline">\(k\)</span> variables, provided that the latter pdf is positive.</strong></p>
<h4 id="conditional-expectation">Conditional Expectation</h4>
<p>The <code>conditional expectation</code> of <span class="math inline">\(u(X_2, ...., X_n)\)</span> given <span class="math inline">\(X_1 = x_1\)</span> (continuous) is given by:</p>
<p><span class="math display">\[E[u(X_2, ...., X_n) | x_1] = \int^{\infty}_{-\infty} .... \int^{\infty}_{-\infty} u(x_2, ...., x_n) f_{X_2, ..., X_n | X_1}(x_2, ....., x_n | x_1)dx_n .... dx_2\]</span></p>
<h3 id="mutually-independent">Mutually Independent</h3>
<p>The random variables <span class="math inline">\(X_1, ...., X_n\)</span> are said to be <code>mutually independent</code> IFF</p>
<p><span class="math display">\[f_{\mathbf{X}}(\mathbf{x}) = f_{X_1} (x_1) .... f_{X_n} (x_n)\]</span></p>
<p>for the continuous case. Similar for discrete case.</p>
<p>Suppose <span class="math inline">\(X_1, ...., X_n\)</span> are mutually independent. Then,</p>
<ol type="1">
<li><p>CDF: <span class="math display">\[P(a_1 &lt; X_1 &lt; b_1, a_2 &lt; X_2 &lt; b_2, ....., a_n &lt; X_n &lt; b_n) = P(a_1 &lt; X_1 &lt; b_1) .... P(a_n &lt; X_n &lt; b_n) = \prod^{n}_{i=1} P(a_i &lt; X_i &lt; b_i)\]</span></p></li>
<li><p>Expectation: <span class="math display">\[E[u_1(X_1) ... u_n(X_n)] = E[u_1(X_1)] ... E[u_n (X_n)]\]</span></p></li>
</ol>
<p><br></p>
<h4 id="pairwise-independent">Pairwise Independent</h4>
<p>If <span class="math inline">\(X_i, X_j, i \neq j\)</span> are independent, we say that they are <code>pairwise independent</code>. If random variables are mutually independent, they are pairwise independent. <strong>However, the converse is false, pairwise independence does not imply mutual independence</strong>:</p>
<p>In addition, if several random variables are mutually independent and have the same distribution, we say that they are <code>independent and identically distributed (i.i.d)</code>.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Policy Iteration</title>
    <url>/2021/05/03/policy-iteration/</url>
    <content><![CDATA[<h1 id="policy-iteration">Policy Iteration</h1>
<p>A different approach is based on the iterative application of:</p>
<ol type="1">
<li>Policy Evaluation: Given a policy <span class="math inline">\(\pi_k\)</span>, compute <span class="math inline">\(V^{\pi_k}, Q^{\pi_k}\)</span></li>
<li>Policy Improvement: Find a new policy <span class="math inline">\(\pi_{k+1}\)</span> that is better than <span class="math inline">\(\pi_{k}\)</span>, i.e., <span class="math inline">\(V^{\pi_{k+1}} \geq V^{\pi_k}\)</span> (with a strict inequality in at least one state, unless at convergence)</li>
</ol>
<p><img src='/images/RL/dp/policy_iteration.png'></p>
<span id="more"></span>
<p>So, how do we perform policy evaluation and policy improvement?</p>
<ol type="1">
<li><p>Policy Evaluation: We can use the policy evaluation part of VI (<span class="math inline">\(V_{k+1} \leftarrow T^{\pi} V_{k}\)</span>) to compute the value of a policy <span class="math inline">\(\pi_k\)</span></p></li>
<li><p>Policy Improvement: We take the <strong>greedy policy</strong>,</p>
<p><span class="math display">\[\pi_{k+1} \leftarrow \pi_g (x; Q^{\pi_k}) = argmax_{a \in A} Q^{\pi_k} (x, a), \forall x \in X\]</span></p></li>
</ol>
<h2 id="why-greedy-policy-intuition">Why Greedy Policy? (Intuition)</h2>
<p>Assume that at state <span class="math inline">\(x\)</span>, we act according to greedy policy <span class="math inline">\(\pi_g (x; Q^{\pi_{k}})\)</span>, and afterwards, we follow <span class="math inline">\(\pi_{k}\)</span>. (we modify our policy at state <span class="math inline">\(x\)</span> to choose the greedy action)</p>
<p>The value of this new policy is:</p>
<p><span class="math display">\[Q^{\pi_k} (x, \pi_g (x; Q^{\pi_{k}})) = Q^{\pi_k} (x, argmax_{a \in A} Q^{\pi_k} (x, a)) = max_{a \in A} Q^{\pi_k} (x, a)\]</span></p>
<p>Compare <span class="math inline">\(max_{a \in A} Q^{\pi_k} (x, a)\)</span> with <span class="math inline">\(V^{\pi_k} (x) = Q^{\pi_k} (x, \underbrace{\pi_k (x)}_{\text{any deterministic policy}})\)</span>, we can see that:</p>
<p><span class="math display">\[max_{a \in A} Q^{\pi_k} (x, a) = Q^{\pi_k} (x, \pi_g (x; Q^{\pi_{k}})) \geq Q^{\pi_k} (x, \underbrace{\pi_k (x)}_{\text{any deterministic policy}}) = V^{\pi_k} (x)\]</span></p>
<p>So this new policy is equal to or better than <span class="math inline">\(\pi_k\)</span> at state <span class="math inline">\(x\)</span>.</p>
<h2 id="algorithm">Algorithm</h2>
<p>Recall that:</p>
<ul>
<li><p><span class="math inline">\(V^{\pi_k}\)</span> is an unique fixed point of bellman operator <span class="math inline">\(T^{\pi_{k}}\)</span></p></li>
<li><p>The greedy policy <span class="math inline">\(\pi_{k+1}\)</span> satisfies:</p>
<span class="math display">\[\begin{aligned}
  T^{\pi_{k+1}} Q^{\pi_k} &amp;= r(x, a) + \int P(dx^{\prime} | x, a) \underbrace{\pi_{k+1} (da^{\prime} | x^{\prime})}_{\text{This policy is greedy policy}} Q^{\pi_k} (x^{\prime}, a^{\prime})\\ 
  &amp;= r(x, a) + \int P(dx^{\prime} | x, a) Q^{\pi_k} (x^{\prime}, argmax_{a^{\prime} \in A} Q^{\pi_k} (x^{\prime}, a^{\prime})\\
  &amp;= r(x, a) + \int P(dx^{\prime} | x, a) max_{a^{\prime} \in A} Q^{\pi_k} (x^{\prime}, a^{\prime})\\
  &amp;= T^{*} Q^{\pi_{k}}
  \end{aligned}\]</span></li>
</ul>
<p>We can summarize each iteration of the Policy iteration algorithm as:</p>
<ul>
<li><p>(<strong>Policy Evaluation</strong>) Given <span class="math inline">\(\pi_k\)</span>, compute Q^{_k}, i.e find a Q that satisfies <span class="math inline">\(Q = T^{\pi_k} Q\)</span></p></li>
<li><p>(<strong>Policy Improvement</strong>) Obtain <span class="math inline">\(\pi_{k+1}\)</span> as a policy that satisfies (select greedy policy at each state <span class="math inline">\(x\)</span>):</p>
<p><span class="math display">\[T^{\pi_{k+1}} Q^{\pi_k} = T^{*} Q^{\pi_{k}}\]</span></p></li>
</ul>
<p>We also have approximate policy iteration algorithms too, where policy evaluation or improvement steps (Truncate evaluation step, function approximation) are performed approximately:</p>
<p><span class="math display">\[Q \approx T^{\pi_k} Q\]</span></p>
<p><span class="math display">\[T^{\pi_{k+1}} Q^{\pi_k} \approx T^{*} Q^{\pi_{k}}\]</span></p>
<p>A generic algorithm can be found in Intro to RL book:</p>
<p><img src='/images/RL/dp/pi.png'></p>
<h3 id="implementation">Implementation</h3>
<h2 id="convergence-of-policy-iteration">Convergence of Policy Iteration</h2>
<p>We can guarantee that the policy iteration algorithm converges to the optimal policy. For finite MDPs, the convergence happens in a finite number of iterations.</p>
<h3 id="policy-improvement-theorem">Policy Improvement Theorem</h3>
<p><img src='/images/RL/dp/pit.png'></p>
<p>In other words, if we choose <span class="math inline">\(\pi^{\prime}\)</span> to be the greedy policy, then we are guaranteed to have a better policy.</p>
<h4 id="poof">Poof</h4>
<p>We have <span class="math inline">\(T^{*} Q^{\pi} \geq T^{\pi} Q^{\pi} = Q^{\pi}\)</span> because for any <span class="math inline">\((x, a) \in X \times A\)</span> it holds that:</p>
<p>Deterministic Policy <span class="math inline">\(\pi(x)\)</span> <span class="math display">\[r(x, a) + \gamma \int P(dx^{\prime} | x, a) max_{a^{\prime} \in A} Q^{\pi} (x^\prime, a^\prime) \geq r(x, a) + \gamma \int P(dx^{\prime} | x, a) Q^{\pi} (x^{\prime}, \pi(x^{\prime}))) \]</span></p>
<p>Stochastic Policy <span class="math inline">\(\pi(a | x)\)</span></p>
<p><span class="math display">\[r(x, a) + \gamma \int P(dx^{\prime} | x, a) max_{a^{\prime} \in A} Q^{\pi} (x^\prime, a^\prime) \geq r(x, a) + \gamma \int P(dx^{\prime} | x, a) \pi(da^{\prime} | x^{\prime}) Q^{\pi} (x^{\prime}, a^{\prime}))) \]</span></p>
<p>Thus, <span class="math display">\[T^{\pi^{\prime}} Q^{\pi} = T^{*} Q^{\pi} \geq T^{\pi} Q^{\pi} = Q^{\pi}\]</span></p>
<p>We have:</p>
<p><span class="math display">\[T^{\pi^{\prime}} Q^{\pi} \geq Q^{\pi}\]</span></p>
<p>Then, we apply <span class="math inline">\(T^{\pi^\prime}\)</span> to both sides, by monotonic property of bellman operator, we have:</p>
<p><span class="math display">\[T^{\pi^{\prime}}(T^{\pi^{\prime}} Q^{\pi}) \geq T^{\pi^{\prime}} Q^{\pi} = T^{*} Q^{\pi} \geq Q^{\pi}\]</span></p>
<p>Repeat this, we have for any <span class="math inline">\(m \geq 1\)</span>:</p>
<p><span class="math display">\[(T^{\pi^{\prime}})^{m} Q^{\pi} \geq T^{*} Q^{\pi} \geq Q^{\pi}\]</span></p>
<p>As <span class="math inline">\(m \rightarrow \infty\)</span>:</p>
<p><span class="math display">\[lim_{m \rightarrow \infty} (T^{\pi^{\prime}})^{m} Q^{\pi} = Q^{\pi^\prime}\]</span></p>
<p><span class="math display">\[\implies Q^{\pi^\prime} = lim_{m \rightarrow \infty} (T^{\pi^{\prime}})^{m} Q^{\pi} \geq Q^{\pi}\]</span></p>
<h3 id="proof-convergence-of-policy-iteration">Proof: Convergence of Policy Iteration</h3>
]]></content>
      <categories>
        <category>RL</category>
        <category>DP</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>Dynamic Programming</tag>
      </tags>
  </entry>
  <entry>
    <title>probability-3</title>
    <url>/2021/07/15/probability-3/</url>
    <content><![CDATA[<h1 id="statistics-inference">Statistics Inference</h1>
<h2 id="sampling-and-statistics">Sampling and Statistics</h2>
<p>In a typical statistical problem, we have <span class="math inline">\(p_X(x), f_X(x)\)</span> unknown. Our ignorance about the <span class="math inline">\(p_X(x), f_X(x)\)</span> can roughly be classified in one of two ways:</p>
<ol type="1">
<li><span class="math inline">\(f(x)\)</span> or <span class="math inline">\(p_X(x)\)</span> is completely unknown.</li>
<li>The form of <span class="math inline">\(f_X(x)\)</span> or <span class="math inline">\(p_X(x)\)</span> is known down to an unknown <code>parameter</code> vector <span class="math inline">\(\mathbf{\theta}\)</span>.</li>
</ol>
<p>We will focus on the second case. We often denote this problem by saying that the random variable <span class="math inline">\(X\)</span> has density or mass function of the form <span class="math inline">\(f_{X}(x; \theta)\)</span> or <span class="math inline">\(p_X(x;\theta)\)</span>, where <span class="math inline">\(\theta \in \Omega\)</span> for a special parameter space <span class="math inline">\(\Omega\)</span>. Since <span class="math inline">\(\theta\)</span> is unknown, we want to estimate it.</p>
<p>In the process, our information about case 1 or 2 comes from a sample on <span class="math inline">\(X\)</span>. The sample observations have the same distribution as <span class="math inline">\(X\)</span>, and we denote them as <span class="math inline">\(X_1, ...., X_n\)</span> where <span class="math inline">\(n\)</span> is the <code>sample size</code>. When the sample is actually drawn, we use lower case letters to represent the <code>realization</code> <span class="math inline">\(x_1, ..., x_n\)</span> of random samples.</p>
<p><img src="/images/RL/background/mprob_4_1_2.png" width="600"> <img src="/images/RL/background/mprob_4_1_1.png" width="600"></p>
<p>Once the sample is drawn, then <span class="math inline">\(t\)</span> is called the realization of <span class="math inline">\(T\)</span>, where <span class="math inline">\(t = T(x_1, ...., x_n)\)</span>.</p>
<span id="more"></span>
<h3 id="point-estimators">Point Estimators</h3>
<p>Continue from above formulation, the problem of case 2 can be phrased as:</p>
<blockquote>
<p>Let <span class="math inline">\(X_1, ...., X_n\)</span> be a random sample on a random variable <span class="math inline">\(X\)</span> with a density or mass function of the form <span class="math inline">\(f_X(x; \theta)\)</span> or <span class="math inline">\(p_X (x; \theta)\)</span>. In this situation, an <code>point estimator</code> of <span class="math inline">\(\theta\)</span> is a <code>statistic</code> <span class="math inline">\(T\)</span>. While we call <span class="math inline">\(T\)</span> an estimator of <span class="math inline">\(\theta\)</span>, we call <span class="math inline">\(t\)</span> an <code>estimate</code> of <span class="math inline">\(\theta\)</span>.</p>
</blockquote>
<p><img src="/images/RL/background/mprob_4_1_3.png" width="600"></p>
<p>In our problem, the information in the sample and the parameter <span class="math inline">\(\theta\)</span> are involved in the joint distribution of the random sample (i.e <span class="math inline">\(\prod^{n}_{i=1} f(x_1 ; \theta)\)</span>). We want to view this as a function of <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[L(\theta) = L(\theta; x_1, ....., x_n) = \prod^{n}_{i=1} f_X(x_i; \theta)\]</span></p>
<p>This is called the <code>likelihood function</code> of the random sample. As an estimate of <span class="math inline">\(\theta\)</span>, an often-used estimate is the value of <span class="math inline">\(\theta\)</span> that provides a maximum of <span class="math inline">\(L(\theta)\)</span>. If it is unique, this is called the <code>Maximum likelihood estimator</code> and we denote it as <span class="math inline">\(\hat{\theta}\)</span>:</p>
<p><span class="math display">\[\hat{\theta} = \arg\max_{\theta} L(\theta; \mathbf{X})\]</span></p>
<p>If <span class="math inline">\(\theta\)</span> is a vector of parameters, this results in a system of equations to be solved simultaneously called <code>estimating equations</code>.</p>
<h2 id="the-method-of-monte-carlo">The Method of Monte Carlo</h2>
<h2 id="bootstrap-procedures">Bootstrap Procedures</h2>
<h1 id="consistency-and-limiting-distributions">Consistency and Limiting Distributions</h1>
<h2 id="convergence-in-probability">Convergence in Probability</h2>
<p>We formalize a way of saying that a sequence of random variables <span class="math inline">\(\{X_n\}\)</span> is getting "close" to another random variable <span class="math inline">\(X\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> by:</p>
<p><img src="/images/RL/background/mprob_5_1_1.png" width="600"></p>
<p>In statistics, <span class="math inline">\(X\)</span> is often a constant (i.e <span class="math inline">\(X\)</span> is a degenerate random variable with all its mass at some constant <span class="math inline">\(a\)</span>). In this case, we write <span class="math inline">\(X_n \overset{P}{\rightarrow} a\)</span>.</p>
<h3 id="weak-law-of-large-numbers">Weak Law of Large Numbers</h3>
<p><img src="/images/RL/background/mprob_5_1_2.png" width="600"></p>
<p>This theorem says that all the mass of the distribution of <span class="math inline">\(\bar{X}_n\)</span> is converging to a constant <span class="math inline">\(\mu\)</span>, as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<p><img src="/images/RL/background/mprob_5_1_3.png" width="600"> <img src="/images/RL/background/mprob_5_1_4.png" width="600"> <img src="/images/RL/background/mprob_5_1_5.png" width="600"> <img src="/images/RL/background/mprob_5_1_6.png" width="600"></p>
<h3 id="consistency">Consistency</h3>
<p><img src="/images/RL/background/mprob_5_1_7.png" width="600"></p>
<p>If <span class="math inline">\(X_1, ..., X_n\)</span> is a random sample from a distribution with finite mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, then by the <code>weak law of large numbers</code>, the sample mean <span class="math inline">\(\bar{X}_n\)</span> is a <code>consistent</code> estimator of <span class="math inline">\(\mu\)</span>.</p>
<h2 id="convergence-in-distribution">Convergence in Distribution</h2>
<p><img src="/images/RL/background/mprob_5_2_1.png" width="600"></p>
<p>Often, we say that the distribution of <span class="math inline">\(X\)</span> is the <code>asymptotic distribution</code> or <code>limiting distribution</code> of sequence <span class="math inline">\(\{X_n\}\)</span>. In general, we can represent <span class="math inline">\(X\)</span> by the distribution it follows, for example:</p>
<p><span class="math display">\[X_n \overset{D}{\rightarrow} N(0, 1)\]</span></p>
<p>The thing on the right hand side is not a random variable, but a distribution, this is just a convention saying the same thing. In addition, we may say that <span class="math inline">\(X_n\)</span> has a <strong>limiting</strong> standard normal distribution to mean the same thing (i.e <span class="math inline">\(X_n \overset{D}{\rightarrow} N(0, 1)\)</span>).</p>
<p>Convergence in probability is a way of saying that a sequence of random variables <span class="math inline">\(X_n\)</span> is getting close to another random variable <span class="math inline">\(X\)</span>. <strong>On the other hand, convergence in distribution only concerned with the cdfs <span class="math inline">\(F_{X_n}\)</span> and <span class="math inline">\(F_X\)</span> (In general, we cannot determine the limiting distribution by considering pmfs or pdfs).</strong></p>
<p>Example:</p>
<blockquote>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable with a pdf <span class="math inline">\(f_X (x)\)</span> that is symmetric about 0 (i.e <span class="math inline">\(f_X(-x) = f_X(x)\)</span>). Then it is easy to show that the density of the random variable <span class="math inline">\(-X\)</span> and <span class="math inline">\(X\)</span> have the same distributions (i.e <span class="math inline">\(F_{-X}(x) = F_X(x)\)</span>). Define the sequence of random variables <span class="math inline">\(X_n\)</span> as: <span class="math display">\[
X_n =
\begin{cases}
X, \quad &amp; \text{if $n$ is odd}\\
-X, \quad &amp; \text{if $n$ is even}\\
\end{cases}
\]</span> Clearly, <span class="math inline">\(F_{X_n} (x) = F_{X} (x)\)</span> so <span class="math inline">\(X_n \overset{D}{\rightarrow} X\)</span>, but <span class="math inline">\(X_n\)</span> does not converge in probability to <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p><img src="/images/RL/background/mprob_5_2_2.png" width="600"> <img src="/images/RL/background/mprob_5_2_3.png" width="600"> <img src="/images/RL/background/mprob_5_2_4.png" width="600"> <img src="/images/RL/background/mprob_5_2_5.png" width="600"></p>
<h3 id="bounded-in-probability">Bounded in Probability</h3>
<p><img src="/images/RL/background/mprob_5_2_6.png" width="600"> <img src="/images/RL/background/mprob_5_2_7.png" width="600"></p>
<h2 id="central-limit-theorem">Central Limit Theorem</h2>
<h1 id="maximum-likelihood-methods">Maximum Likelihood Methods</h1>
<h2 id="maximum-likelihood-estimation-single-parameter">Maximum Likelihood Estimation (Single Parameter)</h2>
<p>Suppose we have a random sample <span class="math inline">\(X_1, ...., X_n\)</span> on <span class="math inline">\(X\)</span> with common pdf <span class="math inline">\(f(x;\theta)\)</span>. Assume that <span class="math inline">\(\theta\)</span> is a scalar and unknown. The <code>likelihood function</code> is given by:</p>
<p><span class="math display">\[L(\theta; \mathbf{x}) = \prod^{n}_{i=1} f(x_i;\theta)\]</span></p>
<p>The <code>log likelihood function</code>:</p>
<p><span class="math display">\[l(\theta; \mathbf{x}) = \sum^{n}_{i=1} \log f(x_i;\theta)\]</span></p>
<p>Then the point estimator (before the observation of <span class="math inline">\(\mathbf{x}\)</span>) of <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\hat{\theta} = \arg\max_{\theta} L(\theta; \mathbf{X})\)</span>. We call <span class="math inline">\(\hat{\theta}\)</span> the <strong>ML estimator</strong> of <span class="math inline">\(\theta\)</span>. If we have the observation <span class="math inline">\(\mathbf{x}\)</span>, we call <span class="math inline">\(\hat{\theta} (\mathbf{x})\)</span> the <strong>ML estimate</strong>.</p>
<p><img src="/images/RL/background/mprob_6_1_2.png" width="600"></p>
<p>Assumption 1 assumes that the parameter identifies the pdf. The second assumption implies that the support of <span class="math inline">\(X_i\)</span> does not depend on <span class="math inline">\(\theta\)</span>.</p>
<p><img src="/images/RL/background/mprob_6_1_1.png" width="600"></p>
<p>The theorem shows that the maximum of <span class="math inline">\(L(\theta; \mathbf{X})\)</span> asymptotically separates the true model at <span class="math inline">\(\theta_0\)</span> from models at <span class="math inline">\(\theta \neq \theta_0\)</span>.</p>
<p><strong>Proof</strong>:</p>
<blockquote>
<p>Assume <span class="math inline">\(\theta_0\)</span> is the true parameter value. Then the inequality we want to show <span class="math inline">\(L(\theta_0; \mathbf{X}) &gt; L(\theta; \mathbf{X})\)</span> can be written as:</p>
<p><span class="math display">\[\frac{1}{n}\sum^{n}_{i=1} \log[f_X(X_i; \theta_0)] &gt; \frac{1}{n}\sum^{n}_{i=1} \log[f_X(X_i; \theta)] \implies \frac{1}{n}\sum^{n}_{i=1} \log[\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}] &gt; 0\]</span></p>
<p>By the Weak law of large numbers, we have: <span class="math display">\[\frac{1}{n}\sum^{n}_{i=1} -\log[\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}] \; \overset{p}{\rightarrow} \; E_{P_X(\cdot | \theta_0)} [ -\log[\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}]]\]</span></p>
<p>Since the <span class="math inline">\(-\log\)</span> function is convex, we can apply <code>jensen's inequality</code> <span class="math display">\[\frac{1}{n}\sum^{n}_{i=1} -\log[\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}] \; \overset{p}{\rightarrow} \; E_{P_X(\cdot | \theta_0)} [ -\log[\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}]] \geq -\log (E_{P_X(\cdot | \theta_0)} [\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}])\]</span></p>
<p>But, the expectation is 1:</p>
<p><span class="math display">\[\int_{x} \frac{f_X(x_i; \theta)}{f_X(x_i; \theta_0)} {f_X(x_i; \theta_0)} dx = 1\]</span></p>
<p>So, we have: <span class="math display">\[\frac{1}{n}\sum^{n}_{i=1} -\log[\frac{f_X(X_i; \theta)}{f_X(X_i; \theta_0)}] \geq 0\]</span></p>
<p>Then: <span class="math display">\[\frac{1}{n}\sum^{n}_{i=1} \log[f_X(X_i; \theta_0)] &gt; \frac{1}{n}\sum^{n}_{i=1} \log[f_X(X_i; \theta)] \implies L(\theta_0; \mathbf{X}) &gt; L(\theta; \mathbf{X})\]</span></p>
<p>As <span class="math inline">\(n \rightarrow \infty\)</span> the above inequality holds.</p>
</blockquote>
<p>That is, asymptotically the likelihood function is maximized at the value <span class="math inline">\(\theta_0\)</span>. So in considering estimates of <span class="math inline">\(\theta_0\)</span>, it is natural to consider the value of <span class="math inline">\(\theta\)</span> that maximizes the likelihood.</p>
<p><img src="/images/RL/background/mprob_6_1_3.png" width="600"></p>
<p><img src="/images/RL/background/mprob_6_1_4.png" width="600"> <img src="/images/RL/background/mprob_6_1_5.png" width="600"> <img src="/images/RL/background/mprob_6_1_6.png" width="600"></p>
<h2 id="maximum-likelihood-estimation-multiple-parameters">Maximum Likelihood Estimation (Multiple Parameters)</h2>
<p>Let <span class="math inline">\(X_1, ...., X_n\)</span> be i.i.d with common pdf <span class="math inline">\(f(x; \boldsymbol{\theta})\)</span>, where <span class="math inline">\(\boldsymbol{\theta} \in \Omega \subset \mathbb{R}^p\)</span>. The <code>likelihood function</code> is given by:</p>
<p><span class="math display">\[L(\boldsymbol{\theta}; \mathbf{x}) = \prod^{n}_{i=1} f_{X}(x_i; \boldsymbol{\theta})\]</span></p>
<p><span class="math display">\[l(\boldsymbol{\theta}) = \log L(\boldsymbol{\theta}; \mathbf{x}) = \sum^{n}_{i=1} \log f_{X}(x_i; \boldsymbol{\theta})\]</span></p>
<p><img src="/images/RL/background/mprob_6_4_1.png" width="600"></p>
<p>Notice that, the proof for scalar case also follows in vector case. Therefore, with probability going to 1, <span class="math inline">\(L(\boldsymbol{\theta}; \mathbf{x})\)</span> is maximized at the true value of <span class="math inline">\(\boldsymbol{\theta}\)</span>. Hence, as an estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span>, we consider the gradient of <span class="math inline">\(L(\boldsymbol{\theta}; \mathbf{x})\)</span> w.r.t <span class="math inline">\(\boldsymbol{\theta}\)</span>:</p>
<p><span class="math display">\[\nabla_{\boldsymbol{\theta}} l(\boldsymbol{\theta}) = \mathbf{0}\]</span></p>
<p>If the maximizer <span class="math inline">\(\hat{\boldsymbol{\theta}} = \hat{\boldsymbol{\theta}} (\mathbf{X})\)</span> exists, it is called the <code>maximum likelihood estimator</code>.</p>
<h3 id="fisher-information">Fisher Information</h3>
<p>The Fisher information in the scalar case is the variance of the random variable (the mean is 0):</p>
<p><span class="math display">\[E[(\frac{\partial \log f(X;\theta)}{\partial \theta})^2]\]</span></p>
<p>It measures the amount of information the random variable <span class="math inline">\(X\)</span> carries about an unknown parameter <span class="math inline">\(\theta\)</span>.</p>
<p>In multivariate case, the variance becomes variance covariance matrix of <span class="math inline">\(\nabla_{\boldsymbol{\theta}} \log f_X(X;\boldsymbol{\theta})\)</span>:</p>
<p><span class="math display">\[I(\boldsymbol{\theta})_{j, k} = cov(\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_j}, \frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_k})\]</span></p>
<p>By assumption, we can swap integral and derivative, thus we have:</p>
<span class="math display">\[\begin{aligned}
0 &amp;= \int_{x} \frac{\partial f(x; \boldsymbol{\theta})}{\partial \theta_j} dx \\
&amp;= \int_{x} \frac{\partial \log f(x; \boldsymbol{\theta})}{\partial \theta_j} f(x; \boldsymbol{\theta})dx\\
&amp;= E[\frac{\partial \log f(X; \boldsymbol{\theta})}{\partial \theta_j}]
\end{aligned}\]</span>
<p>If we take the partial derivative w.r.t <span class="math inline">\(\theta_k\)</span>, after multiplication rule, we have:</p>
<p><span class="math display">\[0 = \int_{x} \frac{\partial^2 \log f(x; \boldsymbol{\theta})}{\partial \theta_j\theta_k} \log f(x; \boldsymbol{\theta})dx + \int_x \frac{\partial \log f(x; \boldsymbol{\theta})}{\partial \theta_j}\frac{\partial \log f(x; \boldsymbol{\theta})}{\partial \theta_k} \log f(x; \boldsymbol{\theta})dx\]</span> <span class="math display">\[\implies -E[\frac{\partial^2 \log f(X; \boldsymbol{\theta})}{\partial \theta_j\theta_k}] = E[\frac{\partial \log f(X; \boldsymbol{\theta})}{\partial \theta_j}\frac{\partial \log f(X; \boldsymbol{\theta})}{\partial \theta_k}]\]</span></p>
<p>Thus, the fisher information matrix can be written as:</p>
<span class="math display">\[\begin{aligned}
cov(\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_j}, \frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_k}) &amp;= E[\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_j}\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_k}] - E[\frac{\partial \log f(x; \boldsymbol{\theta})}{\partial \theta_j}]E[\frac{\partial \log f(x; \boldsymbol{\theta})}{\partial \theta_k}]\\
&amp;= E[\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_j}\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_k}]\\
\implies I(\boldsymbol{\theta})_{j, k} &amp;= E[\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_j}\frac{\partial \log f_X(X;\boldsymbol{\theta})}{\partial \theta_k}]\\
&amp;= -E[\frac{\partial^2 \log f(X; \boldsymbol{\theta})}{\partial \theta_j\theta_k}]
\end{aligned}\]</span>
<p>By replacing <span class="math inline">\(f_X(X; \boldsymbol{\theta})\)</span> by the likelihood function <span class="math inline">\(L(\boldsymbol{\theta}; \mathbf{X})\)</span>, we have:</p>
<p><span class="math display">\[Cov(\sum^{n}_{i=1}\nabla_{\boldsymbol{\theta}} f_X(X; \boldsymbol{\theta})) = nI(\boldsymbol{\theta})\]</span></p>
<p>If <span class="math inline">\(Y_j = u_j (\mathbf{X})\)</span> is an unbiased estimator of <span class="math inline">\(\theta_j\)</span>, then ti can be shown that:</p>
<p><span class="math display">\[Var(Y_j) \leq \frac{1}{n} [I^{-1}(\boldsymbol{\theta})_{jj}]\]</span></p>
<p>Then the estimator <span class="math inline">\(Y_j\)</span> is called <code>efficient</code>.</p>
<p><img src="/images/RL/background/mprob_6_4_2.png" width="600"> <img src="/images/RL/background/mprob_6_4_3.png" width="600"> <img src="/images/RL/background/mprob_6_4_4.png" width="600"></p>
<h1 id="sufficiency">Sufficiency</h1>
<h2 id="measures-of-quality-of-estimators">Measures of Quality of Estimators</h2>
<h1 id="bayesian-statistics">Bayesian Statistics</h1>
<h2 id="maximum-a-posterior-estimation">Maximum A Posterior Estimation</h2>
<p>MLE is not the only way to estimate the parameters. The paradigm of MAP is that we should choose the <strong>value for our parameters that is the most likely given the data</strong>, that is:</p>
<p><span class="math display">\[\hat{\theta} = \underset{\theta}{\arg\max}\; P(\theta| D)\]</span></p>
<p>If we have random sample <span class="math inline">\(X_1, ...., X_n\)</span> that follows some discrete distribution <span class="math inline">\(P(X)\)</span>, then:</p>
<span class="math display">\[\begin{aligned}
\hat{\theta} &amp;= \underset{\theta}{\arg\max}\; p_X(\theta| X_1, ...., X_n)\\
&amp;= \underset{\theta}{\arg\max}\; \frac{p_X(X_1, ...., X_n | \theta) P(\theta)}{p_X(X_1, ..., X_n)}\\
&amp;= \underset{\theta}{\arg\max}\; p_X(X_1, ...., X_n | \theta) P(\theta)\\
&amp;= \underset{\theta}{\arg\max}\; \prod^{N}_{i=1} p_X(X_i | \theta) P(\theta)
\end{aligned}\]</span>
<p>Which is similar to maximum likelihood but with extra prior term <span class="math inline">\(P(\theta)\)</span>. Comparing to MAP, <strong>MLE chooses the value of parameters that makes the data most likely</strong>.</p>
<h1 id="ref">Ref</h1>
<p>https://online.stat.psu.edu/stat415/lesson/1/1.2</p>
<p>https://web.stanford.edu/class/archive/cs/cs109/cs109.1192/reader/11%20Parameter%20Estimation.pdf</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>random_forests</title>
    <url>/2021/07/19/random-forests/</url>
    <content><![CDATA[<h1 id="random-forest">Random Forest</h1>
<h2 id="bootstrap">Bootstrap</h2>
<h2 id="bagging">Bagging</h2>
<p>Earlier, we see that we can use bootstrap as a way of assessing the accuracy of a parameter estimate or a prediction. Here, we show how to use the bootstrap to improve the estimate or prediction itself.</p>
<p>Consider</p>
<h2 id="random-forest-1">Random Forest</h2>
<p><code>Random Forests</code> is a substantial modification of bagging that builds a large collection of <strong>de-correlated</strong> trees and then averages them. The essential idea in bagging is to average many noisy but approximately unbiased models and hence reduce the variance. Trees are ideal candidates for bagging, since they can capture complex interaction structures in the data, and if grown sufficiently deep, have relatively low bias. Since trees are notoriously noisy, they benefit greatly from the averaging (variance reduction).</p>
<p>Since each tree generated in bagging is identically distributed, the expectation of an average of <span class="math inline">\(B\)</span> such tres is the same as the expectation of any one of them, this means <strong>the bias of bagged trees is the same as that of the individual trees and the only hope is the variance reduction</strong>. This is contrast to boosting, <strong>where the trees are grown in an adaptive way to remove bias, and hence are not identically distributed</strong>.</p>
<p>An average of <span class="math inline">\(B\)</span> i.i.d random variables each with variance <span class="math inline">\(\sigma^2\)</span>, has variance <span class="math inline">\(\frac{1}{B} \sigma^2\)</span>. If the variables are simply i.d (not necessarily independent) with <strong>positive</strong> pairwise correlation <span class="math inline">\(\rho\)</span>, the variance of the average is:</p>
<p><span class="math display">\[\rho \sigma^2 + \frac{1 - \rho}{B} \sigma^2\]</span></p>
<p>As <span class="math inline">\(B\)</span> increases, the second term disappears, but the first remains, and hence <strong>the size of the correlation of paris of bagged trees limits the benefits of averaging</strong>. The idea in random forest is to improve the variance reduction of bagging by reducing the correlation between the trees without increasing the variance too much. This is achieved in the tree-growing process through random selection of the input variables.</p>
<p>Specifically, when growing a tree on a bootstrapped dataset:</p>
<ul>
<li>Before each split, select <span class="math inline">\(m \leq p\)</span> of the input variables at random as candidates for splitting (typically values for <span class="math inline">\(m\)</span> are <span class="math inline">\(\sqrt{p}\)</span> or even as low as 1)</li>
<li>After <span class="math inline">\(B\)</span> such trees <span class="math inline">\(\{T(\mathbf{x};\; \Theta_b)\}^{B}_{b=1}\)</span> are grown, the random forest regression predictor is: <span class="math display">\[\hat{f}^B_{rf} (\mathbf{x}) = \frac{1}{B}\sum^{B}_{b=1} T(\mathbf{x};\; \Theta_b)\]</span></li>
<li>For classification, a random forest obtains a class vote from each tree, and then classifies using majority vote.</li>
</ul>
<p><img src='/images/ML/rf_1.png' width="600"></p>
<h3 id="out-of-bag-samples">Out of Bag Samples</h3>
<p>An importance feature of random forest is its use of <code>out-of-bag</code> samples:</p>
<ul>
<li>For each observation <span class="math inline">\(\mathbf{z}_i = (\mathbf{x}_i, y_i)\)</span>, construct its random forest predictor by averaging only those trees corresponding to bootstrap samples in which <span class="math inline">\(\mathbf{z}_i\)</span> did not appear.</li>
</ul>
<p>An out-of-bag error estimate (If short of data, it can be used as validation error) is almost identical to that obtained by <span class="math inline">\(N\)</span>-fold cross validation, so unlike many other nonlinear estimators, random forest can be fit in one sequence, with cross-validation being performed along the way. Once the OOB error stabilizes, the training can be terminated.</p>
<h3 id="variable-importance">Variable Importance</h3>
<p>Random forests also use the OOB samples to construct a different variable-importance measure, apparently to measure the prediction strength of each variable. When the <span class="math inline">\(b\)</span>th tree is grown, the OOB samples are passed down the tree, and the prediction accuracy is recorded. The values for the <span class="math inline">\(j\)</span>th variable are randomly permuted in the OOB samples, and the accuracy is again computed. The decrease in accuracy as a result of this permuting is averaged over all trees, and is used as a measure of the importance of variable <span class="math inline">\(j\)</span> in the random forest.</p>
<h3 id="overfitting">Overfitting</h3>
<p>It is certainly true that increasing <span class="math inline">\(B\)</span> does not cause the random forest sequence to overfit. like bagging, the random forest estimate approximates the expectation:</p>
<p><span class="math display">\[\hat{f}_{rf} (\mathbf{x}) = E[T(\mathbf{x}; \; \Theta)] = \lim_{B \rightarrow \infty} \hat{f}(\mathbf{x})^B_{rf}\]</span></p>
<p>with an average over <span class="math inline">\(B\)</span> realizations of <span class="math inline">\(\Theta\)</span>. However, <strong>this limit can overfit the data, the average of fully grown trees can result in too rich a model and incur unnecessary variance.</strong> One possible solution is to reduce tree depth.</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Probability (1)</title>
    <url>/2021/05/11/probability/</url>
    <content><![CDATA[<h1 id="probability-background-1">Probability Background (1)</h1>
<h2 id="sets">Sets</h2>
<p>A set is a collection of objects, which are the elements of set. If S is a set and <span class="math inline">\(x\)</span> is an element of <span class="math inline">\(S\)</span>, we write <span class="math inline">\(x \in S\)</span>. If <span class="math inline">\(x\)</span> is not an element of <span class="math inline">\(S\)</span>, we write <span class="math inline">\(x \notin S\)</span>. A set can have no elements, in which case it is called the empty set, denoted by <span class="math inline">\(\emptyset\)</span>.</p>
<h3 id="finite-countable-uncountable">Finite, Countable, Uncountable</h3>
<p>If <span class="math inline">\(S\)</span> contains a finite number of elements, say <span class="math inline">\(x_1, x_2, ..., x_n\)</span>, we write it as list of the elements in braces:</p>
<p><span class="math display">\[S = \{x_1, x_2, ...., x_n\}\]</span></p>
<p>if <span class="math inline">\(S\)</span> contains countable infinitely many elements <span class="math inline">\(x_1, x_2, ...\)</span>, we can write:</p>
<p><span class="math display">\[S = \{x_1, x_2, ... \}\]</span></p>
<p><span class="math inline">\(S\)</span> is countable infinite, if the set is countable but has infinitely many elements. However, a set with uncountable elements can not be written down in a list.</p>
<p>We can denote set of all <span class="math inline">\(x\)</span> that have certain property <span class="math inline">\(P\)</span>:</p>
<p><span class="math display">\[\{x | x \text{ satisfies } P\}\]</span></p>
<p>ie. the set of even integers can be written as <span class="math inline">\(\{k | k/2 \text{ is integer}\}\)</span>, <span class="math inline">\(\{x | 0 \leq x \leq 1\}\)</span> (uncountable)</p>
<span id="more"></span>
<h3 id="subsets-and-universal-set">Subsets and Universal set</h3>
<p>If every element of a set <span class="math inline">\(S\)</span> is also an element of a set <span class="math inline">\(T\)</span>, then <span class="math inline">\(S\)</span> is a subset of <span class="math inline">\(T\)</span>, we denote as <span class="math inline">\(S \subset T\)</span> or <span class="math inline">\(T \subset S\)</span>. If <span class="math inline">\(S \subset T\)</span> and <span class="math inline">\(T \subset S\)</span>, the two sets are equal. We also denote universal set to be <span class="math inline">\(\Omega\)</span> which contains all objects that could conceivably be of interest in a particular context.</p>
<h3 id="set-functions">Set Functions</h3>
<p>Many of the functions used in calculus are functions that map real numbers into real numbers. We are concerned also with functions that map sets into real numbers. Such functions are naturally called functions of a set or more simply <strong>set functions</strong>. They are usually used to measure subsets of a given set.</p>
<p>Examples:</p>
<blockquote>
<p>Let <span class="math inline">\(C=\mathbf{R}\)</span>, the set of real numbers. For a subset <span class="math inline">\(A \in C\)</span>, let <span class="math inline">\(Q(A)\)</span> be equal to the number of points in <span class="math inline">\(A\)</span> that correspond to positive integers. Then <span class="math inline">\(Q(A)\)</span> is a set function of the set <span class="math inline">\(A\)</span>. Thus, if <span class="math inline">\(A = \{x: 0 &lt; x &lt; 5\} \implies Q(A) = 4\)</span></p>
</blockquote>
<p>Often our set functions are defined in terms of sums or integrals, the symbol:</p>
<p><span class="math display">\[\int_A f(x) dx\]</span></p>
<p>means the ordinary integral of <span class="math inline">\(f(x)\)</span> over a prescribed one-dimensional set <span class="math inline">\(A\)</span>, and the symbol</p>
<p><span class="math display">\[\underset{A}{\int\int} g(x, y) dx dy\]</span></p>
<p>means the integral of <span class="math inline">\(g(x, y)\)</span> over a prescribed two-dimensional set <span class="math inline">\(A\)</span>.</p>
<p>Examples:</p>
<blockquote>
<p>Let <span class="math inline">\(C\)</span> be the set of all nonnegative integers and let <span class="math inline">\(A\)</span> be a subset of <span class="math inline">\(C\)</span>. Define the set function <span class="math inline">\(Q\)</span> by <span class="math display">\[Q(A) = \sum_{n \in A} 3^{n}\]</span></p>
</blockquote>
<blockquote>
<p>Let <span class="math inline">\(C\)</span> be the interval of positive real numbers, <span class="math inline">\(C = (0, \infty)\)</span>. Let <span class="math inline">\(A\)</span> be a subset of <span class="math inline">\(C\)</span>. Define the set function <span class="math inline">\(Q\)</span> by <span class="math display">\[Q(A = \int_{A} e^{-x} dx\]</span> <span class="math display">\[Q((1, 3)) = \int^{3}_{1} e^{-x} dx\]</span> <span class="math display">\[Q(C) = \int^{\infty}_{0} e^{-x} dx = 1\]</span></p>
</blockquote>
<h2 id="probability-models">Probability Models</h2>
<p>A probabilistic model is a mathematical description of an uncertain situation.</p>
<p><img src='/images/RL/background/prob_1.png' width="600"></p>
<h3 id="sample-spaces-and-events">Sample Spaces and Events</h3>
<p>Every probabilistic model involves an underlying process, called the <strong>experiment</strong>, that will produce exactly <strong>one</strong> out of several possible outcomes. The set of all possible outcomes is called the sample space of the experiment, and is denoted by <span class="math inline">\(\Omega\)</span> (Universal Set). A subset of the sample space, that is, a collection of possible outcomes, is called an <strong>event</strong>. Any collection of possible outcomes, including the entire sample space <span class="math inline">\(\Omega\)</span> and its complement the empty set. There is no restriction on what constitutes an experiment. (ie. it can be one toss of the coin, three tosses of coin, or an infinite sequence of tosses). However, in this formulation, there is only one experiment (three tosses is one experiment rather than three experiments).</p>
<p>The sample space of an experiment may consist of a finite, or an infinite number of possible outcomes.</p>
<p>Regardless of their number. different elements of the sample space should be <strong>distinct and mutually exclusive</strong>, so that when the experiment is carried out there is a unique outcome. For example, the sample space associated with the roll of a die cannot contain "1 or 3" as a possible outcome and also "1 or 4" as another possible outcome. If it did, we would not be able to assign a unique outcome when the roll is a 1.</p>
<p>A given physical situation may be modeled in several ways, depending pending on the kind of questions that we are interested in . Generally, the sample space chosen for a probabilistic model must be <strong>collectively exhaustive</strong>, in the sense that no matter what happens in the experiment, we always obtain an outcome that has been included in the sample space. In addition, the sample space should have enough detail to distinguish between all outcomes of interest to the modeler, while avoiding irrelevant details.</p>
<p><img src="/images/RL/background/prob_2.png" width="600"> <img src="/images/RL/background/prob_3.png" width="600"></p>
<h3 id="probability-laws-and-probability-set-function">Probability Laws and Probability Set Function</h3>
<p>Given an experiment, let <span class="math inline">\(C\)</span> denotes the sample space of all possible outcomes. We assume that in all cases:</p>
<ol type="1">
<li>The collection of events is sufficiently rich to include all possible events of interest.</li>
<li>The collection is closed under complements and countable unions of these events.</li>
<li>The collection is closed under countable intersections.</li>
</ol>
<p>Technically, such a collection of events <span class="math inline">\(\mathbb{B}\)</span> is called a <strong><span class="math inline">\(\sigma-\)</span>field of subsets</strong>.</p>
<p><img src="/images/RL/background/prob_15.png" width="600"></p>
<p><img src="/images/RL/background/prob_14.png" width="600"></p>
<p>In order to visualize a probability law. Consider a unit of mass which is spread over the sample space. Then, <span class="math inline">\(P(A)\)</span> is simply the total mass that was assigned collectively to the elements of A. For example, <span class="math inline">\(\Omega = {1, 2, 3, 4, 5, 6}, A = {1, 2}\)</span>, <span class="math inline">\(P(A) = \frac{1}{3}\)</span></p>
<p>A collection of events whose members are pairwise disjoint, is said to be a mutually exclusive collection and its union is often referred to as a disjoint union. The collection is further said to be <strong>exhaustive</strong> if the union of its events is the sample space. in which case <span class="math inline">\(\sum^{\infty}_{n=1} P(A_n) = 1\)</span>. We often say that a mutually exclusive and exhaustive collection of events forms a <strong>partition</strong> of the sample space <span class="math inline">\(C\)</span>.</p>
<p>The probability set function <span class="math inline">\(P: \mathbb{B} \rightarrow \mathbb{R}\)</span> tells us how the probability is distributed over the set of events, <span class="math inline">\(\mathbb{B}\)</span>. In this sense, we speak of a distribution of probability. We often drop the word set and refer to <span class="math inline">\(P\)</span> as the probability function.</p>
<h4 id="discrete-model">Discrete Model</h4>
<p><img src="/images/RL/background/prob_4.png" width="600"> <img src="/images/RL/background/prob_5.png" width="600"></p>
<h3 id="additional-properties-of-probability">Additional Properties of Probability</h3>
<p><img src="/images/RL/background/prob_16.png" width="600"></p>
<p><img src="/images/RL/background/prob_17.png" width="600"></p>
<p><br></p>
<p>The <strong>Inclusion Exclusion Formula</strong>:</p>
<p><span class="math display">\[P(C_1 \cup C_2 \cup C_3) = p_1 - p_2 + p_3\]</span></p>
<p>Where:</p>
<p><span class="math display">\[p_1 = P(C_1) + P(C_2) + P(C_3)\]</span></p>
<p><span class="math display">\[p_2 = P(C_1 \cap C_2) + P(C_1 \cap C_3) + P(C_2 \bigcap C_3)\]</span></p>
<p><span class="math display">\[p_3 = P(C_1 \cap C_2 \cap C_3)\]</span></p>
<p>The <strong>Bonferroni's inequality</strong>:</p>
<p><span class="math display">\[P(C_1 \cap C_2) \geq P(C_1) + P(C_2) - 1\]</span></p>
<h2 id="conditional-probability">Conditional Probability</h2>
<p>In some random experiment, we are interested only in those outcomes that are elements of a subset <span class="math inline">\(A\)</span> of the sample space <span class="math inline">\(C\)</span>. This means, for our purposes, that the sample space is effectively the subset <span class="math inline">\(A\)</span>.</p>
<p>Let the probability set function <span class="math inline">\(P(A)\)</span> be defined on the sample space <span class="math inline">\(C\)</span> and let <span class="math inline">\(A\)</span> be a subset of <span class="math inline">\(C\)</span> such that <span class="math inline">\(P(A &gt; 0)\)</span>. We only take those outcomes of the random experiment that are elements of <span class="math inline">\(A\)</span> to be the sample space. Let <span class="math inline">\(B\)</span> be another subset of <span class="math inline">\(C\)</span>. The <strong>conditional probability</strong> of event <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span> is denoted by the symbol <span class="math inline">\(P(B | A)\)</span> .</p>
<p>Since <span class="math inline">\(A\)</span> is now the sample space, the only elements of <span class="math inline">\(B\)</span> that concern us are those that are also elements of <span class="math inline">\(A\)</span>, that is the elements of <span class="math inline">\(A \cap B\)</span> and <span class="math inline">\(A\)</span>, relative to the space <span class="math inline">\(A\)</span>, be the same as the ratio of the probabilities of these events relative to the space <span class="math inline">\(C\)</span>, that is, we should have:</p>
<p><span class="math display">\[P(A | A) = 1 \;\;\;\;\;\; P(A \cap B | A) = P(B | A)\]</span></p>
<p>Moreover, it would seem logically inconsistent if we did not require that the ratio of the probabilities of the events <span class="math inline">\(A \cap B\)</span> and <span class="math inline">\(A\)</span>, relative to the space <span class="math inline">\(A\)</span>, be the same as the ratio of the probabilities of these events relative to the space <span class="math inline">\(C\)</span> (ie. if <span class="math inline">\(P(A) = 0.5, P(B) = 0.2, P(A \cap B) = 0.1, P(A) / P(C) = 1 / 2, P(A \cap B | A) = 0.2\)</span>), that is, we should have:</p>
<p><span class="math display">\[\frac{P(A \cap B | A) }{P(A | A)} = \frac{P(A \cap B)}{P(A)}\]</span></p>
<p><img src="/images/RL/background/prob_18.png" width="600"></p>
<p><br></p>
<p><span class="math inline">\(P(B|A)\)</span> the conditional probability set function, defined for subsets of <span class="math inline">\(A\)</span>.</p>
<p>Conditional probability provides us with a way to reason about the outcome of an experiment, based on <strong>partial information</strong>. In more precise terms, given an experiment, a corresponding sample space, and a probability law, suppose that we know that the outcome is within some given event <span class="math inline">\(B\)</span>. We wish to quantify the likelihood that the outcome also belongs to some other given event <span class="math inline">\(A\)</span>. This concept specifies the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, denoted by <span class="math inline">\(P(A | B)\)</span>.</p>
<p>Furthermore, for a fixed event <span class="math inline">\(B\)</span>, it can be verified that the conditional probabilities <span class="math inline">\(P(A | B), \forall A\)</span> form a legitimate probability law that satisfies the requirements.</p>
<h3 id="chain-rule">Chain Rule</h3>
<p><img src="/images/RL/background/prob_7.png" width="600"></p>
<h3 id="law-of-total-probability">Law of Total Probability</h3>
<p><img src="/images/RL/background/prob_8.png" width="600"></p>
<h3 id="bayes-rule">Bayes' Rule</h3>
<p><img src="/images/RL/background/prob_9.png" width="600"></p>
<h2 id="random-variables">Random Variables</h2>
<p>Given an experiment and the corresponding set of possible outcomes (the sample space), a <strong>random variable</strong> is a real-valued <strong>function</strong> (max, min etc.) of experiment outcome that associates a <strong>particular number with each outcome</strong>. We refer to this number as the numerical value or simply the value of the random variable.</p>
<p><img src="/images/RL/background/prob_19.png" width="600"> <img src="/images/RL/background/prob_11.png" width="600"> <img src="/images/RL/background/prob_10.png" width="600"></p>
<h3 id="distribution-of-random-variable">Distribution of Random Variable</h3>
<p>Given a random variable <span class="math inline">\(X\)</span>, its range <span class="math inline">\(\mathbb{D}\)</span> becomes <strong>the sample space of interest</strong>. Besides, inducing the sample space <span class="math inline">\(\mathbb{D}\)</span>, <span class="math inline">\(X\)</span> also induces a probability which we call the distribution of <span class="math inline">\(X\)</span>.</p>
<p>Assume <span class="math inline">\(X\)</span> is a discrete random variable with a finite space <span class="math inline">\(\mathbb{D} = \{d_1, ...., d_m\}\)</span>. Define the function <span class="math inline">\(p_{X} (d_i)\)</span> on <span class="math inline">\(\mathbb{D}\)</span> by:</p>
<p><span class="math display">\[p_X(d_i) = P[\{c: X(c) = d_i\}], \quad \quad \forall i=1, .... ,m\]</span></p>
<p><br></p>
<p>Which is the probability of event that contains the outcomes with value <span class="math inline">\(X(c) = d_i\)</span>, this is called the <strong>probability mass function</strong> of <span class="math inline">\(X\)</span>. Then the <strong>induced probability distribution</strong>, <span class="math inline">\(P_X (\cdot): D \rightarrow \mathbb{R}\)</span>, of <span class="math inline">\(X\)</span> is:</p>
<p><span class="math display">\[P_X (D) = \sum_{d_i \in D} p_X (d_i), \quad \quad D \subset \mathbb{D}\]</span></p>
<p>Similar to <span class="math inline">\(P\)</span> which is defined on <span class="math inline">\(\mathbb{B}\)</span>. This <span class="math inline">\(P_X (\cdot)\)</span> is basically the probability distribution of events defined on sets <span class="math inline">\(D\)</span>, <span class="math inline">\(P_X (D)\)</span> is the probability of event <span class="math inline">\(D\)</span> defined on <span class="math inline">\(\mathbb{D}\)</span>.</p>
<h3 id="cumulative-distribution-function">Cumulative Distribution Function</h3>
<p>The pmf of discrete random variable and the pdf of a continuous random variable are quite different entities. The distribution function, though, uniquely determines the probability distribution of a random variable:</p>
<p><img src="/images/RL/background/prob_20.png" width="600"></p>
<p><strong>Note that, cdf is defined <span class="math inline">\(\quad \forall x \in \mathbb{R}\)</span>.</strong></p>
<p>Remember that <span class="math inline">\(P_X (\cdot)\)</span> is the probability set function (distribution) of the random variable <span class="math inline">\(X\)</span>. The cdf is the probability of event (subset of <span class="math inline">\(\mathbb{D}\)</span>, the random variable range space): <span class="math inline">\(\{a: a \leq x, a \in \mathbb{D}\}\)</span>, this is the same as the event (defined on sample space): <span class="math inline">\(\{c: X(c) \leq x, c \in \mathbb{B}\}\)</span>.</p>
<p><br></p>
<h3 id="equal-in-distribution">Equal in Distribution</h3>
<p>Let <span class="math inline">\(X, Y\)</span> be two random variables. We say that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <strong>equal in distribution</strong> and write:</p>
<p><span class="math display">\[X \overset{D}{=} Y\]</span></p>
<p>IFF:</p>
<p><span class="math display">\[F_X(x) = F_Y (x), \quad \quad \quad \forall x \in \mathbb{R}\]</span></p>
<p>Notice that, equal in distribution does not mean the random variables are the same. For examples, let <span class="math inline">\(X\)</span> be a random variable sampled from range <span class="math inline">\([0, 1)\)</span>, let <span class="math inline">\(Y = 1 - X\)</span>, then <span class="math inline">\(Y\)</span> also has range <span class="math inline">\([0, 1)\)</span>. At the same time, for <span class="math inline">\(x &lt; 0\)</span>, the cdf for both random variables is 0, for <span class="math inline">\(x &lt; 0\)</span>, the cdf for both random variables is 1. And, for <span class="math inline">\(0 \leq x &lt; 1\)</span>, the cdf is <span class="math inline">\(x\)</span> for both random variables. But this two random variables are clearly different.</p>
<p><img src="/images/RL/background/prob_21.png" width="600"></p>
<p><br></p>
<h3 id="theorems-for-cdf">Theorems for CDF</h3>
<p><img src="/images/RL/background/prob_22.png" width="600"></p>
<p><img src="/images/RL/background/prob_23.png" width="600"></p>
<p><strong>Proof of Theorem 1.5.2</strong></p>
<p>Note that the event <span class="math inline">\(\{-\infty &lt; X \leq b\} = \{-\infty &lt; X \leq a\} \cup \{a &lt; X \leq b\}\)</span>, Then <span class="math inline">\(\{-\infty &lt; X \leq a\} \cup \{a &lt; X \leq b\}\)</span> are disjoint events, which means:</p>
<p><span class="math display">\[P_X(\{-\infty &lt; X \leq a\} \cup \{a &lt; X \leq b\}) = P_X(\{-\infty &lt; X \leq a\}) + P_X(\{a &lt; X \leq b\})\]</span></p>
<p>Then,</p>
<span class="math display">\[\begin{aligned}
P(\{-\infty &lt; X \leq b\}) &amp;= P_X(\{-\infty &lt; X \leq a\}) + P_X(\{a &lt; X \leq b\})\\
\implies F_X (b) &amp;= F_X(a) + P_X(\{a &lt; X \leq b\})\\
\end{aligned}\]</span>
<p><br></p>
<p><img src="/images/RL/background/prob_24.png" width="600"></p>
<p>This basically means that the discontinuities of a cdf have mass. That is, if <span class="math inline">\(x\)</span> is a point of discontinuity of <span class="math inline">\(F_x\)</span>, then we have <span class="math inline">\(P(X=x) &gt; 0\)</span>.</p>
<p>Example:</p>
<blockquote>
<p>Let <span class="math inline">\(X\)</span> have discontinuous cdf: <span class="math display">\[
F_X(x)=
\begin{cases}
0, \quad &amp;x &lt; 0\\
\frac{x}{2}, \quad &amp;0 \leq x &lt; 1\\
1, \quad &amp;1 \leq x
\end{cases}
\]</span> Then: <span class="math display">\[P(X=1) = F_X (1) - F_X(1 - ) = 1 - \frac{1}{2} = \frac{1}{2}\]</span></p>
</blockquote>
<h3 id="discrete-random-variables">Discrete Random Variables</h3>
<p><img src="/images/RL/background/prob_25.png" width="600"></p>
<p><img src="/images/RL/background/prob_26.png" width="600"></p>
<p>If a function satisfies properties 1, 2 of the pmf, then this function <span class="math inline">\(p_X\)</span> uniquely determines the distribution (probability set function) of a random variable <span class="math inline">\(P_X\)</span>.</p>
<h4 id="support">Support</h4>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable with space <span class="math inline">\(\mathbb{D}\)</span>. We define the <code>support</code> of a discrete random variable <span class="math inline">\(X\)</span> to be the points in the space (range) of <span class="math inline">\(X\)</span> which have positive probability. We often denote <span class="math inline">\(S\)</span> as the support of <span class="math inline">\(X\)</span>. Note that <span class="math inline">\(S \in \mathbb{D}\)</span>, but it may be that <span class="math inline">\(S = \mathbb{D}\)</span>.</p>
<p>If <span class="math inline">\(x \in S\)</span>, then <span class="math inline">\(p_X (x)\)</span> is equal to the size of the discontinuity of <span class="math inline">\(F_X\)</span> at <span class="math inline">\(x\)</span>. If <span class="math inline">\(x \neq S\)</span> then <span class="math inline">\(P[X=x] = 0\)</span> and hence, <span class="math inline">\(F_X\)</span> is continues at this <span class="math inline">\(x\)</span>.</p>
<h4 id="transformations">Transformations</h4>
<p>If we have a random variable <span class="math inline">\(X\)</span> and we know its distribution (<span class="math inline">\(P_X, p_X\)</span>). We are interested, though, in a random variable <span class="math inline">\(Y\)</span> which is some transformation of <span class="math inline">\(X\)</span> say <span class="math inline">\(g(X) = Y\)</span>. In particular, we want to determine the distribution of <span class="math inline">\(Y\)</span>. Assume <span class="math inline">\(X\)</span> is discrete with space <span class="math inline">\(\mathbb{D}_X\)</span>. Then the space of <span class="math inline">\(Y\)</span> is <span class="math inline">\(D_Y = {g(x): x \in \mathbb{D}_X}\)</span>. We consider two case of <span class="math inline">\(g\)</span>:</p>
<ol type="1">
<li><p>If <span class="math inline">\(g\)</span> is one to one. Then, clearly, the pmf of <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[p_Y (y) = P_Y(Y = y) = P_X(g(X) = y) = p_X (X = g^{-1} (y)) = p_X (g^{-1} (y))\]</span></p></li>
<li><p>If <span class="math inline">\(g\)</span> is not one to one. We basically infer the pmf of <span class="math inline">\(Y\)</span> in a straight forward manner: For each value of <span class="math inline">\(Y=y\)</span>, we infer it:</p>
<p><span class="math display">\[P_X(\{x: g(x) = y, x \in \mathbb{D}\})\]</span></p></li>
</ol>
<p><br></p>
<p>Example (case 1):</p>
<blockquote>
<p>Let X have the pmf: <span class="math display">\[
p_X(x)=
\begin{cases}
\frac{3!}{x!(3 - x)!} {\frac{2}{3}}^x {\frac{1}{3}}^{3 - x}, \quad &amp;x = 0, 1, 2, 3\\
0, \quad &amp;\text{o. w}\\
\end{cases}
\]</span> If <span class="math inline">\(Y = 2X\)</span>, then this is a one to one mapping and <span class="math inline">\(\frac{1}{2} Y = X\)</span>, the pmf of <span class="math inline">\(Y\)</span>: <span class="math display">\[p_Y (y) = p_X (\frac{1}{2} y)\]</span> That is: <span class="math display">\[
p_Y(y)=
\begin{cases}
\frac{3!}{(\frac{1}{2} y)!(3 - \frac{1}{2} y)!} {\frac{2}{3}}^x {\frac{1}{3}}^{3 - \frac{1}{2} y}, \quad &amp;y = 0, \frac{1}{2}, 1, \frac{3}{2}\\
0, \quad &amp;\text{o. w}\\
\end{cases}
\]</span></p>
</blockquote>
<p>Example (case 2):</p>
<blockquote>
<p>If <span class="math inline">\(Y = X^2\)</span>, for <span class="math inline">\(\mathbb{D_X} = \{-1, 1\}\)</span>. Then the pmf of <span class="math inline">\(Y\)</span>: <span class="math display">\[
p_Y(y)=
\begin{cases}
P_X (\{-1, 1\}) = \underset{x \in \{-1, 1\}}{\sum} p_X (x), \quad &amp;y = 1\\
0, \quad &amp;\text{o. w}\\
\end{cases}
\]</span></p>
</blockquote>
<h3 id="continuous-random-variables">Continuous Random Variables</h3>
<p><img src="/images/RL/background/prob_27.png" width="600"></p>
<p>Recall that, a point of discontinuity in cdf has <span class="math inline">\(P(X=x) = F_X(x) - F_X (x -) &gt; 0\)</span>, for any random variable. Hence, for a continuous random variable <span class="math inline">\(X\)</span>, there are no points of discrete mass <span class="math inline">\(\implies P(X=x) =0, \quad \forall x \in \mathbb{R}\)</span>. Most continuous random variables are <code>absolutely continuous</code>:</p>
<p><span class="math display">\[F_X (x) = \int^{x}_{-\infty} f_X(t) dt\]</span></p>
<p>For some function <span class="math inline">\(f_X\)</span> or <span class="math inline">\(f_X (t)\)</span>. The function <span class="math inline">\(f_X (t)\)</span> is called a <code>probabability density function</code> (pdf) of <span class="math inline">\(X\)</span>. If <span class="math inline">\(f_X (x)\)</span> is also continuous, then the fundamental theorem of calculus implies that:</p>
<p><span class="math display">\[\frac{d}{dx}F_X (x) = \frac{d}{dx}\int^{x}_{-\infty} f_X(t) dt = f_X (x)\]</span></p>
<p><br></p>
<p>The <code>support</code> <span class="math inline">\(S\)</span> of a continuous random variable <span class="math inline">\(X\)</span> consists of all points <span class="math inline">\(x\)</span> such that <span class="math inline">\(f_X(x) &gt; 0\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> is a continuous random variable, then probabilities can be obtained by integration:</p>
<p><span class="math display">\[P_X (a &lt; X \leq b) = F_{X} (b) - F_{X} (a) = \int^{b}_{-\infty} f_X(t) dt - \int^{a}_{-\infty} f_X(t) dt = \int^{b}_{a} f_X(t) dt\]</span></p>
<p>Also, for continuous random variables:</p>
<p><span class="math display">\[P_X(a &lt; X \leq b) = P_X(a \leq X \leq b) = P_X (a \leq X &lt; b) = P_X(a &lt; X &lt; b)\]</span></p>
<p>The pdfs satisfy two properties:</p>
<p><span class="math display">\[f_X(x) \geq 0 \quad \quad \quad \int^{\infty}_{-\infty} f_X(t) dt = 1\]</span></p>
<p>At the same time, if a function satisfies the above two properties then it is a pdf for a continuous random variable.</p>
<h4 id="quantiles">Quantiles</h4>
<p><code>Quantile</code> (percentiles) are easily interpretable characteristics of a distribution.</p>
<p><img src="/images/RL/background/prob_28.png" width="600"></p>
<p><code>Median</code> is the quantile <span class="math inline">\(\xi_{\frac{1}{2}}\)</span>. It is a point in the domain of <span class="math inline">\(X\)</span> that divides the mass of the pdf into its lower and upper halves. The first and third quartiles divide each of these halves into quarters. They are respectively <span class="math inline">\(\xi_{\frac{1}{4}}, \xi_{\frac{3}{4}}\)</span>. We label them <span class="math inline">\(q_1, \; q_2, \; q_3\)</span> respectvely. The difference <span class="math inline">\(iqr = q_3 - q_1\)</span> is called the <code>inter-quartile range</code> of <span class="math inline">\(X\)</span>.</p>
<p>The median is often used as a measure of center of the distribution of <span class="math inline">\(X\)</span> (<span class="math inline">\(P_X\)</span>), while the interquartile range is used as a measure of <code>spread</code> and <code>dispersion</code> of the distribution of <span class="math inline">\(X\)</span>.</p>
<p><strong>Quantiles need not be unique even for continuous random variables with pdfs.</strong></p>
<p>Example:</p>
<blockquote>
<p>Any point in the interval (2, 3) serves as a median for the following pdf <span class="math display">\[
f(x)=
\begin{cases}
3(1 - x)(x - 2), \quad &amp;1 &lt; x &lt; 2\\
3(3 - x)(x - 4), \quad &amp;3 &lt; x &lt; 4\\
0, \quad &amp; o. w\
\end{cases}
\]</span></p>
</blockquote>
<p><br></p>
<p>If, however, a quantile, say <span class="math inline">\(\xi\)</span> is in the support of an absolutely continuous random variable <span class="math inline">\(X\)</span> with cdf <span class="math inline">\(F_X(x)\)</span> then <span class="math inline">\(\xi\)</span> is unique solution to the equation:</p>
<p><span class="math display">\[P_X (X &lt; \xi) = p \implies F_X (\xi) = p \implies \xi = F^{-1}_X (p)\]</span></p>
<h4 id="transformations-1">Transformations</h4>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable with pdf <span class="math inline">\(f_X\)</span>. Let <span class="math inline">\(Y = g(X)\)</span> be some transformation of <span class="math inline">\(X\)</span>. We can obtain the pdf of <span class="math inline">\(Y\)</span> by first obtain its cdf.</p>
<p>Example:</p>
<blockquote>
<p><span class="math display">\[
F_X(x)=
\begin{cases}
0, \quad &amp;x &lt; 0\\
x^2, \quad &amp;0 \leq x &lt; 1\\
1, \quad &amp; 1 \leq x
\end{cases}
\]</span> Let <span class="math inline">\(Y = X^2\)</span> and let <span class="math inline">\(y\)</span> be in the support of <span class="math inline">\(Y\)</span>, that is <span class="math inline">\(0&lt; f_Y(y) \implies 0 &lt; y &lt; 1\)</span> (If <span class="math inline">\(y = 1 \implies f_Y (y) = 0\)</span>). <span class="math display">\[F_Y(y) = P_Y (Y &lt; y) = P_X (X &lt; \sqrt{y}) = F_X (\sqrt{y}), \quad \forall 0 &lt; y &lt; 1\]</span> <span class="math display">\[\implies F_Y(y) = F_X (\sqrt(y)) = y, \quad \forall 0 &lt; y &lt; 1\]</span> <span class="math display">\[
\implies f_Y(y)=
\begin{cases}
1, \quad &amp;0 &lt; y &lt; 1\\
0, \quad &amp;o.w
\end{cases}
\]</span></p>
</blockquote>
<p><br></p>
<p><img src="/images/RL/background/prob_29.png" width="600"></p>
<p><strong>Proof</strong>:</p>
<p><span class="math display">\[F_Y(y) = P(X &lt; g^{-1} (y) = F_X (g^{-1} (y)) \implies \frac{d}{dy} F_Y(y) = \frac{d}{dy} F_X (g^{-1} (y)) = f_X (g^{-1} y) |\frac{d}{dy} g^{-1} (y)|\]</span></p>
<p><br></p>
<p>In this case, we refer <span class="math inline">\(\frac{d}{dy} g^{-1} (y)\)</span> as the <code>Jacobian of the inverse transformation</code>.</p>
<p><img src="/images/RL/background/prob_30.png" width="600"></p>
<h3 id="expectation">Expectation</h3>
<p>When dealing with R.V that takes a countably infinite number of values, one has to deal with the possibility that the infinite sum <span class="math inline">\(\sum_x xp_X(x)\)</span> is not well-defined. More concretely, the expectation is well-defined if</p>
<p><span class="math display">\[\sum_x |x| p_X(x) &lt; \infty\]</span></p>
<p><img src="/images/RL/background/prob_31.png" width="600"></p>
<p>Sometimes, the expectation <span class="math inline">\(E[x]\)</span> is called the <code>mathmematical expectation</code> of <span class="math inline">\(X\)</span>, the <code>expected value</code> of <span class="math inline">\(X\)</span> or the <code>mean</code> of <span class="math inline">\(X\)</span>. When the name mean is used, we often denote the <span class="math inline">\(E[X]\)</span> by <span class="math inline">\(\mu\)</span>.</p>
<h1 id="reference">Reference</h1>
<ol type="1">
<li>D. P. Bertsekas and J. N. Tsitsiklis, Introduction to Probability, NH, Nashua:Athena Scientific, 2008.</li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Real Analysis (2)</title>
    <url>/2022/01/01/real-analysis-2/</url>
    <content><![CDATA[<h1 id="real-analysis-2">Real Analysis (2)</h1>
<h2 id="sequence">Sequence</h2>
<h3 id="the-limit-of-sequence">The Limit of Sequence</h3>
<h4 id="definition-2.2.1-definition-of-sequence">Definition 2.2.1: Definition of Sequence</h4>
<p>A <strong>sequence</strong> is a function whose domain is <span class="math inline">\(\mathbb{N}\)</span>. Given a function <span class="math inline">\(f: \mathbb{N} \rightarrow \mathbb{R}\)</span>, <span class="math inline">\(f(n)\)</span> is just the <span class="math inline">\(n\)</span>th term on the list.</p>
<blockquote>
<p><span class="math inline">\((1, \frac{1}{2}, \frac{1}{3}...)\)</span> is a sequence: <span class="math display">\[f(n) = \{n \in \mathbb{N}: \frac{1}{n}\}\]</span></p>
</blockquote>
<h4 id="definition-2.2.3-convergence-of-a-sequence">Definition 2.2.3: Convergence of a Sequence</h4>
<p>A sequence <span class="math inline">\((a_n)\)</span> converges to a real number <span class="math inline">\(a\)</span> if, for every positive number <span class="math inline">\(\epsilon\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that whenever <span class="math inline">\(n \geq \mathbb{N}\)</span>, it follows that <span class="math inline">\(|a_n - a| &lt; \epsilon\)</span>.</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} a_n = a\]</span></p>
<h4 id="definition-2.2.4">Definition 2.2.4</h4>
<p>Given a real number <span class="math inline">\(a \in \mathbb{R}\)</span> and a positive number <span class="math inline">\(\epsilon &gt; 0\)</span>, the set:</p>
<p><span class="math display">\[V_{\epsilon} (a) = \{x \in \mathbb{R}: |x - a| &lt; \epsilon\}\]</span></p>
<p>is called the <span class="math inline">\(\boldsymbol{\epsilon-neighborhood}\)</span> of <span class="math inline">\(a\)</span>. In other words, <span class="math inline">\(V_{\epsilon} (a)\)</span> is an interval, centered at <span class="math inline">\(a\)</span>, with radius <span class="math inline">\(\epsilon\)</span>.</p>
<h4 id="definition-2.2.3b">Definition 2.2.3B</h4>
<p>A sequence <span class="math inline">\((a_n)\)</span> converges to <span class="math inline">\(a\)</span> if, given any <span class="math inline">\(\epsilon-neighborhood V_{\epsilon}(a)\)</span> of <span class="math inline">\(a\)</span>, there exists a point in the sequence after which all of the terms are in <span class="math inline">\(V_{\epsilon} (a)\)</span>.</p>
<span id="more"></span>
<h4 id="theorem-2.2.7-uniqueness-of-limits">Theorem 2.2.7: Uniqueness of Limits</h4>
<p>The limit of a sequence, when it exists, must be unique.</p>
<h3 id="the-algebraic-and-order-limit-theorems">The Algebraic and Order Limit Theorems</h3>
<h4 id="definition-2.3.1-bounded-sequence">Definition 2.3.1: Bounded Sequence</h4>
<p>A sequence <span class="math inline">\((x_n)\)</span> is <strong>Bounded</strong> if there exists a number <span class="math inline">\(M &gt; 0\)</span> such that <span class="math inline">\(|x_n| \leq M, \;\;\forall n \in \mathbb{N}\)</span>. Geometrically, this means that we can find an interval <span class="math inline">\([-M, M]\)</span> that contains every term in the sequence <span class="math inline">\((x_n)\)</span></p>
<h4 id="theorem-2.3.2">Theorem 2.3.2</h4>
<p>Every convergent sequence is bounded.</p>
<h4 id="theorem-2.3.3-algebraic-limit-theorem">Theorem 2.3.3: Algebraic Limit Theorem</h4>
<p>Let <span class="math inline">\(\lim a_n = a\)</span> and <span class="math inline">\(\lim b_n = b\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(\lim (c a_n) = ca, \forall c \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(\lim(a_n + b_n) = a + b\)</span></li>
<li><span class="math inline">\(\lim(a_n b_n) = ab\)</span></li>
<li><span class="math inline">\(\lim(a_n / b_n) = a / b\)</span> only if <span class="math inline">\(b \neq 0\)</span></li>
</ol>
<h4 id="theorem-2.3.4-order-limit-theorem">Theorem 2.3.4: Order Limit Theorem</h4>
<p>Assume <span class="math inline">\(\lim a_n = a\)</span> and <span class="math inline">\(\lim b_n = b\)</span>:</p>
<ol type="1">
<li>If <span class="math inline">\(a_n &gt; 0\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>, then <span class="math inline">\(a \geq 0\)</span>.</li>
<li>If <span class="math inline">\(a_n \leq b_n\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>, then <span class="math inline">\(a \geq b\)</span></li>
<li>If there exists <span class="math inline">\(c \in \mathbb{R}\)</span> for which <span class="math inline">\(c \leq b_n\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>, then <span class="math inline">\(c \leq b\)</span>. Similarly for <span class="math inline">\(a_n\)</span>.</li>
</ol>
<h3 id="the-monotone-convergence-theorem-and-a-first-look-at-infinite-series">The Monotone Convergence Theorem and a First Look at Infinite Series</h3>
<h4 id="definition-2.4.1-monotone">Definition 2.4.1: Monotone</h4>
<p>A sequence <span class="math inline">\((a_n)\)</span> is <strong>increasing</strong> if <span class="math inline">\(a_n \leq a_{n+1}\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span> and <strong>decreasing</strong> if <span class="math inline">\(a_n \geq a_{n+1}\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>. A sequence is <strong>monotone</strong> if it is either increasing or decreasing.</p>
<h4 id="theorem-2.4.2-monotone-convergence-theorem">Theorem 2.4.2: Monotone Convergence Theorem</h4>
<p>If a sequence is monotone and bounded, then it converges.</p>
<h4 id="definition-2.4.3-convergence-of-a-series">Definition 2.4.3: Convergence of a Series</h4>
<p>Let <span class="math inline">\((b_n)\)</span> be a sequence. An <strong>infinite series</strong> is a formal expression of the form:</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} b_n = b_1 + b_2 + b_3 +....\]</span></p>
<p>We define the corresponding <strong>sequence of partial sums</strong> <span class="math inline">\((s_m)\)</span> by</p>
<p><span class="math display">\[s_m = b_1 + b_2 + .... + b_m\]</span></p>
<p>and say that <span class="math inline">\(\sum^{\infty}_{n=1} b_n\)</span> converges to <span class="math inline">\(B\)</span> if the sequence <span class="math inline">\((s_m)\)</span> converges to <span class="math inline">\(B\)</span>. In this case, we write:</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} b_n = B\]</span></p>
<blockquote>
<p>consider the series <span class="math inline">\(\sum^{\infty}_{n=1} \frac{1}{n^2}\)</span> <span class="math inline">\(s_m = 1 + 1 - \frac{1}{m} &lt; 2\)</span> by Monotonic Convergence Theorem, we know that the sequence converges to some value <span class="math inline">\(B\)</span> that we do not know.</p>
</blockquote>
<h4 id="harmonic-series">Harmonic Series</h4>
<p><span class="math display">\[\sum^{\infty}_{n=1} \frac{1}{n}\]</span></p>
<p>The harmonic series is unbounded, thus it diverges.</p>
<h4 id="theorem-2.4.6-cauchy-condensation-test">Theorem 2.4.6: Cauchy Condensation Test</h4>
<p>Suppose <span class="math inline">\((b_n)\)</span> is decreasing and satisfies <span class="math inline">\(b_n \geq 0\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>. Then, the series <span class="math inline">\(\sum^{\infty}_{n=1} b_n\)</span> converges if and only if the series:</p>
<p><span class="math display">\[\sum^{\infty}_{n=0} 2^nb_{2^n} = b_1 + 2b_2 + 4b_4 + ...\]</span></p>
<h4 id="corollary-2.4.7">Corollary 2.4.7</h4>
<p>The series <span class="math inline">\(\sum^{\infty}_{n=1} \frac{1}{n^p}\)</span> converges if and only if <span class="math inline">\(p &gt; 1\)</span></p>
<h3 id="subsequences-and-the-bolzano-weierstrass-theorem">Subsequences and the Bolzano-Weierstrass Theorem</h3>
<h4 id="definition-2.5.1-subsequence">Definition 2.5.1: Subsequence</h4>
<p>Let <span class="math inline">\((a_n)\)</span> be a sequence of real numbers, and let $n_1 &lt; n_2 &lt; n_3 &lt; ... $ be an increasing sequence of natural numbers. Then the sequence:</p>
<p><span class="math display">\[(a_{n1}, a_{n2} ,....)\]</span></p>
<p>is called <strong>subsequence</strong> of <span class="math inline">\((a_n)\)</span> and is denoted by <span class="math inline">\((a_{nk})\)</span>, where <span class="math inline">\(k \in \mathbb{N}\)</span> indexes the subsequence. Notice that the order of the terms in a subsequence is the same as in the original sequence and repetitions are not allowed.</p>
<h4 id="theorem-2.5.2">Theorem 2.5.2</h4>
<p>Subsequences of a convergent sequence converge to the same limit as the original sequence.</p>
<h4 id="theorem-2.5.5-bolzano-weierstrass-theorem">Theorem 2.5.5: Bolzano-Weierstrass Theorem</h4>
<p>Every bounded sequence contains a convergent subsequence.</p>
<h3 id="the-cauchy-criterion">The Cauchy Criterion</h3>
<h4 id="definition-2.6.1-cauchy-sequence">Definition 2.6.1: Cauchy Sequence</h4>
<p>A sequence <span class="math inline">\((a_n)\)</span> is called a <strong>Cauchy sequence</strong> if, for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that whenever <span class="math inline">\(m, n \geq N\)</span> it follows that <span class="math inline">\(|a_n - a_m | &lt; \epsilon\)</span>.</p>
<p>This definition resembles to the definition of convergence. A sequence if a Cauchy sequence if, for every <span class="math inline">\(\epsilon\)</span>, there is a point in the sequence after whcih the terms are all close to each other than the given <span class="math inline">\(\epsilon\)</span>.</p>
<h4 id="theorem-2.6.2">Theorem 2.6.2</h4>
<p>Every convergent sequence is a Cauchy sequence.</p>
<h4 id="lemma-2.6.3">Lemma 2.6.3</h4>
<p>Cauchy sequences are bounded.</p>
<h4 id="cauchy-criterion">Cauchy Criterion</h4>
<p>A sequence is convergent if and only if it is a Cauchy sequence.</p>
<h3 id="properties-of-infinite-series">Properties of Infinite Series</h3>
<p>Given an infinite series <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span>, it is important to keep a clear distinction between:</p>
<ol type="1">
<li>the sequence of terms: <span class="math inline">\((a_1, a_2, a_3, ...)\)</span></li>
<li>the sequence of partial sums: <span class="math inline">\((s_1, s_2, s_3, ...)\)</span>, where <span class="math inline">\(s_n = a_1 + a_2 + ... + a_n\)</span></li>
</ol>
<p>The convergence of the series is defined in terms of the sequence <span class="math inline">\(s_n\)</span>. Specifically, the statement:</p>
<p><span class="math display">\[\sum^{\infty}_{k=1} a_k = A\]</span></p>
<p>Means that</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} s_n = A\]</span></p>
<h4 id="theorem-2.7.1-algebraic-limit-theorem-for-series">Theorem 2.7.1: Algebraic Limit Theorem for Series</h4>
<p>If <span class="math inline">\(\sum^{\infty}_{k=1} a_k = A\)</span> and <span class="math inline">\(\sum^{\infty}_{k=1} b_k = B\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\sum^{\infty}_{k=1} ca_k = cA, \;\forall c \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(\sum^{\infty}_{k=1} a_k + b_k = A + B\)</span></li>
</ol>
<h4 id="theorem-2.7.2-cauchy-criterion-for-series">Theorem 2.7.2: Cauchy Criterion for Series</h4>
<p>The series <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span> converges if and only if, given <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that whenever, <span class="math inline">\(n &gt; m \geq N\)</span> it follows that:</p>
<p><span class="math display">\[|a_{m+1} + a_{m+2} + .... + a_n| &lt; \epsilon\]</span></p>
<h4 id="theorem-2.7.3">Theorem 2.7.3</h4>
<p>If the series <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span> converges, then <span class="math inline">\((a_k) \rightarrow 0\)</span> (the converse is false)</p>
<h4 id="theorem-2.7.4-comparison-test">Theorem 2.7.4: Comparison Test</h4>
<p>Assume <span class="math inline">\((a_k)\)</span> and <span class="math inline">\((b_k)\)</span> are sequences satisfying <span class="math inline">\(0 \leq a_k \leq b_k, \; \forall k \in \mathbb{N}\)</span> (does not need to hold for all <span class="math inline">\(k\)</span>, only need eventually true):</p>
<ol type="1">
<li>If <span class="math inline">\(\sum^{\infty}_{k=1} b_k\)</span> converges, then <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span> converges.</li>
<li>If <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span> diverges, then <span class="math inline">\(\sum^{\infty}_{k=1} b_k\)</span> diverges.</li>
</ol>
<h4 id="definition-2.7.5-geometric-series">Definition 2.7.5: Geometric Series</h4>
<p>A series is called <strong>geometric</strong> if it is of the form:</p>
<p><span class="math display">\[\sum^{\infty}_{k=0} a r^k = a + ar + ar^2 + ar^3 + ...\]</span></p>
<p>If <span class="math inline">\(r=1\)</span> and <span class="math inline">\(a \neq 0\)</span>, the series evidently diverges. For <span class="math inline">\(r \neq 1\)</span>, the algebraic identity</p>
<p><span class="math display">\[(1 - r) (1 + r + r^2 + r^3 + ... + r^{m-1}) = 1 - r^m\]</span></p>
<p>We have:</p>
<p><span class="math display">\[s_m = a + ar + ar^2 + ar^3 + .... + ar^m = a(1 + r + r^2 + r^3 + ... + r^{m-1}) = \frac{a(1 - r^m)}{1 - r}\]</span></p>
<p>Then we have:</p>
<p><span class="math display">\[\lim_{m \rightarrow \infty} (1 - r^m) = 1\]</span> <span class="math display">\[\lim_{m \rightarrow \infty} (1 - r) = 1 - r\]</span></p>
<p>By Theorem 2.3.3(3) we have:</p>
<p><span class="math display">\[\sum^{\infty}_{k=0} a r^k = \frac{a}{1 - r}\]</span></p>
<p>only for <span class="math inline">\(|r| &lt; 1\)</span></p>
<h4 id="theorem-2.7.6-absolute-convergence-test">Theorem 2.7.6: Absolute Convergence Test</h4>
<p>If the series <span class="math inline">\(\sum^{\infty}_{n=1} |a_n|\)</span> converges, then <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> converges as well.</p>
<h4 id="theorem-2.7.7-alternating-series-test">Theorem 2.7.7: Alternating Series Test</h4>
<p>Let <span class="math inline">\((a_n)\)</span> be a sequence satisfying:</p>
<ol type="1">
<li><span class="math inline">\(a_1 \geq a_2 \geq a_3 \geq ... \geq a_n \geq a_{n+1} \geq ...\)</span></li>
<li><span class="math inline">\((a_n) \rightarrow 0\)</span></li>
</ol>
<p>Then the <strong>alternating series</strong> <span class="math inline">\(\sum^{\infty}_{n=1} (-1)^{n+1} a_n\)</span> converges.</p>
<h4 id="definition-2.7.8-conditional-and-absolute-convergence">Definition 2.7.8: Conditional and Absolute Convergence</h4>
<p>If <span class="math inline">\(\sum^{\infty}_{n=1} |a_n|\)</span> converges, then we say that the original series <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> <strong>converges absolutely</strong>. If, on the other hand, the <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> converges but the series of absolute values <span class="math inline">\(\sum^{\infty}_{n=1} |a_n|\)</span> does not converge, we say that the original series <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> <strong>converges conditionally</strong>.</p>
<h4 id="definition-2.7.9-rearrangement">Definition 2.7.9 Rearrangement</h4>
<p>Let <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span> be a series. A series <span class="math inline">\(\sum^{\infty}_{k=1} b_k\)</span> is called a <strong>rearrangement</strong> of <span class="math inline">\(\sum^{\infty}_{k=1} a_k\)</span> if there exists a one-to-one, onto function <span class="math inline">\(f: \mathbb{N} \rightarrow \mathbb{N}\)</span> such taht <span class="math inline">\(b_{f(k)} = a_k, \; \forall k \in \mathbb{N}\)</span>.</p>
<h4 id="theorem-2.7.10">Theorem 2.7.10</h4>
<p>If a series converges absolutely, then any rearrangement of this series converges to the same limit.</p>
<h3 id="double-summations-and-products-of-infinite-series">Double Summations and Products of Infinite Series</h3>
<p><span class="math display">\[\sum^{\infty}_{i=1}\sum^{\infty}_{j=1} a_{ij} \neq \sum^{\infty}_{j=1}\sum^{\infty}_{i=1} a_{ij}\]</span></p>
<h4 id="theorem-2.8.1">Theorem 2.8.1</h4>
<p>Let <span class="math inline">\(\{a_{ij}: i, j \in \mathbb{N}\}\)</span> be a doubly indexed array of real numbers. If</p>
<p><span class="math display">\[\sum^{\infty}_{i=1}\sum^{\infty}_{j=1} |a_{ij}|\]</span></p>
<p>converges, then both <span class="math inline">\(\sum^{\infty}_{i=1}\sum^{\infty}_{j=1} a_{ij}\)</span> and <span class="math inline">\(\sum^{\infty}_{j=1}\sum^{\infty}_{i=1} a_{ij}\)</span> converge to the same value. Moreover:</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} s_{nn} = \sum^{\infty}_{i=1}\sum^{\infty}_{j=1} a_{ij} = \sum^{\infty}_{j=1}\sum^{\infty}_{i=1} a_{ij}\]</span></p>
<p>Where <span class="math inline">\(s_nn = \sum^{n}_{j=1}\sum^{n}_{i=1} a_{ij} = \sum^{n}_{i=1}\sum^{n}_{j=1} a_{ij}\)</span></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Q-Learning</title>
    <url>/2021/05/16/q-learning/</url>
    <content><![CDATA[<h1 id="temporal-difference-learning-for-control-q-learning">Temporal Difference Learning for Control: Q-Learning</h1>
<p>We can use TD-like methods for the problem of control too. Consider any <span class="math inline">\(Q\)</span>. Let <span class="math inline">\(X^{\prime} \sim P(\cdot | X, A)\)</span> and <span class="math inline">\(R \sim R(\cdot | X, A)\)</span> and define:</p>
<p><span class="math display">\[Y = R + \gamma max_{a^{\prime} \in A} Q(X^{\prime}, a^{\prime})\]</span></p>
<p>We have:</p>
<p><span class="math display">\[E[Y | X=x, A=a] = r(x, a) + \gamma \int P(dx^{\prime} | x, a) max_{a^{\prime} \in A} Q(x^{\prime}, a^{\prime}) = T^{*} Q (x, a)\]</span></p>
<p>So, <span class="math inline">\(Y\)</span> is an unbiased estimate of <span class="math inline">\(T^{*} Q (x, a)\)</span>. Let's define the <code>empirical Bellman optimality operator</code> <span class="math inline">\(\hat{T}^{*} Q (x, a)\)</span>:</p>
<p><span class="math display">\[T^{*} Q (x, a) = Y = R + \gamma max_{a^{\prime} \in A} Q(X^{\prime}, a^{\prime})\]</span></p>
<p>We can write the SA update rule for estimating <span class="math inline">\(Q^{*}\)</span> as:</p>
<p><span class="math display">\[Q_{t+1} (X_t, A_t) \leftarrow Q_t(X_t, A_t) + \alpha_t (X_t, A_t) [R_t + \gamma max_{a^{\prime} \in A} Q_t (X^{\prime}_t, a^{\prime}) - Q_t(X_t, A_t)]\]</span></p>
<span id="more"></span>
<p><img src="/images/RL/mc/td_3.png"></p>
<p>We can clearly see that Q-learning is an <code>off-policy</code> method, because we are generating the episode using <span class="math inline">\(\pi\)</span> which is usually an <span class="math inline">\(\epsilon\)</span>-greedy policy. However, we are evaluating the greedy policy (in update rule, we select according to the greedy policy not <span class="math inline">\(\pi\)</span> i.e <span class="math inline">\(a^{\prime}\)</span> is not selected by <span class="math inline">\(\pi\)</span>).</p>
<h2 id="proof-convergence-of-q-learning">Proof: Convergence of Q-Learning</h2>
<p>Suppose that we want to find the fixed-point of an operator <span class="math inline">\(L\)</span>:</p>
<p><span class="math display">\[L \theta = \theta\]</span></p>
<p>for <span class="math inline">\(\theta \in \mathbb{R}^{d}, L: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d}\)</span>.</p>
<p>Consider the iterative update:</p>
<p><span class="math display">\[\theta_{t+1} \leftarrow (1 - \alpha) \theta_t + \alpha L\theta_t\]</span></p>
<p><span class="math inline">\(L\theta_t\)</span> can be anything such as <span class="math inline">\(T^{\pi} V_k\)</span>, as long as <span class="math inline">\(L\)</span> is <span class="math inline">\(c-\)</span>Lipschitz with <span class="math inline">\(c &lt; 1\)</span> and <span class="math inline">\(\alpha\)</span> is small enough <span class="math inline">\((0 &lt; \alpha &lt; \frac{2}{1 - c})\)</span>, this would converge.</p>
<p>To see this, let:</p>
<p><span class="math display">\[L^{\prime}: \theta \rightarrow ((1 - \alpha) I +  \alpha L) \theta\]</span></p>
<p>Then the above update rule can be rewritten as:</p>
<p><span class="math display">\[\theta_{t+1} \leftarrow L^{\prime} \theta_{t}\]</span></p>
<p>For any <span class="math inline">\(\theta_1, \theta_2 \in \mathbb{R}^{d}\)</span>, this new mapping satisfies:</p>
<span class="math display">\[\begin{aligned}
\| L^{\prime} \theta_1 - L^{\prime}\theta_2 \| &amp;= \|((1 - \alpha) I +  \alpha L) \theta_1 - ((1 - \alpha) I +  \alpha L) \theta_2\|\\
&amp; \leq (1 - \alpha) \| \theta_1 - \theta_2 \| + \underbrace{\alpha \|L\theta_1 - L\theta_2 \|}_{\leq \alpha * c \| \theta_1 - \theta_2 \|} \\
&amp; \leq ((1 - \alpha) + c \alpha) \| \theta_1 - \theta_2 \|
\end{aligned}\]</span>
<p>If <span class="math inline">\((1 - \alpha) + c \alpha &lt; 1 \implies 0 &lt; \alpha &lt; \frac{2}{1 - c}\)</span>, then <span class="math inline">\(L^{\prime}\)</span> is a contraction mapping and by the Banach fixed point theorem, the iterative process converges.</p>
<p>However, in reality, we do not have access to <span class="math inline">\(L\theta_t\)</span> in general, but only its noise contaminated version <span class="math inline">\(L\theta_t + \epsilon_t\)</span> with <span class="math inline">\(\epsilon_t \in \mathbb{R}^{d}\)</span> being a zero-mean noise, we have:</p>
<p><span class="math display">\[\theta_{t+1} \leftarrow (1 - \alpha_t) \theta_t + \alpha_t (L\theta_t + \epsilon_t)\]</span></p>
<p>Recall that <span class="math inline">\(\alpha_t\)</span> can not be constant, otherwise the variance of the estimate would not go to zero. Assume that at time <span class="math inline">\(t\)</span>, the <span class="math inline">\(i\)</span>-the component of <span class="math inline">\(\theta_t\)</span> is updated as:</p>
<p><span class="math display">\[\theta_{t+1} (i) \leftarrow (1 - \alpha_t(i)) \theta_t(i) + \alpha_t(i) (L\theta_t(i) + \epsilon_t(i))\]</span></p>
<p>With <span class="math inline">\(\alpha_t (j) = 0, \forall j \neq i\)</span> (other components are not updated)</p>
<p>Now, we know that this iterative process will converge, but which point will it converge?</p>
<p><strong>Next, we will see that <span class="math inline">\(\theta_t\)</span> converges to <span class="math inline">\(\theta^{*}\)</span></strong></p>
<h3 id="convergence-of-theta_t-to-theta">Convergence of <span class="math inline">\(\theta_t\)</span> to <span class="math inline">\(\theta^{*}\)</span></h3>
<p>Denote the history of the algorithm up to time <span class="math inline">\(t\)</span> by <span class="math inline">\(F_t\)</span>:</p>
<p><span class="math display">\[F_t = \{\theta_0, ...., \theta_t\} \cup \underbrace{\{\epsilon_0, ...., \epsilon_{t-1}\}}_{\text{up to time t, the r.v } \epsilon_t \text{ is not observed}} \cup \{\alpha_0, ..., \alpha_t\}\]</span></p>
<p>We need more assumptions:</p>
<p>Assumption A1: 1. For every component <span class="math inline">\(i\)</span> and time step <span class="math inline">\(t\)</span>, we have E[_t (i) | F_t] = 0 (we assume noise are i.i.d) 2. Given any norm <span class="math inline">\(\| \cdot \|\)</span> on <span class="math inline">\(\mathbb{R}^{d}\)</span>, there exist constants <span class="math inline">\(c_1, c_2\)</span> such that for all <span class="math inline">\(i, t\)</span>, we have:</p>
<p><span class="math display">\[\underbrace{E[|\epsilon_t (i) |^2 | F_t]}_{\text{variance of } \epsilon_t (i)} \leq c_1 + c_2 \| \theta_t \|^2\]</span></p>
<p><img src="/images/RL/mc/td_4.png"></p>
<h3 id="convergence-of-q_t-to-q">Convergence of <span class="math inline">\(Q_t\)</span> to <span class="math inline">\(Q^{*}\)</span></h3>
<p>The Q-learning update rule has the same form as the SA update rule:</p>
<ul>
<li><span class="math inline">\(\theta\)</span> is <span class="math inline">\(Q \in \mathbb{R}^{X \times A}\)</span></li>
<li>the operator <span class="math inline">\(L\)</span> is the bellman optimality operator <span class="math inline">\(T^{*}\)</span></li>
<li>the index <span class="math inline">\(i\)</span> in the SA update is the selected <span class="math inline">\((X_t, A_t)\)</span></li>
<li>the noise term <span class="math inline">\(\epsilon_t (i)\)</span> is the difference between <span class="math inline">\(\hat{T}^{*} Q - T^{*} Q\)</span></li>
</ul>
<p>Suppose that at time <span class="math inline">\(t\)</span>, the agent is at state <span class="math inline">\(X_t\)</span>, takes action <span class="math inline">\(A_t\)</span>, gets <span class="math inline">\(X^{\prime}_t \sim P(\cdot | X_t, A_t), R_t \sim R(\cdot | X_t, A_t)\)</span>.</p>
<p>The update rule of the Q-learning is:</p>
<p><span class="math display">\[Q_{t+1} (X_t, A_t) \leftarrow (1 - \alpha_t(X_t, A_t))Q_t(X_t, A_t) + \alpha_t (X_t, A_t) [T^{*}Q_t (X_t, A_t) + \epsilon_t (X_t, A_t)]\]</span></p>
<p>with:</p>
<p><span class="math display">\[\epsilon_{t} (X_t, A_t) = R_t + \gamma max_{a^{\prime} \in A} Q_t (X^{\prime}_t, a^{\prime}) - T^{*} Q(X_t, A_t)\]</span></p>
<p>and:</p>
<p><span class="math display">\[Q_{t+1} (x, a) \leftarrow Q_t(x, a), \forall (x, a) \neq (X_t, A_t)\]</span></p>
<p>We know that:</p>
<ul>
<li><span class="math inline">\(T^{*}\)</span> is a <span class="math inline">\(\gamma\)</span>-contraction mapping, so condition (3) of the Convergence of SA Theorem.</li>
<li>Condition (1) of the Convergence of SA Theorem is assumed too.</li>
</ul>
<p>We only need to verify condition (2) in order to apply the theorem.</p>
<h3 id="proof-of-condition-2">Proof of Condition (2)</h3>
<p>Let <span class="math inline">\(F_t\)</span> be the history of algorithm up to and including when the step size #_t (X_t, A_t)$ is chosen, but just before <span class="math inline">\(X^{\prime}_t\)</span> and <span class="math inline">\(R_t\)</span> are revealed. This implies <span class="math inline">\(X_t=x, A_t=a\)</span> is already given, but <span class="math inline">\(X^{\prime}_t, R_t\)</span> are still unknown. We have:</p>
<p><span class="math display">\[E[\epsilon_t (X_t, A_t) | F_t] = E[R_t + \gamma max_{\alpha^{\prime} \in A} Q_t (X^{\prime}_t, a^{\prime}) | F_t] - E[T^{*} (Q_t) (X_t, A_t) | F_t] = 0\]</span></p>
<p>This verifies condition (a) of Assumption A1: zero-mean noise</p>
<p>To Verify (b) of Assumption A1, we provide an upper bound on <span class="math inline">\(E[\epsilon_t^2 (X_t, A_t) | F_t]\)</span>:</p>
<span class="math display">\[\begin{aligned}
E[\epsilon_t^2 (X_t, A_t) | F_t] &amp;= E[|(R_t - r(X_t, A_t)) + \gamma (max_{a^{\prime}} Q_t (X^{\prime}_t, a^{\prime}) - \int P(dx^{\prime} | X_t, A_t) Q_t (x^{\prime}_t, a^{\prime}))|^2 | F_t]\\
&amp; \leq 2E[|(R_t - \underbrace{r(X_t, A_t)}_{E[R_t | X_t, A_t]})|^2 | F_t] + 2 E[|\gamma (max_{a^{\prime}} Q_t (X^{\prime}_t, a^{\prime}) - \underbrace{\int P(dx^{\prime} | X_t, A_t) Q_t (x^{\prime}_t, a^{\prime})}_{E[max_{a^{\prime} \in A} Q_t(X^\prime, a^{\prime})]})|^2 | F_t] \\
&amp; \leq 2Var[R_t | X_t=x_t, A_t=a_t] + 2 \gamma^2 Var[max_{a^{\prime} \in A} Q_t (X^{\prime}, a^{\prime}) | X_t=x_t, A_t=a_t]\\
\end{aligned}\]</span>
<p>Thus:</p>
<span class="math display">\[\begin{aligned}
Var[max_{a^{\prime} \in A} Q_t (X^{\prime}, a^{\prime}) | X_t=x_t, A_t=a_t] &amp;= E[|max_{a^{\prime} \in A} Q_t (X^{\prime}, a^{\prime})|^2 | X_t=x_t, A_t=a_t] - E[max_{a^{\prime} \in A} Q_t (X^{\prime}, a^{\prime}) | X_t=x_t, A_t=a_t]^2\\
&amp;\leq E[|max_{a^{\prime} \in A} Q_t (X^{\prime}, a^{\prime})|^2 | X_t=x_t, A_t=a_t]\\
&amp;\leq max_{x, a} |Q^{t} (x, a)|^2 \\
&amp;\leq \sum_{x, a} |Q_t(x, a)|^2 \text{ (i.e }max_x |f(x)| \leq \sum_x |f(x)|)\\
&amp;= \| Q_t\|^2_2
\end{aligned}\]</span>
<p>Denote the maximum variance of the reward distributino over the state-action space <span class="math inline">\(max_{(x, a) \in X \times A} Var[R(x, a)]\)</span> by <span class="math inline">\(\sigma^2_{R}\)</span> which is assumed to be bounded, we have:</p>
<p><span class="math display">\[E[\epsilon_t^2 (X_t, A_t) | F_t] \leq 2 (\sigma^2_{R} + \gamma^2 \| Q_t\|^2_2)\]</span></p>
<p>Therefore, we can choose <span class="math inline">\(c_1 = 2\sigma^2, c_2 = 2\gamma^2\)</span> in condition b of Assumption A1. <strong>All conditions of SA Convergence Theorem is satisfied, so Q_t converges to <span class="math inline">\(Q^{*}\)</span></strong></p>
<p><img src="/images/RL/mc/td_5.png"></p>
<h2 id="remark">Remark</h2>
<ul>
<li>The step size condition is state-action dependent.</li>
<li>If there is a state-action pair that is not selected at all or only a finite number of times, the condition cannot be satisfied. (ie. the sum does not go to infinity)</li>
<li>We need each state-action pair to be visited infinitely often.</li>
<li>The state-action-dependence of the step size might be different from how the Q-learning algorithm is sometimes presented, in which a single learning rate <span class="math inline">\(\alpha_t\)</span> is used for all state-action pairs.</li>
<li>A single learning rate suffices if the agent happens to visit all <span class="math inline">\((x, a) \in (X \times A)\)</span> frequent enough.</li>
</ul>
<h1 id="implementations">Implementations:</h1>
]]></content>
      <categories>
        <category>RL</category>
        <category>TD</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>Tabular Methods</tag>
        <tag>TD</tag>
      </tags>
  </entry>
  <entry>
    <title>Real Analysis (3)</title>
    <url>/2022/01/01/real-analysis-3/</url>
    <content><![CDATA[<h1 id="real-analysis-3">Real Analysis (3)</h1>
<h2 id="basic-topology-of-mathbbr">Basic Topology of <span class="math inline">\(\mathbb{R}\)</span></h2>
<h3 id="open-and-closed-sets">Open and Closed Sets</h3>
<h4 id="definition-3.2.1-open">Definition 3.2.1: Open</h4>
<p>A set <span class="math inline">\(O \subseteq \mathbb{R}\)</span> is <strong>open</strong> if for all points <span class="math inline">\(a \in O\)</span> there exists an <span class="math inline">\(\epsilon-neighborhood V_{\epsilon} (a) \subseteq O\)</span>.</p>
<blockquote>
<p><span class="math inline">\(\mathbb{R}\)</span> is open <span class="math inline">\(\emptyset\)</span> is open</p>
</blockquote>
<h4 id="theorem-3.2.3">Theorem 3.2.3</h4>
<ol type="1">
<li>The union of an arbitrary collection of open sets is open.</li>
<li>The intersection of a finite collection of open sets is open.</li>
</ol>
<h4 id="definition-3.2.4-limit-point">Definition 3.2.4: Limit Point</h4>
<p>A point <span class="math inline">\(x\)</span> is a <strong>limit point</strong> of a set <span class="math inline">\(A\)</span> if every <span class="math inline">\(\epsilon-neighborhood V_{\epsilon} (x)\)</span> of <span class="math inline">\(x\)</span> intersects the set <span class="math inline">\(A\)</span> at some point other than <span class="math inline">\(x\)</span>. Limit points may not be in <span class="math inline">\(A\)</span>, consider the end points of open sets.</p>
<h4 id="theorem-3.2.5">Theorem 3.2.5</h4>
<p>A point <span class="math inline">\(x\)</span> is a <strong>limit point</strong> of a set <span class="math inline">\(A\)</span> if and only if <span class="math inline">\(x = \lim_{n \rightarrow \infty} a_n\)</span> for some sequence <span class="math inline">\((a_n)\)</span> contained in <span class="math inline">\(A\)</span> satisfying <span class="math inline">\(a_n \neq x, \; \forall n \in \mathbb{N}\)</span></p>
<h4 id="definition-3.2.6-isolated-point">Definition 3.2.6: Isolated Point</h4>
<p>A point <span class="math inline">\(a \in A\)</span> is an <strong>isolated point</strong> of <span class="math inline">\(A\)</span> if it is not a limit point of <span class="math inline">\(A\)</span>. Isolated point is always in <span class="math inline">\(A\)</span>.</p>
<h4 id="definition-3.2.7-closed-set">Definition 3.2.7: Closed Set</h4>
<p>A set <span class="math inline">\(F \subseteq \mathbb{R}\)</span> is <strong>closed</strong> if it contains all its limit points. Topologically speaking, a closed set is one where convergent sequences within the set have limits that are also in the set.</p>
<span id="more"></span>
<h4 id="theorem-3.2.8">Theorem 3.2.8</h4>
<p>A set <span class="math inline">\(F \subseteq \mathbb{R}\)</span> is <strong>closed</strong> if and only if every Cauchy sequence contained in <span class="math inline">\(\mathbb{F}\)</span> has a limit that is also an element of <span class="math inline">\(F\)</span></p>
<h4 id="theorem-3.2.10-density-of-mathbbq-in-mathbbr">Theorem 3.2.10: Density of <span class="math inline">\(\mathbb{Q}\)</span> in <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>For every <span class="math inline">\(y \in \mathbb{R}\)</span>, there exists a sequence of rational numbers that converges to <span class="math inline">\(y\)</span>.</p>
<h4 id="definition-3.2.11-closure">Definition 3.2.11: Closure</h4>
<p>Given a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, let <span class="math inline">\(L\)</span> be the set of all limit points of <span class="math inline">\(A\)</span>. The <strong>closure</strong> of <span class="math inline">\(A\)</span> is defined to be <span class="math inline">\(\bar{A} = A \cup L\)</span>.</p>
<p>That is, if <span class="math inline">\(A\)</span> is an open interval <span class="math inline">\((a, b)\)</span>, then <span class="math inline">\(\bar{A} = [a, b]\)</span>. If <span class="math inline">\(A\)</span> is a closed interval, then <span class="math inline">\(\{\bar{A} = A\}\)</span>. <span class="math inline">\(\bar{A}\)</span> is always a closed set.</p>
<h4 id="theorem-3.2.12">Theorem 3.2.12</h4>
<p>For any <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, the closure <span class="math inline">\(\bar{A}\)</span> is a closed set and is the smallest closed set containing <span class="math inline">\(A\)</span>.</p>
<h4 id="complement">Complement</h4>
<p>In general, if a set is not open that does not imply it must be closed. Many sets such as half-open interval <span class="math inline">\((c,d]\)</span> are neither open nor closed. <span class="math inline">\(\emptyset, \mathbb{R}\)</span> are both open and closed. The complement of a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is defined to be the set:</p>
<p><span class="math display">\[A^c = \{x \in \mathbb{R}: x \notin A\}\]</span></p>
<h4 id="theorem-3.2.13">Theorem 3.2.13</h4>
<p>A set <span class="math inline">\(O\)</span> is open if and only if <span class="math inline">\(O^c\)</span> is closed. Likewise, a set <span class="math inline">\(F\)</span> is closed if and only if <span class="math inline">\(F^c\)</span> is open.</p>
<h4 id="theorem-3.2.14">Theorem 3.2.14</h4>
<ol type="1">
<li>The union of a finite collection of closed sets is closed.</li>
<li>The intersection of an arbitrary collection of closed sets is closed.</li>
</ol>
<h3 id="compact-sets">Compact Sets</h3>
<h4 id="definition-3.3.1-compactness">Definition 3.3.1: Compactness</h4>
<p>A set <span class="math inline">\(K \subseteq \mathbb{R}\)</span> is <strong>compact</strong> if every sequence in <span class="math inline">\(K\)</span> has a subsequence that converges to a limit that is also in <span class="math inline">\(K\)</span>.</p>
<h4 id="theorem-3.3.3-bounded-sets">Theorem 3.3.3 Bounded Sets</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is <strong>bounded</strong> if there exists <span class="math inline">\(M &gt; 0\)</span> such that <span class="math inline">\(|a| \leq M, \;\forall a \in A\)</span></p>
<h4 id="theorem-3.3.4-characterization-of-compactness-in-mathbbr">Theorem 3.3.4: Characterization of Compactness in <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>A set <span class="math inline">\(K \subseteq \mathbb{R}\)</span> is compact if and only if it is closed and bounded.</p>
<p>We can think of compact sets as generalizations of closed intervals. Whenever a fact involving closed intervals is true, it is often the case that the same results holds when we replace closed interval with compact set.</p>
<h4 id="theorem-3.3.5-nested-compact-set-property">Theorem 3.3.5: Nested Compact Set Property</h4>
<p>If <span class="math inline">\(K_1 \subseteq K_2 \subseteq K_3 \subseteq ..\)</span> is a nested sequence of nonempty compact sets, then the intersection <span class="math inline">\(bigcap^{\infty}_{n=1} K_n\)</span> is nonempty.</p>
<h3 id="perfect-sets-and-connected-sets">Perfect Sets and Connected Sets</h3>
<h4 id="definition-3.4.1">Definition 3.4.1</h4>
<p>A set <span class="math inline">\(P \subseteq \mathbb{R}\)</span> is <strong>perfect</strong> if it is closed and contains no isolated points (eg. closed intervals on real numbers)</p>
<h4 id="theorem-3.4.3">Theorem 3.4.3</h4>
<p>A nonempty perfect set is uncountable.</p>
<h4 id="definition-3.5.1">Definition 3.5.1</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is called an <span class="math inline">\(F_\sigma\)</span> set if it can be written as the countable union of closed sets. A set <span class="math inline">\(B \subseteq \mathbb{R}\)</span> is called a <span class="math inline">\(G_\delta\)</span> set if it can be written as the countable intersection of open sets.</p>
<h4 id="theorem-3.5.2">Theorem 3.5.2</h4>
<p>If <span class="math inline">\(\{G_1, ...\}\)</span> is a countable collection of dense, open sets, then the intersection <span class="math inline">\(\bigcap^{\infty}_{n=1} G_n\)</span> is not empty.</p>
<h2 id="functional-limits-and-continuity">Functional Limits and Continuity</h2>
<h3 id="functional-limits">Functional Limits</h3>
<h4 id="definition-4.2.1-functional-limit">Definition 4.2.1: Functional Limit</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, and let <span class="math inline">\(c\)</span> be a limit point of the domain <span class="math inline">\(A\)</span>. We say that <span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span>, provided that, for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that whenever <span class="math inline">\(0 &lt; | x - c | &lt; \delta\)</span> and <span class="math inline">\(x \in A\)</span> it follows that <span class="math inline">\(| f(x) - L | &lt; \epsilon\)</span>. In other words, Let <span class="math inline">\(c\)</span> be a limit point of the domain of <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>. We say <span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span> provided that, for every <span class="math inline">\(V_{\epsilon} (L)\)</span>, there exists a <span class="math inline">\(V_{\delta} (c)\)</span> with the property that for all <span class="math inline">\(x \in V_{\delta} (c)\)</span> different from <span class="math inline">\(c\)</span>, it follows that <span class="math inline">\(f(x ) \in V_{\epsilon} (L)\)</span>.</p>
<h4 id="theorem-4.2.3-sequential-criterion-for-functional-limits">Theorem 4.2.3: Sequential Criterion for Functional Limits</h4>
<p>Given a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and a limit point <span class="math inline">\(c\)</span> of <span class="math inline">\(A\)</span>, the following two statements are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span></li>
<li>For all sequences <span class="math inline">\((x_n) \subseteq A\)</span> satisfying <span class="math inline">\(x_n \neq c\)</span> and <span class="math inline">\((x_n) \rightarrow c\)</span>, it follows that <span class="math inline">\(f(x_n) \rightarrow L\)</span>.</li>
</ol>
<h4 id="corollary-4.2.4-algebraic-limit-theorem-for-functional-limits">Corollary 4.2.4: Algebraic Limit Theorem for Functional Limits</h4>
<p>Let <span class="math inline">\(f, g\)</span> be functions defined on a domain <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, and assume <span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span> and <span class="math inline">\(\lim_{x \rightarrow c} g(x) = M\)</span>, for some limit point <span class="math inline">\(c\)</span> of <span class="math inline">\(A\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\(\lim_{x \rightarrow c} kf(x) = kL\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow c} [f(x) + g(x)] = L + M\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow c} f(x)g(x) = LM\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow c} \frac{f(x)}{g(x)} = \frac{L}{M}\)</span>, given <span class="math inline">\(M \neq 0\)</span></li>
</ol>
<h4 id="corollary-4.2.5-divergence-criterion-for-functional-limits">Corollary 4.2.5: Divergence Criterion for Functional Limits</h4>
<p>Let <span class="math inline">\(f\)</span> be a function defined on <span class="math inline">\(A\)</span>, and let <span class="math inline">\(c\)</span> be a limit point of <span class="math inline">\(A\)</span>. If there exist two sequences <span class="math inline">\((x_n), (y_n)\)</span> in <span class="math inline">\(A\)</span> with <span class="math inline">\(x_n \neq c\)</span> and <span class="math inline">\(y_n \neq c\)</span> and</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} x_n = \lim_{n \rightarrow \infty} y_n = c\]</span></p>
<p>but</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} f(x_n) \neq \lim_{n \rightarrow \infty} f(y_n) \]</span></p>
<p>then, we can conclude that the functional limit <span class="math inline">\(\lim_{n \rightarrow c} f(x)\)</span> <strong>does not exist</strong>.</p>
<h3 id="continues-functions">Continues Functions</h3>
<h4 id="definition-4.3.1-continuity">Definition 4.3.1: Continuity</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is <strong>continues</strong> at a point <span class="math inline">\(c \in A\)</span> if for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t whenever <span class="math inline">\(|x - c| &lt; \delta\)</span> it follows that <span class="math inline">\(|f(x) - f(c)| &lt; \epsilon\)</span>.</p>
<p>If <span class="math inline">\(c\)</span> is a <strong>limit point</strong> of <span class="math inline">\(A\)</span>, we can reduce the definition to say that, <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c \in A\)</span> if</p>
<p><span class="math display">\[\lim_{x \rightarrow c} f(x) = f(c)\]</span></p>
<p>If <span class="math inline">\(f\)</span> is <strong>continues at every point</strong> in the domain <span class="math inline">\(A\)</span>, then we say that <span class="math inline">\(f\)</span> is continues on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-4.3.2-characterizations-of-continuity">Theorem 4.3.2: Characterizations of Continuity</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and let <span class="math inline">\(c \in A\)</span>. The function <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c\)</span> if and only if any one of the following three conditions is met:</p>
<ol type="1">
<li>For all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(|x - c| &lt; \delta\)</span> implies <span class="math inline">\(|f(x) - f(c)| &lt; \epsilon\)</span>.</li>
<li>For all <span class="math inline">\(V_{\epsilon} (f(c))\)</span>, there exists a <span class="math inline">\(V_{\delta} (c)\)</span> with the property that <span class="math inline">\(x \in V \implies f(x) \in V_{\epsilon} (f(c))\)</span>.</li>
<li>For all <span class="math inline">\((x_n) \rightarrow c\)</span>, it follows that <span class="math inline">\(f(x) \rightarrow f(c)\)</span>.</li>
<li>If <span class="math inline">\(c\)</span> is a limit point of <span class="math inline">\(A\)</span>, then the above conditions equivalent to <span class="math display">\[\lim_{x \rightarrow c} f(x) = f(c)\]</span></li>
</ol>
<h4 id="corollary-4.3.3-criterion-for-discontinuity">Corollary 4.3.3: Criterion for Discontinuity</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, and let <span class="math inline">\(c \in A\)</span> be a limit point of <span class="math inline">\(A\)</span>. If there exists a sequence <span class="math inline">\((x_n) \subseteq A\)</span> where <span class="math inline">\((x_n) \rightarrow c\)</span>, but such that <span class="math inline">\(f(x_n)\)</span> does not converge to <span class="math inline">\(f(c)\)</span>, we may conclude that <span class="math inline">\(f\)</span> is not continues at <span class="math inline">\(c\)</span>.</p>
<h4 id="theorem-4.3.4-algebraic-continuity-theorem">Theorem 4.3.4: Algebraic Continuity Theorem</h4>
<p>Assume <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> are continuous at a point <span class="math inline">\(c \in A\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\(kf(x)\)</span> is continuous at <span class="math inline">\(c\)</span> for all <span class="math inline">\(k \in \mathbb{R}\)</span>.</li>
<li><span class="math inline">\(f(x) + g(x)\)</span> is continuous at <span class="math inline">\(c\)</span>.</li>
<li><span class="math inline">\(f(x) g(x)\)</span> is continuous at <span class="math inline">\(c\)</span>.</li>
<li><span class="math inline">\(\frac{f(x)}{g(x)}\)</span> is continuous at c, provided the quotient is defined.</li>
</ol>
<h4 id="theorem-4.3.9-composition-of-continuous-functions">Theorem 4.3.9: Composition of Continuous Functions</h4>
<p>Given <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(b \rightarrow \mathbb{R}\)</span>, assume that the range <span class="math inline">\(f(A) = \{f(x): x \in A\}\)</span> is contained in the domain <span class="math inline">\(B\)</span> so that the composition <span class="math inline">\(g \circ f(x) = g(f(x))\)</span> is defined on <span class="math inline">\(A\)</span>.</p>
<p>If <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c \in A\)</span>, and if <span class="math inline">\(g\)</span> is continuous at <span class="math inline">\(f(c) \in B\)</span>, then <span class="math inline">\(g \circ f\)</span> is continuous at <span class="math inline">\(c\)</span>.</p>
<h3 id="continuous-functions-on-compact-sets">Continuous Functions on Compact Sets</h3>
<p>Given a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and a subset <span class="math inline">\(B \subseteq A\)</span>, the notation <span class="math inline">\(f(B)\)</span> refers to the range of <span class="math inline">\(f\)</span> over the set <span class="math inline">\(B\)</span>, that is,</p>
<p><span class="math display">\[f(B) = \{f(x): x \in B\}\]</span></p>
<h4 id="theorem-4.4.1-preservation-of-compact-sets">Theorem 4.4.1: Preservation of Compact Sets</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> be continuous on <span class="math inline">\(A\)</span>, if <span class="math inline">\(K \subseteq A\)</span> is compact, then <span class="math inline">\(f(K)\)</span> is compact as well.</p>
<h4 id="theorem-4.4.2-extreme-value-theorem">Theorem 4.4.2: Extreme Value Theorem</h4>
<p>If <span class="math inline">\(f: K \rightarrow \mathbb{R}\)</span> is continuous on a compact set <span class="math inline">\(K \subseteq \mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> attains a maximum and minimum value. In other words, there exist <span class="math inline">\(x_0, x_1 \in K\)</span> such that <span class="math inline">\(f(x_0) \leq f(x) \leq f(x_1)\)</span> for all <span class="math inline">\(x \in K\)</span>.</p>
<h4 id="definition-4.4.4-uniform-continuity-stronger-than-continuity">Definition 4.4.4: Uniform Continuity (stronger than continuity)</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is <strong>uniformly continuous</strong> on <span class="math inline">\(A\)</span> if for every <span class="math inline">\(\epsilon &gt; 0\)</span> there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that for all <span class="math inline">\(x, y \in A\)</span>, <span class="math inline">\(|x - y| &lt; \delta \implies |f(x) - f(y)| &lt; \epsilon\)</span>.</p>
<p><strong>The difference between saying "f is continuous on A" and "f is uniformly continuous on A" is that, for the first definition, given <span class="math inline">\(\epsilon &gt; 0\)</span> and <span class="math inline">\(c \in A\)</span>, we can find a <span class="math inline">\(\delta &gt; 0\)</span> s.t the conditions are satisfied. However, for a function to be uniformly continuous, given <span class="math inline">\(\epsilon &gt; 0\)</span>, we need to find a <span class="math inline">\(\delta &gt; 0\)</span> that works for all <span class="math inline">\(c \in A\)</span>. Thus, uniform continuity is stronger.</strong></p>
<h4 id="theorem-4.4.5-sequential-criterion-for-absence-of-uniform-continuity">Theorem 4.4.5: Sequential Criterion for Absence of Uniform Continuity</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> fails to be uniformly continuous on <span class="math inline">\(A\)</span> if and only if there exists a particular <span class="math inline">\(\epsilon_0 &gt; 0\)</span> and two sequences <span class="math inline">\((x_n), (y_n)\)</span> in <span class="math inline">\(A\)</span> satisfying:</p>
<p><span class="math display">\[|x_n - y_n| \rightarrow 0\]</span></p>
<p>but</p>
<p><span class="math display">\[|f(x_n) - f(y_n)| \geq \epsilon_0\]</span></p>
<h4 id="theorem-4.4.7-uniform-continuity-on-compact-sets">Theorem 4.4.7: Uniform Continuity on Compact Sets</h4>
<p>A function that is continuous on a compact set <span class="math inline">\(K\)</span> is uniformly continuous on <span class="math inline">\(K\)</span>.</p>
<h4 id="theorem-4.5.1-intermediate-value-theorem">Theorem 4.5.1: Intermediate Value Theorem</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous. If <span class="math inline">\(L\)</span> is a real number satisfying <span class="math inline">\(f(a) &lt; L &lt; f(b)\)</span> or <span class="math inline">\(f(a) &gt; L &gt; f(b)\)</span>, then there exists a point <span class="math inline">\(c \subseteq (a, b)\)</span> where <span class="math inline">\(f(c) = L\)</span>.</p>
<h4 id="definition-4.5.3-intermediate-value-property">Definition 4.5.3: Intermediate Value Property</h4>
<p>A function <span class="math inline">\(f\)</span> has the <strong>intermediate value property</strong> on an interval <span class="math inline">\([a, b]\)</span> if for all <span class="math inline">\(x &lt; y\)</span> in <span class="math inline">\([a, b]\)</span> and all <span class="math inline">\(L\)</span> between <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(f(y)\)</span>, it is always possible to find a point <span class="math inline">\(c \in (x, y)\)</span> where <span class="math inline">\(f(c) = L\)</span>.</p>
<p>Another way to summarize the intermediate value theorem is to day that every continuous function on <span class="math inline">\([a, b]\)</span> has the intermediate value property.</p>
<h3 id="sets-of-discontinuity">Sets of Discontinuity</h3>
<h4 id="definition-4.6.1-monotonic-function">Definition 4.6.1: Monotonic Function</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is <strong>increasing</strong> on <span class="math inline">\(A\)</span> if <span class="math inline">\(f(x) \leq f(y)\)</span> whenever <span class="math inline">\(x &lt; y\)</span> and <strong>decreasing</strong> if <span class="math inline">\(f(x) \geq f(y)\)</span> whenever <span class="math inline">\(x &lt; y\)</span> in <span class="math inline">\(A\)</span>. A <strong>monotone function</strong> is one that is either increasing or decreasing.</p>
<h4 id="definition-4.6.2-right-hand-limit">Definition 4.6.2 Right Hand Limit</h4>
<p>Given a limit point <span class="math inline">\(c\)</span> of a set <span class="math inline">\(A\)</span> and a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, we write:</p>
<p><span class="math display">\[\lim_{x \rightarrow c^+} f(x) = L\]</span></p>
<p>if for all <span class="math inline">\(\epsilon &gt; 0\)</span> there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(|f(x) - L| &lt; \epsilon\)</span> whenever <span class="math inline">\(0 &lt; x - c &lt; \delta\)</span>.</p>
<h4 id="definition-4.6.3-left-hand-limit">Definition 4.6.3 Left Hand Limit</h4>
<p>Given a limit point <span class="math inline">\(c\)</span> of a set <span class="math inline">\(A\)</span> and a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, we write:</p>
<p><span class="math display">\[\lim_{x \rightarrow c^-} f(x) = L\]</span></p>
<p>if for all <span class="math inline">\(\epsilon &gt; 0\)</span> there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(|f(x) - L| &lt; \epsilon\)</span> whenever <span class="math inline">\(-\delta &lt; x - c &lt; 0\)</span>.</p>
<h4 id="theorem-4.6.4">Theorem 4.6.4</h4>
<p>Given <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and a limit point <span class="math inline">\(c\)</span> of <span class="math inline">\(A\)</span>, <span class="math inline">\(lim_{x \rightarrow c} f(x) = L\)</span> if and only if</p>
<p><span class="math display">\[\lim_{x \rightarrow c^-} f(x) = L\]</span></p>
<p>and</p>
<p><span class="math display">\[\lim{x \rightarrow c^+} f(x) = L\]</span></p>
<h4 id="definition-4.6.5-alpha-continuous">Definition 4.6.5: <span class="math inline">\(\alpha\)</span>-continuous</h4>
<p>Let <span class="math inline">\(f\)</span> be defined on <span class="math inline">\(\mathbb{R}\)</span>, and let <span class="math inline">\(\alpha &gt; 0\)</span>. The function <span class="math inline">\(f\)</span> is <span class="math inline">\(\alpha\)</span>-continuous at <span class="math inline">\(x \in \mathbb{R}\)</span> if there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t for all <span class="math inline">\(y, z \in (x - \delta, x + \delta)\)</span> it follows that <span class="math inline">\(f(y) - f(z)| &lt; \alpha\)</span>.</p>
<h2 id="derivatives">Derivatives</h2>
<h3 id="derivatives-and-the-intermediate-value-property">Derivatives and the Intermediate Value Property</h3>
<h4 id="definition-5.2.1-differentiability">Definition 5.2.1: Differentiability</h4>
<p>Let <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> be a function defined on an interval <span class="math inline">\(A\)</span>. Given <span class="math inline">\(c \in A\)</span>, the <strong>derivative</strong> of <span class="math inline">\(g\)</span> at <span class="math inline">\(c\)</span> is defined by:</p>
<p><span class="math display">\[g^{\prime} (c) = \lim_{x \rightarrow c} \frac{g(x) - g(c)}{x - c}\]</span></p>
<p>provided this limit exists. In this case, we say <span class="math inline">\(g\)</span> is differentiable at <span class="math inline">\(c\)</span>. If <span class="math inline">\(g^{\prime}\)</span> exists for all points <span class="math inline">\(c \in A\)</span>, we say that <span class="math inline">\(g\)</span> is differentiable on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-5.2.3">Theorem 5.2.3</h4>
<p>If <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> is differentiable at a point <span class="math inline">\(c \in A\)</span>, then <span class="math inline">\(g\)</span> is continuous at <span class="math inline">\(c\)</span> as well.</p>
<h4 id="theorem-5.2.4-algebraic-differentiability-theorem">Theorem 5.2.4: Algebraic Differentiability Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be functions defined on an interval <span class="math inline">\(A\)</span>, and assume both are differentiable at some point <span class="math inline">\(c \in A\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\((f + g)^{\prime} (c) = f^{\prime} (c) + g^{\prime} (c)\)</span></li>
<li><span class="math inline">\((kf)^{\prime} (c) = kf^{\prime} (c), \forall k \in \mathbb{R}\)</span></li>
<li><span class="math inline">\((fg)^{\prime} (c) = f^{\prime} (c) g(c) + f(c) g^{\prime} (c)\)</span></li>
<li><span class="math inline">\((\frac{f}{g})^{\prime} (c) = \frac{g(c)f^{\prime}(c) - f(c)g^{\prime}(c)}{[g(c)]^2}, \;\; g(c) \neq 0\)</span></li>
</ol>
<h4 id="theorem-5.2.5-chain-rule">Theorem 5.2.5: Chain Rule</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(g: B \rightarrow \mathbb{R}\)</span> satisfy <span class="math inline">\(f(A) \subseteq B\)</span> so that the composition <span class="math inline">\((g \circ f)^{\prime}\)</span> is defined. If <span class="math inline">\(f\)</span> is differentiable at <span class="math inline">\(c \in A\)</span> and if <span class="math inline">\(g\)</span> is differentiable at <span class="math inline">\(f(c) \in B\)</span>, then <span class="math inline">\(g \circ f\)</span> is differentiable at <span class="math inline">\(c\)</span> with:</p>
<p><span class="math display">\[(g\circ f)^{\prime}(c) = g^{\prime} (f(c)) \cdot f^{\prime} (c)\]</span></p>
<h4 id="theorem-5.2.6-interior-extremum-theorem">Theorem 5.2.6: Interior Extremum Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> be differentiable on an open interval <span class="math inline">\((a, b)\)</span>. If <span class="math inline">\(f\)</span> attains a maximum value at some point <span class="math inline">\(c \in (a, b)\)</span> (i.e <span class="math inline">\(f(c) \geq f(x) \; \forall x \in (a, b)\)</span>), then <span class="math inline">\(f^{\prime}(c) = 0\)</span>. The same is true if <span class="math inline">\(f(c)\)</span> is a minimum value.</p>
<h4 id="theorem-5.2.7-darbouxs-theorem">Theorem 5.2.7: Darboux's Theorem</h4>
<p>If <span class="math inline">\(f\)</span> is differentiable on an interval <span class="math inline">\([a, b]\)</span>, and if <span class="math inline">\(\alpha\)</span> satisfies <span class="math inline">\(f^{\prime}(a) &lt; \alpha &lt; f^{\prime} (b)\)</span> or <span class="math inline">\(f^{\prime} &gt; \alpha &gt; f^{\prime} (b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where <span class="math inline">\(f^{\prime} (c) = \alpha\)</span>.</p>
<h3 id="mean-value-theorem">Mean Value Theorem</h3>
<h4 id="theorem-5.3.1-rolles-theorem">Theorem 5.3.1: Rolle's Theorem</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous on <span class="math inline">\([a, b]\)</span> and differentiable on <span class="math inline">\((a, b)\)</span>. If <span class="math inline">\(f(a) = f(b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where <span class="math inline">\(f^{\prime} (c) = 0\)</span>.</p>
<h4 id="theorem-5.3.2-mean-value-theorem">Theorem 5.3.2: Mean Value Theorem</h4>
<p>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is continuous on <span class="math inline">\([a, b]\)</span> and differentiable on <span class="math inline">\((a, b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where</p>
<p><span class="math display">\[f^{\prime} (c) = \frac{f(b) - f(a)}{b - a}\]</span></p>
<h4 id="corollary-5.3.3">Corollary 5.3.3</h4>
<p>If <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> is differentiable on an interval <span class="math inline">\(A\)</span> and satisfies <span class="math inline">\(g^{\prime}(x) = 0, \;\forall x \in A\)</span>, then <span class="math inline">\(g(x) = k\)</span> for some constant <span class="math inline">\(k \in \mathbb{R}\)</span>.</p>
<h4 id="corollary-5.3.4">Corollary 5.3.4</h4>
<p>If <span class="math inline">\(f, g\)</span> are differentiable functions on an interval <span class="math inline">\(A\)</span> and satisfy <span class="math inline">\(f^{\prime} (x) = g^{\prime} (x), \; \forall x \in A\)</span>, then <span class="math inline">\(f(x) = g(x) + k\)</span> for some constant <span class="math inline">\(k \in \mathbb{R}\)</span>.</p>
<h4 id="theorem-5.3.5-generalized-mean-value-theorem">Theorem 5.3.5: Generalized Mean Value Theorem</h4>
<p>If <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are continuous on the closed interval <span class="math inline">\([a, b]\)</span> and differentiable on the open interval <span class="math inline">\((a, b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where</p>
<p><span class="math display">\[[f(b) - f(a)]g^{\prime} (c) = [g(b) - g(a)] f^{\prime} (c)\]</span></p>
<p>If <span class="math inline">\(g^{\prime}\)</span> is never zero on <span class="math inline">\((a, b)\)</span>, then the conclusion can be stated as:</p>
<p><span class="math display">\[\frac{f^{\prime}(c)}{g^{\prime}(c)} = \frac{f(b) - f(a)}{g(b) - g(a)}\]</span></p>
<h4 id="theorem-5.3.6-lhospitals-rule-00-case">Theorem 5.3.6: L’Hospital’s Rule: 0/0 case</h4>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be continuous on an interval containing <span class="math inline">\(a\)</span>, and assume <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are differentiable on this interval with the possible exception of the point <span class="math inline">\(a\)</span>. If <span class="math inline">\(f(a) = g(a) = 0\)</span> and <span class="math inline">\(g^{\prime} (x) \neq 0, \; \forall x \neq a\)</span>, then:</p>
<p><span class="math display">\[\lim_{x \rightarrow a} \frac{f^{\prime} (x)}{g^{\prime} (x)} = L \implies \lim_{x \rightarrow a} \frac{f (x)}{g (x)} = L\]</span></p>
<h4 id="definition-5.3.7">Definition 5.3.7</h4>
<p>Given <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> and a limit point <span class="math inline">\(c \in A\)</span>, we say that <span class="math inline">\(\lim_{x \rightarrow c} g(x) = \infty\)</span> if, for every <span class="math inline">\(M &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that whenever <span class="math inline">\(0 &lt; | x - c | &lt; \delta\)</span> it follows that <span class="math inline">\(g(x) \geq M\)</span>. We can define <span class="math inline">\(\lim_{x \rightarrow c} g(x) = -\infty\)</span> in a similar way.</p>
<h4 id="theorem-5.3.8-lhospitals-rule-inftyinfty-case">Theorem 5.3.8: L’Hospital’s Rule: <span class="math inline">\(\infty/\infty\)</span> case</h4>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be differentiable on <span class="math inline">\((a, b)\)</span>. If <span class="math inline">\(\lim_{x \rightarrow a} g(x) = \infty\)</span> or <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(g^{\prime} (x) \neq 0, \; \forall x \neq a\)</span>, then:</p>
<p><span class="math display">\[\lim_{x \rightarrow a} \frac{f^{\prime} (x)}{g^{\prime} (x)} = L \implies \lim_{x \rightarrow a} \frac{f (x)}{g (x)} = L\]</span></p>
<p>Moreover, these functions have derivatives of all orders.</p>
<h4 id="theorem">Theorem</h4>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Real Analysis (1)</title>
    <url>/2021/12/25/real-analysis-1/</url>
    <content><![CDATA[<h1 id="real-analysis-1">Real Analysis (1)</h1>
<h2 id="preliminaries">Preliminaries</h2>
<h3 id="sets">Sets</h3>
<p>If an element <span class="math inline">\(x\)</span> is in a set <span class="math inline">\(A\)</span>, we write:</p>
<p><span class="math display">\[x \in A\]</span></p>
<p>and say that <span class="math inline">\(x\)</span> is a <strong>member</strong> of <span class="math inline">\(A\)</span>, or that <span class="math inline">\(x\)</span> belongs to <span class="math inline">\(A\)</span>. If <span class="math inline">\(x\)</span> is not in <span class="math inline">\(A\)</span>, we write:</p>
<p><span class="math display">\[x \notin A\]</span></p>
<p>If every element of a set <span class="math inline">\(A\)</span> also belongs to a set <span class="math inline">\(B\)</span>, we say that <span class="math inline">\(A\)</span> is a <strong>subset</strong> of <span class="math inline">\(B\)</span> and write:</p>
<p><span class="math display">\[A \subseteq B\]</span></p>
<p>We say that <span class="math inline">\(A\)</span> is a <strong>proper subset</strong> of <span class="math inline">\(B\)</span> if <span class="math inline">\(A \subset B\)</span>, but there is at least one element of <span class="math inline">\(B\)</span> that is not in <span class="math inline">\(A\)</span>. In this case we write:</p>
<p><span class="math display">\[A \subset B\]</span></p>
<h4 id="definition-1.11-equal-sets">Definition 1.11: Equal Sets</h4>
<p>Two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be <strong>equal</strong>, we write <span class="math inline">\(A = B\)</span> if they contain the same elements. Thus, to prove that sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are equal, we must show that:</p>
<p><span class="math display">\[A \subseteq B, \;\; B \subseteq A\]</span></p>
<p>A set is normally defined by either listing its elements explicitly, or by specifying a property that determines the elements of the set. If <span class="math inline">\(P\)</span> denotes a property that is meaningful and unambiguous for elements of a set <span class="math inline">\(S\)</span>, then we write:</p>
<p><span class="math display">\[\{x \in S; P(x)\}\]</span></p>
<p>for the set of all elements <span class="math inline">\(x\)</span> in <span class="math inline">\(S\)</span> for which the property <span class="math inline">\(P\)</span> is true.</p>
<span id="more"></span>
<h4 id="de-morgans-law">De Morgan's Law</h4>
<p>If <span class="math inline">\(A, B, C\)</span> are sets, then:</p>
<p><span class="math display">\[A / (B \cup C) = (A / B) \cap (A / C)\]</span> <span class="math display">\[A / (B \cap C) = (A / B) \cup (A / C)\]</span></p>
<p>Where <span class="math inline">\(A / B\)</span> denotes the <strong>complement of <span class="math inline">\(B\)</span> relative to <span class="math inline">\(A\)</span></strong>:</p>
<p><span class="math display">\[A / B := \{x : x \in A \cap x \notin B\}\]</span></p>
<h4 id="unions-and-interactions">Unions and Interactions</h4>
<p>For a <strong>finite</strong> collection of sets <span class="math inline">\(\{A_1,...., A_n\}\)</span>, their <strong>union</strong> is the set <span class="math inline">\(A\)</span> consisting of all elements that belong to at least one of the sets <span class="math inline">\(A_k\)</span>, and their <strong>intersection</strong> consists of all elements that belong to all of the sets <span class="math inline">\(\{A_k\}\)</span>.</p>
<p>For an <strong>infinite</strong> collection of sets <span class="math inline">\(\{A_1, ...., A_n, ...\}\)</span>, their <strong>union</strong> is the set of elements that belong to at least one of the sets <span class="math inline">\(A_k\)</span>:</p>
<p><span class="math display">\[\bigcup^{\infty}_{n=1} A_n = \{x : \exists \; n \in \mathbb{N}, \text{s.t } x \in A_n \}\]</span></p>
<p>Similarly, their <strong>intersection</strong> is the set of elements that belong to all of these sets <span class="math inline">\(A_n\)</span>:</p>
<p><span class="math display">\[\bigcap^{\infty}_{n=1} A_n = \{x : \forall \; n \in \mathbb{N}, \text{s.t } x \in A_n \}\]</span></p>
<h3 id="functions">Functions</h3>
<h4 id="definition-1.15-cartesian-product">Definition 1.15: Cartesian Product</h4>
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are nonempty sets, then the <strong>Cartesian product</strong> <span class="math inline">\(A \times B\)</span> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is the set of all ordered pairs <span class="math inline">\((a, b)\)</span> with <span class="math inline">\(a \in A\)</span> and <span class="math inline">\(b \in B\)</span>. That is,</p>
<p><span class="math display">\[A \times B := \{(a, b): a \in A, b \in B\}\]</span></p>
<h4 id="general-definition">General Definition</h4>
<p>A function <span class="math inline">\(f\)</span> from a set <span class="math inline">\(A\)</span> into a set <span class="math inline">\(B\)</span> is a rule of correspondence that assigns to each element <span class="math inline">\(x \in A\)</span> an <strong>uniquely</strong> determined element <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(B\)</span>.</p>
<h4 id="definition-1.1.6-function-as-sets">Definition 1.1.6: Function as sets</h4>
<p>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be sets. Then a <strong>function</strong> from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> is a set <span class="math inline">\(f\)</span> of ordered pairs in <span class="math inline">\(A \times B\)</span> such that for each <span class="math inline">\(a \in A\)</span> there exists a unique <span class="math inline">\(b \in B\)</span> with <span class="math inline">\((a, b) \in f\)</span></p>
<p>The set <span class="math inline">\(A\)</span> of first elements of a function <span class="math inline">\(f\)</span> is called the <strong>domain</strong> of <span class="math inline">\(f\)</span> and is often denoted by <span class="math inline">\(D(f)\)</span>. The set of all second elements in <span class="math inline">\(f\)</span> is called the <strong>range</strong> of <span class="math inline">\(f\)</span> and denoted as <span class="math inline">\(R(f)\)</span>. Notice that:</p>
<p><span class="math display">\[D(f) = A\]</span></p>
<p>but:</p>
<p><span class="math display">\[R(f) \subseteq B\]</span></p>
<p>The notation:</p>
<p><span class="math display">\[f: A \rightarrow B\]</span></p>
<p>is often used to indicate that <span class="math inline">\(f\)</span> is a function from <span class="math inline">\(A\)</span> into <span class="math inline">\(B\)</span>. We will also say that <span class="math inline">\(f\)</span> is a mapping of <span class="math inline">\(A\)</span> into <span class="math inline">\(B\)</span>. If <span class="math inline">\(b = f(a)\)</span>, we often refer to <span class="math inline">\(b\)</span> as the <strong>value</strong> of <span class="math inline">\(f\)</span> at <span class="math inline">\(a\)</span>, or as the <strong>image</strong> of <span class="math inline">\(a\)</span> under <span class="math inline">\(f\)</span>.</p>
<p><img src="real_analysis/1_1_1.jpg"></p>
<h4 id="direct-and-inverse-images">Direct and Inverse Images</h4>
<p>Let <span class="math inline">\(f: A \rightarrow B\)</span> be a function with domain <span class="math inline">\(D(f) = A\)</span> and range <span class="math inline">\(R(f) \subseteq B\)</span></p>
<h5 id="definition-1.1.7-direct-image-and-inverse-image">Definition 1.1.7: Direct Image and Inverse Image</h5>
<p>If <span class="math inline">\(E\)</span> is a subset of <span class="math inline">\(A\)</span>, then the <strong>direct image</strong> of <span class="math inline">\(E\)</span> under <span class="math inline">\(f\)</span> is the subset <span class="math inline">\(f(E)\)</span> of <span class="math inline">\(B\)</span> given by:</p>
<p><span class="math display">\[f(E):= \{f(x): x \in E\}\]</span></p>
<p>If <span class="math inline">\(H\)</span> is a subset of <span class="math inline">\(B\)</span>, then the <strong>inverse image</strong> of <span class="math inline">\(H\)</span> under <span class="math inline">\(f\)</span> is the subset <span class="math inline">\(f^{-1}(H)\)</span> of <span class="math inline">\(A\)</span> given by:</p>
<p><span class="math display">\[f^{-1}(H) := \{x \in A: f(x) \in H\}\]</span></p>
<h4 id="definition-1.1.9-injection-surjection-and-bijection">Definition 1.1.9: Injection, Surjection and Bijection</h4>
<p>Let <span class="math inline">\(f: A \rightarrow B\)</span> be a function from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span></p>
<ol type="1">
<li>The function <span class="math inline">\(f\)</span> is said to be <strong>Injective(one to one)</strong> if whenever <span class="math inline">\(x_1 \neq x_2\)</span>, then <span class="math inline">\(f(x_1) \neq f(x_2)\)</span>.</li>
<li>The function <span class="math inline">\(f\)</span> is said to be <strong>Surjective(to map <span class="math inline">\(A\)</span> onto <span class="math inline">\(B\)</span>)</strong> if whenever <span class="math inline">\(f(A) = B\)</span>, that is if <span class="math inline">\(R(f) = B\)</span>.</li>
<li>The function <span class="math inline">\(f\)</span> is said to be <strong>Bijective</strong> if <span class="math inline">\(f\)</span> is both <strong>injective</strong> and <strong>surjective</strong>.</li>
</ol>
<h4 id="definition-1.1.11-inverse-functions">Definition 1.1.11: Inverse Functions</h4>
<p>If <span class="math inline">\(f: A \rightarrow B\)</span> is bijection of <span class="math inline">\(A\)</span> onto <span class="math inline">\(B\)</span> then:</p>
<p><span class="math display">\[g:= \{(b, a) \in B \times A: (a, b) \in f\}\]</span></p>
<p>is a function on <span class="math inline">\(B\)</span> into <span class="math inline">\(A\)</span>. This function is called <strong>inverse function</strong> of <span class="math inline">\(f\)</span> and denoted as <span class="math inline">\(f^{-1}\)</span></p>
<p><strong>Remark, <span class="math inline">\(f^{-1}\)</span> (inverse image) make sense even if <span class="math inline">\(f\)</span> has no inverse function. However, if the inverse function <span class="math inline">\(f^{-1}\)</span> does exist, then <span class="math inline">\(f^{-1} (H)\)</span> is the direct image of the set <span class="math inline">\(H \subseteq B\)</span> under <span class="math inline">\(f^{-1}\)</span></strong></p>
<h4 id="definition-1.1.12-composition-of-functions">Definition 1.1.12: Composition of Functions</h4>
<p>If <span class="math inline">\(f: A \rightarrow B\)</span> and <span class="math inline">\(g : B \rightarrow C\)</span>, and if <span class="math inline">\(R(f) \subseteq D(g) = B\)</span>, then the <strong>composition function</strong> <span class="math inline">\(g \circ f\)</span> is the function from <span class="math inline">\(A \rightarrow C\)</span>:</p>
<p><span class="math display">\[(g \circ f) (x) := g(f(x))\]</span></p>
<h4 id="theorem-1.1.14">Theorem 1.1.14</h4>
<p>Let <span class="math inline">\(f: A \rightarrow B\)</span> and <span class="math inline">\(g: B \rightarrow C\)</span> be functions and let <span class="math inline">\(H\)</span> be a subset of <span class="math inline">\(C\)</span>, then we have:</p>
<p><span class="math display">\[(g \circ f)^{-1} (H) = f^{-1}(g^{-1} (H))\]</span></p>
<h4 id="restrictions-of-functions">Restrictions of Functions</h4>
<p>If <span class="math inline">\(f: A \rightarrow B\)</span> is a function and if <span class="math inline">\(A_1 \subset A\)</span>, we can define a function <span class="math inline">\(f_1: A_1 \rightarrow B\)</span> by:</p>
<p><span class="math display">\[f_1(x) := f(x) \;\; x \in A_1\]</span></p>
<p>The function <span class="math inline">\(f_1\)</span> is called the <strong>restriction of <span class="math inline">\(f\)</span> to <span class="math inline">\(A_1\)</span></strong> denoted by <span class="math inline">\(f_1 = f|A_1\)</span>.</p>
<h3 id="finite-and-infinite-sets">Finite and Infinite Sets</h3>
<p>From a mathematical perspective, what we are doing is defining a bijective mapping between the set and a portion of the set of natural numbers. If the set is such that the counting does not terminate, such as the set of natural numbers itself, then we describe the set as being infinite.</p>
<h4 id="definition-1.3.1-set-elements-finite-infinite">Definition 1.3.1: Set Elements, finite, infinite</h4>
<ol type="1">
<li>The empty set <span class="math inline">\(\emptyset\)</span> is said to have 0 <strong>elements</strong>.</li>
<li>If <span class="math inline">\(n \in \mathbb{N}\)</span>, a set <span class="math inline">\(S\)</span> is said to have <span class="math inline">\(n\)</span> <strong>elements</strong> if there exists a bijection from the set <span class="math inline">\(\mathbb{N}: \{1, 2, ...., n\}\)</span> onto S.</li>
<li>A set <span class="math inline">\(S\)</span> is said to be <strong>finite</strong>, if it is either empty or it has <span class="math inline">\(n\)</span> elements for some <span class="math inline">\(n \in \mathbb{N}\)</span>.</li>
<li>A set <span class="math inline">\(S\)</span> is said to be <strong>infinite</strong> if it is not finite.</li>
<li>A set <span class="math inline">\(T_1\)</span> is finite if and only if there is a bijection from <span class="math inline">\(T_1\)</span> onto another set <span class="math inline">\(T_2\)</span> that is finite.</li>
</ol>
<h4 id="uniqueness-theorem">Uniqueness Theorem:</h4>
<p>If <span class="math inline">\(S\)</span> is a finite set, then the number of elements in <span class="math inline">\(S\)</span> is a unique number in <span class="math inline">\(\mathbb{N}\)</span>.</p>
<h4 id="theorem-1.3.3">Theorem 1.3.3</h4>
<p>The set <span class="math inline">\(\mathbb{N}\)</span> of natural numbers is an infinite set.</p>
<h4 id="theorem-1.3.4">Theorem 1.3.4</h4>
<ol type="1">
<li>If <span class="math inline">\(A\)</span> is a set with <span class="math inline">\(m\)</span> elements and <span class="math inline">\(B\)</span> is a set with <span class="math inline">\(n\)</span> elements and if <span class="math inline">\(A \cap B = \emptyset\)</span>, then <span class="math inline">\(A \cup B\)</span> has <span class="math inline">\(m + n\)</span> elements.</li>
<li>If <span class="math inline">\(A\)</span> is a set with <span class="math inline">\(m \in \mathbb{N}\)</span> elements and <span class="math inline">\(C \subseteq A\)</span> is a set with 1 element, then <span class="math inline">\(A/ C\)</span> is a set with <span class="math inline">\(m-1\)</span> elements.</li>
<li>If <span class="math inline">\(C\)</span> is an infinite set and <span class="math inline">\(B\)</span> is a finite set, then <span class="math inline">\(C/ B\)</span> is an infinite set.</li>
</ol>
<h4 id="theorem-1.3.5">Theorem 1.3.5</h4>
<p>Suppose that <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are sets and that <span class="math inline">\(T \subseteq S\)</span>:</p>
<ol type="1">
<li>If <span class="math inline">\(S\)</span> is a finite set, then <span class="math inline">\(T\)</span> is a finite set.</li>
<li>If <span class="math inline">\(T\)</span> is an infinite set, then <span class="math inline">\(S\)</span> is an infinite set.</li>
</ol>
<h4 id="definition-1.3.6-denumberable-countable">Definition 1.3.6: Denumberable, Countable</h4>
<ol type="1">
<li>A set <span class="math inline">\(S\)</span> is said to be <strong>denumberable</strong> (countably infinite) if there exists a bijection of <span class="math inline">\(\mathbb{N}\)</span> onto <span class="math inline">\(S\)</span>.</li>
<li>A set <span class="math inline">\(S\)</span> is said to be <strong>countable</strong> if it is either finite or denumberable.</li>
<li>A set <span class="math inline">\(S\)</span> is said to be <strong>uncountable</strong> if it is not countable.</li>
</ol>
<h4 id="theorem-1.3.8">Theorem 1.3.8</h4>
<p>The set <span class="math inline">\(\mathbb{N} \times \mathbb{N}\)</span> is denumberable</p>
<h4 id="theorem-1.3.9">Theorem 1.3.9</h4>
<p>Suppose that <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are sets and that <span class="math inline">\(T \subset S\)</span>:</p>
<ol type="1">
<li>If <span class="math inline">\(S\)</span> is a countable set, then <span class="math inline">\(T\)</span> is a countable set.</li>
<li>If <span class="math inline">\(T\)</span> is an uncountableset, then <span class="math inline">\(S\)</span> is an uncountable sets.</li>
</ol>
<h4 id="theorem-1.3.10">Theorem 1.3.10</h4>
<p>The following statements are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(S\)</span> is a countable set.</li>
<li>There exists a surjection of <span class="math inline">\(\mathbb{N}\)</span> onto <span class="math inline">\(S\)</span>.</li>
<li>There exists an injection of <span class="math inline">\(S\)</span> into <span class="math inline">\(\mathbb{N}\)</span>.</li>
</ol>
<h4 id="theorem">Theorem</h4>
<p>The set <span class="math inline">\(\mathbb{Q}\)</span> of all rational numbers is denumberable.</p>
<h4 id="theorem-1.3.12">Theorem 1.3.12</h4>
<p>If <span class="math inline">\(A_m\)</span> is a countable set for each <span class="math inline">\(m \in \mathbb{N}\)</span>, then the union <span class="math inline">\(A:= \bigcup^{\infty}_{m=1} A_m\)</span> is countable.</p>
<h2 id="real-numbers">Real Numbers</h2>
<h3 id="least-upper-bounds-supremum-and-greatest-lower-bounds-infimum">Least Upper Bounds (Supremum) and Greatest Lower Bounds (infimum)</h3>
<h4 id="definition-1.1.3.1">Definition 1.1.3.1</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is <strong>bounded above</strong> if there exists a number <span class="math inline">\(b \in \mathbb{R}\)</span> such that <span class="math inline">\(a \leq b\)</span> for all <span class="math inline">\(a \in A\)</span>. The number <span class="math inline">\(b\)</span> is called an <strong>upper bound</strong> for <span class="math inline">\(A\)</span>. Similarly, the set <span class="math inline">\(A\)</span> is <strong>bounded below</strong> if there exists a <strong>lower bound</strong> <span class="math inline">\(l \in \mathbb{R}\)</span> satisfying <span class="math inline">\(l \leq a\)</span> for every <span class="math inline">\(a \in A\)</span>.</p>
<h4 id="definition-1.1.3.2">Definition 1.1.3.2</h4>
<p>A real number <span class="math inline">\(s\)</span> is the <strong>least upper bound</strong> for a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> if:</p>
<ol type="1">
<li><span class="math inline">\(s\)</span> is an upper bound for <span class="math inline">\(A\)</span>.</li>
<li>If <span class="math inline">\(b\)</span> is any upper bound for <span class="math inline">\(A\)</span>, <span class="math inline">\(b \geq s\)</span>.</li>
</ol>
<p>The <strong>least upper bound</strong> is also called <strong>supremum</strong> of the set <span class="math inline">\(A\)</span> denoted as:</p>
<p><span class="math display">\[\sup A\]</span></p>
<p>The <strong>greatest lower bound</strong> is called <strong>infimum</strong> for <span class="math inline">\(A\)</span>:</p>
<p><span class="math display">\[\inf A\]</span></p>
<p><strong>infimum and supremum are unique for a set <span class="math inline">\(A\)</span> and may or may not be elements in the set <span class="math inline">\(A\)</span>.</strong></p>
<h4 id="definition-1.1.3.4">Definition 1.1.3.4</h4>
<p>A real number <span class="math inline">\(a_0\)</span> is a <strong>maximum</strong> of the set <span class="math inline">\(A\)</span> if <span class="math inline">\(a_0\)</span> is an element of <span class="math inline">\(A\)</span> and <span class="math inline">\(a_0 \geq a\)</span> for all <span class="math inline">\(a \in A\)</span>. Similarly, a number <span class="math inline">\(a_1\)</span> is a <strong>minimum</strong> of <span class="math inline">\(A\)</span> if <span class="math inline">\(a_1 \in A\)</span> and <span class="math inline">\(a_1 \leq a\)</span> for every <span class="math inline">\(a \in A\)</span>.</p>
<h4 id="axiom-of-completeness">Axiom of Completeness</h4>
<p>Every nonempty set of real numbers that is bounded above has a least upper bound.</p>
<h4 id="lemma-1.1.3.8">Lemma 1.1.3.8</h4>
<p>Assume <span class="math inline">\(s \in \mathbb{R}\)</span> is an upper bound for a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then <span class="math inline">\(s = \sup A\)</span> if and only if for every choice of <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists an element <span class="math inline">\(a \in A\)</span> satisfying <span class="math inline">\(s &lt; a + \epsilon\)</span>.</p>
<h3 id="theorem-1.1.4.1-nested-interval-property">Theorem 1.1.4.1: Nested Interval Property</h3>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, assume we are given a closed interval <span class="math inline">\(I_n = [a_n, b_n] = \{x \in \mathbb{R}: a_n \leq x \leq b\}\)</span>. Assume also that each <span class="math inline">\(I_n\)</span> contains <span class="math inline">\(I_{n+1}\)</span>. Then the resulting nested sequence of closed intervals:</p>
<p><span class="math display">\[I_1 \supseteq I_2 \supseteq I_3 .... \]</span></p>
<p>has a nonempty intersection. That is:</p>
<p><span class="math display">\[\bigcap^{\infty}_{n=1} I_{n} \neq 0\]</span></p>
<h3 id="theorem-1.1.4.2-archimedean-property">Theorem 1.1.4.2: Archimedean Property</h3>
<ol type="1">
<li>Given any number <span class="math inline">\(x \in \mathbb{R}\)</span>, there exists an <span class="math inline">\(n \in \mathbb{N}\)</span> satisfying <span class="math inline">\(n &gt; x\)</span>.</li>
<li>Given any real number <span class="math inline">\(y &gt; 0\)</span>, there exists an <span class="math inline">\(n \in \mathbb{N}\)</span> satisfying <span class="math inline">\(\frac{1}{n} &lt; y\)</span></li>
</ol>
<h3 id="theorem-1.1.4.3-density-of-mathbbq-in-mathbbr">Theorem 1.1.4.3: Density of <span class="math inline">\(\mathbb{Q}\)</span> in <span class="math inline">\(\mathbb{R}\)</span></h3>
<p>For every two real numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> with <span class="math inline">\(a &lt; b\)</span>, there exists a rational number <span class="math inline">\(r\)</span> satisfying <span class="math inline">\(a &lt; r &lt; b\)</span>. In other words, rational numbers are dense in <span class="math inline">\(\mathbb{R}\)</span>.</p>
<h3 id="theorem-1.1.4.5">Theorem 1.1.4.5</h3>
<p>There exists a real number <span class="math inline">\(\alpha \in \mathbb{R}\)</span> satisfying <span class="math inline">\(\alpha^2 = x, \;\; \forall x \in \mathbb{R} \geq 0\)</span></p>
<h3 id="cantors-diagonalizing-method">Cantor's Diagonalizing Method</h3>
<h4 id="theorem-1.1.6.1">Theorem 1.1.6.1</h4>
<p>The open interval <span class="math inline">\((0, 1) = \{x \in \mathbb{R}: 0 &lt; x &lt; 1\}\)</span> is uncountable</p>
<h4 id="power-sets">Power Sets</h4>
<p>Given a set <span class="math inline">\(A\)</span>, the <strong>power set</strong> <span class="math inline">\(P(A)\)</span> refers to the collection of all subsets of <span class="math inline">\(A\)</span>. It is important to understand that <span class="math inline">\(P(A)\)</span> is itself considered a set whose elements are the different possible subsets of <span class="math inline">\(A\)</span>.</p>
<h4 id="cantors-theorem">Cantor's Theorem</h4>
<p>Given any set <span class="math inline">\(A\)</span>, there does not exist a function <span class="math inline">\(f: A \rightarrow P(A)\)</span> that is onto. That is, no function satisfies <span class="math inline">\(R(f) = B\)</span>.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>real-analysis-4</title>
    <url>/2022/01/06/real-analysis-4/</url>
    <content><![CDATA[<h1 id="real-analysis-4">Real Analysis (4)</h1>
<h2 id="sequences-and-series-of-functions-1">Sequences and Series of Functions [1]</h2>
<h3 id="uniform-convergence-of-a-seuqence-of-functions">Uniform Convergence of a Seuqence of Functions</h3>
<h4 id="definition-6.2.1-pointwise-convergence">Definition 6.2.1: Pointwise Convergence</h4>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, let <span class="math inline">\(f_n\)</span> be a function defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The sequence <span class="math inline">\((f_n)\)</span> of functions <strong>converges pointwise</strong> on <span class="math inline">\(A\)</span> to a function <span class="math inline">\(f\)</span> if, for all <span class="math inline">\(x \in A\)</span>, the sequence of real numbers <span class="math inline">\(f_{n} (x)\)</span> converges to <span class="math inline">\(f(x)\)</span>.</p>
<p>In this case, we write <span class="math inline">\(f_n \rightarrow f\)</span>, <span class="math inline">\(\lim_{n \rightarrow \infty} f_n = f\)</span> or <span class="math inline">\(\lim_{n \rightarrow \infty} f_n(x) = f(x)\)</span>.</p>
<h4 id="definition-6.2.1b-pointwise-convergence">Definition 6.2.1B: Pointwise Convergence</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then, <span class="math inline">\((f_n)\)</span> <strong>convergence pointwise</strong> on <span class="math inline">\(A\)</span> to a limit function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(A\)</span> if, for every <span class="math inline">\(\epsilon &gt; 0\)</span> and <span class="math inline">\(x \in A\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> (<strong>perhaps depends on <span class="math inline">\(x\)</span></strong>) such that <span class="math inline">\(|f_{n} (x) - f(x) | &lt; \epsilon\)</span> whenever <span class="math inline">\(n \geq N\)</span>.</p>
<h4 id="definition-6.2.3-uniform-convergence-stronger-than-pointwise">Definition 6.2.3: Uniform Convergence (Stronger than Pointwise)</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then, <span class="math inline">\((f_n)\)</span> <strong>convergence uniformly</strong> on <span class="math inline">\(A\)</span> to a limit function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(A\)</span> if, for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that <span class="math inline">\(|f_{n} (x) - f(x) | &lt; \epsilon\)</span> whenever <span class="math inline">\(n \geq N\)</span> and <span class="math inline">\(x \in A\)</span>.</p>
<p><strong>Similar to uniform continuous, this is a stronger, which involves finding <span class="math inline">\(N \in \mathbb{N}\)</span> for a given <span class="math inline">\(\epsilon &gt; 0\)</span> for all <span class="math inline">\(x \in A\)</span></strong>.</p>
<p>Graphically speaking, the uniform convergence of <span class="math inline">\(f_n\)</span> to a limit <span class="math inline">\(f\)</span> on a set <span class="math inline">\(A\)</span> can be seen as there exists a point in the sequence after which each <span class="math inline">\(f_n\)</span> is <strong>completely</strong> contained in the <span class="math inline">\(\epsilon\)</span>-strip.</p>
<p><img src="/images/RL/background/ra_6_2_3.png" width="600"></p>
<span id="more"></span>
<h4 id="theorem-6.2.5-cauchy-criterion-for-uniform-convergence">Theorem 6.2.5: Cauchy Criterion for Uniform Convergence</h4>
<p>A sequence of functions <span class="math inline">\((f_n)\)</span> defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> converges uniformly on <span class="math inline">\(A\)</span> if and only if for every <span class="math inline">\(\epsilon &gt; 0\)</span> there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that <span class="math inline">\(|f_n(x) - f_m(x)| &lt; \epsilon\)</span> whenever <span class="math inline">\(m, n \geq N\)</span> for all <span class="math inline">\(x \in A\)</span>.</p>
<h4 id="theorem-6.2.6-continuous-limit-theorem">Theorem 6.2.6: Continuous Limit Theorem</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions defined on <span class="math inline">\(A \subseteq \mathbb{R}\)</span> that converges uniformly on <span class="math inline">\(A\)</span> to a function <span class="math inline">\(f\)</span>. If each <span class="math inline">\(f_n\)</span> is continuous at <span class="math inline">\(c \in A\)</span>, then <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c\)</span>.</p>
<h3 id="uniform-convergence-and-differentiation">Uniform Convergence and Differentiation</h3>
<h4 id="theorem-6.3.1-differentiable-limit-theorem">Theorem 6.3.1: Differentiable Limit Theorem</h4>
<p>Let <span class="math inline">\(f_n \rightarrow f\)</span> pointwise on the closed interval <span class="math inline">\([a, b]\)</span>, and assume that each <span class="math inline">\(f_n\)</span> is differentiable. If <span class="math inline">\((f^{\prime}(c))\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span> to a function <span class="math inline">\(g\)</span>, then the function <span class="math inline">\(f\)</span> is differentiable and <span class="math inline">\(f^{\prime} = g\)</span>.</p>
<h4 id="theorem-6.3.2">Theorem 6.3.2</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of differentiable functions defined on the closed interval <span class="math inline">\([a, b]\)</span>, and assume <span class="math inline">\((f^{\prime}_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span>. If there exists a point <span class="math inline">\(x_0 \in [a, b]\)</span>, where <span class="math inline">\(f_{n} (x_0)\)</span> is convergent, then <span class="math inline">\((f_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span>.</p>
<h4 id="theorem-6.3.3-combine-theorem-6.3.1-and-6.3.2">Theorem 6.3.3: Combine Theorem 6.3.1 and 6.3.2</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of differentiable functions defined on the closed interval <span class="math inline">\([a, b]\)</span>, and assume <span class="math inline">\((f^{\prime}_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span> to a function <span class="math inline">\(g\)</span> on <span class="math inline">\([a, b]\)</span>. If there exists a point <span class="math inline">\(x_0 \in [a, b]\)</span>, where <span class="math inline">\(f_{n} (x_0)\)</span> is convergent, then <span class="math inline">\((f_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span>. Moreover, the limit function <span class="math inline">\(f = \lim_{n\rightarrow \infty} f_n\)</span> is differentiable and satisfies <span class="math inline">\(f^{\prime} = g\)</span>.</p>
<h3 id="series-of-functions">Series of Functions</h3>
<h4 id="definition-6.4.1-pointwise-convergence-and-uniform-convergence-of-series-of-functions">Definition 6.4.1: Pointwise Convergence and Uniform Convergence of Series of Functions</h4>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, let <span class="math inline">\(f_n\)</span> and <span class="math inline">\(f\)</span> be functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The infinite series:</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} f_n  = f_1 + f_2 + .... \]</span></p>
<p><strong>converges pointwise</strong> on <span class="math inline">\(A\)</span> to <span class="math inline">\(f\)</span> if the sequence <span class="math inline">\(s_k\)</span> of partial sums defined by:</p>
<p><span class="math display">\[s_k = f_1  + f_2  + ... + f_k\]</span></p>
<p>converges pointwise to <span class="math inline">\(f\)</span>. The series <strong>converges uniformly</strong> on <span class="math inline">\(A\)</span> to <span class="math inline">\(f\)</span> if the sequence <span class="math inline">\(s_k\)</span> converges uniformly on <span class="math inline">\(A\)</span> to <span class="math inline">\(f\)</span>. In either case, we can write:</p>
<p><span class="math display">\[f = \sum^{\infty}_{n=1} f_n\]</span></p>
<p>or</p>
<p><span class="math display">\[f(x) = \sum^{\infty}_{n=1} f_n(x)\]</span></p>
<h4 id="theorem-6.4.2-term-by-term-continuity-theorem">Theorem 6.4.2: Term-by-Term Continuity Theorem</h4>
<p>Let <span class="math inline">\(f_n\)</span> be continuous functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, and assume <span class="math inline">\(\sum^{\infty}_{m=1} f_n\)</span> converges uniformly on <span class="math inline">\(A\)</span> to a function <span class="math inline">\(f\)</span>. Then <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-6.4.3-term-by-term-differentiability-theorem">Theorem 6.4.3: Term-by-Term Differentiability Theorem</h4>
<p>Let <span class="math inline">\(f_n\)</span> be differentiable functions defined on an interval <span class="math inline">\(A\)</span>, and assume <span class="math inline">\(\sum^{\infty}_{n=1} f^{\prime}_n\)</span> converges uniformly to a limit function <span class="math inline">\(g\)</span> on <span class="math inline">\(A\)</span>. If there exists a point <span class="math inline">\(x_0 \in [a, b]\)</span> where <span class="math inline">\(\sum^{\infty}_{n=1} f_n (x_0)\)</span> converges, then the series <span class="math inline">\(\sum^{\infty}_{n=1} f_n\)</span> converges uniformly to a differentiable function <span class="math inline">\(f\)</span> satisfying <span class="math inline">\(f^{\prime} = g\)</span> on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-6.4.4-cauchy-criterion-for-uniform-convergence-of-series">Theorem 6.4.4: Cauchy Criterion for Uniform Convergence of Series</h4>
<p>A series <span class="math inline">\(\sum^{\infty}_{n=1} f_n\)</span> converges uniformly on <span class="math inline">\(A \subseteq \mathbb{R}\)</span> if and only if for every <span class="math inline">\(\epsilon &gt; 0\)</span> there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> s.t</p>
<p><span class="math display">\[|f_{m+1} (x) + f_{m+2} (x) + ... + f_{n} (x) | &lt; \epsilon\]</span></p>
<p>whenever <span class="math inline">\(n &gt; m \geq N\)</span> and <span class="math inline">\(x \in A\)</span></p>
<h4 id="corollary-6.4.5-weierstrass-m-test">Corollary 6.4.5: Weierstrass M-Test</h4>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, let <span class="math inline">\(f_n\)</span> be a function defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, and let <span class="math inline">\(M_n &gt; 0\)</span> be a real number satisfying:</p>
<p><span class="math display">\[|f_n(x)| \leq M_n\]</span></p>
<p>for all <span class="math inline">\(x \in A\)</span>. If <span class="math inline">\(\sum^{\infty}_{n=1} M_n\)</span> converges, then <span class="math inline">\(\sum^{\infty}_{n=1} f_n\)</span> converges uniformly on <span class="math inline">\(A\)</span>.</p>
<!-- more -->
<h3 id="power-series">Power Series</h3>
<p><span class="math display">\[f(x) = \sum^{\infty}_{n=0} a_n x^n = a_0 + a_1x + a_2x^2 + a_3 x^3 + ...\]</span></p>
<h4 id="theorem-6.5.1">Theorem 6.5.1</h4>
<p>If a power series <span class="math inline">\(\sum^{\infty}_{n=0} a_n x^n\)</span> converges at some point <span class="math inline">\(x_0 \in \mathbb{R}\)</span>, then it converges absolutely for any <span class="math inline">\(x\)</span> satisfying <span class="math inline">\(|x| &lt; |x_0|\)</span>.</p>
<h4 id="theorem-6.5.2">Theorem 6.5.2</h4>
<p>If a power series <span class="math inline">\(\sum^{\infty}_{n=0} a_n x^n\)</span> converges absolutely at a point <span class="math inline">\(x_0\)</span>, then it converges uniformly on the closed interval <span class="math inline">\([-c, c]\)</span>, where <span class="math inline">\(c=|x_0|\)</span>.</p>
<h4 id="lemma-6.5.3-abels-lemma">Lemma 6.5.3: Abel's Lemma</h4>
<p>Let <span class="math inline">\(b_n\)</span> satisfy <span class="math inline">\(b_1 \geq b_2 \geq b_3 \geq .... \geq 0\)</span>, and let <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> be a series for which the partial sums are bounded. In other words, assume there exists <span class="math inline">\(A &gt; 0\)</span> s.t</p>
<p><span class="math display">\[|a_1 + a_2 + ... + a_n| \leq A\]</span></p>
<p>for all <span class="math inline">\(n \in \mathbb{N}\)</span>. Then for all <span class="math inline">\(n \in \mathbb{N}\)</span>,</p>
<p>$$|a_1b_1 + a_2b_2 + .... + a_nb_n| </p>
<h4 id="theorem-6.5.4-abels-theorem">Theorem 6.5.4: Abel's Theorem</h4>
<p>Let <span class="math inline">\(g(x) = \sum^{\infty}_{n=0} a_nx^n\)</span> be a power series that converges at the point <span class="math inline">\(x = R &gt; 0\)</span>. Then the series converges uniformly on the interval <span class="math inline">\([0, R]\)</span>. A similar result holds if the series converges at <span class="math inline">\(x = -R\)</span>.</p>
<h4 id="theorem-6.5.5">Theorem 6.5.5</h4>
<p>If a power series converges pointwise on the set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, then it converges uniformly on any compact set <span class="math inline">\(K \subseteq A\)</span>.</p>
<h4 id="theorem-6.5.6">Theorem 6.5.6</h4>
<p>If <span class="math inline">\(\sum^{\infty}_{n=0}a_n x^n\)</span> converges for all <span class="math inline">\(x \in (-R, R)\)</span>, then the differentiated series <span class="math inline">\(\sum^{\infty}_{n=1} na_n x^{n-1}\)</span> converges at each <span class="math inline">\(x\in (-R, R)\)</span> as well. Consequently, the convergence is unifrom on compact sets contained in <span class="math inline">\((-R, R)\)</span>.</p>
<h4 id="theorem-6.5.7">Theorem 6.5.7</h4>
<p>Assume</p>
<p><span class="math display">\[f(x) = \sum^{\infty}_{n=0} a_n x^n\]</span></p>
<p>converges on an interval <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The function <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\(A\)</span> and differentiable on any open interval <span class="math inline">\((-R, R) \subseteq A\)</span>. The derivative is given by:</p>
<p><span class="math display">\[f^{\prime} (x) = \sum^{\infty}_{n=1} na_nx^{n-1}\]</span></p>
<p>Moreover, <span class="math inline">\(f\)</span> is infinitely differentiable on <span class="math inline">\((-R, R)\)</span>, and the successive derivatives can be obtained via term-by-term differentiation of the appropriate series.</p>
<h3 id="taylor-series">Taylor Series</h3>
<p>Given an infinitely differentiable function <span class="math inline">\(f\)</span> defined on some interval centered at zero, the idea is to assume that <span class="math inline">\(f\)</span> has a power series expansion and deduce what the coefficients must be. (<strong>Not every infinitely differentiable function can be represented by its taylor series</strong>)</p>
<h4 id="theorem-6.6.2-taylors-formula-centered-at-zero-maclaurin-series">Theorem 6.6.2: Taylor's Formula Centered at Zero (Maclaurin Series)</h4>
<p>Let</p>
<p><span class="math display">\[f(x) = a_0 + a_1x + a_2x^2 + ...\]</span></p>
<p>be defined on some nontrivial interval centered at zero. Then:</p>
<p><span class="math display">\[a_n = \frac{f^{(n)}(0)}{n!}\]</span></p>
<p>Where <span class="math inline">\(f^{(n)}(0)\)</span> is the <span class="math inline">\(n\)</span>th derivative of <span class="math inline">\(f\)</span> evaluate at <span class="math inline">\(0\)</span>.</p>
<p><strong>This formula assumes that the function <span class="math inline">\(f\)</span> has a power series representation.</strong></p>
<h4 id="theorem-6.6.3-lagranges-remainder-theorem">Theorem 6.6.3: Lagrange's Remainder Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> be differentiable <span class="math inline">\(N + 1\)</span> times on <span class="math inline">\((-R, R)\)</span>, define <span class="math inline">\(a_n = \frac{f^{n} (0)}{n!}\)</span> for <span class="math inline">\(n=0, 1, ... , N\)</span>, and let:</p>
<p><span class="math display">\[S_N(x) = a_0 + a_1 x + a_2 x^2 + ... + a_N x^N\]</span></p>
<p>Given <span class="math inline">\(x \neq 0\)</span> in <span class="math inline">\((-R, R)\)</span>, there exists a point <span class="math inline">\(c\)</span> satisfying <span class="math inline">\(|c| &lt; |x|\)</span> where the error function <span class="math inline">\(E_N(x) = f(x) - S_N (x)\)</span> satisfies:</p>
<p><span class="math display">\[E_N(x) = \frac{f^{(N+1)} (c)}{(N+1)!} x^{N+1}\]</span></p>
<h4 id="definition-6.6.7-taylor-series-centered-at-a-neq-0">Definition 6.6.7: Taylor Series Centered at <span class="math inline">\(a \neq 0\)</span></h4>
<p>If <span class="math inline">\(f\)</span> is defined in some neighborhood of <span class="math inline">\(a \in \mathbb{R}\)</span> and infinitely differentiable at <span class="math inline">\(a\)</span>, then the Taylor series expansion around <span class="math inline">\(a\)</span> takes the form:</p>
<p><span class="math display">\[\sum^{\infty}_{n=0}c_n (x - a)^n\]</span></p>
<p>where <span class="math inline">\(c_n = \frac{f^{(n)} (a)}{n!}\)</span></p>
<h3 id="the-weierstrass-approximation-theorem">The Weierstrass Approximation Theorem</h3>
<h4 id="theorem-6.7.1-weierstrass-approximation-theorem">Theorem 6.7.1: Weierstrass Approximation Theorem</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous. Given <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a polynomial <span class="math inline">\(p(x)\)</span> satisfying:</p>
<p><span class="math display">\[|f(x) - p(x) | &lt; \epsilon\]</span></p>
<p>for all <span class="math inline">\(x \in [a, b]\)</span>.</p>
<p>In other words, every continuous function on a closed interval can be uniformly approximated by a polynomial.</p>
<h4 id="definition-6.7.2-polygonal">Definition 6.7.2: Polygonal</h4>
<p>A continuous function <span class="math inline">\(\phi: [a, b] \rightarrow \mathbb{R}\)</span> is <strong>polygonal</strong> if there is a partition:</p>
<p><span class="math display">\[a = x_0 &lt; x_1 &lt; x_2 &lt; .... &lt; x_n = b\]</span></p>
<p>of <span class="math inline">\([a, b]\)</span> such that <span class="math inline">\(\phi\)</span> is linear on each subinterval <span class="math inline">\([x_{i-1}, x_i]]\)</span> where <span class="math inline">\(i=1, ..., n\)</span></p>
<h4 id="theorem-6.7.3">Theorem 6.7.3</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous. Given <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a polygonal function <span class="math inline">\(\phi\)</span> satisfying:</p>
<p><span class="math display">\[|f(x) - \phi(x) | &lt; \epsilon\]</span></p>
<h2 id="the-riemann-integral">The Riemann Integral</h2>
<h3 id="the-definition-of-the-riemann-integral">The Definition of the Riemann Integral</h3>
<p><strong>Throughout this section, it is assumed that we are working with a bounded function <span class="math inline">\(f\)</span> on a closed interval <span class="math inline">\([a, b]\)</span>, meaning that there exists an <span class="math inline">\(M &gt; 0\)</span> s.t <span class="math inline">\(|f(x)| \leq M, \; \forall x \in [a, b]\)</span></strong></p>
<h4 id="definition-7.2.1-partition-lower-sum-upper-sum">Definition 7.2.1: Partition, Lower Sum, Upper Sum</h4>
<p>A <strong>partition</strong> <span class="math inline">\(P\)</span> of <span class="math inline">\([a, b]\)</span> is a finite set of points from <span class="math inline">\([a, b]\)</span> that includes both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. A partition <span class="math inline">\(P = \{x_0, ...., x_n\}\)</span> is listed in increasing order:</p>
<p><span class="math display">\[a=x_0 &lt; x_1 &lt; x_2 &lt; ... &lt; x_n = b\]</span></p>
<p>For each subinterval <span class="math inline">\([x_{k-1}, x_k]\)</span> of <span class="math inline">\(P\)</span>, let:</p>
<p><span class="math display">\[m_k = \inf\{f(x): x \in [x_{k-1}, x_k]\}\]</span></p>
<p>and</p>
<p><span class="math display">\[M_k = \sup\{f(x): x\in[x_{k-1}, x_k]\}\]</span></p>
<p>Since the function is bounded, the supreme and infimum always exists.</p>
<p>The <strong>lower sum</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(P\)</span> is given by:</p>
<p><span class="math display">\[L(f, P) = \sum^{n}_{k=1} m_k (x_k - x_{k-1})\]</span></p>
<p>The <strong>upper sum</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(P\)</span> is given by:</p>
<p><span class="math display">\[U(f, P) = \sum^{n}_{k=1} M_k (x_k - x_{k-1})\]</span></p>
<p>For a particular partition <span class="math inline">\(P\)</span>, it is clear that:</p>
<p><span class="math display">\[U(f, P) \geq L(f, P)\]</span></p>
<h4 id="definition-7.2.2-refinement">Definition 7.2.2: Refinement</h4>
<p>A partition <span class="math inline">\(Q\)</span> is a <strong>refinement</strong> of a partition <span class="math inline">\(P\)</span> if <span class="math inline">\(Q\)</span> contains all of the points of <span class="math inline">\(P\)</span> if <span class="math inline">\(Q\)</span> contains all of the points of <span class="math inline">\(P\)</span>; that is, if <span class="math inline">\(P \in Q\)</span>.</p>
<h4 id="lemma-7.2.3">Lemma 7.2.3</h4>
<p>If <span class="math inline">\(P \subseteq Q\)</span>, then <span class="math inline">\(L(f, P) \leq L(f, Q)\)</span>, and <span class="math inline">\(U(f, P) \geq U(f, Q)\)</span>.</p>
<h4 id="lemma-7.2.4">Lemma 7.2.4</h4>
<p>If <span class="math inline">\(P_1, P_2\)</span> are any two partitions of <span class="math inline">\([a, b]\)</span>, then <span class="math inline">\(L(f, P_1) \leq U(f, P_2)\)</span>.</p>
<p><strong>We can think of upper sum as an overestimate for the value of the integral and a lower sum as an underestimate. As the partitions get more refined, the upper sums get potentially smaller while the lower sums get potentially larger.</strong></p>
<h4 id="definition-7.2.5-upper-integral-lower-integral">Definition 7.2.5: Upper Integral, Lower Integral</h4>
<p>Let <span class="math inline">\(\mathbf{P}\)</span> be the collection of all possible partitions of the interval <span class="math inline">\([a, b]\)</span>. The <strong>upper integral</strong> of <span class="math inline">\(f\)</span> is defined to be:</p>
<p><span class="math display">\[U(f) = \inf\{U(f, P): P \in \mathbf{P}\}\]</span></p>
<p>In a similar way, define the <strong>lower integral</strong> of <span class="math inline">\(f\)</span> by:</p>
<p><span class="math display">\[L(f) = \sup\{L(f, P): P\in\mathbf{P}\}\]</span></p>
<h4 id="lemma-7.2.6">Lemma 7.2.6</h4>
<p>For any bounded function <span class="math inline">\(f\)</span> on <span class="math inline">\([a, b]\)</span>, it is always the case that <span class="math inline">\(U(f) \geq L(f)\)</span>.</p>
<h4 id="definition-7.2.7-riemann-integrability">Definition 7.2.7: Riemann Integrability</h4>
<p>A bounded function <span class="math inline">\(f\)</span> defined on the interval <span class="math inline">\([a, b]\)</span> is <strong>Riemann-integrable</strong> if <span class="math inline">\(U(f) = L(f)\)</span>. In this case, we define <span class="math inline">\(\int^{b}_{a} f\)</span> or <span class="math inline">\(\int^{a}_{b} f(x) dx\)</span> to be this common value, namely:</p>
<p><span class="math display">\[\int^b_{a} f = U(f) = L(f)\]</span></p>
<h3 id="criteria-for-integrability">Criteria for Integrability</h3>
<h4 id="theorem-7.2.8-integrability-criterion">Theorem 7.2.8: Integrability Criterion</h4>
<p>A bounded function <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, b]\)</span> if and only if, for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a partition <span class="math inline">\(P_{\epsilon}\)</span> of <span class="math inline">\([a, b]\)</span> s.t</p>
<p><span class="math display">\[U(f, P_\epsilon) - L(f, P_{\epsilon}) &lt; \epsilon\]</span></p>
<h4 id="theorem-7.2.9">Theorem 7.2.9</h4>
<p>If <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\([a, b]\)</span>, then it is integrable.</p>
<h4 id="theorem-7.3.2">Theorem 7.3.2</h4>
<p>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is bounded, and <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([c, b]\)</span> for all <span class="math inline">\(c \in (a, b)\)</span>, then <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, b]\)</span>. An analogous result holds at the other end point.</p>
<h3 id="properties-of-the-integral">Properties of the Integral</h3>
<h4 id="theorem-7.4.1">Theorem 7.4.1</h4>
<p>Assume <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is bounded, and let <span class="math inline">\(c \in (a, b)\)</span>. Then, <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, b]\)</span> if and only if <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, c]\)</span> and <span class="math inline">\([c, b]\)</span>. In this case, we have:</p>
<p><span class="math display">\[\int^{b}_{a} f = \int^{c}_{a} f + \int^{b}_{c} f\]</span></p>
<h4 id="theorem-7.4.2">Theorem 7.4.2</h4>
<p>Assume <span class="math inline">\(f, g\)</span> are integrable functions on the interval <span class="math inline">\([a, b]\)</span>.</p>
<ol type="1">
<li>The function <span class="math inline">\(f + g\)</span> is integrable on <span class="math inline">\([a, b]\)</span> with <span class="math inline">\(\int^{b}_{a} (f + g) = \int^{b}_{a} f + \int^{b}_{a} g\)</span>.</li>
<li>For <span class="math inline">\(k \in \mathbb{R}\)</span>, the function <span class="math inline">\(kf\)</span> is integrable with <span class="math inline">\(\int^{b}_{a} kf = k \int^{b}_{a} f\)</span>.</li>
<li>If <span class="math inline">\(m \leq f(x) \leq M\)</span> on <span class="math inline">\([a, b]\)</span>, then <span class="math inline">\(m(b - a) \leq \int^{b}_{a} f \leq M (b - a)\)</span>.</li>
<li>If <span class="math inline">\(f(x) \leq g(x)\)</span> on <span class="math inline">\([a, b]\)</span>, then <span class="math inline">\(\int^{b}_{a} f \leq \int^b_a g\)</span></li>
<li>The function <span class="math inline">\(|f|\)</span> is integrable and <span class="math inline">\(|\int^{b}_{a} f| \leq \int^{b}_{a} |f|\)</span></li>
</ol>
<h4 id="definition-7.4.3">Definition 7.4.3</h4>
<p>If <span class="math inline">\(f\)</span> is integrable on the interval <span class="math inline">\([a, b]\)</span>, define:</p>
<p><span class="math display">\[\int^a_{b} f = - \int^b_a f\]</span></p>
<p>Also, for <span class="math inline">\(c \in [a, b]\)</span>, definte:</p>
<p><span class="math display">\[\int^c_c f = 0\]</span></p>
<h4 id="theorem-7.4.4-integrable-limit-theorem">Theorem 7.4.4: Integrable Limit Theorem</h4>
<p>Assume that <span class="math inline">\(f_n \rightarrow f\)</span> uniformly on <span class="math inline">\([a, b]\)</span> and that each <span class="math inline">\(f_n\)</span> is integrable. Then <span class="math inline">\(f\)</span> is integrable and:</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} f_n = \int^b_{a} f\]</span></p>
<h3 id="the-fundamental-theorem-of-calculus">The Fundamental Theorem of Calculus</h3>
<h4 id="theorem-7.5.1-fundamental-theorem-of-calculus">Theorem 7.5.1: Fundamental Theorem of Calculus</h4>
<ol type="1">
<li><p>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is integrable, and <span class="math inline">\(\mathbb{F}: [a, b] \rightarrow \mathbb{R}\)</span> satisfies <span class="math inline">\(F^{\prime} (x) = f(x) \;\; \forall x \in [a, b]\)</span> satisfies <span class="math inline">\(F^{\prime} (x) = f(x), \; \forall x \in [a, b]\)</span>, then:</p>
<p><span class="math display">\[\int^b_a f = F(b) - F(a)\]</span></p></li>
<li><p>Let <span class="math inline">\(g: [a, b] \rightarrow \mathbb{R}\)</span> be integrable, and for <span class="math inline">\(x \in [a, b]\)</span>, define:</p>
<p><span class="math display">\[G(x) = \int^x_a g\]</span></p>
<p>Then <span class="math inline">\(G\)</span> is continuous on <span class="math inline">\([a, b]\)</span>. If <span class="math inline">\(g\)</span> is continuous at some point <span class="math inline">\(c \in [a, b]\)</span>, then <span class="math inline">\(G\)</span> is differentiable at <span class="math inline">\(c\)</span> and <span class="math inline">\(G^{\prime}(c) = g(c)\)</span></p>
<p><span class="math display">\[G^{\prime}(x) = \frac{d}{dx} \int^x_a g = g(x)\]</span></p></li>
</ol>
<h4 id="definition-7.6.1-measure-zero">Definition 7.6.1: Measure Zero</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> has <strong>measure zero</strong> if, for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a countable collection of open intervals <span class="math inline">\(O_n\)</span> with the property that <span class="math inline">\(A\)</span> is contained in the union of all of the intervals <span class="math inline">\(O_n\)</span> and the sum of the lengths of all of the intervals is less than or equal to <span class="math inline">\(\epsilon\)</span>. More precisely, if <span class="math inline">\(|O_n|\)</span> refers to the length of the interval <span class="math inline">\(O_n\)</span>, then we have:</p>
<p><span class="math display">\[A \subseteq \bigcup^{\infty}_{n=1} O_n\]</span></p>
<p>and</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} | O_n | \leq \epsilon\]</span></p>
<blockquote>
<p>Consider a finite set <span class="math inline">\(A = \{a_1, ..., a_n\}\)</span>. To show that <span class="math inline">\(A\)</span> has measure zero, let <span class="math inline">\(\epsilon &gt; 0\)</span> be arbitrary. For each <span class="math inline">\(1 \leq n &lt; N\)</span>, construct the interval: <span class="math display">\[G_n = (a_n - \frac{\epsilon}{2N}, a_n + \frac{\epsilon}{2N})\]</span></p>
<p>Clearly, <span class="math inline">\(A\)</span> is contained in the union of these intervals, and <span class="math display">\[\sum^N_{n=1} | G_n | = \sum^N_{n=1}\frac{\epsilon}{N} = \epsilon\]</span></p>
</blockquote>
<h4 id="definition-7.6.3-alpha-continuity">Definition 7.6.3: <span class="math inline">\(\alpha\)</span>-Continuity</h4>
<p>Let <span class="math inline">\(f\)</span> be defined on <span class="math inline">\([a, b]\)</span>, and let <span class="math inline">\(\alpha &gt; 0\)</span>. The function <span class="math inline">\(f\)</span> is <span class="math inline">\(\alpha\)</span>-continuous at <span class="math inline">\(x \in [a, b]\)</span> if there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t for all <span class="math inline">\(y, z \in (x - \delta, x + \delta)\)</span>, it follows that <span class="math inline">\(|f(y) - f(z)| &lt; \alpha\)</span>.</p>
<p>Let <span class="math inline">\(f\)</span> be a bounded function on <span class="math inline">\([a, b]\)</span>, for each <span class="math inline">\(\alpha &gt; 0\)</span>, defined <span class="math inline">\(D^{\alpha}\)</span> to be the set of points in <span class="math inline">\([a, b]\)</span>, where the function <span class="math inline">\(f\)</span> fails to be <span class="math inline">\(\alpha\)</span>-continuous;</p>
<h4 id="definition-7.6.4-uniformly-alpha-continuous">Definition 7.6.4: Uniformly <span class="math inline">\(\alpha\)</span>-continuous</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is uniformly <span class="math inline">\(\alpha\)</span>-continuous on <span class="math inline">\(A\)</span>, if there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t whenever <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are points in <span class="math inline">\(A\)</span> satisfying <span class="math inline">\(|x - y| &lt; \delta\)</span>, it follows that <span class="math inline">\(|f(x) - f(y)| &lt; \alpha\)</span>..</p>
<h4 id="theorem-7.6.5-lebesgues-theorem">Theorem 7.6.5 Lebesgue's Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> be a bounded function defined on the interval <span class="math inline">\([a, b]\)</span>. Then, <span class="math inline">\(f\)</span> is Riemann-integrable if and only if the set of points where <span class="math inline">\(f\)</span> is not continuous has measure zero.</p>
<h4 id="definition-8.4.3-improper-riemann-integrals">Definition 8.4.3: Improper Riemann Integrals</h4>
<p>Assume <span class="math inline">\(f\)</span> is defined on <span class="math inline">\([a, \infty)\)</span> and integrable on every interval of the form <span class="math inline">\([a, b]\)</span>. Then define <span class="math inline">\(\int^{\infty}_{a} f\)</span> to be:</p>
<p><span class="math display">\[\lim_{b \rightarrow \infty} \int^{b}_{a} f\]</span></p>
<p>provided the limit exists, in this case we say that the <strong>improper integral</strong> <span class="math inline">\(\int^{\infty}_a f\)</span> converges.</p>
<h3 id="interchange-of-limits-2">Interchange of Limits [2]</h3>
<h4 id="theorem-8.2.4">Theorem 8.2.4</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions be defined on <span class="math inline">\([a, b] \in \mathbb{R}\)</span> and suppose that <span class="math inline">\((f_n)\)</span> converges <strong>uniformly</strong> on <span class="math inline">\([a, b]\)</span> to <span class="math inline">\(f\)</span>. Then <span class="math inline">\(f \in \mathbb{R}\)</span> and:</p>
<p><span class="math display">\[\int^{a}_{b} f = \lim_{n \rightarrow \infty} \int^b_a f_n\]</span></p>
<p>We can switch the integral and the limit.</p>
<h4 id="theorem-8.2.5-bounded-convergence-theorem">Theorem 8.2.5: Bounded Convergence Theorem</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence defined on <span class="math inline">\(\mathbb{R}[a, b]\)</span> that converges on <span class="math inline">\([a, b]\)</span> to a function <span class="math inline">\(f \in \mathbb{R} [a, b]\)</span>. Suppose also that there exists a <span class="math inline">\(B &gt; 0\)</span> s.t <span class="math inline">\(|f_n(x)| \leq B, \; \forall x \in [a, b]\)</span>, <span class="math inline">\(n \in \mathbb{N}\)</span>. Then:</p>
<p><span class="math display">\[\int^{a}_{b} f = \lim_{n \rightarrow \infty} \int^b_a f_n\]</span></p>
<h4 id="theorem-8.2.6-dinis-theorem">Theorem 8.2.6: Dini's Theorem</h4>
<p>Suppose that <span class="math inline">\((f_n)\)</span> is a monotone sequence of continuous functions on <span class="math inline">\(I:=[a, b]\)</span> that converges on <span class="math inline">\(I\)</span> to a continuous function <span class="math inline">\(f\)</span>. Then the convergence of the sequence is uniform.</p>
<h3 id="the-exponential-function">The Exponential Function</h3>
<h4 id="theorem-8.3.1">Theorem 8.3.1:</h4>
<p>There exists a function <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t:</p>
<ol type="1">
<li><span class="math inline">\(E^{\prime} (x) = E(x)\)</span></li>
<li><span class="math inline">\(E(0) = 1\)</span></li>
</ol>
<h5 id="partial-proof-of-theorem-8.3.1">Partial Proof of Theorem 8.3.1</h5>
<p>We define a sequence <span class="math inline">\((E_n)\)</span> of continuous functions as follows:</p>
<ol type="1">
<li><span class="math inline">\(E_{1} (x) := 1 + x\)</span></li>
<li><span class="math inline">\(E_{n + 1} (x) := 1 + \int^x_0 E_n(t) dt\)</span></li>
</ol>
<p>for all <span class="math inline">\(n \in \mathbb{N}, x \in \mathbb{R}\)</span>, we can also show that:</p>
<p><span class="math display">\[E_{n} (x) = 1 + \frac{x}{1!} + \frac{x^2}{2!} + ... + \frac{x^n}{n!}\]</span></p>
<p>We can show that the limiting function <span class="math inline">\(E = \lim_{n\rightarrow \infty}\)</span> exists and satisfies all two points of <code>theorem 8.3.1</code>.</p>
<h4 id="corollary-8.3.2">Corollary 8.3.2</h4>
<p>The function <span class="math inline">\(E\)</span> has a derivative of every order and <span class="math inline">\(E^(n) (x) = E(x), \; \forall n \in \mathbb{N}, x \in \mathbb{R}\)</span>.</p>
<h4 id="corollary-8.3.3">Corollary 8.3.3</h4>
<p>If <span class="math inline">\(x &gt; 0\)</span>, then <span class="math inline">\(1 + x &lt; E(x)\)</span></p>
<h4 id="theorem-8.3.4">Theorem 8.3.4</h4>
<p>The function <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span> that satisfies <code>theorem 8.3.1 (i) and (ii)</code> is unique.</p>
<h4 id="definition-8.3.5">Definition 8.3.5</h4>
<p>The unique function <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span>, such that <span class="math inline">\(E^{\prime} (x) = E(x)\)</span> for all <span class="math inline">\(x \in \mathbb{R}\)</span> and <span class="math inline">\(E(0) = 1\)</span> is called the <strong>exponential function</strong>. The number <span class="math inline">\(e := E(1)\)</span> is called <strong>Euler's number</strong>:</p>
<p><span class="math display">\[\exp(x) := E(x)\]</span></p>
<p>or</p>
<p><span class="math display">\[e^x := E(x)\]</span></p>
<p>for <span class="math inline">\(x \in \mathbb{R}\)</span></p>
<h4 id="theorem-8.3.6">Theorem 8.3.6</h4>
<p>The exponential function satisfies the following properties:</p>
<ol type="1">
<li><span class="math inline">\(E(x) \neq 0, \; \forall x \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(E(x + y) = E(x)E(y), \; \forall x, y \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(E(r) = e^r, \;\forall r \in \mathbb{Q}\)</span></li>
</ol>
<h4 id="theorem-8.3.7">Theorem 8.3.7</h4>
<p>The exponential function <span class="math inline">\(E\)</span> is <strong>strictly increasing</strong> on <span class="math inline">\(\mathbb{R}\)</span> and has range equal to <span class="math inline">\(y \in \mathbb{R}: y &gt; 0\)</span>. Further, we have:</p>
<ol type="1">
<li><span class="math inline">\(\lim_{x \rightarrow \infty} E(x) = 0\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow \infty} E(x) = \infty\)</span></li>
</ol>
<h3 id="the-logarithm-function">The Logarithm Function</h3>
<h4 id="definition-8.3.8-logarithm-function">Definition 8.3.8: Logarithm Function</h4>
<p>The function inverse to <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span> is called the <strong>logarithm (natural logarithm)</strong> denoted by <span class="math inline">\(L\)</span> or by <span class="math inline">\(\ln\)</span>.</p>
<p>Since they are inverse, we have:</p>
<p><span class="math display">\[(L \circ E) (x) = x, \; \forall x \in \mathbb{R}\]</span></p>
<p>and</p>
<p><span class="math display">\[(E \circ L) (y) = y, \; \forall y \in \mathbb{R}, y &gt; 0\]</span></p>
<h4 id="theorem-8.3.9">Theorem 8.3.9</h4>
<p>The logarithm is a strictly increasing function <span class="math inline">\(L\)</span> with doman <span class="math inline">\(x \in \mathbb{R}: x &gt; 0\)</span> and range <span class="math inline">\(\mathbb{R}\)</span>. The derivative of <span class="math inline">\(L\)</span> is given by:</p>
<ol type="1">
<li><span class="math inline">\(L^{\prime} (x) = \frac{1}{x}\)</span></li>
<li><span class="math inline">\(L(xy) = L(x) L(y)\)</span></li>
<li><span class="math inline">\(L(1) = 0, L(e) = 1\)</span></li>
<li><span class="math inline">\(L(x^r) = rL(x), \; \forall r \in \mathbb{Q}\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow 0^+} L(x) = -\infty\)</span> and <span class="math inline">\(\lim_{x \rightarrow \infty} L(x) = \infty\)</span></li>
</ol>
<h3 id="power-function">Power Function</h3>
<h4 id="definition-8.3.10-power-function">Definition 8.3.10: Power Function</h4>
<p>If <span class="math inline">\(\alpha \in \mathbb{R}\)</span> and <span class="math inline">\(x &gt; 0\)</span>, the number <span class="math inline">\(x^\alpha\)</span> is defined to be</p>
<p><span class="math display">\[x^\alpha := e^{\alpha \ln x} = E(\alpha L(x))\]</span></p>
<p>The function <span class="math inline">\(x \rightarrow x^\alpha\)</span> for <span class="math inline">\(x &gt; 0\)</span> is called the <strong>power function</strong> with exponent <span class="math inline">\(\alpha\)</span>.</p>
<h4 id="theorem-8.3.11">Theorem 8.3.11</h4>
<p>If <span class="math inline">\(\alpha \in \mathbb{R}\)</span> and <span class="math inline">\(x, y\)</span> belong to <span class="math inline">\((0, \infty)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(1^\alpha = 1\)</span></li>
<li><span class="math inline">\(x^\alpha &gt; 0\)</span></li>
<li><span class="math inline">\((xy)^\alpha = x^\alpha y^\alpha\)</span></li>
<li><span class="math inline">\((\frac{x}{y})^{\alpha} = \frac{x^\alpha}{y^\alpha}\)</span></li>
</ol>
<h4 id="theorem-8.3.12">Theorem 8.3.12</h4>
<p>If <span class="math inline">\(\alpha, \beta \in \mathbb{R}\)</span> and <span class="math inline">\(x \in (0, \infty)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(x^{\alpha + \beta} = x^{\alpha} + x^{\beta}\)</span></li>
<li><span class="math inline">\((x^\alpha)^\beta = x^{\alpha\beta} = (x^{\beta})^\alpha\)</span></li>
<li><span class="math inline">\(x^{-\alpha} = \frac{1}{x^\alpha}\)</span></li>
<li>If <span class="math inline">\(\alpha &lt; \beta\)</span>, then <span class="math inline">\(x^\alpha &lt; x^\beta\)</span> for <span class="math inline">\(x &gt; 1\)</span></li>
</ol>
<h4 id="theorem-8.3.13">Theorem 8.3.13</h4>
<p>Let <span class="math inline">\(\alpha \in \mathbb{R}\)</span>. Then the function <span class="math inline">\(x \rightarrow x^\alpha\)</span> on <span class="math inline">\((0, \infty)\)</span> to <span class="math inline">\(\mathbb{R}\)</span> is continuous and differentiable, and</p>
<p><span class="math display">\[D x^\alpha = \alpha x^{\alpha - 1}\]</span></p>
<p>If <span class="math inline">\(\alpha &gt; 0\)</span> the power function is strictly increasing, if <span class="math inline">\(\alpha &lt; 0\)</span>, the power function is strictly decreasing.</p>
<h3 id="function-log_a">Function <span class="math inline">\(\log_a\)</span></h3>
<p>if <span class="math inline">\(a &gt; 0\)</span>, <span class="math inline">\(a \neq 1\)</span>, it is sometimes useful to define the function <span class="math inline">\(\log_a\)</span></p>
<h4 id="definition-8.3.14">Definition 8.3.14</h4>
<p>Let <span class="math inline">\(a &gt; 0, a \neq 1\)</span>. We define:</p>
<p><span class="math display">\[\log_a (x) := \frac{\ln x}{\ln a}\]</span></p>
<p>for <span class="math inline">\(x \in (0, \infty)\)</span></p>
<p>This is called <strong>logarithm of <span class="math inline">\(x\)</span> to the base <span class="math inline">\(a\)</span>.</strong></p>
<h3 id="the-trigonometric-function">The Trigonometric Function</h3>
<h4 id="theorem-8.4.1">Theorem 8.4.1</h4>
<p>There exist functions <span class="math inline">\(C: \mathbb{R} \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(S: \mathbb{R} \rightarrow \mathbb{R}\)</span> such that:</p>
<ol type="1">
<li><span class="math inline">\(C^{\prime\prime} (x) = - C(x)\)</span> and <span class="math inline">\(S^{\prime\prime} (x) = - S(x)\)</span> for all <span class="math inline">\(S: \mathbb{R} \rightarrow \mathbb{R}\)</span>.</li>
<li><span class="math inline">\(C(0) = 1, C^{\prime} (0)\)</span>, and <span class="math inline">\(S(0) = 0, S^{\prime} (0) = 1\)</span></li>
</ol>
<h5 id="partial-proof-of-theorem-8.4.1">Partial Proof of Theorem 8.4.1</h5>
<p>Define the sequences <span class="math inline">\((C_n), (S_n)\)</span> of continuous functions inductively as:</p>
<ol type="1">
<li><span class="math inline">\(C_1 (x) := 1, \; S_1 (x) := x\)</span></li>
<li><span class="math inline">\(S_n(x) := \int^x_0 C_n(t) dt\)</span></li>
<li><span class="math inline">\(C_{n+1} (x) := 1 - \int^x_0 S_n(t) dt\)</span></li>
</ol>
<p>for all <span class="math inline">\(n \in \mathbb{N}, x \in \mathbb{R}\)</span>. By induction, we have:</p>
<p><span class="math display">\[C_{n+1} (x) = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - ... + (-1)^n \frac{x^{2n}}{(2n)!}\]</span> <span class="math display">\[S_{n+1} (x) = x - \frac{x^3}{3!} + \frac{x^5}{t!} - .... + (-1)^n \frac{x^{2n+1}}{(2n+1)!}\]</span></p>
<p>Then the sequences converges uniformly to some function <span class="math inline">\(C, S\)</span> that satisfies all the properties of <code>theorem 8.4.1</code>.</p>
<h4 id="corollary-8.4.2">Corollary 8.4.2</h4>
<p>If <span class="math inline">\(C, S\)</span> are the functions in <code>theorem 8.4.1</code>, then:</p>
<ol type="1">
<li><span class="math inline">\(C^{\prime} (x) = -S(x)\)</span> and <span class="math inline">\(S^{\prime} (x) = C(x)\)</span> for all <span class="math inline">\(x \in \mathbb{R}\)</span>.</li>
</ol>
<p>Moreover, these functions have derivatives of all orders.</p>
<h4 id="corollary-8.4.3">Corollary 8.4.3</h4>
<p>The functions <span class="math inline">\(C, S\)</span> satisfy the pythagorean identity:</p>
<ol type="1">
<li><span class="math inline">\((C(x))^2 + (S(x))^2 = 1\)</span></li>
</ol>
<h4 id="theorem-8.4.4">Theorem 8.4.4</h4>
<p>The function <span class="math inline">\(C, S\)</span> satisfying properties of <code>theorem 8.4.1</code> are unique.</p>
<h4 id="definition-8.4.5">Definition 8.4.5</h4>
<p>The unique functions <span class="math inline">\(C: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math inline">\(S: \mathbb{R} \rightarrow \mathbb{R}\)</span> satisfying properties in <code>theorem 8.4.1</code> are called <strong>cosine function</strong> and <strong>sine function</strong>:</p>
<p><span class="math display">\[\cos x := C(x)\]</span> <span class="math display">\[\sin x := S(x)\]</span></p>
<h4 id="theorem-8.4.6">Theorem 8.4.6</h4>
<p>If <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is such that</p>
<p><span class="math display">\[f^{\prime\prime} (x) = -f(x), \;\; \forall x \in \mathbb{R}\]</span></p>
<p>then there exist real numbers <span class="math inline">\(\alpha, \beta\)</span> s.t</p>
<p><span class="math display">\[f(x) = \alpha C(x) + \beta S(x)\]</span></p>
<h4 id="theorem-8.4.7">Theorem 8.4.7:</h4>
<p>The function <span class="math inline">\(C\)</span> is even and <span class="math inline">\(S\)</span> is odd in the sense that:</p>
<ol type="1">
<li><span class="math inline">\(C(-x) = C(x)\)</span> and <span class="math inline">\(S(-x) = - S(x)\)</span></li>
</ol>
<p>If <span class="math inline">\(x, y \in \mathbb{R}\)</span>, then we have the <strong>addition formula</strong>:</p>
<p><span class="math display">\[C(x + y) = C(x) C(y) - S(x)S(y)\]</span> <span class="math display">\[S(x + y) = S(x)C(y) + C(x)S(y)\]</span></p>
<h2 id="ref">Ref</h2>
<p>[1] Understanding Analysis by Stephen Abbott</p>
<p>[2] Introduction to Real Analysis by G.Bartle, R.Sherbert</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Rigorous Probability (2)</title>
    <url>/2022/05/02/rigorous-probability-2/</url>
    <content><![CDATA[<h1 id="rigorous-probability-2">Rigorous Probability (2)</h1>
<h2 id="conditional-expectations">Conditional Expectations</h2>
<h3 id="elementary-conditional-probabilities">Elementary Conditional Probabilities</h3>
<h4 id="definition-8.2-conditional-probability">Definition 8.2 Conditional Probability</h4>
<p>Let <span class="math inline">\((\Omega, \mathbb{A}, P)\)</span> be a probability space adn <span class="math inline">\(B \in \mathbb{A}\)</span>. We define the <strong>conditional probability</strong> given <span class="math inline">\(B\)</span> for any <span class="math inline">\(A \in \mathbb{A}\)</span> by:</p>
<p><span class="math display">\[P(A | B) = \frac{P(A \cap B)}{P(B)}\]</span></p>
<p>with <span class="math inline">\(P(B) &gt; 0\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.4-pcdot-b-is-a-probability-measure">Theorem 8.4: <span class="math inline">\(P(\cdot | B)\)</span> is a Probability Measure</h4>
<p>If <span class="math inline">\(P(B) &gt; 0\)</span>, then <span class="math inline">\(P(\cdot | B)\)</span> is a probability measure on <span class="math inline">\((\Omega, \mathbb{A})\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.5-conditional-probability-of-independent-events">Theorem 8.5: Conditional Probability of Independent Events</h4>
<p>Let <span class="math inline">\(A, B \in \mathbb{A}\)</span> with <span class="math inline">\(P(A), P(B) &gt; 0\)</span>. Then, belows are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(A, B\)</span> are independent.</li>
<li><span class="math inline">\(P(A | B) = P(A)\)</span></li>
<li><span class="math inline">\(P(B | A) = P(B)\)</span></li>
</ol>
<p><br></p>
<span id="more"></span>
<h4 id="theorem-8.6-summation-formula-law-of-total-probability">Theorem 8.6: Summation Formula (Law of Total Probability)</h4>
<p>Let <span class="math inline">\(I\)</span> be a countable set and let <span class="math inline">\((B_i)_{i \in I} \in \mathbf{A}\)</span> be disjoint sets with <span class="math inline">\(P[\bigcup_{i \in I} B_i] = 1\)</span>. Then, for any <span class="math inline">\(A \in \mathbb{A}\)</span>:</p>
<p><span class="math display">\[P(A) = \sum_{i \in I} P(A | B_i) P(B_i)\]</span></p>
<p>If <span class="math inline">\(X\)</span> is a continuous random variable, then:</p>
<p><span class="math display">\[P(A) = \int P(A | X=x) f(x) dx\]</span></p>
<p><br></p>
<h4 id="theorem-8.7-bayess-formula">Theorem 8.7: Bayes's Formula</h4>
<p>Let <span class="math inline">\(I\)</span> be a countable set and let <span class="math inline">\((B_i)_{i \in I} \in \mathbf{A}\)</span> be pairwise disjoint sets with <span class="math inline">\(P(B_i) = 1\)</span>. Then, for any <span class="math inline">\(A \in \mathbb{A}\)</span> with <span class="math inline">\(P(A) &gt; 0\)</span> and any <span class="math inline">\(k \in I\)</span>,</p>
<p><span class="math display">\[P(B_k | A) = \frac{P(A | B_k) P(B_k)}{\sum_{i \in I} P(A | B_i) P(B_i)}\]</span></p>
<p><br></p>
<h4 id="definition-8.9-condition-on-event">Definition 8.9: Condition on Event</h4>
<p>Let <span class="math inline">\(X \in L^1(P)\)</span> and <span class="math inline">\(A \in \mathbf{A}\)</span>. Then we define:</p>
<p><span class="math display">\[E[X | A] := \int X(\omega) P(d\omega | A) = \frac{E[\mathbb{I}_A X]}{P(A)}\]</span></p>
<p>given <span class="math inline">\(P(A) &gt; 0\)</span>. Clearly <span class="math inline">\(P(B | A) = \int \mathbb{I}_B dP(\cdot | A) = E[\mathbb{I}_B | A]\)</span></p>
<p><br></p>
<h4 id="definition-8.10-condition-on-sigma-algebra-of-disjoint-events">Definition 8.10: Condition on Sigma Algebra of Disjoint Events</h4>
<p>Let <span class="math inline">\(I\)</span> be a countable set and let <span class="math inline">\((B_i)_{i \in I}\)</span> be pairwise disjoint events with <span class="math inline">\(\bigcup_{i \in I} B_i = \Omega\)</span>. We define <span class="math inline">\(F := \sigma(B_i, i \in I)\)</span>. For <span class="math inline">\(X \in L^1(P)\)</span>, we define a map <span class="math inline">\(E[X | F]: \Omega \rightarrow \mathbb{R}\)</span> by:</p>
<p><span class="math display">\[E[X | F](\omega) = E[X | B_i] \quad \text{ IFF } \quad \omega \in B_i\]</span></p>
<p><br></p>
<h4 id="theorem-8.10-properties-of-ex-f">Theorem 8.10: Properties of <span class="math inline">\(E[X | F]\)</span></h4>
<p>The map <span class="math inline">\(E[X | F]\)</span> has the following properties:</p>
<ul>
<li><span class="math inline">\(E[X | F]\)</span> is <span class="math inline">\(F\)</span>-measurable.</li>
<li><span class="math inline">\(E[X | F] \in L^1(P)\)</span>, and for any <span class="math inline">\(A \in F\)</span>, we have: <span class="math display">\[\int_A E[X | F] dP = \int_A X dP\]</span></li>
</ul>
<p><br></p>
<h3 id="conditional-expectation">Conditional Expectation</h3>
<p>All the equalities involving conditional expectations are only up to equality a.s. And we will write it explicitly.</p>
<h4 id="definition-8.11-conditional-expectation">Definition 8.11: Conditional Expectation</h4>
<p>Let <span class="math inline">\(F \subseteq \mathbf{A}\)</span> be a sub-<span class="math inline">\(\sigma\)</span>-algebra (A <span class="math inline">\(\sigma\)</span>-algebra contained in <span class="math inline">\(\mathbf{A}\)</span>). Any random variable <span class="math inline">\(Y\)</span> is called a <strong>conditional expectation</strong> of <span class="math inline">\(X\)</span> given <span class="math inline">\(F\)</span>, symbolically <span class="math inline">\(E[X | F] := Y\)</span>, if:</p>
<ol type="1">
<li><span class="math inline">\(Y\)</span> is <span class="math inline">\(F\)</span>-measurable.</li>
<li>For any <span class="math inline">\(A \in F\)</span>, we have <span class="math inline">\(E[\mathbb{I}_A X] = E[\mathbb{I}_A Y]\)</span>.</li>
</ol>
<p>For <span class="math inline">\(B \in \mathbf{A}\)</span>, <span class="math inline">\(P(B | F) := E[\mathbb{I}_B | F]\)</span> is called a <strong>conditional probability</strong> of <span class="math inline">\(B\)</span> given the <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\(F\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.12-existence-and-uniqueness-of-conditional-expectation">Theorem 8.12: Existence and Uniqueness of Conditional Expectation</h4>
<p><span class="math inline">\(E[X | F]\)</span> exists and is unique (up to equality almost surely).</p>
<p><br></p>
<h4 id="definition-8.13-conditional-expectation-with-r.v">Definition 8.13: Conditional Expectation with R.V</h4>
<p>If <span class="math inline">\(Y\)</span> is a random variable and <span class="math inline">\(X \in L^1(P)\)</span>, then we define <span class="math inline">\(E[X | Y] := E[X | \sigma(Y)]\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.14-properties-of-the-conditional-expectation">Theorem 8.14: Properties of the Conditional Expectation</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A}, P)\)</span> and let <span class="math inline">\(X\)</span> be as above. Let <span class="math inline">\(G \subseteq F \subseteq \mathbf{A}\)</span> be <span class="math inline">\(\sigma\)</span>-algebras and let <span class="math inline">\(Y \in L^1(\Omega, \mathbf{A}, P)\)</span>. Then:</p>
<ol type="1">
<li><strong>Linearity</strong>: <span class="math display">\[E[\lambda E + Y | F] = \lambda E[X | F] + E[Y | F]\]</span></li>
<li><strong>Monotonicity</strong>: If <span class="math inline">\(X \geq Y\)</span> a.s, then <span class="math inline">\(E[X | F] \geq E[Y | F]\)</span>.</li>
<li>If <span class="math inline">\(E[|XY|] &lt; \infty\)</span>, and <span class="math inline">\(Y\)</span> is <strong>measurable</strong> w.r.t <span class="math inline">\(F\)</span>, then: <span class="math display">\[E[XY | F] = YE[X | F], \quad E[Y | F] = E[Y | Y] = Y\]</span></li>
<li><strong>Tower Property</strong>: <span class="math display">\[E[E[X | F] | G] = E[E[X | G] | F] = E[X | G]\]</span></li>
<li><strong>Triangle inequality</strong>: <span class="math display">\[E[|X| | F] \geq |E[X | F]|\]</span></li>
<li><strong>Independence</strong>: if <span class="math inline">\(\sigma(X)\)</span> and <span class="math inline">\(F\)</span> are independent, then <span class="math inline">\(E[X | F] = E[X]\)</span>.</li>
<li>If <span class="math inline">\(P(A) \in \{0, 1\}\)</span> for any <span class="math inline">\(A \in F\)</span>, then <span class="math inline">\(E[X | F] = E[X]\)</span>.</li>
<li><strong>Dominated Convergence</strong>: Assume <span class="math inline">\(Y \in L^1(P)\)</span>, <span class="math inline">\(Y \geq 0\)</span> and <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> is a sequence of random variables with <span class="math inline">\(|X_n| \leq Y\)</span> for <span class="math inline">\(n \in \mathbb{N}\)</span> and s.t <span class="math inline">\(P(\lim_{n \rightarrow \infty} X_n = X) = 1\)</span>. Then: <span class="math display">\[\lim_{n \rightarrow \infty} E[X_n | F] = E[X | F] , \;\text{ a. s and in $L^1(P)$}\]</span></li>
</ol>
<p><strong>Intuitively, <span class="math inline">\(E[X | F]\)</span> is the best prediction we can make for the value of <span class="math inline">\(X\)</span> if we only have the information of the <span class="math inline">\(\sigma-\)</span>algebra <span class="math inline">\(F\)</span>. If <span class="math inline">\(\sigma(X) \subseteq F\)</span>, then <span class="math inline">\(E[X | F] = X\)</span>, that is, the knowledge of <span class="math inline">\(F\)</span> give all information on <span class="math inline">\(X\)</span>.</strong></p>
<p><br></p>
<h4 id="theorem-8.17-conditional-expectation-as-orthogonal-projection">Theorem 8.17: Conditional Expectation as Orthogonal Projection</h4>
<p>Let <span class="math inline">\(F \subseteq \mathbf{A}\)</span> be a <span class="math inline">\(\sigma\)</span>-algebra and let <span class="math inline">\(X\)</span> be a random variable with <span class="math inline">\(E[X^2] &lt; \infty\)</span>. Then <span class="math inline">\(E[X | F]\)</span> is the <strong>orthogonal projection</strong> of <span class="math inline">\(X\)</span> on <span class="math inline">\(L^2((\Omega, F, P))\)</span>. That is, for any <span class="math inline">\(F\)</span>-measurable <span class="math inline">\(Y\)</span> with <span class="math inline">\(E[Y^2] &lt; \infty\)</span>:</p>
<p><span class="math display">\[\int (X - Y)^2 dP \geq \int (X - E[X | F])^2 dP = Proj_{(L^2((\Omega, F, P)))}(X)\]</span></p>
<p>In other words:</p>
<p><span class="math display">\[E[(X - Y)^2] \geq E[(X - E[X | F])^2]\]</span></p>
<p>with equality IFF <span class="math inline">\(Y = E[X | F]\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.20-jensens-inequality-for-conditional-expectation">Theorem 8.20: Jensen's Inequality for Conditional Expectation</h4>
<p>Let <span class="math inline">\(I \in \mathbb{R}\)</span> be an interval, let <span class="math inline">\(\psi: I \rightarrow \mathbb{R}\)</span> be <strong>convex</strong> and let <span class="math inline">\(X\)</span> be an <span class="math inline">\(I\)</span>-valued random variable on <span class="math inline">\((\Omega, \mathbf{A}, P)\)</span>. Further, let <span class="math inline">\(E[|X|] &lt; \infty\)</span> and let <span class="math inline">\(F \subseteq \mathbf{A}\)</span> be a <span class="math inline">\(\sigma\)</span>-algebra. Then:</p>
<p><span class="math display">\[\infty \geq E[\psi(X) | F] \geq \psi (E[X | F])\]</span></p>
<p><br></p>
<h4 id="theorem-8.21">Theorem 8.21:</h4>
<p>let <span class="math inline">\(p \in [1, \infty)\)</span> and let <span class="math inline">\(F \subseteq \mathbf{A}\)</span> be a sub-<span class="math inline">\(\sigma\)</span>-algebra. Then the map:</p>
<p><span class="math display">\[L^p ((\Omega, \mathbf{A}, P)) \rightarrow L^p((\Omega, F, P)), \quad X \mapsto E[X | F]\]</span></p>
<p>is a <strong>contraction</strong> mapping. (<span class="math inline">\(\|E[X | F]\|_p \leq \|X\|_p\)</span>) and thus continuous. Hence, for <span class="math inline">\(X, X_1, .... \in L^p(\Omega, \mathbf{A}, P)\)</span> with <span class="math inline">\(\lim_{n \rightarrow \infty}\|X_n - X\|_p = 0\)</span>:</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty}\|E[X_n | F] - E[X | F]\|_p = 0\]</span></p>
<p><br></p>
<h4 id="definition-8.24">Definition 8.24:</h4>
<p>Let <span class="math inline">\(Y \in L^1(P)\)</span> and <span class="math inline">\(X: (\Omega, \mathbf{A}) \to (E, \varepsilon)\)</span>. We define the conditional expectation of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X = x\)</span> by <span class="math inline">\(E[Y | X=x] := \psi(x)\)</span>, where <span class="math inline">\(\psi(X) = E[Y | X]\)</span> is a <span class="math inline">\(\varepsilon-B(\mathbb{R})\)</span> measurable function.</p>
<p>Analogously, define <span class="math inline">\(P(A | X=x) = E[\mathbb{I}_A | X = x], \; \forall A \in \mathbf{A}\)</span></p>
<p><br></p>
<h4 id="definition-8.25-transition-kernel-markove-kernel">Definition 8.25: Transition Kernel, Markove Kernel</h4>
<p>Let <span class="math inline">\((\Omega_1, \mathbf{A}_1), (\Omega_2, \mathbf{A}_2)\)</span> be measurable spaces. A map <span class="math inline">\(k: \Omega_1 \times \mathbf{A}_2 \rightarrow [0, \infty]\)</span> is called a <span class="math inline">\(\sigma\)</span>-finite <strong>transition</strong> kernel (from <span class="math inline">\(\Omega_1\)</span> to <span class="math inline">\(\Omega_2\)</span>) if:</p>
<ol type="1">
<li><span class="math inline">\(\omega_1 \mapsto k(\omega_1, A_2)\)</span> is <span class="math inline">\(\mathbf{A}_1\)</span>-measurable for any <span class="math inline">\(A_2 \in \mathbf{A}_2\)</span>.</li>
<li><span class="math inline">\(A_2 \mapsto k(\omega_1, A_2)\)</span> is a <span class="math inline">\(\sigma\)</span>-finite meausre on <span class="math inline">\((\Omega_2, \mathbf{A}_2)\)</span> for any <span class="math inline">\(\omega_1 \in \Omega_1\)</span>.</li>
</ol>
<p>if the second condition is a probability measure for all <span class="math inline">\(\omega_1 \in \Omega_1\)</span>, then <span class="math inline">\(k\)</span> is called <strong>stochastic kernel</strong> or <strong>Markov kernel</strong>. If in the second condition, we also have <span class="math inline">\(k(\omega_2, \Omega_2) \leq 1\)</span> for any <span class="math inline">\(\omega_1 \in \Omega_1\)</span>, then <span class="math inline">\(k\)</span> is called <strong>sub-Markov</strong>.</p>
<p><br></p>
<h4 id="definition-8.28-regular-conditional-distribution">Definition 8.28: Regular Conditional Distribution</h4>
<p>Let <span class="math inline">\(Y\)</span> be a random variable with values in a measurable space <span class="math inline">\((E, \varepsilon)\)</span> and let <span class="math inline">\(F \subseteq \mathbf{A}\)</span> be a sub-<span class="math inline">\(\sigma\)</span>-algebra. A stochastic kernel <span class="math inline">\(k_{Y, F}\)</span> from <span class="math inline">\((\Omega, F)\)</span> is called a <strong>regular conditional distribution</strong> of <span class="math inline">\(Y\)</span> given <span class="math inline">\(F\)</span> if:</p>
<p><span class="math display">\[k_{Y, F} (\omega, B) = P(\{Y \in B\} | F) (\omega)\]</span></p>
<p>for <span class="math inline">\(P\)</span>-almost all <span class="math inline">\(\omega \in \Omega\)</span> and for all <span class="math inline">\(B \in \varepsilon\)</span>, that is, if:</p>
<p><span class="math display">\[\int \mathbb{I}_{B} (Y) \mathbb{I}_A dP = \int k_{Y, F} (\cdot, B) \mathbb{I}_A d P, \quad \forall A \in F, \; B \in \varepsilon\]</span></p>
<p>Consider a special case where <span class="math inline">\(F = \sigma(X)\)</span> for a random variable <span class="math inline">\(X\)</span> with its values in an arbitrary measurable space <span class="math inline">\((E^\prime, \varepsilon^\prime)\)</span>. Then the stochastic kernel:</p>
<p><span class="math display">\[(x, A) \mapsto k_{Y, X} (x, A) = P(\{Y \in A\} | X = x) = k_{Y, \sigma(X)} (X^{-1}(x), A)\]</span></p>
<p>is called a regular conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.29-regular-conditional-distribution-in-mathbbr">Theorem 8.29: Regular Conditional Distribution in <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>Let <span class="math inline">\(Y: (\Omega, \mathbf{A}) \to (\mathbb{R}, B(\mathbb{R}))\)</span> be real-valued. Then there exists a regular conditional distribution <span class="math inline">\(k_{Y, F}\)</span> of <span class="math inline">\(Y\)</span> given <span class="math inline">\(F\)</span>.</p>
<p><br></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN</title>
    <url>/2021/08/02/rnn/</url>
    <content><![CDATA[<h1 id="recurrent-neural-network">Recurrent Neural Network</h1>
<h2 id="introduction">Introduction</h2>
<p>Consider the recurrent equation:</p>
<p><span class="math display">\[\mathbf{s}^{t} = f(\mathbf{s}^{t-1}; \; \boldsymbol{\theta})\]</span></p>
<p>For a finite time step <span class="math inline">\(\tau\)</span>, this equation can be unfolded by applying the definition <span class="math inline">\(\tau - 1\)</span> times:</p>
<p><span class="math display">\[f(f(....f(\mathbf{s}^{1}; \; \boldsymbol{\theta}) ... ; \; \boldsymbol{\theta}) ; \; \boldsymbol{\theta})\]</span></p>
<p>Then, this expression can now be represented as a DAG because it no longer involves recurrence:</p>
<p><img src="/images/ML/rnn_1.png" width="600"></p>
<p>Notice here, the parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> are shared. The idea extends smoothly to:</p>
<p><span class="math display">\[\mathbf{s}^{t} = f(\mathbf{s}^{t-1}, \mathbf{x}^{t}; \; \boldsymbol{\theta})\]</span></p>
<p>We can see that now, <span class="math inline">\(s^{t}\)</span> contains information about the whole past <span class="math inline">\(\mathbf{x}^1 , ....., \mathbf{x}^t\)</span></p>
<p>Many Recurrent Neural Networks use similar idea to express their hidden units:</p>
<span class="math display">\[\begin{aligned}
\mathbf{h}^t &amp;= f(\mathbf{h}^{t-1}, \mathbf{x}^t ; \; \boldsymbol{\theta})\\
&amp;= g^t (\mathbf{x}^1 , ....., \mathbf{x}^t)
\end{aligned}\]</span>
<p>Typically, RNN will have output layers to output predictions at given timesteps. When the recurrent network is trained to perform a task that requires predicting the future from the past, the network typically learns to use <span class="math inline">\(\mathbf{h}^t\)</span> to give a lossy summary of past sequence up to time <span class="math inline">\(t\)</span>. The summary is lossy because we are mapping <span class="math inline">\(\mathbf{x}^1 , ....., \mathbf{x}^t\)</span> to a fixed length <span class="math inline">\(\mathbf{h}^t\)</span></p>
<p><img src="/images/ML/rnn_2.png" width="600"></p>
<p>The unfolded structure has several advantages:</p>
<ol type="1">
<li>The learned model <span class="math inline">\(f\)</span> is defined as transition from hidden units (input) <span class="math inline">\(h^{t - 1}\)</span> to <span class="math inline">\(h^{t}\)</span> (output) regardless the value of time <span class="math inline">\(t\)</span>. Thus, we can have one model for different lengths of sequences.</li>
<li>The parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> are shared.</li>
</ol>
<span id="more"></span>
<h2 id="forward-pass">Forward Pass</h2>
<p><img src="/images/ML/rnn_3.png" width="600"></p>
<p>In formulas, the forward pass for <strong>same output and input length</strong> RNN with <strong>tanh non-linearity and probability as prediction</strong> can be described as starting from <span class="math inline">\(\mathbf{h}^0\)</span>:</p>
<p><span class="math display">\[\mathbf{a}^{t} = \mathbf{b} + W\mathbf{h}^{t-1} + U\mathbf{x}^{t}\]</span> <span class="math display">\[\mathbf{h}^t = \tanh (\mathbf{a}^t)\]</span> <span class="math display">\[\mathbf{o}^t = \mathbf{c} + V\mathbf{h}^t \]</span> <span class="math display">\[\hat{\mathbf{y}}^t = softmax(\mathbf{o}^t)\]</span></p>
<ul>
<li><span class="math inline">\(W\)</span> is the hidden to hidden weights that encodes information about past sequences.</li>
<li><span class="math inline">\(V\)</span> is the hidden to output weights that is responsible for prediction using current hidden units.</li>
<li><span class="math inline">\(U\)</span> is the input to hidden weights that is responsible for input parameterization.</li>
<li><span class="math inline">\(\mathbf{b}\)</span> is the bias associated with <span class="math inline">\(W\)</span></li>
<li><span class="math inline">\(\mathbf{c}\)</span> is the bias associated with <span class="math inline">\(V\)</span></li>
</ul>
<p>Then the multi-class cross entropy loss of the sequence of <span class="math inline">\(\{(\mathbf{x}^{1}, \mathbf{y}^{1}) ,...., (\mathbf{x}^{\tau}, \mathbf{y}^{\tau})\}\)</span> (<span class="math inline">\(\mathbf{y}\)</span> is encoded as one hot vector) is just the sum of per timestep loss:</p>
<span class="math display">\[\begin{aligned}
L(\{\mathbf{y}^{1}, ..., \mathbf{y}^{\tau}\}, \; \{\mathbf{\hat{y}}^{1}, ..., \mathbf{\hat{y}}^{\tau}\}) &amp;= \sum^{\tau}_{i=1} L(\mathbf{y}^i, \; \mathbf{\hat{y}}^{i})\\
&amp;= -\sum^{\tau}_{i=1} \sum_{k} y_k \log (\hat{y}^{i}_{k})
\end{aligned}\]</span>
<p>Where <span class="math inline">\(\hat{y}^{i}_{k}\)</span> is the <span class="math inline">\(k\)</span>th element of <span class="math inline">\(\mathbf{\hat{y}}^{i}\)</span>. Since we are using one-hot encoding, we can also write it as:</p>
<p><span class="math display">\[L(\{\mathbf{y}^{1}, ..., \mathbf{y}^{\tau}\}, \; \{\mathbf{\hat{y}}^{1}, ..., \mathbf{\hat{y}}^{\tau}\}) = -\sum^{\tau}_{i=1} \log (P_{\hat{Y}}(y^{i} | \{\mathbf{x}^{1}, ..., \mathbf{x}^{\tau}\}))\]</span></p>
<p>Where <span class="math inline">\(P_{\hat{Y}}(y^{i} | \{\mathbf{x}^{1}, ..., \mathbf{x}^{\tau}\})\)</span> is the value of the target position (ie. the position of <span class="math inline">\(\mathbf{y}^{i}\)</span> with 1) in <span class="math inline">\(\mathbf{\hat{y}}\)</span>.</p>
<h2 id="teacher-forcing-and-networks-with-output-recurrence">Teacher Forcing and Networks with Output Recurrence</h2>
<p>RNNs are expensive to train. The runtime is <span class="math inline">\(O(\tau)\)</span> and cannot be reduced by parallelization because the forward propagation graph is inherently sequential (i.e calculation of <span class="math inline">\(\mathbf{h}^t\)</span> depends on <span class="math inline">\(\mathbf{h}^{t-1}\)</span>, the total loss is sum of per-timestep loss and per-timestep loss has to calculate in order); each time step may only be computed after the previous one. States computed in the forward pass must be stored until they are reused during the backward pass, so the memory cost is also <span class="math inline">\(O(\tau)\)</span>.</p>
<p>To reduce computational and memory cost, one way is to remove the hidden to hidden recurrence by a target to hidden recurrence. Thus, for any loss function based on comparing the prediction at time <span class="math inline">\(t\)</span> to the training target at time <span class="math inline">\(t\)</span>, all time steps are decoupled and can be parallelized (because the loss calculation at each time step <span class="math inline">\(t\)</span> is no longer dependent on <span class="math inline">\(\mathbf{h}^{t-1}\)</span>, it only depends on <span class="math inline">\(\mathbf{y}^{t-1}\)</span>).</p>
<p>This technique is called <code>teacher forcing</code>. Teacher forcing is a procedure that emerges from the maximum likelihood criterion, in which during training the model receives the ground truth output <span class="math inline">\(\mathbf{y}^{t-1}\)</span> as input at time <span class="math inline">\(t\)</span>. <strong>It can be applied to train models that have connections from the output at one time step to the value computed in the next time step</strong>.</p>
<p>The disadvantage of strict teacher forcing arises if the network is going to be later used in an open-loop model, with the network outputs fed back as input. In this case, there is a gap between training and testing. One approach to collapse this gap is to mitigate the gap between the inputs seen at train time and the inputs seen at test time randomly chooses to use generated values or actual data values as input.</p>
<p><img src="/images/ML/rnn_4.png" width="600"></p>
<h2 id="backward-pass">Backward Pass</h2>
<p>The backward propagation for RNN is called <code>back propagation through time</code>:</p>
<p>Assume we have RNN structure as forward pass (<strong>gradients are reshaped to column vectors, <span class="math inline">\(\nabla_{\mathbf{v}} L = (\frac{\partial L}{\partial \mathbf{v}})^T\)</span></strong>). Then, for any time step <span class="math inline">\(t\)</span> <span class="math display">\[\frac{\partial L}{\partial L^t} = 1\]</span></p>
<p><span class="math display">\[\frac{\partial L}{\partial L^t} \frac{\partial L^t}{\partial \mathbf{\hat{y}}^t} \frac{\partial \mathbf{\hat{y}}^t}{o^t_i} = \hat{y}^t_i - y^t_i\]</span></p>
<p>Then the gradient for hidden units in last time step <span class="math inline">\(\tau\)</span> is:</p>
<p><span class="math display">\[(\frac{\partial L}{\partial \mathbf{o}^t} \frac{\partial \mathbf{o}^t}{\partial \mathbf{h}^t})^T = V^T \frac{\partial L}{\partial \mathbf{o}^t}\]</span></p>
<p>Work our way backwards for <span class="math inline">\(t = 1, ...., \tau - 1\)</span>, since <span class="math inline">\(\mathbf{h}^t\)</span> is descendants of both <span class="math inline">\(\mathbf{o}^t\)</span> and <span class="math inline">\(\mathbf{h}^{t+1}\)</span>. We have:</p>
<p><span class="math display">\[(\frac{\partial L}{\partial \mathbf{h}^t})^T = (\frac{\partial L}{\partial \mathbf{o}^t}\frac{\partial \mathbf{o}^t}{\partial \mathbf{h}^t})^T + (\frac{\partial L}{\partial \mathbf{h}^{t+1}}\frac{\partial \mathbf{h}^{t+1}}{\partial \mathbf{h}^t})^T\]</span></p>
<p>Since <span class="math inline">\(\frac{\partial \tanh (\mathbf{a}^{t+1})}{\partial \mathbf{a}^{t+1}}\)</span> is a diagonal matrix with <span class="math inline">\(1 - \tanh (h^{t+1}_i)^2\)</span> terms in the diagonal, we can denoted it as:</p>
<span class="math display">\[\begin{aligned}
\frac{\partial \tanh (\mathbf{a}^{t+1})}{\partial \mathbf{a}^{t+1}} &amp;= diag (1 - \tanh (\mathbf{h}^{t+1})^2)\\
\end{aligned}\]</span>
<p><span class="math display">\[\implies (\frac{\partial \mathbf{h}^{t+1}}{\partial \mathbf{h}^{t+1}})^T = W^T diag (1 - \tanh (\mathbf{h}^{t+1})^2)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[(\frac{\partial L}{\partial \mathbf{h}^t})^T = V^T (\frac{\partial L}{\partial \mathbf{o}^t})^T + W^T diag (1 - \tanh (\mathbf{h}^{t+1})^2)(\frac{\partial L}{\partial \mathbf{h}^{t+1}})^T\]</span></p>
<p>Recall that in RNN, all parameters are shared, so <span class="math inline">\(\frac{\partial L}{\partial W}\)</span> represents the contribution of <span class="math inline">\(W\)</span> to the value of <span class="math inline">\(L\)</span> due to all edges in the computational graph. To resolve the ambiguity, we index <span class="math inline">\(W\)</span> by time <span class="math inline">\(W^t\)</span> where <span class="math inline">\(W^t\)</span> is copy of <span class="math inline">\(W\)</span> and only used in time step <span class="math inline">\(t\)</span>. Thus, we can use <span class="math inline">\(\frac{\partial f}{\partial W^t}\)</span> to denote the contribution of the weights to the gradient at time step t:</p>
<p><span class="math display">\[(\frac{\partial L}{\partial \mathbf{c}})^T = \sum^{\tau}_{t=1} I (\frac{\partial L}{\partial \mathbf{o}^t})^T = \sum^{\tau}_{t=1} (\frac{\partial L}{\partial \mathbf{o}^t})^T\]</span> <span class="math display">\[(\frac{\partial L}{\partial \mathbf{b}})^T = \sum^{\tau}_{t=1} diag (1 - \tanh (\mathbf{h}^{t})^2) I (\frac{\partial L}{\partial \mathbf{h}^{t}})^T = \sum^{\tau}_{t=1} diag (1 - \tanh (\mathbf{h}^{t})^2) (\frac{\partial L}{\partial \mathbf{h}^{t}})^T \]</span> <span class="math display">\[\frac{\partial L}{\partial V}= \sum^{\tau}_{t=1} (\frac{\partial L}{\partial \mathbf{o}^t})^T (\mathbf{h}^t)^T\]</span> <span class="math display">\[\frac{\partial L}{\partial W}= \sum^{\tau}_{t=1}  diag (1 - \tanh (\mathbf{h}^{t})^2) (\frac{\partial L}{\partial \mathbf{h}^{t}})^T (\mathbf{h}^{t-1})^T\]</span> <span class="math display">\[\frac{\partial L}{\partial U}= \sum^{\tau}_{t=1}  diag (1 - \tanh (\mathbf{h}^{t})^2) (\frac{\partial L}{\partial \mathbf{h}^{t}})^T (\mathbf{x}^{t})^T\]</span></p>
<h2 id="bidirectional-rnns">Bidirectional RNNs</h2>
<p>The RNN structures so far only captures information from the past (i.e output at time step <span class="math inline">\(t\)</span> is calculated using <span class="math inline">\((\mathbf{x}^1, \mathbf{y}^1) , ...., (\mathbf{x}^{t-1}, \mathbf{y}^{t-1}), \mathbf{x}^t\)</span>). It is sometimes useful to have another RNN that moves from the back of the sequence.</p>
<p><img src="/images/ML/rnn_5.png" width="600"></p>
<ul>
<li><span class="math inline">\(\mathbf{h}^t\)</span> is the hidden units of sub-RNN that moves forward through time.</li>
<li><span class="math inline">\(\mathbf{g}^t\)</span> is the hidden units of sub-RNN that moves backward through time.</li>
<li><span class="math inline">\(\mathbf{o}^t\)</span> is calculated using both <span class="math inline">\(\mathbf{h}^t\)</span>, <span class="math inline">\(\mathbf{g}^t\)</span> but is more sensitive to input values around <span class="math inline">\(t\)</span> without having to specify a fixed-size window around <span class="math inline">\(t\)</span>.</li>
</ul>
<h2 id="encoder-decoder">Encoder-Decoder</h2>
<p><img src="/images/ML/rnn_6.png" width="600"> <img src="/images/ML/rnn_7.png" width="600"></p>
<p>We know that we can use RNN to encode inputs to a fixed length vector, and we know that we can map a fixed-size vector to a sequence. Previously, we have one output corresponding to one input, the input sequence and the output sequence have same length. Using <code>encoder-decoder</code> or <code>sequence to sequence</code> structure, we can train an <code>encoder</code> RNN to process the input sequence <span class="math inline">\(\mathbf{x} = (\mathbf{x}^1, ...., \mathbf{x}^{n_x})\)</span> and emits a <code>context vector</code> <span class="math inline">\(C\)</span>, then this context vector <span class="math inline">\(C\)</span> is mapped to an output sequence <span class="math inline">\(\mathbf{y} = (\mathbf{y}^1, ....., \mathbf{y}^{n_y})\)</span> which is not necessarily of the same length using a <code>decoder</code> RNN.</p>
<p>In the sequence to sequence structure, the two RNNs are trained jointly to maximize the average of log conditional probability <span class="math inline">\(\log P_{\mathbf{Y}}(\mathbf{y}^{1} ,...., \mathbf{y}^{n_y} | \; \mathbf{x}^1 , ...., \mathbf{x}^{n_x})\)</span> or minimize the cross entropy over all sequence in the training set. The <strong>last state <span class="math inline">\(\mathbf{h}_{n_x}\)</span> of the encoder RNN</strong> is typically used as a representation <span class="math inline">\(C\)</span> of the input sequence that is provided as input to the decoder RNN.</p>
<p>One clear limitation of this architecture is when the context <span class="math inline">\(C\)</span> output by the encoder RNN has a dimension that is too small to properly summarize a long sequence. Thus, rather than a fixed length of context vector, a variable-length sequence should be used which is the result of <code>attention</code> that learns to associate elements of the sequence <span class="math inline">\(C\)</span> to elements of the output sequence.</p>
<h2 id="gated-rnn">Gated RNN</h2>
<p><code>Gated RNN</code> includes <code>long short-term memory</code> and networks based on the <code>gated recurrent unit</code>. Gated RNNs are based on the idea of creating paths through time that have derivatives that neither banish nor explode. Gated RNNs did this with connection weights that may change at each time step.</p>
<h3 id="lstm">LSTM</h3>
<p>Instead of a unit that simply applies an element wise linearity to the affine transformation of inputs and recurrent units, LSTM recurrent networks have <strong>LSTM cells</strong> that have an internal recurrence in addition to the outer recurrence of the RNN. Each cell has more parameters and a system of gating units that controls the flow of information. The most important component is the state unit <span class="math inline">\(\mathbf{c}^{(t)}_i\)</span> that is a linear function.</p>
<p>For each timestep <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[\mathbf{z} = \tanh (W * [\mathbf{x}^t, \mathbf{h}^{t-1}] + \mathbf{b})\]</span></p>
<p><span class="math display">\[\mathbf{z}^i = \sigma(W^i * [\mathbf{x}^t, \mathbf{h}^{t-1}] + \mathbf{b}_i)\]</span></p>
<p><span class="math display">\[\mathbf{z}^f = \sigma(W^f * [\mathbf{x}^t, \mathbf{h}^{t-1}] + \mathbf{b}_f)\]</span></p>
<p><span class="math display">\[\mathbf{z}^o = \sigma(W^o * [\mathbf{x}^t, \mathbf{h}^{t-1}] + \mathbf{b}_o)\]</span></p>
<p>Where <span class="math inline">\((W^i, \mathbf{b}_i), (W^f, \mathbf{b}_f), (W^o, \mathbf{b}_o)\)</span> are the parameters associated with input gate, forget gate, output gate respectively. Notice each gate is a value between <span class="math inline">\([0, 1]\)</span>. The internal states is computed as:</p>
<p><span class="math display">\[\mathbf{c}^{t} = \mathbf{z}^f \odot \mathbf{c}^{t-1} + \mathbf{z}^i \odot \mathbf{z}\]</span></p>
<p>We can see that if <span class="math inline">\(\mathbf{z}^f = 1\)</span> and <span class="math inline">\(\mathbf{z}^i = 1\)</span>, we transfer the current and past information directly to next layer without any transformation.</p>
<p>Then:</p>
<p><span class="math display">\[\mathbf{h}^t = \mathbf{z}^o \odot \tanh (\mathbf{c}^t)\]</span></p>
<p><span class="math display">\[\mathbf{y}^t = \sigma (V\mathbf{h}^t + \mathbf{b}_y)\]</span></p>
<p><img src="/images/ML/lstm_1.png" width="600"> <img src="/images/ML/lstm_2.png" width="600"></p>
<p>In LSTMs, you have the state <span class="math inline">\(\mathbf{c}^t\)</span>. The derivative there is of the form:</p>
<p><span class="math display">\[\frac{\partial \mathbf{c}^{t^{\prime}}}{\partial \mathbf{c}^{t}} = \prod^{t^{\prime} - t}_{k=1} \sigma (\mathbf{v}_{t+k})\]</span></p>
<p>Where <span class="math inline">\(\mathbf{v}_{t+k}\)</span> is the input to the forget gate. We can see that compare with the <span class="math inline">\(\frac{\partial \mathbf{h}^{t^{\prime}}}{\partial \mathbf{h}^{t}}\)</span> in RNN, we do not have <span class="math inline">\(W^T\)</span> term. Thus, we have somewhat solved the vanishing gradient problem (at least one path the gradient is not vanishing). However, we still have vanishing gradient problem in LSTM, but not as much as RNN (no gradient of sigmoid or multiplication of <span class="math inline">\(W\)</span>).</p>
<h3 id="gru">GRU</h3>
<p>The main difference with the LSTM is that a single gating unit simultaneously controls the forgetting factor and the decision to update the state unit so we have less parameters.</p>
<p>The input and output to GRU is same as RNN</p>
<p><img src="/images/ML/gru_1.png" width="600"></p>
<p>GRU has two gates at each timestep <span class="math inline">\(t\)</span>:</p>
<ul>
<li><p><strong>Reset gate</strong> <span class="math inline">\(\mathbf{r}^{t}\)</span>: <span class="math display">\[\mathbf{r}^{t} = \sigma(W^r * [\mathbf{x}^t, \mathbf{h}^{t-1}] + \mathbf{b}_r)\]</span></p></li>
<li><p><strong>Update gate</strong> <span class="math inline">\(\mathbf{u}^t\)</span>: <span class="math display">\[\mathbf{u}^t = \sigma(W^u * [\mathbf{x}^t, \mathbf{h}^{t-1}] + \mathbf{b}_u)\]</span></p></li>
</ul>
<p>The hidden unit update equation is:</p>
<p><span class="math display">\[\mathbf{h}^{t-1, \prime} = h^{t-1} \odot \mathbf{r}\]</span></p>
<p><span class="math display">\[\mathbf{h}^{t, \prime} = \tanh(W * [\mathbf{h}^{t-1, \prime}, \mathbf{x}_t] + \mathbf{b})\]</span></p>
<p><span class="math display">\[\mathbf{h}^{t} = \mathbf{u}^t \odot \mathbf{h}^{t-1} + (1 - \mathbf{u}^t) \odot \mathbf{h}^{t, \prime}\]</span></p>
<p>Where <span class="math inline">\(\mathbf{h}^{t, \prime}\)</span> is the candidate at timestep <span class="math inline">\(t\)</span> that has some new information <span class="math inline">\(\mathbf{x}^t\)</span> and old information <span class="math inline">\(\mathbf{h}^{t-1, \prime}\)</span>. When <span class="math inline">\(\mathbf{u}_t = 1\)</span> we simply keep the old information and the new information <span class="math inline">\(\mathbf{x}_t\)</span> is ignored. In contrast, whenever <span class="math inline">\(Z_t\)</span> is close to 0, the candidate is used inplace.</p>
<p>In summary:</p>
<ul>
<li>Reset gates help capture short-term dependencies in sequences (by integrating part of past information with new information to produce the candidate).</li>
<li>Update gates help capture long-term dependencies in sequences.</li>
</ul>
<p><img src="/images/ML/gru_2.png" width="600"></p>
<h1 id="ref">Ref</h1>
<p>https://zhuanlan.zhihu.com/p/32085405</p>
<p>https://zhuanlan.zhihu.com/p/32481747</p>
<p>https://stats.stackexchange.com/questions/185639/how-does-lstm-prevent-the-vanishing-gradient-problem</p>
<p>https://d2l.ai/chapter_recurrent-modern/gru.html</p>
]]></content>
      <categories>
        <category>DL</category>
        <category>RNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>ROC</title>
    <url>/2021/08/09/roc/</url>
    <content><![CDATA[<h1 id="roc-curve">ROC Curve</h1>
<p><code>ROC Curve</code> is a graph showing the performance of a classification model at all classification thresholds (e.g for logistic regression the threshold is default 0.5, we can adjust this threshold to 0.8 and assign examples to classes using this threhold). This curve plots two parameters:</p>
<ul>
<li>True Positive Rate (<span class="math inline">\(\text{sensitivity} = \frac{\text{True Positive}}{\text{True Positive + False Negative}}\)</span>)</li>
<li>False Positive Rate (<span class="math inline">\(1 - \text{specificity} = 1 -\frac{\text{True Negative}}{\text{True Negative + False Positive}} = \frac{\text{False Positive}}{\text{True Negative + False Positive}}\)</span>)</li>
</ul>
<p>An ROC curve plots TRP vs FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive (e.g threshold 0.1 for logistic regression), thus increasing both FP and TP.</p>
<p><img src='/images/ML/roc_1.png' width="600"></p>
<p>To compute the points an ROC curve, we could evaluate a classification model many times with different threshold and repeat this for all thresholds, but this is inefficient. Fortunately, there's an effective algorithm that can provide this information called <code>AUC</code>.</p>
<h2 id="auc">AUC</h2>
<p>AUC stands for <strong>Area under ROC curve</strong>. It measures the entire two-dimensional area underneath the entire ROC curve. Since <span class="math inline">\(TPR \in [0, 1]\)</span> and <span class="math inline">\(FPR \in [0, 1]\)</span>, the AUC can be interpreted as probability. It is the probability that the model ranks a random positive example more highly than a random negative example. Thus, by rearranging the predictions from left to right, AUC is the probability that a random positive example is positioned to the right of a random negative example:</p>
<p><img src='/images/ML/roc_2.png' width="600"></p>
<p>A model whose predictions are 100% wrong will have AUC 0, a model whose predictions are 100% correct has an AUC of 1.</p>
<p><br></p>
<h3 id="properties">Properties</h3>
<p>AUC is desirable for the following two reasons:</p>
<ul>
<li><strong>Scale-invariant</strong>: It measures hwo well predictions are ranked, rather than their absolute values.</li>
<li><strong>Classification-threshold-invariant</strong>: It measures the quality of the model's predictions irrespective of what classification threshold is chosen. (when we draw ROC, we are varying the threshold, the only thing matters to AUC is the predicted values (not class) and how true positive class samples ranked against negative class samples w.r.t their predicted values)</li>
</ul>
<p>However, AUC is not desirable when:</p>
<ol type="1">
<li><strong>Sometimes probabilities matters</strong>, AUC does not tell you how good is a predicted probability.</li>
<li><strong>Sometimes classification threshold matters</strong>, In cases where there are wide disparities in the cost of false negatives vs. false positives, it may be critical to minimize one type of classification error. For example, when doing email spam detection, you likely want to prioritize minimizing false positives (even if that results in a significant increase of false negatives). AUC isn't a useful metric for this type of optimization.</li>
</ol>
<h1 id="ref">Ref</h1>
<p>https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>SAC</title>
    <url>/2021/07/22/sac/</url>
    <content><![CDATA[<h1 id="soft-actor-critic-off-policy-maximum-entropy-deep-reinforcement-learning-with-a-stochastic-actor">Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</h1>
<h2 id="introductions-and-notations">Introductions and Notations</h2>
<p>Maximum entropy reinforcement learning optimizes policies to maximize both the expected return and the expected entropy of the policy.</p>
]]></content>
  </entry>
  <entry>
    <title>SARSA</title>
    <url>/2021/05/16/sarsa/</url>
    <content><![CDATA[<h1 id="sarsa">SARSA</h1>
<p>SARSA (State Action State Reward State Action) is an on-policy TD algorithm that follows a PI-like procedure:</p>
<ol type="1">
<li>Estimate <span class="math inline">\(Q^{\pi_k}\)</span> for a given policy <span class="math inline">\(\pi_k\)</span></li>
<li>Perform policy improvement to obtain a new policy <span class="math inline">\(\pi_{k+1}\)</span></li>
</ol>
<p>Compare with usual Policy iteration, SARSA uses <code>Generalized policy iteration</code> to improve the policy before <span class="math inline">\(Q\)</span> converges to <span class="math inline">\(Q^{\pi_k}\)</span>.</p>
<span id="more"></span>
<h2 id="algorithm">Algorithm</h2>
<p><img src="/images/RL/mc/td_6.png"></p>
<p>Notice that, <span class="math inline">\(\pi_t\)</span> here is a <span class="math inline">\(\epsilon\)</span>-greedy policy because we want to ensure some exploration. The greedy part of the policy performs the policy improvement while the occasional random choice of actions allows the agent to have some exploration.</p>
<h2 id="implementation">Implementation</h2>
]]></content>
      <categories>
        <category>RL</category>
        <category>TD</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>Tabular Methods</tag>
        <tag>TD</tag>
      </tags>
  </entry>
  <entry>
    <title>Measure Integral and Real Analysis (2)</title>
    <url>/2022/02/27/mira-2/</url>
    <content><![CDATA[<h1 id="measure-integral-and-real-analysis-2">Measure Integral and Real Analysis (2)</h1>
<ol type="1">
<li><span class="math inline">\((A \times C) / (B \times D) = [A \times (C / D)] \cup [(A / B) \times C]\)</span></li>
<li><span class="math inline">\((A \cap B) \times (C \cap D) = (A \times C) \cap (B \times D)\)</span></li>
<li><span class="math inline">\((A \cup B) \times (C \cup D) \neq (A \times C) \cup (B \times D)\)</span></li>
</ol>
<h2 id="integration">Integration</h2>
<h3 id="integration-w.r.t-a-measure">Integration w.r.t a Measure</h3>
<h4 id="definition-3.1-s-partition">Definition 3.1: <span class="math inline">\(S\)</span>-Partition</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on a set <span class="math inline">\(X\)</span>. An <strong><span class="math inline">\(S\)</span>-partition</strong> of <span class="math inline">\(X\)</span> is finite collection <span class="math inline">\(A_1, ..., A_m\)</span> of disjoint sets in <span class="math inline">\(S\)</span> s.t <span class="math inline">\(A_1 \cup ... \cup A_m = X\)</span>.</p>
<p><br></p>
<h4 id="definition-3.1-lower-lebesgue-sum">Definition 3.1: Lower Lebesgue Sum</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function, and <span class="math inline">\(P\)</span> is an <span class="math inline">\(S\)</span>-partition <span class="math inline">\(A_1, ..., A_m\)</span> of <span class="math inline">\(X\)</span>. The <strong>lower Lebesgue sum</strong> <span class="math inline">\(L(f, P)\)</span> is defined by:</p>
<p><span class="math display">\[L(f, P) = \sum^m_{j=1} \mu(A_j) \inf_{A_j} f\]</span></p>
<p><strong>The definition does not assume <span class="math inline">\(X\)</span> is a subset of <span class="math inline">\(\mathbb{R}\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-3.3-integral-of-a-nonnegative-function">Definition 3.3: Integral of a Nonnegative Function</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function. The <strong>integral</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(\mu\)</span>, denoted by <span class="math inline">\(\int f d\mu\)</span> is defined by:</p>
<p><span class="math display">\[\int f d\mu = \sup\{L(f, P): \text{ $P$ is an $S$-partition of $X$}\}\]</span></p>
<p><br></p>
<h4 id="theorem-3.4-integral-of-a-characteristic-function-chi_e">Theorem 3.4: Integral of a Characteristic Function <span class="math inline">\(\chi_E\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E \in S\)</span>. Then:</p>
<p><span class="math display">\[\int \chi_E d\mu = \mu(E)\]</span></p>
<span id="more"></span>
<h5 id="proof-of-theorem-3.4">Proof of Theorem 3.4:</h5>
<p>If <span class="math inline">\(P\)</span> is the <span class="math inline">\(S\)</span>-partition of <span class="math inline">\(E, X / E\)</span>, then:</p>
<p><span class="math display">\[L(\chi_E, P) = \mu(E) * 1 + 0 * \mu(X / E) = \mu(E)\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[\int \chi_E d\mu \geq \mu(E)\]</span></p>
<p>Let <span class="math inline">\(P\)</span> be an <span class="math inline">\(S\)</span>-partition <span class="math inline">\(A_1, ..., A_m\)</span> of <span class="math inline">\(X\)</span>, then</p>
<p><span class="math display">\[
\mu(A_j) \inf_{A_j} \chi_ E=
\begin{cases}
\mu(A_j), \quad \text{if } A_j \subseteq E\\
0, \quad \text{ o. w }
\end{cases}
\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sum^{m}_{j=1} \mu(A_j) \inf_{A_j} \chi_E = \sum_{\{j: A_j \subseteq E\}} \mu(A_j) = \mu(\bigcup_{\{j: A_j \subseteq E\}} A_j) \leq \mu(E)\]</span></p>
<p><br></p>
<h4 id="theorem-3.7-integral-of-a-simple-function">Theorem 3.7: Integral of a Simple Function</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(E_1, E_2, .., E_n\)</span> are disjoint sets in <span class="math inline">\(S\)</span>, and <span class="math inline">\(c_1, ..., c_n \in [0, \infty]\)</span>. Then:</p>
<p><span class="math display">\[\int (\sum^n_{k=1} c_k \chi_{E_k}) d\mu = \sum^{n}_{k=1} c_k \mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-3.8-integration-is-order-preserving">Theorem 3.8: Integration is Order Preserving</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f, g: X \rightarrow [0, \infty]\)</span> are <span class="math inline">\(S\)</span>-measurable functions s.t <span class="math inline">\(f(x) \leq g(x)\)</span> for all <span class="math inline">\(x \in X\)</span>. Then:</p>
<p><span class="math display">\[\int f d\mu \leq \int g d\mu\]</span></p>
<h5 id="proof-of-theorem-3.8">Proof of Theorem 3.8:</h5>
<p>Suppose <span class="math inline">\(P\)</span> is a <span class="math inline">\(S\)</span>-partition <span class="math inline">\(A_1, ..., A_n\)</span> of <span class="math inline">\(X\)</span>. Then:</p>
<p><span class="math display">\[\inf_{A_i} f \leq \inf_{A_i} g \implies L(f, P) \leq L(g, P)\]</span></p>
<p>Then for any <span class="math inline">\(P\)</span>, we have:</p>
<p><span class="math display">\[\sup_P L(f, P) \leq \sup_P L(g, P)\]</span></p>
<p><br></p>
<h4 id="theorem-3.9-integral-via-simple-functions">Theorem 3.9: Integral Via Simple Functions</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable. Then:</p>
<p><span class="math display">\[\int f d\mu = \sup\{\sum^{m}_{j=1}c_j\mu(A_j): \text{ $A_1, ..., A_m$ are disjoint sets in $S$, $c_1, ...., c_m \in [0, \infty)$, $f(x)\geq \sum^m_{j=1}c_j \chi_{A_j}(x)$ for every $x \in X$}\}\]</span></p>
<p>Here, we have <span class="math inline">\(A_1, ..., A_m \in S\)</span> as arbitrary disjoint sets, they do not have to be <span class="math inline">\(S\)</span>-partition.</p>
<p><br></p>
<h4 id="theorem-3.11-monotone-convergence-theorem">Theorem 3.11: Monotone Convergence Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 \leq f_1 \leq f_2 \leq ...\)</span> is an increasing sequence of <span class="math inline">\(S\)</span>-measurable functions. Define <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> by:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} f_k (x)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu = \int f d\mu\]</span></p>
<p>If:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} \sum^{k}_{n=1}f_n (x)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} \int f_n d\mu = \int f d\mu\]</span></p>
<h5 id="proof-of-theorem-3.11">Proof of Theorem 3.11:</h5>
<p>To show that the equality holds, we need to show that:</p>
<ol type="1">
<li><span class="math inline">\(\lim_{k\rightarrow \infty} \int f_k d\mu \leq \int f d\mu\)</span></li>
<li><span class="math inline">\(\lim_{k\rightarrow \infty} \int f_k d\mu \geq \int f d\mu\)</span></li>
</ol>
<p><strong>We first prove 1:</strong></p>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 \leq f_1 \leq f_2 \leq ...\)</span> is an increasing sequence of <span class="math inline">\(S\)</span>-measurable functions. Define <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> by:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} f_k (x)\]</span></p>
<p>Then by <code>theorem 2.53</code>, we have <span class="math inline">\(f\)</span> to be <span class="math inline">\(S\)</span>-measurable. Since <span class="math inline">\(f_k(x) \leq f(x), \;\; \forall x \in X, k \in \mathbb{Z}^+\)</span>, by <code>theorem 3.8</code>, we have:</p>
<p><span class="math display">\[\int f_k d \mu \leq \int f d\mu \implies \lim_{k \rightarrow \infty} \int f_k d \mu \leq \int f d\mu\]</span></p>
<p><strong>To prove 2, we need to use <code>theorem 3.9</code>:</strong></p>
<p>Suppose <span class="math inline">\(A_1, ..., A_m\)</span> are disjoint sets in <span class="math inline">\(S\)</span>, and <span class="math inline">\(c_1, ..., c_m \in [0, \infty)\)</span> are s.t:</p>
<p><span class="math display">\[f(x) \geq \sum^{m}_{j=1} c_j \chi_{A_j} (x)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\int f d\mu = \sup_{\text{all disjoint sets in $S$}}\{\sum^{m}_{j=1} c_j \mu(A_j)\}\]</span></p>
<p>Let <span class="math inline">\(t \in (0, 1)\)</span>. For <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, let:</p>
<p><span class="math display">\[E_k = \{x \in X: f_k (x) \geq t \sum^{m}_{j=1} c_j \chi_{A_j} (x)\}\]</span></p>
<p>Then <span class="math inline">\(E_1 \subseteq E_2 \subseteq , ...\)</span> is an increasing sequence of sets whose union is <span class="math inline">\(X\)</span> (because <span class="math inline">\(f(x) \geq \sum^{m}_{j=1} c_j \chi_{A_j} (x)\)</span>) and <span class="math inline">\((E_1 \cap A_j) \subseteq (E_2 \cap A_j) \subseteq .... \;\; \forall j \in \{1, ..., m\}\)</span> is also an increasing sequence of sets, this implies (by <code>theorem 2.59</code>) that:</p>
<p><span class="math display">\[\mu(\lim_{k\rightarrow \infty} (E_k \cap A_j)) = \mu(X \cap A_j) = \mu(A_j)\]</span></p>
<p>Then for all <span class="math inline">\(x \in X\)</span>:</p>
<p><span class="math display">\[f_k (x) \geq t \sum^{m}_{j=1} c_j \chi_{A_j \cap E_k} (x) \implies \int f_k d\mu \geq \int t \sum^{m}_{j=1} c_j \chi_{A_j \cap E_k} d \mu \implies \int f_k d\mu \geq t\sum^{m}_{j=1} c_j \mu(A_j \cap E_k)\]</span></p>
<p>Taking the limit to infinity:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu \geq  \lim_{k\rightarrow \infty} t\sum^{m}_{j=1} c_j \mu(A_j \cap E_k) = t \sum^{m}_{j=1} c_j \mu(A_j)\]</span></p>
<p>Taking the limit <span class="math inline">\(t \rightarrow 1\)</span>:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu \geq  \sum^{m}_{j=1} c_j \mu(A_j)\]</span></p>
<p>Since right-hand side works for any <span class="math inline">\(c_1, ...., c_m \in [0, \infty)\)</span>, disjoint sets <span class="math inline">\(A_1, ..., A_m\)</span> that satisfies <span class="math inline">\(f(x) \geq \sum^{m}_{j=1} c_j \chi_{A_j} (x)\)</span>, we have:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} f_k(x) \geq  \sup_{\text{all disjoint sets in $S$}}\{\sum^{m}_{j=1} c_j \mu(A_j)\} = \int f d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-3.13-integral-type-sums-for-simple-functions">Theorem 3.13: Integral-type Sums for Simple Functions</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measurable space. Suppose <span class="math inline">\(a_1, ..., a_m, b_1, ..., b_n \in [0, \infty]\)</span> and <span class="math inline">\(A_1, ..., A_m, B_1, ..., B_n \in S\)</span> s.t <span class="math inline">\(\sum^m_{j=1} a_j \chi_{A_j} = \sum^n_{k=1} b_k \chi_{B_k}\)</span>. Then:</p>
<p><span class="math display">\[\sum^{m}_{j=1} a_j \mu(A_j) = \sum^n_{k=1} b_k \mu(B_k)\]</span></p>
<p><br></p>
<h4 id="theorem-3.15-integral-of-a-linear-combination-of-characteristic-functions">Theorem 3.15: Integral of a Linear Combination of Characteristic Functions</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(E_1, ..., E_n \in S\)</span>, and <span class="math inline">\(c_1, ..., c_n \in [0, \infty)\)</span>. Then:</p>
<p><span class="math display">\[\int (\sum^{n}_{k=1} c_k \chi_{E_k}) d\mu = \sum^{n}_{k=1} c_k \mu(E_k)\]</span></p>
<p><strong>The difference between this theorem and <code>theorem 3.7</code> is that, here we do not require <span class="math inline">\(E_1, ..., E_n\)</span> to be disjoint</strong></p>
<p><br></p>
<h4 id="theorem-3.16-additivity-of-integration">Theorem 3.16: Additivity of Integration</h4>
<p>Suppose <span class="math inline">\((X . S, \mu)\)</span> is a measure space and <span class="math inline">\(f, g: X \rightarrow [0, \infty]\)</span> are <span class="math inline">\(S\)</span>-measurable functions. Then:</p>
<p><span class="math display">\[\int (f+g) d\mu = \int f d\mu + \int g d\mu\]</span></p>
<h5 id="proof-of-theorem-3.16">Proof of Theorem 3.16:</h5>
<p>Suppose <span class="math inline">\(f, g\)</span> are simple functions, then:</p>
<p><span class="math display">\[\int (f + g) d\mu = \int (\sum_j c_j \chi_{E_j} + \sum_k c_k \chi_{E_k}) d\mu = \sum_j c_j \mu(E_j) + \sum_{k} c_k \mu(E_k) = \int f d\mu + \int g d\mu\]</span></p>
<p>So the integrals of simple functions are additive.</p>
<p>Let <span class="math inline">\(f_1, f_2, ...\)</span>, <span class="math inline">\(g_1, g_2, ....\)</span> be increasing sequence of simple functions s.t:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} f_k = f\]</span></p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} g_k = g\]</span></p>
<p>By <code>theorem 2.89</code>, these sequences exist.</p>
<p>Since <span class="math inline">\(f_k, g_k, f, g\)</span> are <span class="math inline">\(S\)</span>-measurable functions, <span class="math inline">\(f + g\)</span> is <span class="math inline">\(S\)</span>-measurable function. Then by <code>Monotone Convergence Theorem</code>, we have:</p>
<p><span class="math display">\[\int (f + g) d\mu = \lim_{k \rightarrow \infty} \int (f_k + g_k) d\mu = \lim_{k \rightarrow \infty} \int f_k \mu + \lim_{k \rightarrow \infty} \int g_k d\mu = \int f d\mu + \int g d\mu\]</span></p>
<p><br></p>
<h4 id="definition-3.17-f-f-">Definition 3.17: <span class="math inline">\(f^+, f^-\)</span></h4>
<p>Suppose <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is a function. Define function <span class="math inline">\(f^+\)</span> and <span class="math inline">\(f^-\)</span> from <span class="math inline">\(X\)</span> to <span class="math inline">\([0, \infty]\)</span> by:</p>
<p><span class="math display">\[
f^{+} (x) =
\begin{cases}
f^{+}(x), \quad \text{if } f(x) \geq 0\\
0, \quad \text{if } f(x) &lt; 0
\end{cases}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
f^{-} (x) =
\begin{cases}
0, \quad \text{if } f(x) \geq 0\\
-f^{-}(x), \quad \text{if } f(x) &lt; 0
\end{cases}
\]</span></p>
<p>Then:</p>
<p><span class="math display">\[f = f^+ - f^-\]</span></p>
<p>and</p>
<p><span class="math display">\[|f| = f^+ + f^-\]</span></p>
<p><strong>This decomposition allows us to extend our definition of integration to functions that take on negative as well as positive values.</strong></p>
<p><br></p>
<h4 id="definition-3.18-integral-of-a-real-valued-function-int-f-dmu">Definition 3.18: Integral of a Real-Valued Function: <span class="math inline">\(\int f d\mu\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function s.t at least one of <span class="math inline">\(\int f^+ d\mu\)</span> and <span class="math inline">\(\int f^{-} d\mu\)</span> is finite. The <strong>integral</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(\mu\)</span>, denoted <span class="math inline">\(\int f d\mu\)</span> is defined by:</p>
<p><span class="math display">\[\int f d\mu = \int f^+ d\mu - \int f^- d\mu\]</span></p>
<p>The condition <span class="math inline">\(\int |f| d\mu &lt; \infty\)</span> is equivalent to the condition <span class="math inline">\(\int f^+ d\mu &lt; \infty\)</span> and <span class="math inline">\(\int f^- d\mu &lt; \infty\)</span></p>
<blockquote>
<h5 id="example-3.19">Example 3.19</h5>
<p>Suppose <span class="math inline">\(\lambda\)</span> is a Lebesgue measure on <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is a function defined by:</p>
<p><span class="math display">\[
f (x) =
\begin{cases}
1, \quad \text{if } x \geq 0\\
0, \quad \text{if } x &lt; 0
\end{cases}
\]</span> Then <span class="math inline">\(\int f^+ d\lambda = \infty\)</span> and <span class="math inline">\(\int f^- d\lambda = \infty\)</span>, so <span class="math inline">\(\int f d\lambda\)</span> is not defined.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-3.20-integration-is-homogeneous">Theorem 3.20: Integration is Homogeneous</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is a function such that <span class="math inline">\(\int f d\mu\)</span> is defined. If <span class="math inline">\(c \in \mathbb{R}\)</span>, then:</p>
<p><span class="math display">\[\int cf d\mu = c\int f d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-3.21-additivity-of-integration">Theorem 3.21: Additivity of Integration</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f, g: X \rightarrow \mathbb{R}\)</span> are <span class="math inline">\(S\)</span>-measurable functions s.t <span class="math inline">\(\int |f| d\mu &lt; \infty\)</span> and <span class="math inline">\(\int |g| d\mu &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[\int (f + g) d\mu = \int f d\mu + \int g d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-3.22-integration-is-order-preserving">Theorem 3.22: Integration is Order Preserving</h4>
<p>Suppose <span class="math inline">\((X, S ,\mu)\)</span> is a measure space and <span class="math inline">\(f, g: X \rightarrow \mathbb{R}\)</span> are <span class="math inline">\(S\)</span>-measurable functions s.t <span class="math inline">\(\int f d\mu\)</span> and <span class="math inline">\(\int g d\mu\)</span> are defined. Suppose also that <span class="math inline">\(f(x) \leq g(x)\)</span> for all <span class="math inline">\(x \in X\)</span>. Then <span class="math inline">\(\int f d\mu \leq \int g d\mu\)</span>.</p>
<p><br></p>
<h4 id="theorem-3.23-absolute-value-of-integral-leq-integral-of-absolute-value">Theorem 3.23: Absolute Value of Integral <span class="math inline">\(\leq\)</span> Integral of Absolute Value</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is a function s.t <span class="math inline">\(\int f d\mu\)</span> is defined. Then:</p>
<p><span class="math display">\[|\int f d\mu| \leq \int |f| d\mu\]</span></p>
<p><br></p>
<h3 id="limits-of-integrals-and-integrals-of-limits">Limits of Integrals and Integrals of Limits</h3>
<h4 id="definition-3.24-integration-on-a-subset-int_e-f-dmu">Definition 3.24: Integration on a Subset; <span class="math inline">\(\int_E f d\mu\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E \in S\)</span>. If <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function, then <span class="math inline">\(\int_E f d\mu\)</span> is defined by:</p>
<p><span class="math display">\[\int_E f d\mu = \int \chi_{E} f d\mu\]</span></p>
<p>If the right side of the equation above is defined, o.w <span class="math inline">\(\int_E f d\mu\)</span> is undefined.</p>
<p>We can also think of <span class="math inline">\(\int_E f d\mu\)</span> as <span class="math inline">\(\int f_E d\mu_E\)</span> where <span class="math inline">\(\mu_E\)</span> is the measure botained by restricting <span class="math inline">\(\mu\)</span> to the elements of <span class="math inline">\(S\)</span> that are contained in <span class="math inline">\(E\)</span>.</p>
<p><strong>Notice that, <span class="math inline">\(\int_X f d\mu\)</span> means the same as <span class="math inline">\(\int f d\mu\)</span>.</strong></p>
<p><br></p>
<h4 id="theorem-3.25-bounded-an-integral">Theorem 3.25: Bounded an Integral</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(E \in S\)</span> and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is a function s.t <span class="math inline">\(\int_E fd\mu\)</span> is defined. Then:</p>
<p><span class="math display">\[| \int_E fd\mu| \leq \mu(E) \sup_E |f|\]</span></p>
<h5 id="proof-theorem-3.25">Proof Theorem 3.25:</h5>
<p>Let <span class="math inline">\(c = \sup_E |f|\)</span>:</p>
<p><span class="math display">\[|\int_E f d\mu| = |\int \chi_E f d\mu| \leq \int \chi_E |f| d\mu \leq \int \chi_E c d\mu = c\mu(E)\]</span></p>
<p><br></p>
<h4 id="theorem-3.26-bounded-convergence-theorem">Theorem 3.26: Bounded Convergence Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(\mu(X) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>. If there exists <span class="math inline">\(c \in (0, \infty)\)</span> s.t:</p>
<p><span class="math display">\[|f_k (x) \leq c|\]</span></p>
<p>for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span> and all <span class="math inline">\(x \in X\)</span>, then:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu = \int f d\mu\]</span></p>
<h5 id="proof-of-theorem-3.26">Proof of Theorem 3.26:</h5>
<p>The function <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable by <code>theorem 2.48</code>. Suppose <span class="math inline">\(c\)</span> satisfies the assumption above. Let <span class="math inline">\(\epsilon &gt; 0\)</span>, by <code>Theorem 2.85</code>, there exists <span class="math inline">\(E \in S\)</span>, s.t <span class="math inline">\(\mu(S/ E) &lt; \frac{\epsilon}{4c}\)</span> and <span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(E\)</span>. Now:</p>
<p><span class="math display">\[|\int f_k d\mu - \int f d\mu| = |\int_{X / E} (f_k  - f) d\mu + \int_E (f_k - f)d\mu| = |\int_{X / E} f_k d\mu - \int_{X / E} f d\mu + \int_E (f_k - f)d\mu|\]</span></p>
<p>Then by <code>theorem 3.23</code>:</p>
<p><span class="math display">\[|\int_{X / E} f_k d\mu - \int_{X / E} f d\mu + \int_E (f_k - f)d\mu| \leq \int_{X / E} |f_k| d\mu + \int_{X / E} |f| d\mu + \int_E |f_k - f|d\mu|\]</span></p>
<p>Since <span class="math inline">\(|f_k (x)| \leq c \forall x \in X\)</span> and by <code>theorem 3.25</code>:</p>
<p><span class="math display">\[\int_{X / E} |f_k| d\mu + \int_{X / E} |f| d\mu + \int_E |f_k - f|d\mu| \leq \int c\chi_{X/E} d\mu + \int c\chi_{X/E} d\mu + \int_E |f_k - f|d\mu| \leq \frac{\epsilon}{2} + \mu(E)\sup_E |f_k - f|\]</span></p>
<p>Since <span class="math inline">\(f_k\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(E\)</span>, for <span class="math inline">\(k\)</span> sufficient large, we have <span class="math inline">\(|f_k(x) - f(x)| &lt; \epsilon, \;\forall x\in X\)</span>, this implies that:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} |\int f_k d\mu - \int f d\mu| = 0\]</span></p>
<p><br></p>
<h4 id="definition-3.27-almost-every">Definition 3.27: Almost Every</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space. A set <span class="math inline">\(E \in S\)</span> is said to contain <strong><span class="math inline">\(\mu-almost\)</span> every</strong> element of <span class="math inline">\(X\)</span> if <span class="math inline">\(\mu(X / E) = 0\)</span>. If the measure <span class="math inline">\(\mu\)</span> is clear from the context, then the phrase <strong>almost every</strong> can be used.</p>
<p>For example, <strong>almost every</strong> real number is irrational w.r.t the usual Lebesgue measure because <span class="math inline">\(|\mathbb{Q}| = 0\)</span>.</p>
<p><strong>Theorems about integrals can almost always be relaxed so that the hypotheses apply only almost everywhere instead of everywhere</strong>.</p>
<p><br></p>
<h4 id="theorem-3.28-integral-on-small-sets-are-small">Theorem 3.28: Integral on Small Sets are Small</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(g: X \rightarrow [0, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable, and <span class="math inline">\(\int g d\mu &lt; \infty\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t:</p>
<p><span class="math display">\[\int_B g d\mu &lt; \epsilon\]</span></p>
<p>For every set <span class="math inline">\(B \in S\)</span> s.t <span class="math inline">\(\mu(B) &lt; \delta\)</span>.</p>
<p><br></p>
<h4 id="theorem-3.29-integrable-functions-live-mostly-on-sets-of-finite-measure">Theorem 3.29: Integrable Functions Live Mostly on Sets of Finite Measure</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(g: X \rightarrow [0, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable, and <span class="math inline">\(\int g d\mu &lt; \infty\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(E \in S\)</span> s.t <span class="math inline">\(\mu(E) &lt; \infty\)</span> and</p>
<p><span class="math display">\[\int_{X/ E} g d\mu &lt; \epsilon\]</span></p>
<p><br></p>
<h4 id="theorem-3.31-dominated-convergence-theorem">Theorem 3.31: Dominated Convergence Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable, and <span class="math inline">\(f_1, f_2, ...\)</span> are <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X\)</span> to <span class="math inline">\([-\infty, \infty]\)</span> s.t:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} f_k(x) = f(x)\]</span></p>
<p>for almost every <span class="math inline">\(x \in X\)</span>. If there exists an <span class="math inline">\(S\)</span>-measurable function <span class="math inline">\(g: X \rightarrow [0, \infty]\)</span> s.t:</p>
<p><span class="math display">\[\int gd\mu &lt; \infty\]</span></p>
<p>and</p>
<p><span class="math display">\[|f_k(x) | \leq g(x)\]</span></p>
<p>for every <span class="math inline">\(k \in \mathbb{Z}^+\)</span> and almost every <span class="math inline">\(x \in X\)</span>, then:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu = \int f d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-3.34-riemann-integrable-longleftrightarrow-continuous-almost-everywhere">Theorem 3.34: Riemann Integrable <span class="math inline">\(\Longleftrightarrow\)</span> Continuous Almost Everywhere</h4>
<p>Suppose <span class="math inline">\(a &lt; b\)</span> and <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function. Then <span class="math inline">\(f\)</span> is Riemann integrable IFF:</p>
<p><span class="math display">\[|\{x \in [a, b]: \text{ $f$ is not continuous at $x$}\}| = 0\]</span></p>
<p>This implies that the outer measure of the set of discontinuities equals to 0 (The set of discontinuities is countable).</p>
<p>Furthermore, if <span class="math inline">\(f\)</span> is Riemann integrable and <span class="math inline">\(\lambda\)</span> denotes Lebesgue measure on <span class="math inline">\(\mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> is Lebesgue measurable and:</p>
<p><span class="math display">\[\int^b_a f = \int_{[a, b]} f d\lambda\]</span></p>
<p><br></p>
<h4 id="definition-3.39-intb_a-f">Definition 3.39: <span class="math inline">\(\int^b_a f\)</span></h4>
<p><strong>We previously defined the notation <span class="math inline">\(\int^b_a f\)</span> to mean the Riemann integral of <span class="math inline">\(f\)</span>, now we redefine <span class="math inline">\(\int^b_a f\)</span> to denote the Lebesgue integral.</strong></p>
<p>Suppose <span class="math inline">\(-\infty \leq a &lt; b \leq \infty\)</span> and <span class="math inline">\(f: (a, b) \rightarrow \mathbb{R}\)</span> is Lebesgue measurable. Then:</p>
<ul>
<li><span class="math inline">\(\int^b_a f\)</span> and <span class="math inline">\(\int^b_a f(x) dx\)</span> mean <span class="math inline">\(\int_{(a, b)} f d\lambda\)</span>, where <span class="math inline">\(\lambda\)</span> is Lebesgue measure on <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\int^b_a f\)</span> is defined to be <span class="math inline">\(- \int^b_a f\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-3.40-f-l1mu">Definition 3.40: <span class="math inline">\(\|f\|; L^1(\mu)\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space. If <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable, then the <span class="math inline">\(L^1\)</span>-norm of <span class="math inline">\(f\)</span> is denoted by <span class="math inline">\(\|f\|_1\)</span> and is defined by:</p>
<p><span class="math display">\[\|f\|_1 = \int |f| d\mu\]</span></p>
<p>The <strong>Lebesgue space</strong> <span class="math inline">\(L^1(\mu)\)</span> is defined by:</p>
<p><span class="math display">\[L^1(\mu) = \{f: f \text{ $f$ is an $S$-measurable function from $X \rightarrow \mathbb{R}$ and $\|f\|_1 &lt; \infty$}\}\]</span></p>
<blockquote>
<h5 id="example-3.41">Example 3.41:</h5>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1, ..., E_n\)</span> are disjoint subsets of <span class="math inline">\(X\)</span>. Suppose <span class="math inline">\(a_1, ..., a_n\)</span> are distinct nonzero real numbers. Then:</p>
<p><span class="math display">\[a_1 \chi_{E_1} + ... + a_n \chi_{E_n} \in L^1(\mu)\]</span></p>
<p>IFF <span class="math inline">\(E_k \in S\)</span> and <span class="math inline">\(\mu(E_k) &lt; \infty\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-3.43-properties-of-the-l1-norm">Theorem 3.43: Properties of the <span class="math inline">\(L^1-\)</span>norm</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f, g \in L^1(\mu)\)</span>, then:</p>
<ul>
<li><span class="math inline">\(\|f\|_1 \geq 0\)</span></li>
<li><span class="math inline">\(\|f\|_1 = 0\)</span> IFF <span class="math inline">\(f(x) = 0\)</span> for almost every <span class="math inline">\(x \in X\)</span></li>
<li><span class="math inline">\(\|cf\|_1 = |c|\|f\|_1, \; \forall c \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(\|f+g\|_1 \leq \|f\|_1 + \|g\|_1\)</span></li>
</ul>
<p><br></p>
<h4 id="theorem-3.44-approximation-by-simple-functions">Theorem 3.44: Approximation by Simple Functions</h4>
<p>Suppose <span class="math inline">\(\mu\)</span> is a measure and <span class="math inline">\(f \in L^1 (\mu)\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a simple function <span class="math inline">\(g \in L^1(\mu)\)</span> s.t:</p>
<p><span class="math display">\[\|f - g\|_1 &lt; \epsilon\]</span></p>
<p><br></p>
<h4 id="definition-3.45-l1mathbbr-f_1">Definition 3.45: <span class="math inline">\(L^1(\mathbb{R}); \|f\|_1\)</span></h4>
<ul>
<li>The notation <span class="math inline">\(L^1(\mathbb{R})\)</span> denotes <span class="math inline">\(L^1(\lambda)\)</span>, where <span class="math inline">\(\lambda\)</span> is Lebesgue measure on either the Borel subsets of <span class="math inline">\(\mathbb{R}\)</span> or the Lebesgue measurable subsets of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>When working with <span class="math inline">\(L^1 (\mathbb{R})\)</span>, the notation <span class="math inline">\(\|f\|_1\)</span> denotes the integral of the absolute value of <span class="math inline">\(f\)</span> w.r.t Lebesgue measure on <span class="math inline">\(\mathbb{R}\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-3.46-step-function">Definition 3.46: Step Function</h4>
<p>A <strong>step function</strong> is a function <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> of the form:</p>
<p><span class="math display">\[g = a_1 \chi_{I_1} + .... + a_n \chi_{I_n}\]</span></p>
<p>Where <span class="math inline">\(I_1, ...., I_n\)</span> are intervals of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(a_1, ..., a_n\)</span> are nonzero real numbers. The <strong>intervals</strong> can be open, closed or half-open intervals.</p>
<p><strong>Compare with simple function, the sets <span class="math inline">\(I_1, ..., I_n\)</span> are required to be intervals in step functions.</strong></p>
<p><br></p>
<h4 id="theorem-3.47-approximation-by-step-functions">Theorem 3.47: Approximation by Step Functions</h4>
<p>Suppose <span class="math inline">\(f \in L^1 (\mathbb{R})\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a step function <span class="math inline">\(g \in L^1 (\mathbb{R})\)</span> s.t:</p>
<p><span class="math display">\[||f - g\|_1 &lt; \epsilon\]</span></p>
<p><br></p>
<h4 id="theorem-3.48-approximation-by-continuous-functions">Theorem 3.48: Approximation by Continuous Functions</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a continuous function <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[\|f - g\|_1 &lt; \epsilon\]</span></p>
<p>and <span class="math inline">\(\{x \in \mathbb{R}: g(x) \neq 0\}\)</span> is a bounded set.</p>
<p><br></p>
<h2 id="differentiation">Differentiation</h2>
<h3 id="hardy-littlewood-maximal-function">Hardy-Littlewood Maximal Function</h3>
<h4 id="theorem-4.1-markovs-inequality">Theorem 4.1: Markov's Inequality</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(h \in L^1 (\mu)\)</span>. Then:</p>
<p><span class="math display">\[\mu(\{x \in X: |h(x)| \geq c\}) \leq \frac{1}{c} \|h\|_1\]</span></p>
<p>for every <span class="math inline">\(c &gt; 0\)</span>.</p>
<h5 id="proof-of-theorem-4.1">Proof of Theorem 4.1:</h5>
<p>Suppose <span class="math inline">\(c &gt; 0\)</span>. Then:</p>
<span class="math display">\[\begin{aligned}
\mu(\{x \in X: |h(x)| \geq c\}) &amp;= \int_{\{x \in X: |h(x)| \geq c\}} 1 d\mu \\
&amp;= \frac{1}{c}\int_{\{x \in X: |h(x)| \geq c\}} c d\mu\\
&amp;\leq \frac{1}{c}\int_{\{x \in X: |h(x)| \geq c\}} |h| d\mu\\
&amp;\leq \frac{1}{c}\int_{\{x \in X: |h(x)| \geq c\}} |h| d\mu + \frac{1}{c}\int_{\{x \in X: |h(x)| &lt; c\}} |h| d\mu\\
&amp;=\frac{1}{c}\|h\|_1
\end{aligned}\]</span>
<p><br></p>
<h4 id="definition-4.2-3-times-a-bounded-nonempty-open-interval">Definition 4.2: <span class="math inline">\(3\)</span> times a Bounded Nonempty Open Interval</h4>
<p>Suppose <span class="math inline">\(I\)</span> is a bounded nonempty open interval of <span class="math inline">\(\mathbb{R}\)</span>. Then <span class="math inline">\(3 * I\)</span> denotes the open interval with the same center as <span class="math inline">\(I\)</span> and three times the length of <span class="math inline">\(I\)</span>.</p>
<blockquote>
<p>If <span class="math inline">\(I = (0, 10)\)</span>, <span class="math inline">\(3 * I = (-10, 20)\)</span></p>
</blockquote>
<p><br></p>
<h4 id="theorem-4.4-vitali-covering-lemma">Theorem 4.4: Vitali Covering Lemma</h4>
<p>Suppose <span class="math inline">\(I_1, ..., I_n\)</span> is a list of bounded nonempty open intervals of <span class="math inline">\(\mathbb{R}\)</span>. Then there exists a disjoint sublist <span class="math inline">\(I_{k_1}, ..., I_{k_m}\)</span> s.t:</p>
<p><span class="math display">\[I_1 \cup ... \cup I_n \subseteq (3 * I_{k_1}) \cup .... \cup (3 * I_{k_n})\]</span></p>
<blockquote>
<h5 id="example-4.5">Example 4.5:</h5>
<p>Suppose <span class="math inline">\(n = 4\)</span> and</p>
<p><span class="math display">\[I_1 = (0, 10), I_2 = (9, 15), I_3 = (14, 22), I_4 = (21, 31)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[3 * I_1 = (-10, 20), 3 * I_2 = (3, 21), 3 * I_3 = (6, 30), 3 * I_4 = (11, 41)\]</span></p>
<p>Thus, <span class="math inline">\(I_1 \cup I_2 \cup I_3 \cup I_4 \subseteq (3 * I_1) \cup (3 * I_4)\)</span></p>
<p>In this example, <span class="math inline">\(I_1, I_4\)</span> is the only sublist of <span class="math inline">\(I_1, ..., I_4\)</span> that produces the conclusion of Vitali Covering Lemma.</p>
</blockquote>
<p><br></p>
<h4 id="definition-4.6-hardy-littlewood-maximal-function-h">Definition 4.6: Hardy-Littlewood Maximal Function; <span class="math inline">\(h^*\)</span></h4>
<p>Suppose <span class="math inline">\(h: \mathbb{R} \rightarrow \mathbb{R}\)</span> is a Lebesgue measurable function. Then the <strong>Hardy-Littlewood maximal function</strong> of <span class="math inline">\(h\)</span> is the function <span class="math inline">\(h^* : \mathbb{R} \rightarrow [0, \infty]\)</span> defined by:</p>
<p><span class="math display">\[h^*(b) = \sup_{t &gt; 0} \frac{1}{2t}\int^{b+t}_{b-t} |h| = \sup_{t &gt; 0} \frac{1}{2t}\int_{(b+t, b-t)} |h| d\lambda\]</span></p>
<p>Where <span class="math inline">\(h^*\)</span> is a Borel measurable function.</p>
<p><strong>In other words, <span class="math inline">\(h^*(b)\)</span> is the supremum over all bounded intervals centered at <span class="math inline">\(b\)</span> of average of <span class="math inline">\(|b|\)</span> on those intervals.</strong></p>
<p><br></p>
<h4 id="theorem-4.8-hardy-littlewood-maximal-inequality">Theorem 4.8: Hardy-Littlewood Maximal Inequality</h4>
<p>Suppose <span class="math inline">\(h \in L^1 (\mathbb{R})\)</span>. Then:</p>
<p><span class="math display">\[|\{b \in \mathbb{R}: h^*(b) &gt; c\}| \leq \frac{3}{c}\|h\|_1\]</span></p>
<p><br></p>
<h3 id="derivatives-of-integrals">Derivatives of Integrals</h3>
<h4 id="theorem-4.10-lebesgue-differentiation-theorem-first-version">Theorem 4.10: Lebesgue Differentiation Theorem, First Version</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>. Then:</p>
<p><span class="math display">\[\lim_{t \rightarrow 0} \frac{1}{2t} \int^{b+t}_{b-t} |f - f(b)| = 0\]</span></p>
<p>for almost every <span class="math inline">\(b \in \mathbb{R}\)</span></p>
<p>In other words, <strong>the average amount by which a function in <span class="math inline">\(L^1(\mathbb{R})\)</span> differs from its values is small almost everywhere on small intervals.</strong></p>
<p><br></p>
<h4 id="definition-4.16-derivative-gprime-differentiable">Definition 4.16: Derivative; <span class="math inline">\(g^{\prime}\)</span>; Differentiable</h4>
<p>Suppose <span class="math inline">\(g: I \rightarrow \mathbb{R}\)</span> is a function defined on an open interval <span class="math inline">\(I\)</span> of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(b \in I\)</span>. Then <strong>derivative</strong> of <span class="math inline">\(g\)</span> at <span class="math inline">\(b\)</span>, denoted <span class="math inline">\(g^{\prime}(b)\)</span> is defined by:</p>
<p><span class="math display">\[g^{\prime}(b) = \lim_{t \rightarrow 0} \frac{g(b + t) - g(b)}{t}\]</span></p>
<p>If the limit above exists, in which case <span class="math inline">\(g\)</span> is called <strong>differentiable</strong> at <span class="math inline">\(b\)</span>.</p>
<p><br></p>
<h4 id="theorem-4.17-fundamental-theorem-of-calculus">Theorem 4.17: Fundamental Theorem of Calculus</h4>
<p>Suppose <span class="math inline">\(f \in L^1(\mathbb{R})\)</span>. Define <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> by:</p>
<p><span class="math display">\[g(x) = \int^x_{-\infty} f\]</span></p>
<p>Suppose <span class="math inline">\(b \in \mathbb{R}\)</span> and <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(b\)</span>. Then <span class="math inline">\(g\)</span> is differentiable at <span class="math inline">\(b\)</span> and:</p>
<p><span class="math display">\[g^{\prime}(b) = f(b)\]</span></p>
<h5 id="proof-of-theorem-4.17">Proof of Theorem 4.17:</h5>
<p>If <span class="math inline">\(t \neq 0\)</span>, then:</p>
<span class="math display">\[\begin{aligned}
|\frac{g(b + t) - g(b)}{t} - f(b)| &amp;= |\frac{\int^{b+t}_{-\infty} f - \int^b_{-\infty} f}{t} - f(b)|\\
&amp;=|\frac{\int^{b+t}_{b} f}{t} - f(b)|\\
&amp;=|\frac{\int^{b+t}_{b} f}{t} - \frac{\int^{b+t}_{b} f(b)}{t}|\\
&amp;=|\frac{\int^{b+t}_{b} f - f(b)}{t}|\\
&amp;\leq \sup_{\{x \in \mathbb{R}: |x - b| &lt; |t|\}} |f(x) - f(b)|
\end{aligned}\]</span>
<p>Since <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(b\)</span>, for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(\delta &gt; 0\)</span>, s.t <span class="math inline">\(|x - b| &lt; \delta \implies |f(x) - f(b)| &lt; \epsilon\)</span>, if we let <span class="math inline">\(|t| \rightarrow 0\)</span>, s.t <span class="math inline">\(|t| &lt; \delta, \; \forall \delta &gt; 0\)</span>, then:</p>
<p><span class="math display">\[\lim_{t \rightarrow 0} \sup_{\{x \in \mathbb{R}: |x - b| &lt; |t|\}} |f(x) - f(b)| &lt; \epsilon\]</span></p>
<p>Thus, <span class="math inline">\(g^{\prime}(b) = f(b)\)</span>.</p>
<p><br></p>
<h4 id="theorem-4.19-lebesgue-differentiation-theorem-second-version">Theorem 4.19: Lebesgue Differentiation Theorem, Second Version</h4>
<p>Suppose <span class="math inline">\(f \in L^{1} (\mathbb{R})\)</span>. Define <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> by:</p>
<p><span class="math display">\[g(x) = \int^x_{-\infty} f\]</span></p>
<p>Then <span class="math inline">\(g^{\prime} (b) = f(b)\)</span> for almost every <span class="math inline">\(b \in \mathbb{R}\)</span></p>
<p><br></p>
<h4 id="theorem-4.21-l1-mathbbr-function-equals-its-local-average-almost-everywhere">Theorem 4.21: <span class="math inline">\(L^1 (\mathbb{R})\)</span> Function Equals Its Local Average Almost Everywhere</h4>
<p>Suppose <span class="math inline">\(f \in L^1 (\mathbb{R})\)</span>. Then:</p>
<p><span class="math display">\[f(b) = \lim_{t \rightarrow 0} \frac{1}{2t} \int^{b+t}_{b-t} f\]</span></p>
<p>for almost every <span class="math inline">\(b \in \mathbb{R}\)</span>.</p>
<p><strong>The results holds for at every number <span class="math inline">\(b\)</span> at which <span class="math inline">\(f\)</span> is continuous. Even if <span class="math inline">\(f\)</span> is discontinuous everywhere, the conclusion holds for almost every real number <span class="math inline">\(b\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-4.22-density">Definition 4.22: Density</h4>
<p>Suppose <span class="math inline">\(E \subseteq \mathbb{R}\)</span>. The <strong>density</strong> of <span class="math inline">\(E\)</span> at a number <span class="math inline">\(b \in \mathbb{R}\)</span> is:</p>
<p><span class="math display">\[\lim_{t \rightarrow 0} \frac{|E \cap (b-t, b+t)|}{2t}\]</span></p>
<p>If this limit exists (o.w the density of <span class="math inline">\(E\)</span> at <span class="math inline">\(b\)</span> is undefined).</p>
<blockquote>
<h5 id="example-4.23">Example 4.23</h5>
<p><span class="math display">\[
\text{The density of $[0, 1]$ at $b$ } = 
\begin{cases}
 1, \quad &amp;\text{If } b \in (0, 1)\\
 \frac{1}{2}, \quad &amp;\text{If $b = 0$ or $b = 1$}\\
 0, \quad &amp; o.w
\end{cases}
\]</span></p>
</blockquote>
<p><br></p>
<h4 id="theorem-4.24-lebesgue-density-theorem">Theorem 4.24: Lebesgue Density Theorem</h4>
<p>Suppose <span class="math inline">\(E \subseteq \mathbb{R}\)</span> is a Lebesgue measurable set. Then the density of <span class="math inline">\(E\)</span> is <span class="math inline">\(1\)</span> at almost every elment of <span class="math inline">\(E\)</span> and is <span class="math inline">\(0\)</span> at almost every element of <span class="math inline">\(\mathbb{R} / E\)</span>.</p>
<p><br></p>
<h4 id="theorem-4.25-bad-borel-set">Theorem 4.25: Bad Borel Set</h4>
<p>There exists a Borel set <span class="math inline">\(E \subseteq \mathbb{R}\)</span> s.t</p>
<p><span class="math display">\[0 &lt; |E \cap I| &lt; |I|\]</span></p>
<p>For every nonempty bounded open interval <span class="math inline">\(I\)</span>.</p>
<p><br></p>
<h2 id="product-measures">Product Measures</h2>
<h3 id="products-of-measures">Products of Measures</h3>
<h4 id="definition-5.1-rectangle">Definition 5.1: Rectangle</h4>
<p>Suppose <span class="math inline">\(X, Y\)</span> are sets. A <strong>rectangle</strong> in <span class="math inline">\(X \times Y\)</span> is a set of the form <span class="math inline">\(A \times B\)</span>, where <span class="math inline">\(A \subseteq X, B \subseteq Y\)</span>.</p>
<p><br></p>
<h4 id="definition-5.2-product-of-two-sigma-algebras-s-otimes-t-measurable-rectangle">Definition 5.2: Product of Two <span class="math inline">\(\sigma\)</span>-algebras; <span class="math inline">\(S \otimes T\)</span>; Measurable Rectangle</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> and <span class="math inline">\((Y, T)\)</span> are measurable spaces. Then:</p>
<ul>
<li>The <strong>product</strong> <span class="math inline">\(S \otimes T\)</span> is defined to be the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X \times Y\)</span> that contains: <span class="math display">\[\{A \times B: A \in S, B \in T\}\]</span></li>
<li>A <strong>measurable rectangle</strong> in <span class="math inline">\(S \otimes T\)</span> is a set of the form <span class="math inline">\(A \times B\)</span>, where <span class="math inline">\(A \in S\)</span> and <span class="math inline">\(B \in T\)</span>.</li>
</ul>
<p>Thus, <span class="math inline">\(S \otimes T\)</span> is the smallest <span class="math inline">\(\sigma\)</span>-algebra that contains all the measurable rectangles in <span class="math inline">\(S \otimes T\)</span>.</p>
<p><br></p>
<h4 id="definition-5.3-cross-sections-of-sets-e_a-and-eb">Definition 5.3: Cross Sections of Sets; <span class="math inline">\(E_a\)</span> and <span class="math inline">\(E^b\)</span></h4>
<p>Suppose <span class="math inline">\(X, Y\)</span> are sets and <span class="math inline">\(E \subseteq X \times Y\)</span>. Then for <span class="math inline">\(a \in X\)</span> and <span class="math inline">\(b \in Y\)</span>, the <strong>cross sections</strong> <span class="math inline">\(E_a\)</span> and <span class="math inline">\(E^b\)</span> are defined by:</p>
<p><span class="math display">\[E_a = \{y \in Y: (a, y) \in E\}, \quad E^b = \{x \in X: (x, b) \in E\}\]</span></p>
<h5 id="example-5.5">Example 5.5:</h5>
<p>Suppose <span class="math inline">\(X, Y\)</span> are sets and <span class="math inline">\(A \subseteq X, B \subseteq Y\)</span>, then:</p>
<p><span class="math display">\[
[A \times B]_a = 
\begin{cases}
B, \quad &amp; \text{if } a \in A\\
\emptyset, \quad &amp; \text{if } a \notin A
\end{cases}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
[A \times B]^b = 
\begin{cases}
A, \quad &amp; \text{if } b \in B\\
\emptyset, \quad &amp; \text{if } b \notin B
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="theorem-5.6-cross-sections-of-measurable-sets-are-measurable">Theorem 5.6: Cross Sections of Measurable sets are Measurable</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span> and <span class="math inline">\(T\)</span> is <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(Y\)</span>. If <span class="math inline">\(E \in S \otimes T\)</span>, then</p>
<p><span class="math display">\[E_a \in T, \; \forall a \in X , \quad\quad E^b \in S, \; \forall b \in Y\]</span></p>
<p>In other words, Let <span class="math inline">\(\varepsilon\)</span> denotes the collection of subsets <span class="math inline">\(E\)</span> of <span class="math inline">\(X \times Y\)</span> for which the conclusion of this result holds. Then <span class="math inline">\(\varepsilon\)</span> is <span class="math inline">\(\sigma\)</span>-algebra that contains <span class="math inline">\(S \otimes T\)</span>.</p>
<p><br></p>
<h4 id="definition-5.7-cross-sections-of-functions-f_a-fb">Definition 5.7: Cross Sections of Functions; <span class="math inline">\(f_a, f^b\)</span></h4>
<p>Suppose <span class="math inline">\(X, Y\)</span> are sets and <span class="math inline">\(f: X \times Y \rightarrow \mathbb{R}\)</span> is a function. Then for <span class="math inline">\(a \in X\)</span> and <span class="math inline">\(b \in Y\)</span>, the cross section functions <span class="math inline">\(f_a: Y \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(f^b: X \rightarrow \mathbb{R}\)</span> are defined by:</p>
<p><span class="math display">\[f_a (y) = f(a, y), \quad \forall y \in Y\]</span></p>
<p>and</p>
<p><span class="math display">\[f^b (x) = f(x , b), \quad \forall x \in X\]</span></p>
<p><br></p>
<h4 id="theorem-5.9-cross-sections-of-measurable-functions-are-measurable">Theorem 5.9: Cross Sections of Measurable Functions are Measurable</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span> and <span class="math inline">\(T\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span> and <span class="math inline">\(T\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(Y\)</span>. Suppose <span class="math inline">\(f: X \times Y \rightarrow \mathbb{R}\)</span> is an <span class="math inline">\(S \otimes T\)</span>-measurable function. Then:</p>
<p><span class="math display">\[f_a \text{ is a $T$-measurable function on $Y$ for every $a \in X$}\]</span></p>
<p>and</p>
<p><span class="math display">\[f^b \text{ is a $S$-measurable function on $X$ for every $b \in Y$}\]</span></p>
<h5 id="proof-of-theorem-5.9">Proof of Theorem 5.9:</h5>
<p>Suppose <span class="math inline">\(D\)</span> is a Borel set of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(a \in X\)</span>. For all <span class="math inline">\(y \in Y\)</span>, we want to show that:</p>
<p><span class="math display">\[y \in (f_a)^{-1}(D) \Longleftrightarrow y \in [f^{-1}(D)]_a\]</span></p>
<p>Then,</p>
<span class="math display">\[\begin{aligned}
y \in (f_a)^{-1}(D) &amp;\Longleftrightarrow f(a, y) \in D\\
&amp;\Longleftrightarrow (a, y) \in f^{-1} (D)\\
&amp;\Longleftrightarrow y \in [f^{-1}(D)]_a\\
\end{aligned}\]</span>
<p>Thus, <span class="math inline">\((f_a)^{-1}(D) = [f^{-1}(D)]_a\)</span></p>
<p>If <span class="math inline">\(f\)</span> is <span class="math inline">\(S \otimes T\)</span>-measurable, then:</p>
<p><span class="math display">\[f^{-1}(D) \in S \otimes T \implies [f^{-1}(D)]_a \in T \implies (f_a)^{-1}(D) \in T \implies (f_a)^{-1} \text{ is $T$-measurable}\]</span></p>
<p><br></p>
<h3 id="monotone-class-theorem">Monotone Class Theorem</h3>
<p>The following standard two-step technique often works to prove that every set in a <span class="math inline">\(\sigma\)</span>-algebra has a certain property:</p>
<ol type="1">
<li>Show that Every set in a collection of sets that generates the <span class="math inline">\(\sigma\)</span>-algebra has the property.</li>
<li>Show that the collection of sets that has the property is a <span class="math inline">\(\sigma\)</span>-algebra.</li>
</ol>
<h4 id="definition-5.10-algebra">Definition 5.10: Algebra</h4>
<p>Suppose <span class="math inline">\(W\)</span> is set and <span class="math inline">\(A\)</span> is a set of subsets of <span class="math inline">\(W\)</span>. Then <span class="math inline">\(A\)</span> is called an <strong>algebra</strong> on <span class="math inline">\(W\)</span> if the following three conditions are satisfied:</p>
<ol type="1">
<li><span class="math inline">\(\emptyset \in A\)</span>.</li>
<li>If <span class="math inline">\(E \in A\)</span>, then <span class="math inline">\(W / E \in A\)</span>.</li>
<li>If <span class="math inline">\(E, F \in A\)</span>, then <span class="math inline">\(E \cup F \in A\)</span>.</li>
</ol>
<p><strong>Thus, an algebra is closed under complementation and under finite unions. A <span class="math inline">\(\sigma\)</span>-algebra is closed under complementation and countable unions.</strong></p>
<p><br></p>
<h4 id="theorem-5.13-the-set-of-finite-unions-of-measurable-rectangles-is-an-algebra">Theorem 5.13: The Set of Finite Unions of Measurable Rectangles is an Algebra</h4>
<p>Suppose <span class="math inline">\((X, S), (Y, T)\)</span> are measurable spaces. Then:</p>
<ol type="1">
<li><p>The set of finite unions of measurable rectangles in <span class="math inline">\(S \otimes T\)</span> is an algebra on <span class="math inline">\(X \times Y\)</span>.</p></li>
<li><p>Every finite union of measurable rectangles in <span class="math inline">\(S \otimes T\)</span> can be written as a finite union of disjoint measurable rectangles in <span class="math inline">\(S \otimes T\)</span>.</p>
<p><span class="math display">\[(A \times B) \cup (C \times D) = (A \times B) \cup (C \times (D / B)) \cup ((C / A) \times (B \cap D))\]</span></p></li>
</ol>
<p><img src='/images/RL/background/mira_1.png' width="600"></p>
<p><br></p>
<h4 id="definition-5.15-monotone-class">Definition 5.15: Monotone Class</h4>
<p>Suppose <span class="math inline">\(W\)</span> is a set and <span class="math inline">\(M\)</span> is a set of subsets of <span class="math inline">\(W\)</span>. Then <span class="math inline">\(M\)</span> is called a <strong>Monotone class</strong> on <span class="math inline">\(W\)</span> if the following two conditions are satisfied:</p>
<ul>
<li>If <span class="math inline">\(E_1 \subseteq E_2 \subseteq ...\)</span> is an increasing sequence of sets in <span class="math inline">\(M\)</span>, then: <span class="math display">\[\bigcup^{\infty}_{k=1} E_k \in M\]</span></li>
<li>If <span class="math inline">\(E_1 \supseteq E_2 \supseteq ...\)</span> is an decreasing sequence of sets in <span class="math inline">\(M\)</span>, then: <span class="math display">\[\bigcap^{\infty}_{k=1} E_k \in M\]</span></li>
</ul>
<p>Every <span class="math inline">\(\sigma\)</span>-algebra is a monotone class. However, some monotone classes are not closed under even finite unions.</p>
<p><br></p>
<h4 id="theorem-5.17-monotone-class-theorem">Theorem 5.17: Monotone Class Theorem</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an algebra on a set <span class="math inline">\(W\)</span>. Then the smallest <span class="math inline">\(\sigma\)</span>-algebra containing <span class="math inline">\(A\)</span> is the smallest monotone class containing <span class="math inline">\(A\)</span>. (The smallest monotone class is the intersection of all monotone classes on <span class="math inline">\(W\)</span> that contain <span class="math inline">\(A\)</span>.)</p>
<p><br></p>
<h4 id="definition-5.18-finite-measure-sigma-finite-measure">Definition 5.18: Finite Measure; <span class="math inline">\(\sigma\)</span>-Finite Measure</h4>
<ul>
<li>A measure <span class="math inline">\(\mu\)</span> on a measurable space <span class="math inline">\((X, S)\)</span> is called <strong>finite</strong> if <span class="math inline">\(\mu(X) &lt; \infty\)</span>.</li>
<li>A measure is called <strong><span class="math inline">\(\sigma\)</span>-finite</strong> if the whole space can be written as the countable union of sets with finite measure.</li>
<li>More precisely, a measure <span class="math inline">\(\mu\)</span> on a measurable space <span class="math inline">\((X, S)\)</span> is called <strong>-finite</strong> if there exists a sequence <span class="math inline">\(X_1, X_2, ...\)</span> of sets in <span class="math inline">\(S\)</span> s.t: <span class="math display">\[X = \bigcup^{\infty}_{k=1} X_k, \quad \quad \mu(X_k) &lt; \infty, \quad \forall k \in \mathbb{Z}^+\]</span></li>
</ul>
<p><br></p>
<h4 id="theorem-5.20-measure-of-cross-section-is-a-measurable-function">Theorem 5.20: Measure of Cross Section is a Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> and <span class="math inline">\((Y, T, v)\)</span> are <strong><span class="math inline">\(\sigma\)</span>-finite</strong> measure spaces. If <span class="math inline">\(E \in S \otimes T\)</span>, then:</p>
<ol type="a">
<li><span class="math inline">\(x \longmapsto v(E_x)\)</span> is an <span class="math inline">\(S\)</span>-measurable function on <span class="math inline">\(X\)</span> (Think of the function as <span class="math inline">\(f(x) = v(E_x)\)</span>).</li>
<li><span class="math inline">\(y \longmapsto \mu(E^y)\)</span> is a <span class="math inline">\(T\)</span>-measurable function on <span class="math inline">\(Y\)</span> (Think of the function as <span class="math inline">\(g(y) = \mu(E^y)\)</span>).</li>
</ol>
<p><br></p>
<h4 id="definition-5.21-integration-notation">Definition 5.21: Integration Notation</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(g: X \rightarrow [-\infty, \infty]\)</span> is a function. The notation:</p>
<p><span class="math display">\[\int g(x) d\mu(x) := \int g d\mu\]</span></p>
<p>Where <span class="math inline">\(d\mu(x)\)</span> indicates that variables other than <span class="math inline">\(x\)</span> should be treated as constants.</p>
<p><br></p>
<h4 id="definition-5.23-iterated-integrals">Definition 5.23: Iterated Integrals</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> and <span class="math inline">\((Y, T, v)\)</span> are measure spaces and <span class="math inline">\(f: X \times Y \rightarrow \mathbb{R}\)</span> is a function. Then:</p>
<p><span class="math display">\[\int_{X} \int_{Y} f(x, y) dv(y) d\mu(x)\]</span></p>
<p>means:</p>
<p><span class="math display">\[\int_x (\int_{Y} f(x, y) dv(y)) d\mu(x)\]</span></p>
<p>In other words, to compute the integral above, first fix <span class="math inline">\(x \in X\)</span> and compute <span class="math inline">\(\int_{Y} f(x, y) dv(y)\)</span> if this integral makes sense. Then compute the integral w.r.t <span class="math inline">\(\mu\)</span> of the function:</p>
<p><span class="math display">\[x \longmapsto \int_Y f(x, y) dv(y)\]</span></p>
<p>If this integral makes sense.</p>
<p><br></p>
<h4 id="definition-5.25-product-of-two-measures-mu-times-v">Definition 5.25: Product of Two Measures; <span class="math inline">\(\mu \times v\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> and <span class="math inline">\((Y, T, v)\)</span> are <span class="math inline">\(\sigma\)</span>-finite measure spaces. For <span class="math inline">\(E \in S \otimes T\)</span>, define <span class="math inline">\((\mu \times v) (E)\)</span> by:</p>
<p><span class="math display">\[(\mu \times v) (E) = \int_X \int_Y \chi_{E} (x, y) dv(y) d\mu(x)\]</span></p>
<blockquote>
<h5 id="example-5.26">Example 5.26</h5>
<p>Suppose <span class="math inline">\((X, S, \mu), (Y, T, v)\)</span> are <span class="math inline">\(\sigma\)</span>-finite measure spaces. If <span class="math inline">\(A \in S\)</span> and <span class="math inline">\(B \in T\)</span>, then: <span class="math display">\[(\mu \times v) (A \times B) = \int_{X} \int_{Y} \chi_{A \times B} (x, y) dv(y) d\mu(x) = \int_{X} \int_{Y} \chi_{B} (y) \chi_{A} (x) dv(y) d\mu(x) = \int_{X} \chi_{A} (x) v(B) d\mu(x) = \mu(A) v(B)\]</span></p>
<p><strong>Product measure of a measurable rectangle is the product of the measures of the corresponding sets.</strong></p>
</blockquote>
<p><br></p>
<h4 id="theorem-5.27-product-of-two-measures-is-a-measure">Theorem 5.27: Product of Two Measures is a Measure</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> and <span class="math inline">\((Y, T, v)\)</span> are <span class="math inline">\(\sigma\)</span>-finite measure spaces. Then <span class="math inline">\(\mu \times v\)</span> is a measure on <span class="math inline">\((X \times Y, S \otimes T)\)</span>.</p>
<p><br></p>
<h4 id="theorem-5.28-tonellis-theorem">Theorem 5.28: Tonelli's Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> and <span class="math inline">\((Y, T, v)\)</span> are <span class="math inline">\(\sigma\)</span>-finite measure spaces. Suppose <span class="math inline">\(f: X \times Y \rightarrow [0, \infty]\)</span> is <span class="math inline">\(S \otimes T\)</span> measurable. Then:</p>
<p><span class="math display">\[x \longmapsto  \int_Y f(x, y) dv(y) \text{ is an $S$-measurable function on $X$}\]</span></p>
<p><span class="math display">\[y \longmapsto  \int_X f(x, y) d\mu(x) \text{ is an $T$-measurable function on $Y$}\]</span></p>
<p>and</p>
<p><span class="math display">\[\int_{X \times Y} f d(\mu \times v) = \int_X \int_Y f(x, y) dv(y) d\mu(x) = \int_Y \int_X f(x, y) d\mu(x) dv(y)\]</span></p>
<p><br></p>
<h4 id="theorem-5.31-double-sums-of-nonnegative-numbers">Theorem 5.31: Double Sums of Nonnegative Numbers</h4>
<p>If <span class="math inline">\(x_{j, k}: j, k \in \mathbb{Z}^+\)</span> is a doubly indexed collection of nonnegative numbers, then:</p>
<p><span class="math display">\[\sum^\infty_{j=1}\sum^{\infty}_{k=1} x_{j, k} = \sum^{\infty}_{k=1} \sum^{\infty}_{j=1} x_{j, k}\]</span></p>
<p><br></p>
<h4 id="theorem-5.32-fubinis-theorem">Theorem 5.32: Fubini's Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> and <span class="math inline">\((Y, T, v)\)</span> are <span class="math inline">\(\sigma\)</span>-finite measure spaces. Suppose <span class="math inline">\(f: X \times Y \rightarrow [-\infty, \infty]\)</span> is <span class="math inline">\(S \otimes T\)</span>-measurable and <span class="math inline">\(\int_{X \times Y} |f| d(\mu \times v) &lt; \infty\)</span>, then:</p>
<p><span class="math display">\[\int_Y |f(x, y)| dv(y) &lt; \infty \text{ for almost every $x \in X$}\]</span></p>
<p>and</p>
<p><span class="math display">\[\int_Y |f(x, y)| d\mu(x) &lt; \infty \text{ for almost every $y \in Y$}\]</span></p>
<p>Furthermore:</p>
<p><span class="math display">\[x \longmapsto  \int_Y f(x, y) dv(y) \text{ is an $S$-measurable function on $X$}\]</span></p>
<p><span class="math display">\[y \longmapsto  \int_X f(x, y) d\mu(x) \text{ is an $T$-measurable function on $Y$}\]</span></p>
<p>And:</p>
<p><span class="math display">\[\int_{X \times Y} f d(\mu \times v) = \int_X \int_Y f(x, y) dv(y) d\mu(x) = \int_Y \int_X f(x, y) d\mu(x) dv(y)\]</span></p>
<p><br></p>
<h4 id="definition-5.34-region-under-the-graph-u_f">Definition 5.34: Region Under the Graph; <span class="math inline">\(U_f\)</span></h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is a function. Then the <strong>region under the graph</strong> of <span class="math inline">\(f\)</span>, denoted <span class="math inline">\(U_f\)</span> is defined by:</p>
<p><span class="math display">\[U_f = \{(x, t) \in X \times (0, \infty): 0 &lt; t &lt; f(x)\}\]</span></p>
<p><br></p>
<h4 id="theorem-5.35-area-under-the-graph-of-a-function-equals-the-integral">Theorem 5.35: Area Under the Graph of a Function Equals the Integral</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a <span class="math inline">\(\sigma\)</span>-finite measure space and <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function. Let <span class="math inline">\(B\)</span> denotes the <span class="math inline">\(\sigma\)</span>-algebra subsets of <span class="math inline">\((0, \infty)\)</span>, and let <span class="math inline">\(\lambda\)</span> denotes the Lebesgue measure on <span class="math inline">\(((0, \infty), B)\)</span>. Then <span class="math inline">\(U_f \in S \otimes B\)</span> and:</p>
<p><span class="math display">\[(\mu \times \lambda) (U_f) = \int_X f d\mu = \int_{(0, \infty)} \mu(\{x \in X: t &lt; f(x)\}) d\lambda(t)\]</span></p>
<p><br></p>
<h3 id="lebesgue-integration-on-mathbbrn">Lebesgue Integration on <span class="math inline">\(\mathbb{R}^n\)</span></h3>
<p>Assume throughout this section, <span class="math inline">\(m, n\)</span> are positive integers.</p>
<ol type="1">
<li>An <strong>open cube</strong> <span class="math inline">\(B(x, \delta)\)</span> with side length <span class="math inline">\(2\delta\)</span> is defined by: <span class="math display">\[B(x, \delta) = \{y \in \mathbb{R}^n: \|y - x\|_{\infty} &lt; \delta\}\]</span></li>
<li>A subset <span class="math inline">\(G \in \mathbb{R}^n\)</span> is called <strong>open</strong> if for every <span class="math inline">\(x \in G\)</span>, there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(B(x, \delta) \subseteq G\)</span>.</li>
<li>The union of every collection (finite or infinite) of open subsets of <span class="math inline">\(\mathbb{R}^n\)</span> is an open subset of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>The intersection of every finite collection of open subsets of <span class="math inline">\(\mathbb{R}^n\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
<li>A subset of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>closed</strong> if its complement in <span class="math inline">\(\mathbb{R}^n\)</span> is open.</li>
<li>A set <span class="math inline">\(A \subseteq \mathbb{R}^n\)</span> is called <strong>bounded</strong> if <span class="math inline">\(\sup\{\|a\|_{\infty}: a \in A\} &lt; \infty\)</span>.</li>
<li><span class="math inline">\(\mathbb{R}^m \times \mathbb{R}^n\)</span> is identified with <span class="math inline">\(\mathbb{R}^{m + n}\)</span>, note that <span class="math inline">\(\mathbb{R}^2 \times \mathbb{R}^{1} \neq \mathbb{R}^3\)</span> however we can identify <span class="math inline">\(((x_1, x_2), x_3)\)</span> with <span class="math inline">\((x_1, x_2, x_3)\)</span>, so we say that they are <strong>equal</strong>.</li>
<li><span class="math inline">\(B(x, \delta) \times B(y, \delta) = B((x, y), \delta) \in \mathbb{R}^{m + n}, x \in \mathbb{R}^m, y \in \mathbb{R}^n\)</span> <br></li>
</ol>
<h4 id="theorem-5.36-product-of-open-set-is-open">Theorem 5.36: Product of Open Set is Open</h4>
<p>Suppose <span class="math inline">\(G_1\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^m\)</span> and <span class="math inline">\(G_2\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^n\)</span>. Then <span class="math inline">\(G_1 \times G_2\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^{m+n}\)</span>.</p>
<p><br></p>
<h4 id="definition-5.37-borel-set-b_n">Definition 5.37: Borel set; <span class="math inline">\(B_n\)</span></h4>
<ul>
<li>A <strong>Borel set</strong> of <span class="math inline">\(\mathbb{R}^n\)</span> is an element of the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}^n\)</span> that containing all open subsets of <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
<li>The <strong><span class="math inline">\(\sigma\)</span>-algebra</strong> of Borel subsets of <span class="math inline">\(\mathbb{R}^n\)</span> is denoted by <span class="math inline">\(B_n\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-5.38-open-sets-are-countable-unions-of-open-cubes">Theorem 5.38: Open Sets are Countable Unions of Open Cubes</h4>
<ol type="a">
<li>A subset of <span class="math inline">\(\mathbb{R}^n\)</span> is open in <span class="math inline">\(\mathbb{R}^n\)</span> if and only if it is a countable union of open cubes in <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
<li><span class="math inline">\(B_n\)</span> is the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}^n\)</span> containing all open cubes in <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-5.39-product-of-the-borel-subsets-of-mathbbrm-and-the-borel-subsets-of-mathbbrn">Theorem 5.39: Product of the Borel Subsets of <span class="math inline">\(\mathbb{R}^m\)</span> and the Borel Subsets of <span class="math inline">\(\mathbb{R}^n\)</span></h4>
<p><span class="math display">\[B_{m} \otimes B_{n} = B_{m + n}\]</span></p>
<p>In other words, <span class="math inline">\(B_{m + n}\)</span> is the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}^{m + n}\)</span> that containing all measurable rectangles <span class="math inline">\(\{A \times B: A \subseteq B_m, B \subseteq B_n\}\)</span>.</p>
<p>And we can define <span class="math inline">\(B_m \otimes B_n \otimes B_p\)</span> directly as the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}^{m + n + p}\)</span> that containing <span class="math inline">\(\{A \times B \times C: A \subseteq B_m, B \subseteq B_n, C \subseteq B_p\}\)</span></p>
<p><br></p>
<h4 id="definition-5.40-lebesgue-measure-lambda_n">Definition 5.40: Lebesgue Measure; <span class="math inline">\(\lambda_n\)</span></h4>
<p><strong>Lebesgue measure</strong> on <span class="math inline">\(\mathbb{R}^n\)</span> is denoted by <span class="math inline">\(\lambda_n\)</span> and is defined indutively by:</p>
<p><span class="math display">\[\lambda_n = \lambda_{n-1} \times \lambda_1\]</span></p>
<p>where <span class="math inline">\(\lambda_1\)</span> is the Lebesgue measure on <span class="math inline">\((\mathbb{R}, B_1)\)</span></p>
<p>or identically, we can write:</p>
<p><span class="math display">\[\lambda_n = \lambda_{j} \times \lambda_{k}\]</span></p>
<p>where <span class="math inline">\(j, k \in \mathbb{Z}^+, j + k = n\)</span>.</p>
<p><br></p>
<h4 id="theorem-5.41-measure-of-a-dilation">Theorem 5.41: Measure of a Dilation</h4>
<p>Suppose <span class="math inline">\(t &gt; 0\)</span>. If <span class="math inline">\(E \subseteq B_n\)</span>, then <span class="math inline">\(tE \subseteq B_n\)</span> and <span class="math inline">\(\lambda_n(tE) = t^n\lambda_n(E)\)</span></p>
<p>where <span class="math inline">\(tE = \{tx: \forall x \in E\}\)</span></p>
<p><br></p>
<h4 id="definition-5.43-open-unit-ball-in-mathbbrn-b_n">Definition 5.43: Open Unit Ball in <span class="math inline">\(\mathbb{R}^n\)</span>; <span class="math inline">\(B_n\)</span></h4>
<p>The <strong>open unit ball</strong> in <span class="math inline">\(\mathbb{R}^n\)</span> is denoted by <span class="math inline">\(\mathbf{B}_n\)</span> and is defined by:</p>
<p><span class="math display">\[\mathbf{B}_n = \{(x_1, ..., x_n) \in \mathbb{R}^n : x^2_1 + .... + x_n^2 &lt; 1\}\]</span></p>
<p><br></p>
<h4 id="definition-5.46-partial-derivatives-d_1-f-and-d_2-f">Definition 5.46: Partial Derivatives; <span class="math inline">\(D_1 f\)</span> and <span class="math inline">\(D_2 f\)</span></h4>
<p>Suppose <span class="math inline">\(G\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^2\)</span> and <span class="math inline">\(f: G \rightarrow \mathbb{R}\)</span> is a function. For <span class="math inline">\((x, y) \in G\)</span>, the <strong>partial derivatives <span class="math inline">\((D_1f)(x, y)\)</span> and <span class="math inline">\(D_2f(x, y)\)</span></strong> are defined by:</p>
<p><span class="math display">\[(D_1f)(x, y) = \lim_{t\rightarrow 0} \frac{f(x+t, y) - f(x, y)}{t}\]</span></p>
<p><span class="math display">\[(D_2f)(x, y) = \lim_{t \rightarrow 0} \frac{f(x, y+t) - f(x, y)}{t}\]</span></p>
<p>If these limit exists.</p>
<p><br></p>
<h4 id="theorem-5.48-equality-of-mixed-partial-derivatives">Theorem 5.48: Equality of Mixed Partial Derivatives</h4>
<p>Suppose <span class="math inline">\(G\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^2\)</span> and <span class="math inline">\(f: G \rightarrow \mathbb{R}\)</span> is a funciton s.t <span class="math inline">\(D_1 f\)</span>, <span class="math inline">\(D_2 f\)</span>, <span class="math inline">\(D_1 (D_2 f)\)</span>, <span class="math inline">\(D_2 (D_1 f)\)</span> all exists and are continuous functions on <span class="math inline">\(G\)</span>. Then:</p>
<p><span class="math display">\[D_1(D_2 f) = D_2(D_1 f)\]</span></p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Search</title>
    <url>/2021/06/13/search/</url>
    <content><![CDATA[<h1 id="search">Search</h1>
<h1 id="breath-first-search">Breath First Search</h1>
<p>Breadth First Search (BFS) algorithm traverses a graph in a breadthward motion and uses a queue to remember to get the next vertex to start a search, when a dead end occurs in any iteration.</p>
<p><img src="/images/algo/dfs_1.png" width="600px"></p>
<p>As in the example given above, BFS algorithm traverses from A to B to E to F first then to C and G lastly to D. It employs the following rules:</p>
<ul>
<li>Visit the adjacent unvisited vertex. Mark it as visited. Display it. Insert it in a queue.</li>
<li>If no adjacent vertex is found, remove the first vertex from the queue, and set this vertex as the head.</li>
<li>Repeat Rule 1 and Rule 2 until the queue is empty.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, key=<span class="literal">None</span>, parent=<span class="literal">None</span>, left_child=<span class="literal">None</span>, right_child=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.key = key</span><br><span class="line">        self.parent = parent</span><br><span class="line">        self.left_child = left_child</span><br><span class="line">        self.right_child = right_child</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tree</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, tree=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.root = tree</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span>(<span class="params">tree</span>):</span></span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line">    q = deque()</span><br><span class="line">    q.append(tree)</span><br><span class="line">    <span class="keyword">while</span> q:</span><br><span class="line">        head = q.popleft()</span><br><span class="line">        <span class="built_in">print</span>(head.key)</span><br><span class="line">        <span class="keyword">if</span> head.left_child:</span><br><span class="line">            q.append(head.left_child)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> head.right_child:</span><br><span class="line">            q.append(head.right_child)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="depth-first-search">Depth First Search</h1>
<p>Depth First Search (DFS) algorithm traverses a graph in a depthward motion and uses a stack to remember to get the next vertex to start a search, when a dead end occurs in any iteration.</p>
<p><img src="/images/algo/dfs_2.png" width="600px"></p>
<p>As in the example given above, DFS algorithm traverses from S to A to D to G to E to B first, then to F and lastly to C. It employs the following rules:</p>
<ul>
<li>Visit the adjacent unvisited vertex. Mark it as visited. Display it. Push it in a stack.</li>
<li>If no adjacent vertex is found, pop up a vertex from the stack. (It will pop up all the vertices from the stack, which do not have adjacent vertices.)</li>
<li>Repeat Rule 1 and Rule 2 until the stack is empty.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">tree</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tree.left_child <span class="keyword">and</span> <span class="keyword">not</span> tree.right_child:</span><br><span class="line">        <span class="built_in">print</span>(tree.key)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(tree.key)</span><br><span class="line">        <span class="keyword">if</span> tree.left_child:</span><br><span class="line">            dfs(tree.left_child)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> tree.right_child:</span><br><span class="line">            dfs(tree.right_child)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs_stack</span>(<span class="params">tree</span>):</span></span><br><span class="line">    stack = [tree]</span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        head = stack.pop()</span><br><span class="line">        <span class="built_in">print</span>(head.key)</span><br><span class="line">        <span class="keyword">if</span> head.right_child:</span><br><span class="line">            stack.append(head.right_child)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> head.left_child:</span><br><span class="line">            stack.append(head.left_child)</span><br></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<p>https://www.tutorialspoint.com/data_structures_algorithms/depth_first_traversal.htm</p>
]]></content>
      <categories>
        <category>CS Basics</category>
      </categories>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>semi-mdp</title>
    <url>/2021/06/28/semi-mdp/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Sorts</title>
    <url>/2021/06/06/sort/</url>
    <content><![CDATA[<h1 id="sorts">Sorts</h1>
<p><img src="/images/algo/complex.png" width="600px"></p>
<h2 id="insetion-sort">Insetion Sort</h2>
<p>The insertion sort algorithm iterates through an input array and removes one element per iteration, finds the place the element belongs in the array, and then places it there. This process grows a sorted list from left to right. The algorithm is as follows:</p>
<p>To sort an array of size n in ascending order:</p>
<ol type="1">
<li><p>Iterate from arr[1] to arr[n] over the array.</p></li>
<li><p>Compare the current element (key) to its predecessor.</p></li>
<li><p>If the key element is smaller than its predecessor, compare it to the elements before. Move the greater elements one position up to make space for the swapped element.</p></li>
</ol>
<p><strong>The key is that: arr[i - 1] is always sorted.</strong></p>
<p><img src="/images/algo/insertion_sort.png" width="600px"></p>
<h3 id="implementation">Implementation</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertion_sort</span>(<span class="params">lst</span>):</span></span><br><span class="line">    <span class="comment"># assume len(lst) &gt; 1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(lst)):</span><br><span class="line">        <span class="comment"># swap lst[i - 1] and lst[i] if lst[i - 1] &gt; lst[i]</span></span><br><span class="line">        <span class="comment"># we stop at i &lt; 1 because we know arr[0] is the smallest</span></span><br><span class="line">        <span class="keyword">while</span> (i &gt;= <span class="number">1</span>) <span class="keyword">and</span> (lst[i] &lt; lst[i - <span class="number">1</span>]):</span><br><span class="line">            val = lst[i]</span><br><span class="line">            lst[i] = lst[i - <span class="number">1</span>]</span><br><span class="line">            lst[i - <span class="number">1</span>] = val</span><br><span class="line">            i = i - <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> lst</span><br></pre></td></tr></table></figure>
<h2 id="merge-sort">Merge Sort</h2>
<p>Mergesort has two steps: merging and sorting. The algorithm uses a divide-and-conquer approach to merge and sort a list.</p>
<p>Divide and conquer is a technique used for breaking algorithms down into subproblems, solving the subproblems, and then combining the results back together to solve the original problem. It can be helpful to think of this method as divide, conquer, and combine.</p>
<p>The mergesort algorithm focuses on how to merge together two pre-sorted arrays such that the resulting array is also sorted. Mergesort can be implemented either recursively or iteratively.</p>
<p>Here is the recursive mergesort algorithm:</p>
<ol type="1">
<li>If the list has only one element, return the list and terminate. (Base case)</li>
<li>Split the list into two halves that are as equal in length as possible. (Divide)</li>
<li>Using recursion, sort both lists using mergesort. (Conquer)</li>
<li><strong>Merge</strong> the two sorted lists and return the result. (Combine)</li>
</ol>
<p>The merge step:</p>
<ol type="1">
<li>Create an empty list called the result list.</li>
<li>Do the following until one of the input lists is empty: Remove the first element of the list that has a lesser first element and append it to the result list.</li>
<li>When one of the lists is empty, append all elements of the other list to the result.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">lst</span>):</span></span><br><span class="line">    <span class="comment"># base case</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(lst) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> lst</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sorted_lst = []</span><br><span class="line">        mid = <span class="built_in">len</span>(lst) // <span class="number">2</span></span><br><span class="line">        left_lst = merge_sort(lst[:mid])</span><br><span class="line">        right_lst = merge_sort(lst[mid:])</span><br><span class="line">        <span class="comment"># left_lst and right_lst will return two sorted lists, so we need to merge them</span></span><br><span class="line">        <span class="comment"># if left_lst[0] &gt; right_lst[0], we remove first element from right_lst and append to </span></span><br><span class="line">        <span class="comment"># the sorted_lst, if one of the lst is empty, we extend the another list to sorted_lst and exist the loop</span></span><br><span class="line">        <span class="keyword">while</span> left_lst <span class="keyword">or</span> right_lst:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left_lst <span class="keyword">or</span> <span class="keyword">not</span> right_lst:</span><br><span class="line">                sorted_lst.extend(left_lst)</span><br><span class="line">                sorted_lst.extend(right_lst)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">elif</span> left_lst[<span class="number">0</span>] &gt; right_lst[<span class="number">0</span>]:</span><br><span class="line">                sorted_lst.append(right_lst.pop(<span class="number">0</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sorted_lst.append(left_lst.pop(<span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> sorted_lst</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="bubble-sort">Bubble Sort</h2>
<p>Bubble sort is a simple, inefficient sorting algorithm used to sort lists. The Bubble sort algorithm compares each pair of elements in an array and swaps them if they are out of order until the entire array is sorted. For each element in the list, the algorithm compares every pair of elements.</p>
<p>The bubble sort algorithm is as follows:</p>
<ol type="1">
<li>Compare A[0] and A[1]. If A[0] is bigger than A[1], swap the elements.</li>
<li>Move to the next element, A[1] (which might now contain the result of a swap from the previous step), and compare it with A[2]. If A[1] is bigger than A[2], swap the elements. Do this for every pair of elements until the end of the list.</li>
<li>Do steps 1 and 2 n times.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span>(<span class="params">lst</span>):</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> lst[j] &gt; lst[j + <span class="number">1</span>]:</span><br><span class="line">                val = lst[j]</span><br><span class="line">                lst[j] = lst[j + <span class="number">1</span>]</span><br><span class="line">                lst[j + <span class="number">1</span>] = val</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="selection-sort">Selection Sort</h2>
<p>The selection sort algorithm sorts an array by repeatedly finding the minimum element (considering ascending order) from unsorted part and putting it at the beginning. The algorithm maintains two subarrays in a given array. 1. The subarray which is already sorted. 2. Remaining subarray which is unsorted. In every iteration of selection sort, the minimum element (considering ascending order) from the unsorted subarray is picked and moved to the sorted subarray.</p>
<p>We perform the steps given below until the unsorted subarray becomes empty:</p>
<ol type="1">
<li>Pick the minimum element from the unsorted subarray.</li>
<li>Swap it with the leftmost element of the unsorted subarray.</li>
<li>Now the leftmost element of unsorted subarray becomes a part (rightmost) of sorted subarray and will not be a part of unsorted subarray.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span>(<span class="params">lst</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_min</span>(<span class="params">start</span>):</span></span><br><span class="line">        l, r = start, <span class="built_in">len</span>(lst) - <span class="number">1</span></span><br><span class="line">        curr_min, index = (lst[l], l) <span class="keyword">if</span> lst[l] &lt; lst[r] <span class="keyword">else</span> (lst[r], r)</span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            <span class="keyword">if</span> lst[l] &lt; curr_min:</span><br><span class="line">                curr_min = lst[l]</span><br><span class="line">                index = l</span><br><span class="line">            <span class="keyword">if</span> lst[r] &lt; curr_min:</span><br><span class="line">                curr_min = lst[r]</span><br><span class="line">                index = r</span><br><span class="line">            </span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">            r -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> index</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst)):</span><br><span class="line">        min_index = find_min(i)</span><br><span class="line">        val = lst[i]</span><br><span class="line">        lst[i] = lst[min_index]</span><br><span class="line">        lst[min_index] = val</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="quick-sort">Quick Sort</h2>
<p>Quicksort uses divide and conquer to sort an array. Divide and conquer is a technique used for breaking algorithms down into subproblems, solving the subproblems, and then combining the results back together to solve the original problem. It can be helpful to think of this method as divide, conquer, and combine. Divide:</p>
<ol type="1">
<li>Pick a pivot element, A[q].</li>
<li>Partition, or rearrange, the array into two subarrays: A[p,…,q−1] such that all elements are less than A[q], and A[q+1,…,r] such that all elements are greater than or equal to A[q].</li>
<li>Conquer: Sort the subarrays A[p,…,q−1] and A[q+1,…,r] recursively with quicksort.</li>
<li>Combine: No work is needed to combine the arrays because they are already sorted.</li>
</ol>
<p>Here is a recursive algorithm for quicksort:</p>
<ol type="1">
<li>If the list is empty, return the list and terminate. (Base case)</li>
<li>Choose a pivot element in the list.</li>
<li>Take all of the elements that are less than or equal to the pivot and use quicksort on them. (skip pivot, otherwise [5, 5, 5] will not reach base case)</li>
<li>Take all of the elements that are greater than the pivot and use quicksort on them.</li>
<li>Return the concatenation of the quicksorted list of elements that are less than or equal to the pivot, the pivot, and the quicksorted list of elements that are greater than the pivot.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">lst</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(lst) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> lst</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        mid = <span class="built_in">len</span>(lst) // <span class="number">2</span></span><br><span class="line">        small_lst = []</span><br><span class="line">        large_lst = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst)):</span><br><span class="line">            <span class="keyword">if</span> i != mid:</span><br><span class="line">                <span class="keyword">if</span> lst[i] &gt;= lst[mid]:</span><br><span class="line">                    large_lst.append(lst[i])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    small_lst.append(lst[i])</span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">        left_lst = quick_sort(small_lst)</span><br><span class="line">        right_lst = quick_sort(large_lst)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> left_lst + [lst[mid]] + right_lst</span><br></pre></td></tr></table></figure>
<h2 id="heap-sort">Heap Sort</h2>
<p>Recall that, a root of the max heap is the maximum item in the array <span class="math inline">\(A[1 ... A.heap\_size]\)</span>. if we do a <code>build_max_heap</code> on entire <span class="math inline">\(A\)</span>, swap <span class="math inline">\(A[1]\)</span> with <span class="math inline">\(A[n]\)</span> and then do a <code>max_heapify(A[1 ... n - 1], i)</code>, we end up with a sorted array.</p>
<p>For more detail please see <a href="/2021/07/19/heaps/" title="Heaps">Heaps</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span>(<span class="params">A</span>):</span></span><br><span class="line">    build_max_heap(A)</span><br><span class="line">    <span class="keyword">while</span> A.heap_size &gt;= <span class="number">2</span>:</span><br><span class="line">        A[<span class="number">0</span>], A[heap_size - <span class="number">1</span>] = A[heap_size - <span class="number">1</span>], A[<span class="number">0</span>]</span><br><span class="line">        A.heap_size = A.heap_size - <span class="number">1</span></span><br><span class="line">        max_heapify(A, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<p>https://lamfo-unb.github.io/2019/04/21/Sorting-algorithms/</p>
<p>https://brilliant.org/wiki/sorting-algorithms/#sorting-algorithms</p>
]]></content>
      <categories>
        <category>CS Basics</category>
      </categories>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>Temporal Difference Learning</title>
    <url>/2021/05/15/td/</url>
    <content><![CDATA[<h1 id="learning-from-stream-of-data-temporal-difference-learning-methods">Learning From Stream of Data (Temporal Difference Learning Methods)</h1>
<p>We can see that from MC algorithm, in order to update <span class="math inline">\(\hat{Q^{\pi}}_{k+1} (x, a)\)</span>, we need to calculate the entire <span class="math inline">\(\hat{G^{\pi}_{k}}\)</span> which involves sum over product of rewards. If each episode is long or even continuous, the calculation of <span class="math inline">\(\hat{G^{\pi}_{k}}\)</span> will be hard or impossible. In general, MC is agnostic to the MDP structure, if the problem is an MDP, it does not benefit from the recursive property of the value functions.</p>
<p>TD methods benefit from the structure of the MDP even if we do not know the environment dynamics <span class="math inline">\(P\)</span> and <span class="math inline">\(R\)</span>.</p>
<h2 id="td-for-policy-evaluation">TD for Policy Evaluation</h2>
<p>We first focus on VI for PE: at each state <span class="math inline">\(x\)</span>, the procedure is:</p>
<p><span class="math display">\[V_{k+1} (x) = T^{\pi} V_{k} (x) = r^{\pi} (x) + \gamma \int P(dx^{\prime} | x, a) \pi(da | x) V_{k} (x^{\prime})\]</span></p>
<p>If we do not know <span class="math inline">\(r^{\pi}, P\)</span>, we cannot compute this. Suppose that we have n samples starting from state <span class="math inline">\(x\)</span>, <span class="math inline">\(A_i \sim \pi(\cdot | x), X^{\prime}_i \sim P(\cdot | x, A_i), R_i \sim R(\cdot | x, A_i)\)</span>, using these samples and <span class="math inline">\(V_{k}\)</span>, we compute:</p>
<p><span class="math display">\[Y_i = R_i + \gamma V_{k} (X_i^{\prime})\]</span></p>
<p>Now, notice that:</p>
<p><span class="math display">\[E[R_i | X=x] = r^{\pi} (x)\]</span></p>
<p>and</p>
<p><span class="math display">\[E[V_{k} (X^{\prime}_i) | X=x] = \int P(dx^{\prime} | x, a) \pi(da | x)V_{k} (x^{\prime})\]</span></p>
<p>so the r.v $Y_i (x) $ (emphasis starting from state <span class="math inline">\(x\)</span> )satisfies:</p>
<p><span class="math display">\[E[Y_i | X=x] = E[R_i + \gamma V_{k} (X_i^{\prime}) | X=x] = E[R_i | X=x] + \gamma E[V_{k} (X_i^{\prime}) | X=x] = T^{\pi} V_{k} (x)\]</span></p>
<p>This implies that <span class="math inline">\(Y_i\)</span> is an unbiased estimator of <span class="math inline">\(T^{\pi} V_{k}\)</span> evaluated at <span class="math inline">\(x\)</span>. Thus, we can use a sample mean of <span class="math inline">\(Y_i\)</span> starting from <span class="math inline">\(x\)</span> to estimate <span class="math inline">\(T^{\pi} V_k (x)\)</span>, or we can use SA procedure.</p>
<p><span class="math display">\[T^{\pi}V^{t+1}_{k} (x) \leftarrow  (1 - \alpha_t) T^{\pi}V^{t}_{k} (x) + \alpha Y_i\]</span></p>
<span id="more"></span>
<h3 id="empirical-bellman-operator">Empirical Bellman Operator</h3>
<p>This <span class="math inline">\(Y_i\)</span> is called <code>empirical Bellman operator</code> (this (x) notation emphasises that we are starting from x):</p>
<p><span class="math display">\[\hat{T}^{\pi} V_{k} (x) = Y_i (x) = R(x) + \gamma V_{k} (X^{\prime} (x))\]</span></p>
<p>This operator is an unbiased estimate of <span class="math inline">\(T^{\pi} V_{k} (x)\)</span>:</p>
<p><span class="math display">\[E[\hat{T}^{\pi} V_k (X) | X=x] = T^{\pi} V_{k} (x)\]</span></p>
<p>The empirical version of the VI for Policy evaluation with some noise:</p>
<p><span class="math display">\[V_{k+1} (x) \leftarrow \hat{T}^{\pi} V_k (x) = \underbrace{T^{\pi} V_{k} (x)}_{\text{deterministic part}} + \underbrace{(\hat{T}^{\pi} V_k (x) - T^{\pi} V_{k} (x))}_{\text{the stochastic part, the noise}}\]</span></p>
<p>On average, this noise is 0.</p>
<h2 id="generic-td-algorithms">Generic TD algorithms</h2>
<p>A synchronous version of generic TD algorithm updates all states at the same time:</p>
<p><img src="/images/RL/mc/td_1.png"></p>
<p>However, we do not need to update all states at the same time, an asynchronous version of generic TD algorithm:</p>
<p><img src="/images/RL/mc/td_2.png"></p>
<p>From the above generic algorithms, we can see that the update following policy <span class="math inline">\(\pi\)</span> in general is :</p>
<span class="math display">\[\begin{aligned}
V_{t+1} (x) &amp;\leftarrow (1 - \alpha_t) V_t (x) + \alpha_t (\hat{T}^{\pi} V_t (x)) \\
&amp;\leftarrow (1 - \alpha_t) V_t (x) + \alpha_t (R(x) + \gamma V_t (X^{\prime} (x)))\\
&amp;\leftarrow V_t (x) + \alpha_t (x) [R_t (x) + \gamma V_t(X^{\prime} (x)) - V_t (x)]
\end{aligned}\]</span>
<p>The update rule could be written in perhaps a simpler but less precise, form of:</p>
<p><span class="math display">\[V(X_t) \leftarrow V(X_t) + \alpha_t (X_t) [R_t + \gamma V(X_{t+1}) - V(X_t)]\]</span></p>
<p>We can see that, at each time step, instead update <span class="math inline">\(V_{k+1} (x)\)</span> with <span class="math inline">\(T^{\pi} V_{k}\)</span>, we update it with the <code>empirical bellman operator</code> <span class="math inline">\(\hat{T}^{\pi} V_k\)</span> which is an unbiased estimate. The SA procedure seems a little strange because we are estimating the mean of a sequence of <span class="math inline">\(\hat{T}^{\pi} V_1, \hat{T}^{\pi} V_2, ...\)</span>, <strong>we will prove later that this update rule actually converge to <span class="math inline">\(V^{\pi}\)</span></strong>.</p>
<h3 id="td-error">TD Error</h3>
<h4 id="td-erorr-and-bellman-residual">TD Erorr and Bellman Residual</h4>
<p>Moreover, the term:</p>
<p><span class="math display">\[\delta_t = R_t + \gamma V(X_{t+1}) - V(X_t)\]</span></p>
<p>is called <code>TD error</code>. It is a noisy measure of how close we are to <span class="math inline">\(V^{\pi}\)</span>. To see this more clearly, let us define the dependence on the <code>TD error</code> on its components more explicitly. Given transitions <span class="math inline">\((X, X^{\prime}, R)\)</span> and value function <span class="math inline">\(V\)</span>, policy <span class="math inline">\(\pi\)</span>, we define:</p>
<p><span class="math display">\[\delta (R, X^{\prime}, X; V, \pi) = R + \gamma V(X^{\prime}) - V(X)\]</span></p>
<p>We have:</p>
<p><span class="math display">\[E[\delta (X, R, X^{\prime}; V, \pi) | X=x] = T^{\pi} V (x) - V(x) = BR(V) (x)\]</span></p>
<p>So in expectation, the TD error is equal to the Bellman residual of <span class="math inline">\(V\)</span>, evaluated at state <span class="math inline">\(x\)</span>. If BR = 0, we reach the fix point, so the algorithm reach the fix point.</p>
<h4 id="td-erorr-and-advantage">TD Erorr and Advantage</h4>
<p>The advantage function is defined as:</p>
<p><span class="math display">\[A^{\pi}(x, a) = Q^{\pi} (x, a) - V^{\pi} (x)\]</span></p>
<p>In expectation:</p>
<span class="math display">\[\begin{aligned}
E[\delta (X, R, X^{\prime}; V^{\pi}) | X=x, A=a] &amp;= E[R + \gamma V^{\pi}(X^{\prime}) - V^{\pi}(X) | X=x, A=a]\\
&amp;= r(x, a) + \gamma \int_{x^{\prime}, a^{\prime}} P(x^{\prime} | x, a) \pi(a^{\prime} | x^{\prime})Q^{\pi} (x^{\prime}, a^{\prime}) - V^{\pi}(x)\\
&amp;= Q^{\pi} (x, a) - V^{\pi} (x)
\end{aligned}\]</span>
<p>Thus, the <strong>true</strong> TD error is an unbiased estimator of the advantage function.</p>
<h3 id="td-learning-for-action-value-function">TD Learning for Action-Value Function</h3>
<p>We can use a similar procedure to estimate the action-value function which is often used in TD and MC.</p>
<p>To evaluate <span class="math inline">\(\pi\)</span>, we need to have an estimate of <span class="math inline">\(T^{\pi} Q (x, a) \forall (x, a) \in X \times A\)</span>.</p>
<p>Suppose that <span class="math inline">\((X_t, A_t) \sim \mu\)</span> (where <span class="math inline">\(\mu\)</span> is some stationary distribution or initial distribution) and <span class="math inline">\(X^{\prime}_t \sim P(\cdot | X_t, A_t)\)</span> and <span class="math inline">\(R_t \sim R(\cdot | X_t, A_t), A^{\prime} \sim \pi(\cdot | X^{\prime})\)</span></p>
<p>The update rule would be:</p>
<p><span class="math display">\[Q_{t+1} (X_t, A_t) \leftarrow Q_t(X_t, A_t) + \alpha_t (X_t, A_t) [R_t + \gamma Q_t (X^{\prime}_t, A^{\prime}) - Q_t(X_t, A_t)]\]</span></p>
<p>and</p>
<p><span class="math display">\[Q_{t+1} (x, a) \leftarrow Q_t (x, a)\]</span></p>
<p>for all other <span class="math inline">\((x, a) \neq (X_t, A_t)\)</span></p>
<p>It is easy to see that following the same procedure for <span class="math inline">\(\hat{T}^{\pi} V\)</span>:</p>
<p><span class="math display">\[E[\hat{T}^{\pi} Q (X_t, A_t) | X_t=x, A_t=a] = T^{\pi} Q (x, a)\]</span></p>
<h1 id="further">Further</h1>
<p>In this post, we have some basic understanding of generic TD methods and basic framework of TD Policy evaluation. Next, we will explore some popular TD methods for solving control problems. We will see that TD learning methods can be generalized to both on-policy sampling scenario (ie. SARSA) and off-policy sampling scenario (ie. Q-learning). At the same time, we will prove the update rule for each algorithm.</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>TD</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>Tabular Methods</tag>
        <tag>TD</tag>
      </tags>
  </entry>
  <entry>
    <title>Rigorous Probability (1)</title>
    <url>/2022/03/10/rigorous-probability-1/</url>
    <content><![CDATA[<h1 id="rigorous-probability-1">Rigorous Probability (1)</h1>
<h2 id="preliminaries">Preliminaries</h2>
<p>For <span class="math inline">\(x, y \in \mathbb{\bar{R}} := \mathbb{R} \cup \{-\infty, \infty\}\)</span>, we agree on the following notation:</p>
<ol type="1">
<li><span class="math inline">\(x \vee y = \max (x, y)\)</span></li>
<li><span class="math inline">\(x \wedge y = \min(x, y)\)</span></li>
<li><span class="math inline">\(x^+ = \max(x, 0)\)</span></li>
<li><span class="math inline">\(x^- = \max(-x, 0)\)</span></li>
<li><span class="math inline">\(|x| = \max(x, -x) = x^- + x^+\)</span></li>
<li><span class="math inline">\(sign(x) = I_{x &gt; 0} - I_{x &lt; 0}\)</span></li>
</ol>
<h3 id="class-of-sets">Class of Sets</h3>
<p>Let <span class="math inline">\(\Omega \neq \emptyset\)</span>, let <span class="math inline">\(\mathbf{A} \subseteq 2^{\Omega}\)</span> (set of all possible subsets of <span class="math inline">\(\Omega\)</span>) be a class of subsets of <span class="math inline">\(\Omega\)</span>.</p>
<h4 id="definition-1.1-cap-closed-sigma-cap-closed-cup-closed-sigma-cup-closed--closed-ac-closed">Definition 1.1: <span class="math inline">\(\cap\)</span>-closed, <span class="math inline">\(\sigma-\cap\)</span>-closed, <span class="math inline">\(\cup\)</span>-closed, <span class="math inline">\(\sigma-\cup\)</span>-closed, <span class="math inline">\(/\)</span>-closed, <span class="math inline">\(A^c\)</span>-closed</h4>
<p>A class of sets <span class="math inline">\(\mathbf{A} \in 2^{\Omega}\)</span> is called:</p>
<ul>
<li><span class="math inline">\(\cap\)</span>-closed (<strong>closed under intersections</strong>) or <strong><span class="math inline">\(\pi\)</span>-system</strong> if <span class="math inline">\(A \cap B \in \mathbf{A}\)</span>, whenever <span class="math inline">\(A, B \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\sigma-\cap-\)</span>closed (<strong>closed under countable intersections</strong>) if <span class="math inline">\(\bigcap^{\infty}_{n=1}A_n \in \mathbf{A}\)</span> for any choice of countably (finite or countably infinite) many sets <span class="math inline">\(A_1, A_2, ...., \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\cup-\)</span>closed (<strong>closed under unions</strong>) if <span class="math inline">\(A \cup B \in \mathbf{A}\)</span>, whenever <span class="math inline">\(A, B \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\sigma-\cup-\)</span>closed (<strong>closed under countable unions</strong>) if <span class="math inline">\(\bigcup^{\infty}_{n=1}A_n \in \mathbf{A}\)</span> for any choice of countably (finite or countably infinite) many sets <span class="math inline">\(A_1, A_2, ...., \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(/-\)</span>closed (<strong>closed under differences</strong>) if <span class="math inline">\(A / B \in \mathbf{A}\)</span>, whenever <span class="math inline">\(A, B \in \mathbf{A}\)</span>.</li>
<li><strong>closed under complements</strong> if <span class="math inline">\(A^c := \Omega / A \in A\)</span> for any set <span class="math inline">\(A \in \mathbf{A}\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-1.2-sigma-algebra">Definition 1.2: <span class="math inline">\(\sigma-\)</span>algebra</h4>
<p>A class of sets <span class="math inline">\(A \subseteq 2\)</span> is called a <span class="math inline">\(\sigma\)</span>-algebra if it fulfills the following three properties:</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is closed under complements.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is closed under countable unions.</li>
</ol>
<p>If <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\sigma\)</span>-algebra, we also have:</p>
<ul>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\cup\)</span>-closed <span class="math inline">\(\Longleftrightarrow\)</span> <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\cap\)</span>-closed.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\sigma-\cup\)</span>-closed <span class="math inline">\(\Longleftrightarrow\)</span> <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\sigma-\cap\)</span>-closed</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is closed under differences</li>
<li>Any countable union of sets in <span class="math inline">\(\mathbf{A}\)</span> cna be expressed as a countable disjoint union of sets in <span class="math inline">\(\mathbf{A}\)</span></li>
</ul>
<p><br></p>
<h4 id="definition-1.6-algebra">Definition 1.6: Algebra</h4>
<p>A class of sets <span class="math inline">\(\mathbf{A} \subseteq 2^{\pi}\)</span> is called an <strong>algebra</strong> if the following three conditions are fulfilled:</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(/\)</span>-closed.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\cup\)</span>-closed.</li>
</ol>
<p>If <span class="math inline">\(\mathbf{A}\)</span> is Algebra, we also have:</p>
<ol type="1">
<li><span class="math inline">\(\mathbf{A}\)</span> is closed under complements.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is closed under intersections.</li>
</ol>
<p><br></p>
<span id="more"></span>
<h4 id="definition-1.8-ring">Definition 1.8: Ring</h4>
<p>A class of sets <span class="math inline">\(\mathbf{A} \in 2^{\Omega}\)</span> is called a <strong>ring</strong> if the following three conditions hold:</p>
<ol type="1">
<li><span class="math inline">\(\emptyset \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(/\)</span>-closed.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\cup\)</span>-closed.</li>
</ol>
<p>A ring is called <span class="math inline">\(\sigma\)</span>-ring if it is also <span class="math inline">\(\sigma-\cup\)</span>-closed.</p>
<p><br></p>
<h4 id="definition-1.9-semiring">Definition 1.9: Semiring</h4>
<p>A class of sets <span class="math inline">\(\mathbf{A} \subseteq 2^\Omega\)</span> is called a <strong>semiring</strong> if</p>
<ol type="1">
<li><span class="math inline">\(\emptyset \in \mathbf{A}\)</span>.</li>
<li>for any two sets <span class="math inline">\(A, B \in \mathbf{A}\)</span>, <span class="math inline">\(B / A\)</span> is a finite union of mutually disjoint sets in <span class="math inline">\(\mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\cap\)</span>-closed.</li>
</ol>
<p><br></p>
<h4 id="definition-1.10-lambda-system">Definition 1.10: <span class="math inline">\(\lambda\)</span>-system</h4>
<p>A class of sets <span class="math inline">\(\mathbf{A} \subseteq 2^\Omega\)</span> is called a <span class="math inline">\(\lambda\)</span>-system if:</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathbf{A}\)</span>.</li>
<li>For any two sets <span class="math inline">\(A, B \in \mathbf{A}\)</span> with <span class="math inline">\(A \subseteq B\)</span>, the difference set <span class="math inline">\(B / A \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\uplus^{\infty}_{n=1} A_n \in A\)</span> for any choice of countably many pairwise disjoint sets <span class="math inline">\(A_1, A_2, .... \in \mathbf{A}\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-1.12-relations-between-classes-of-sets">Theorem 1.12: Relations Between Classes of Sets</h4>
<ol type="1">
<li>Every <span class="math inline">\(\sigma\)</span>-algebra is also a <span class="math inline">\(\lambda\)</span>-system, an algebra, and a <span class="math inline">\(\sigma\)</span>-ring.</li>
<li>Every <span class="math inline">\(\sigma\)</span>-ring is a ring, and every ring is a semiring.</li>
<li>Every algebra is a ring. An algebra on a finite set <span class="math inline">\(\Omega\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra.</li>
</ol>
<p><br></p>
<h4 id="definition-1.13-limit-inferior-and-limit-superior-of-sequence-and-sets">Definition 1.13: Limit Inferior and Limit Superior of Sequence and Sets</h4>
<p>The <strong>limit inferior</strong> of a sequence <span class="math inline">\((a_n)\)</span> is defined as:</p>
<p><span class="math display">\[\lim\inf_n a_n = \lim_{n \rightarrow \infty} \inf_{k \geq n} a_n\]</span></p>
<p>and the <strong>limit superior</strong> of the sequence is defined as:</p>
<p><span class="math display">\[\lim\sup_n a_n = \lim_{n \rightarrow \infty} \inf_{k \geq n} a_n\]</span></p>
<p>Furthermore, <span class="math inline">\(\lim_n a_n\)</span> exists IFF <span class="math inline">\(\lim\sup_n a_n = \lim \inf_n a_n\)</span></p>
<p>Given subsets <span class="math inline">\(A_1, A_2, ... \in 2^{\Omega}\)</span>, we define <strong>infinitely many</strong>:</p>
<p><span class="math display">\[A^* := \lim\sup_n A_n = \lim_{n \rightarrow \infty} \bigcup^{\infty}_{k=n} A_n = \bigcap^{\infty}_{n=1}\bigcup^{\infty}_{k=n} A_k\]</span></p>
<p><span class="math display">\[w \in \bigcap^{\infty}_{n=1}\bigcup^{\infty}_{k=n} A_k \implies \forall N \geq 1, \exists k \geq N \text{ s.t } w \in A_n\]</span></p>
<p>This is equivalently saying that:</p>
<p><span class="math display">\[\{x: \text{ $x$ in infinitely many $A_n$}\}\]</span></p>
<p>and <strong>almost always</strong>:</p>
<p><span class="math display">\[A_* := \lim\inf_n A_n = \lim_{n \rightarrow \infty} \bigcap^{\infty}_{k=n} A_n = \bigcup^{\infty}_{n=1}\bigcap^{\infty}_{k=n} A_k\]</span></p>
<p><span class="math display">\[w \in \bigcup^{\infty}_{n=1}\bigcap^{\infty}_{k=n} A_k \implies \exists N \geq 1, \text{ s.t } \forall k \geq N, w \in A_n\]</span></p>
<p>This is equivalently saying that:</p>
<p><span class="math display">\[\{x: \text{ $x$ in all $A_n$ except for finitely many $n$}\}\]</span></p>
<p><br></p>
<h4 id="theorem-1.15-intersection-of-classes-of-sets">Theorem 1.15: Intersection of Classes of Sets</h4>
<p>Let <span class="math inline">\(I\)</span> be an arbitrary index set, and assume that <span class="math inline">\(A_i\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra for every <span class="math inline">\(i \in I\)</span>. Hece the intersection:</p>
<p><span class="math display">\[A_I := \{A \subseteq \Omega: A \in A_i \; \forall i \in I\} = \bigcap_{i \in I}A_i\]</span></p>
<p>is a <span class="math inline">\(\sigma\)</span>-algebra. The analogous statement holds for rings, <span class="math inline">\(\sigma\)</span>-rings, algebras and <span class="math inline">\(\lambda\)</span>-systems, but fails for semirings.</p>
<p><br></p>
<h4 id="theorem-1.16-generated-sigma-algebra">Theorem 1.16: Generated <span class="math inline">\(\sigma\)</span>-algebra</h4>
<p>Let <span class="math inline">\(\epsilon \subseteq 2^\Omega\)</span>. Then, there exists a smallest <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\(\sigma(\epsilon)\)</span> with <span class="math inline">\(\epsilon \subseteq \sigma(\epsilon)\)</span></p>
<p><span class="math display">\[\sigma(\epsilon) := \bigcap_{A \subseteq 2^{\Omega} \text{ is a $\sigma$-algebra and } A \supseteq \epsilon$} A\]</span></p>
<p><span class="math inline">\(\sigma(\epsilon)\)</span> is called the <span class="math inline">\(\sigma\)</span>-algebra generated by <span class="math inline">\(\epsilon\)</span>. <span class="math inline">\(\epsilon\)</span> is called the generator of <span class="math inline">\(\sigma(\epsilon)\)</span>. Similarly, we define <span class="math inline">\(\delta(\epsilon)\)</span> as the <span class="math inline">\(\lambda\)</span>-system generated by <span class="math inline">\(\epsilon\)</span>.</p>
<p>Furthermore, <strong>the following three statements hold:</strong></p>
<ol type="1">
<li><span class="math inline">\(\epsilon \subseteq \sigma(\epsilon)\)</span>.</li>
<li>If <span class="math inline">\(\epsilon_1 \subseteq \epsilon_2\)</span>, then <span class="math inline">\(\sigma(\epsilon_1) \subseteq \sigma(\epsilon_2)\)</span>.</li>
<li><span class="math inline">\(A\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra IFF <span class="math inline">\(\sigma(A) = A\)</span>.</li>
</ol>
<p>The same holds for <span class="math inline">\(\lambda\)</span>-systems, and <span class="math inline">\(\delta(\epsilon) \subseteq \sigma(\epsilon)\)</span>.</p>
<h5 id="proof-of-theorem-1.16">Proof of Theorem 1.16:</h5>
<p>Since <span class="math inline">\(\Omega\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra, so <span class="math inline">\(\sigma(\epsilon)\)</span> is non-empty, since the intersection of all <span class="math inline">\(\sigma\)</span>-algebra is also <span class="math inline">\(\sigma\)</span>-algebra, so it is the smallest that containing <span class="math inline">\(\epsilon\)</span>.</p>
<p><br></p>
<h4 id="theorem-1.18-cap-closed-lambda-system">Theorem 1.18: <span class="math inline">\(\cap\)</span>-closed <span class="math inline">\(\lambda\)</span>-system</h4>
<p>Let <span class="math inline">\(D \subseteq 2^\Omega\)</span> be a <span class="math inline">\(\lambda\)</span>-system. Then:</p>
<p><span class="math display">\[D \text{ is a $\pi$-system } \Longleftrightarrow D \text{ is $\sigma$-algebra}\]</span></p>
<h4 id="theorem-1.19-dynkins-pi-lambda-theorem">Theorem 1.19: Dynkin's <span class="math inline">\(\pi-\lambda\)</span> Theorem</h4>
<p>If <span class="math inline">\(\epsilon \subseteq 2^\Omega\)</span> is a <span class="math inline">\(\pi\)</span>-system, then:</p>
<p><span class="math display">\[\sigma(\epsilon) = \delta(\epsilon)\]</span></p>
<p><br></p>
<p><img src='/images/RL/background/pt_1_1_1.png' width="600"></p>
<p><br></p>
<h4 id="theorem-1.20-topology">Theorem 1.20: Topology</h4>
<p>Let <span class="math inline">\(\Omega \neq \emptyset\)</span> be an arbitrary set. A class of sets <span class="math inline">\(\tau \subseteq 2^\Omega\)</span> is called a <strong>topology</strong> on <span class="math inline">\(\Omega\)</span> if it has the following three properties:</p>
<ol type="1">
<li><span class="math inline">\(\emptyset, \Omega \in \tau\)</span>.</li>
<li><span class="math inline">\(A \cap B \in \tau\)</span> for any <span class="math inline">\(A, B \in \tau\)</span>.</li>
<li><span class="math inline">\((\bigcup_{A \in F} A) \in \tau\)</span> for any <span class="math inline">\(F \subseteq \tau\)</span></li>
</ol>
<p>The pair <span class="math inline">\((\Omega, \tau)\)</span> is called <strong>topological space</strong>. The sets <span class="math inline">\(A \in \tau\)</span> are called <strong>open</strong>, and the sets <span class="math inline">\(A \subseteq \Omega\)</span> with <span class="math inline">\(A^c \in \tau\)</span> are called <strong>closed</strong>.</p>
<h4 id="definition-1.21-borel-sigma-algebra">Definition 1.21: Borel <span class="math inline">\(\sigma\)</span>-algebra</h4>
<p>Let <span class="math inline">\((\Omega, \tau)\)</span> be a topological space. The <span class="math inline">\(\sigma\)</span>-algebra:</p>
<p><span class="math display">\[B(\Omega) := B(\Omega, \tau) := \sigma(\tau)\]</span></p>
<p>that is generated by the open subsets of <span class="math inline">\(\Omega\)</span> is called the <strong>Borel <span class="math inline">\(\sigma\)</span>-algebra</strong> on <span class="math inline">\(\Omega\)</span>. The elements <span class="math inline">\(A \in B(\Omega, \tau)\)</span> are called <strong>Borel sets</strong> or <span class="math inline">\(Borel measurable sets\)</span>.</p>
<p><br></p>
<h4 id="theorem-1.22-the-tail-of-convergent-series-trends-to-zero">Theorem 1.22: The Tail of Convergent Series Trends to Zero</h4>
<p>Let <span class="math inline">\((a_n)\)</span> be a sequence of real numbers. Let <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> be a convergent series and <span class="math inline">\(N \in \mathbb{Z}^+\)</span> be a positive integer, then:</p>
<p><span class="math display">\[\lim_{N \rightarrow \infty} \sum^{\infty}_{n=N} a_n = 0\]</span></p>
<p><br></p>
<h4 id="definition-1.25-trace-of-a-class-of-sets">Definition 1.25: Trace of a Class of Sets</h4>
<p>Let <span class="math inline">\(\mathbf{A} \subseteq 2^\Omega\)</span> be an arbitrary class of subsets of <span class="math inline">\(\Omega\)</span> and let <span class="math inline">\(A \in 2^\Omega / \emptyset\)</span>. The class:</p>
<p><span class="math display">\[\mathbf{A}|_A := \{A \cap B: B \in \mathbf{A}\} \subseteq 2^A\]</span></p>
<p>is called the <strong>trace</strong> of <span class="math inline">\(\mathbf{A}\)</span> on <span class="math inline">\(A\)</span> or the <strong>restriction</strong> of <span class="math inline">\(\mathbf{A}\)</span> to <span class="math inline">\(A\)</span>.</p>
<p><br></p>
<h3 id="set-functions">Set Functions</h3>
<h4 id="definition-1.27-types-of-set-functions">Definition 1.27: Types of Set Functions</h4>
<p>Let <span class="math inline">\(\mathbf{A} \subseteq 2^{\Omega}\)</span> and let <span class="math inline">\(\mu: \mathbf{A} \rightarrow [0, \infty]\)</span> be a set function. We say that <span class="math inline">\(\mu\)</span> is:</p>
<ol type="1">
<li><strong>monotone</strong> if <span class="math inline">\(\mu(A) \leq \mu(B)\)</span> for any two sets <span class="math inline">\(A, B \in \mathbf{A}\)</span> with <span class="math inline">\(A \subseteq B\)</span>.</li>
<li><strong>additive</strong> if <span class="math inline">\(\mu(\uplus^n_{i=1} A_i) = \sum^n_{=1} \mu(A_i)\)</span> for any choice of finitely many mutually disjoint sets <span class="math inline">\(A_1, ...., A_n \in \mathbf{A}\)</span>.</li>
<li><strong><span class="math inline">\(\sigma\)</span>-additive</strong> if <span class="math inline">\(\mu(\uplus^\infty_{i=1} A_i) = \sum^\infty_{i=1} \mu(A_i)\)</span> for any choice of countably many mutually disjoint sets <span class="math inline">\(A_1, A_2, .... \in \mathbf{A}\)</span> with <span class="math inline">\(\bigcup^{\infty}_{i=1} A_i \in \mathbf{A}\)</span>.</li>
<li><strong>subadditive</strong> if for any choice of finitely many sets <span class="math inline">\(A, A_1, A_2, ...., A_n \in \mathbf{A}\)</span> with <span class="math inline">\(A \subseteq \bigcup^{n}_{i=1} A_i\)</span>, we have <span class="math inline">\(\mu(A) \leq \sum^n_{i=1} \mu(A_i)\)</span>.</li>
<li><strong><span class="math inline">\(\sigma\)</span>-subadditive</strong> if for any choice of countably many sets <span class="math inline">\(A, A_1, A_2, .... \in \mathbf{A}\)</span> with <span class="math inline">\(A \subseteq \bigcup^{\infty}_{i=1} A_i\)</span>, we have <span class="math inline">\(\mu(A) \leq \sum^\infty_{i=1} \mu(A_i)\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-1.28-types-of-set-functions-on-semiring">Definition 1.28: Types of Set Functions on Semiring</h4>
<p>Let <span class="math inline">\(\mathbf{A}\)</span> be a semiring and let <span class="math inline">\(\mu: \mathbf{A} \rightarrow [0, \infty]\)</span> be a set function with <span class="math inline">\(\mu(\emptyset) = 0\)</span>. <span class="math inline">\(\mu\)</span> is called a:</p>
<ul>
<li><strong>content</strong> if <span class="math inline">\(\mu\)</span> is additive.</li>
<li><strong>premeasure</strong> if <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\sigma\)</span>-additive.</li>
<li><strong>measure</strong> if <span class="math inline">\(\mu\)</span> is a premeasure and <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\sigma\)</span>-algebra, and</li>
<li><strong>probability measure</strong> if <span class="math inline">\(\mu\)</span> is a measure and <span class="math inline">\(\mu(\Omega) = 1\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-1.29-finite-sigma-finite-measures">Definition 1.29: Finite, <span class="math inline">\(\sigma\)</span>-finite measures</h4>
<p>Let <span class="math inline">\(\mathbf{A}\)</span> be a semiring. A content <span class="math inline">\(\mu\)</span> is called:</p>
<ol type="1">
<li><strong>finite</strong> if <span class="math inline">\(\mu(A) &lt; \infty\)</span> for every <span class="math inline">\(A \in \mathbf{A}\)</span> and</li>
<li><strong><span class="math inline">\(\sigma\)</span>-finite</strong> if <span class="math inline">\(\exists (A)_i \in \mathbf{A}\)</span> s.t <span class="math inline">\(\Omega = \bigcup^\infty_{i=1} A_i\)</span> and such that <span class="math inline">\(\mu(A_i) &lt; \infty\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>.</li>
</ol>
<p><br></p>
<h4 id="lemma-1.31-properties-of-content">Lemma 1.31: Properties of Content</h4>
<p>Let <span class="math inline">\(\mathbf{A}\)</span> be a semiring and let <span class="math inline">\(\mu\)</span> be a content on <span class="math inline">\(\mathbf{A}\)</span>. Then the following statements hold:</p>
<ol type="1">
<li>If <span class="math inline">\(\mathbf{A}\)</span> is a ring, then <span class="math inline">\(\mu(A \cup B) + \mu(A \cap B) = \mu(A) + \mu(B)\)</span> for any two sets <span class="math inline">\(A, B \in \mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is monotone, moreover if <span class="math inline">\(\mathbf{A}\)</span> is a ring, then <span class="math inline">\(\mu(B) = \mu(A) + \mu(B / A)\)</span> for any two sets <span class="math inline">\(A, B \in \mathbf{A}\)</span> with <span class="math inline">\(A \subseteq B\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is subadditive, moreover if <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\sigma\)</span>-additive, then <span class="math inline">\(\mu\)</span> is also <span class="math inline">\(\sigma\)</span>-subadditive.</li>
<li>If <span class="math inline">\(\mathbf{A}\)</span> is a ring, then <span class="math inline">\(\sum^\infty_{n=1} \mu(A_n) \leq \mu(\bigcup^\infty_{n=1} A_n)\)</span> for any choice of countably many mutually disjoint sets <span class="math inline">\(A_1, A_2, .... \in \mathbf{A}\)</span> with <span class="math inline">\(\bigcup^\infty_{n=1}A_n \in \mathbf{A}\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-1.34-increasing-decreasing">Definition 1.34: Increasing, Decreasing</h4>
<p>Let <span class="math inline">\(A, A_1, ....\)</span> be sets. We write:</p>
<ul>
<li><span class="math inline">\(A_n \uparrow A\)</span> and say that <span class="math inline">\((A_n)_{n \in \mathbb{N}}\)</span> <strong>increases</strong> to <span class="math inline">\(A\)</span> if <span class="math inline">\(A_1 \subseteq A_2 \subseteq ...., \; \bigcup^\infty_{n=1}A_n = A\)</span>.</li>
<li><span class="math inline">\(A_n \downarrow A\)</span> and say that <span class="math inline">\((A_n)_{n \in \mathbb{N}}\)</span> <strong>decrease</strong> to <span class="math inline">\(A\)</span> if <span class="math inline">\(A_1 \supseteq A_2 \supseteq ...., \; \bigcap^\infty_{n=1}A_n = A\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-1.35-continuity-of-contents">Definition 1.35: Continuity of Contents</h4>
<p>Let <span class="math inline">\(\mu\)</span> be a content on the ring <span class="math inline">\(\mathbf{A}\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\mu\)</span> is called <strong>lower semicontinuous</strong> if <span class="math inline">\(\mu(A_n) \rightarrow_{n \rightarrow \infty} \mu(A)\)</span> for any <span class="math inline">\(A \in \mathbf{A}\)</span> and any sequence <span class="math inline">\((A_n) \in \mathbf{A}\)</span> with <span class="math inline">\(A_n \uparrow A\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is called <strong>upper semicontinuous</strong> if <span class="math inline">\(\mu(A_n) \rightarrow_{n \rightarrow \infty} \mu(A)\)</span> for any <span class="math inline">\(A \in \mathbf{A}\)</span> any sequence <span class="math inline">\((A_n) \in \mathbf{A}\)</span> with <span class="math inline">\(\mu(A_n) &lt; \infty\)</span> for some <span class="math inline">\(n \in \mathbf{N}\)</span> and <span class="math inline">\(A_n \downarrow A\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is called <strong><span class="math inline">\(\emptyset\)</span>-continuous</strong> if (2) holds for <span class="math inline">\(A = \emptyset\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-1.38-measurable-space-measurable-sets-discrete-events">Theorem 1.38: Measurable Space, Measurable Sets, Discrete, Events</h4>
<ol type="1">
<li>A pair <span class="math inline">\((\Omega, \mathbf{A})\)</span> consisting of nonempty set <span class="math inline">\(\Omega\)</span> and <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\(\mathbf{A} \subseteq 2^\Omega\)</span> is called a <strong>measurable space</strong>. The sets <span class="math inline">\(A \in \mathbf{A}\)</span> are called <strong>measurable sets</strong>. If <span class="math inline">\(\Omega\)</span> is at most countable infinite and if <span class="math inline">\(\mathbf{A} = 2^\Omega\)</span>, then the measurable space is called <strong>discrete</strong>.</li>
<li>A triple <span class="math inline">\((\Omega, \mathbf{A}, \mu)\)</span> is called <strong>measure space</strong> if <span class="math inline">\((\Omega, \mathbf{A})\)</span> is a measurable space and <span class="math inline">\(\mu\)</span> is a measure on <span class="math inline">\(\mathbf{A}\)</span>.</li>
<li>If in addition <span class="math inline">\(\mu(\Omega) = 1\)</span>, then <span class="math inline">\((\Omega, \mathbf{A}, \mu)\)</span> is called a <strong>probability space</strong>. In this case, sets <span class="math inline">\(A \in \mathbf{A}\)</span> are called <strong>events</strong>.</li>
<li>The set of all finite measures on <span class="math inline">\((\Omega, \mathbf{A})\)</span> is denoted by <span class="math inline">\(M_f(\Omega) := M_f((\Omega, \mathbf{A}))\)</span>, probability measures is denoted by <span class="math inline">\(M_1(\Omega) := M_1((\Omega, \mathbf{A}))\)</span>, the set of <span class="math inline">\(\sigma\)</span>-finite measures is denoted <span class="math inline">\(M_\sigma(\Omega):= M_\sigma((\Omega, \mathbf{A}))\)</span>.</li>
</ol>
<p><br></p>
<h3 id="the-measure-extension-theorem">The Measure Extension Theorem</h3>
<p>We can construct measures <span class="math inline">\(\mu\)</span> on <span class="math inline">\(\sigma\)</span>-algebra by first define the values of <span class="math inline">\(\mu\)</span> on a smaller class of sets, that is, on semiring. Under a mild consistency condition, the resulting set function can be extended to the whole <span class="math inline">\(\sigma\)</span>-algebra.</p>
<h4 id="theorem-1.41-caratheodorys-measure-extension-theorem">Theorem 1.41: Caratheodory's Measure Extension Theorem</h4>
<p>Let <span class="math inline">\(\mathbf{A} \subseteq 2^\Omega\)</span> be a ring and let <span class="math inline">\(\mu\)</span> be a <span class="math inline">\(\sigma\)</span>-finite <strong>premeasure</strong> on <span class="math inline">\(\mathbf{A}\)</span>. There exists a unique measure <span class="math inline">\(\tilde{\mu}\)</span> on <span class="math inline">\(\sigma(\mathbf{A})\)</span> s.t <span class="math inline">\(\tilde{\mu}(A) = \mu(A)\)</span> for all <span class="math inline">\(A \in \mathbf{A}\)</span>. Furthermore, <span class="math inline">\(\tilde{\mu}\)</span> is <span class="math inline">\(\sigma\)</span>-finite.</p>
<p><br></p>
<h4 id="theorem-1.53-extension-theorem-for-measures">Theorem 1.53: Extension Theorem For Measures</h4>
<p>Let <span class="math inline">\(\mathbf{A}\)</span> be a semiring and let <span class="math inline">\(\mu: \mathbf{A} \rightarrow [0, \infty]\)</span> be an additive, <span class="math inline">\(\sigma-\)</span>subadditive and <span class="math inline">\(\sigma\)</span>-finite set function with <span class="math inline">\(\mu(\emptyset) = 0\)</span>. Then there is a unique <span class="math inline">\(\sigma\)</span>-finite measure <span class="math inline">\(\tilde{\mu}: \sigma(\mathbf{A}) \rightarrow [0, \infty]\)</span> s.t <span class="math inline">\(\tilde{\mu}(A) = \mu(A)\)</span> for all <span class="math inline">\(A \in \mathbf{A}\)</span>.</p>
<p><br></p>
<h4 id="definition-1.59-distribution-function">Definition 1.59: Distribution Function</h4>
<p>A right continuous monotone increasing function <span class="math inline">\(F: \mathbb{R} \rightarrow [0, 1]\)</span> with:</p>
<ul>
<li><span class="math inline">\(F(-\infty) := \lim_{x \rightarrow -\infty} F(x) = 0\)</span></li>
<li><span class="math inline">\(F(\infty) := \lim_{x \rightarrow \infty} F(x) = 1\)</span></li>
</ul>
<p>is called a <strong>proper probability distribution function</strong>, if we only have <span class="math inline">\(F(\infty) \leq 1\)</span> instead of <span class="math inline">\(F(\infty) = 1\)</span>, then <span class="math inline">\(F\)</span> is called a <strong>defective</strong> probability distribution function. If <span class="math inline">\(\mu\)</span> is a probability measure on <span class="math inline">\((\mathbb{R}, B(\mathbb{R}))\)</span>, then <span class="math inline">\(F_\mu: x \mapsto \mu((-\infty, x])\)</span> is called the <strong>distribution function</strong> of <span class="math inline">\(\mu\)</span>.</p>
<p><br></p>
<h4 id="definition-1.57-lebesgue-stieltjes-measure">Definition 1.57: Lebesgue-Stieltjes Measure</h4>
<p>The measure <span class="math inline">\(\mu_F\)</span> on <span class="math inline">\((\mathbb{R}, B(\mathbb{R}))\)</span> defined by:</p>
<p><span class="math display">\[\mu_F((a, b]) = F(b) - F(a), \; \forall a, b \in \mathbb{R}, a &lt; b\]</span></p>
<p>is called the <strong>Lebesgue-Stieltjes measure</strong> with distribution function <span class="math inline">\(F\)</span>.</p>
<p>If <span class="math inline">\(\lim_{x \rightarrow \infty} (F(x) - F(-x)) = 1\)</span>, then <span class="math inline">\(\mu_F\)</span> is a probability measure.</p>
<p>Associated with each <span class="math inline">\(F\)</span>, there is a <strong>unique</strong> measure <span class="math inline">\(\mu\)</span> on <span class="math inline">\((\mathbb{R}, B(\mathbb{R}))\)</span> with <span class="math inline">\(\mu_F((a, b]) = F(b) - F(a)\)</span>.</p>
<p><br></p>
<h4 id="definition-1.58-distribution-functions-in-mathbbrd">Definition 1.58: Distribution Functions in <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>Let <span class="math inline">\(A := (a_1, b_1] \times ... \times (a_d, b_d]\)</span> be a finite rectangle (<span class="math inline">\(-\infty &lt; a_i &lt; b_i &lt; \infty\)</span>). Let <span class="math inline">\(V := \{a_1, b_1\} \times .... \times \{a_d, b_d\}\)</span> be a set of vertices of the rectangle <span class="math inline">\(A\)</span>. If <span class="math inline">\(v \in V\)</span>, let: <span class="math display">\[sign(v) = (-1)^{\text{number of $a$&#39;s in $v$}}\]</span> <span class="math display">\[\Delta_A F = \sum_{v \in V} sign(v) F(v)\]</span> <span class="math display">\[\mu(A) = \Delta_A F\]</span></p>
<p>Let <span class="math inline">\(F: \mathbb{R}^d \rightarrow [0, 1]\)</span> be a function that satisfies:</p>
<ol type="1">
<li>Nondecreasing: <span class="math inline">\(x \leq y (x_i \leq y_i \;\forall i) \implies F(x) \leq F(y)\)</span>.</li>
<li><span class="math inline">\(F\)</span> is right continuous: <span class="math inline">\(\lim_{y \rightarrow x^+} F(y) = F(x) (y \rightarrow x^+ \implies y_i \rightarrow x_i^+ \;\forall i)\)</span>.</li>
<li>If <span class="math inline">\(x_n \rightarrow -\infty \;\forall n \implies F(x) = 0\)</span>. If <span class="math inline">\(x_n \rightarrow \infty \;\forall n \implies F(x) = 1\)</span>.</li>
<li><span class="math inline">\(\Delta_A F \geq 0\)</span> for all finite measurable rectangles <span class="math inline">\(A\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-1.59-lebesgue-stieltjes-measure-in-mathbbrd">Theorem 1.59: Lebesgue-Stieltjes Measure in <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>Suppose <span class="math inline">\(F: \mathbb{R}^d \rightarrow [0, 1]\)</span> satisfies all conditions above. Then there is a unique probability measure <span class="math inline">\(\mu\)</span> on <span class="math inline">\((\mathbb{R}^d, B(\mathbb{R}^d))\)</span> so that <span class="math inline">\(\mu(A) = \Delta_A F\)</span> for all finite measurable rectangles.</p>
<p><br></p>
<h4 id="theorem-1.60-every-finite-measure-on-mathbbr-bmathbbr-is-a-lebesgue-stieltjes-measure">Theorem 1.60: Every Finite Measure on <span class="math inline">\((\mathbb{R}, B(\mathbb{R}))\)</span> is a Lebesgue Stieltjes Measure</h4>
<p>The map <span class="math inline">\(\mu \mapsto F_\mu\)</span> is a bijection from the set of probability measures on <span class="math inline">\((\mathbb{R}, B(\mathbb{R}))\)</span> to the set of probability distribution functions.</p>
<p><br></p>
<h4 id="theorem-1.61-finite-products-of-measures">Theorem 1.61: Finite Products of Measures</h4>
<p>Let <span class="math inline">\(n \in \mathbb{N}\)</span> and let <span class="math inline">\(\mu_1, ...., \mu_n\)</span> be finite measures or more generally Lebesgue-Stieltjes measures on <span class="math inline">\((\mathbb{R}, B(\mathbb{R}))\)</span>. Then there exists a unique <span class="math inline">\(\sigma\)</span>-finite measure <span class="math inline">\(\mu\)</span> on <span class="math inline">\((\mathbb{R}^n, B(\mathbb{R}^n))\)</span> s.t:</p>
<p><span class="math display">\[\mu((a, b]) = \prod^n_{i=1} \mu_i ((a_i, b_i]), \; \forall a, b \in \mathbb{R^n}, a &lt; b\]</span></p>
<p>We call <span class="math inline">\(\mu := \otimes^n_{i=1} \mu_i\)</span> the <strong>product measure of the measures <span class="math inline">\(\mu_1, ...., \mu_n\)</span></strong>.</p>
<p><br></p>
<h4 id="theorem-1.64-product-measure-bernoulli-measure">Theorem 1.64: Product Measure, Bernoulli Measure</h4>
<p>Let <span class="math inline">\(E\)</span> be a finite nonempty set (possible outcomes), and <span class="math inline">\(\Omega = E^\mathbb{N}\)</span> (space of <span class="math inline">\(E\)</span>-valued sequence, infinite repeats of the experiment). Let <span class="math inline">\((p_e)_{e \in E}\)</span> be a probability vector. Then there exists a unique probability measure <span class="math inline">\(\mu\)</span> on <span class="math inline">\(\sigma (\mathbf{A}) = B(\Omega)\)</span> s.t:</p>
<p><span class="math display">\[\mu([\omega_1, ...., \omega_n]) = \prod^n_{i=1} p_{\omega_i} \quad \forall \omega_1, ..., \omega_n \in E, n \in \mathbb{N}\]</span></p>
<p><span class="math inline">\(\mu\)</span> is called the <strong>product measure or Bernoulli measure on <span class="math inline">\(\Omega\)</span></strong> with weights <span class="math inline">\((p_e)_{e \in E}\)</span>, we write:</p>
<p><span class="math display">\[(\sum_{e \in E} p_e \delta_e)^{otimes \mathbb{N}} := \mu\]</span></p>
<p>The <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\((2^E)^{\otimes \mathbb{N}} := \sigma(\mathbf{A})\)</span> is called the product <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\Omega\)</span>.</p>
<p><br></p>
<h4 id="section"></h4>
<h3 id="measurable-maps">Measurable Maps</h3>
<p>A major task of mathematics is to study homomorphisms between objects; that is, structure-preserving maps. For topological spaces, these are the continuous maps, and for measurable spaces, these are the measurable maps.</p>
<p>We assume <span class="math inline">\((\Omega, \mathbf{A}), (\Omega^\prime, \mathbf{A}^\prime)\)</span> are two measurable spaces.</p>
<h4 id="definition-1.76-measurable-maps">Definition 1.76: Measurable Maps</h4>
<ol type="1">
<li><p>A map <span class="math inline">\(X: \Omega \rightarrow \Omega^\prime\)</span> is called <span class="math inline">\(\mathbf{A}-\mathbf{A}^\prime\)</span> measurable or <strong>measurable (from one measurable space to another measurable space)</strong> if <span class="math inline">\(X^{-1} (\mathbf{A}^\prime) := \{X^{-1} (A^{\prime}): A^{\prime} \in \mathbf{A}\} \subseteq \mathbf{A}\)</span>. That is, if: <span class="math display">\[X^{-1}(A^\prime) \in \mathbf{A}, \; \forall A^\prime \in \mathbf{A}^\prime\]</span></p>
<p>If <span class="math inline">\(X\)</span> is measurable, we write <span class="math inline">\(X: (\Omega, \mathbf{A}) \rightarrow (\Omega^\prime, \mathbf{A}^\prime)\)</span></p></li>
<li><p>If <span class="math inline">\(\Omega^\prime = \mathbb{R}\)</span> and <span class="math inline">\(A^\prime = B(\mathbb{R})\)</span> is the Borel <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span>, then <span class="math inline">\(X: (\Omega, \mathbf{A}) \rightarrow (\mathbb{R}, B(\mathbb{R}))\)</span> is called an <span class="math inline">\(\mathbf{A}\)</span> measurable real map. For example <span class="math inline">\(X\)</span> is measurable if: <span class="math display">\[X^{-1}(B) \subseteq \mathbf{A}, \; \forall B \in B(\mathbb{R})\]</span></p></li>
</ol>
<p><br></p>
<h4 id="theorem-1.78-generated-sigma-algebra-by-a-function">Theorem 1.78: Generated <span class="math inline">\(\sigma\)</span>-algebra by a function</h4>
<p>Let <span class="math inline">\(((\Omega^\prime, \mathbf{A}^\prime)\)</span> be a measurable space and let <span class="math inline">\(\Omega\)</span> be a nonempty set. Let <span class="math inline">\(X: \Omega \rightarrow \Omega^\prime\)</span> be a map. The preimage:</p>
<p><span class="math display">\[X^{-1}(\mathbf{A}^\prime) := \{X^{-1} (A^\prime): A^\prime \in \mathbf{A}^\prime\}\]</span></p>
<p>is the smallest <span class="math inline">\(\sigma\)</span>-algebra with respect to which <span class="math inline">\(X\)</span> is measurable. We say that <span class="math inline">\(\sigma(X) := X^{-1} (\mathbf{A}^\prime)\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\Omega\)</span> that is generated by <span class="math inline">\(X\)</span>.</p>
<p><br></p>
<h4 id="definition-1.79-generated-sigma-algebra-by-more-than-one-functions">Definition 1.79: Generated <span class="math inline">\(\sigma\)</span>-algebra by more than one functions</h4>
<p>Let <span class="math inline">\(\Omega\)</span> be a nonempty set. Let <span class="math inline">\(I\)</span> be an arbitrary index set. For any <span class="math inline">\(i \in I\)</span>, let <span class="math inline">\((\Omega_i, \mathbf{A}_i)\)</span> be a measurable space and let <span class="math inline">\(X_i:\Omega \rightarrow \mathbf{A}_i\)</span> be an arbitrary map, then:</p>
<p><span class="math display">\[\sigma(X_i, i\in I) := \sigma(\bigcup_{i\in I} \sigma(X_i))) = \sigma(\bigcup_{i\in I} X^{-1}_i (\mathbf{A}_i))\]</span></p>
<p>is called the <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\Omega\)</span> that is <strong>generated</strong> by <span class="math inline">\((X_i, i \in I)\)</span>. This is the smallest <span class="math inline">\(\sigma\)</span>-algebra w.r.t which all <span class="math inline">\(X_i\)</span> are measurable.</p>
<p><br></p>
<h4 id="theorem-1.80-composition-of-maps">Theorem 1.80: Composition of Maps</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A}), (\Omega^\prime, \mathbf{A}^\prime), (\Omega^{\prime\prime}, \mathbf{A}^{\prime\prime})\)</span> be measurable spaces and let <span class="math inline">\(X: \Omega \rightarrow \Omega^\prime\)</span> and <span class="math inline">\(X^\prime: \Omega^\prime \rightarrow \Omega^{\prime\prime}\)</span> be measurable maps. Then the map:</p>
<p><span class="math display">\[Y := X^\prime \circ X: \Omega \rightarrow \Omega^{\prime\prime}\]</span></p>
<p>is <span class="math inline">\(\mathbf{A}-\mathbf{A}^{\prime\prime}\)</span> measurable.</p>
<p><br></p>
<h4 id="theorem-1.81-measurability-on-a-generator">Theorem 1.81: Measurability on a Generator</h4>
<p>Let <span class="math inline">\(\varepsilon^\prime \subseteq \mathbf{A}^\prime\)</span> be a class of <span class="math inline">\(\mathbf{A}^\prime\)</span>-measurable sets. Then <span class="math inline">\(\sigma(X^{-1}(\varepsilon^\prime)) = X^{-1} (\sigma(\varepsilon^\prime))\)</span> and hence:</p>
<p><span class="math display">\[X \text{ is $\mathbf{A}-\sigma(\varepsilon^\prime)$ measurable} \Longleftrightarrow X^{-1} (E^\prime) \in \mathbf{A} \;\; \forall E^\prime \in \varepsilon^\prime\]</span></p>
<p>If in particular <span class="math inline">\(\sigma(\varepsilon^\prime) = \mathbf{A}^\prime\)</span>, then:</p>
<p><span class="math display">\[X \text{ is $\mathbf{A}-\mathbf{A}^\prime$-measurable}  \Longleftrightarrow X^{-1} (\varepsilon^\prime) \subseteq \mathbf{A}\]</span></p>
<p><br></p>
<h4 id="corollary-1.83-trace-of-a-generated-sigma-algebra">Corollary 1.83: Trace of a Generated <span class="math inline">\(\sigma\)</span>-algebra</h4>
<p>Let <span class="math inline">\(\varepsilon \subseteq 2^\Omega\)</span> and assume that <span class="math inline">\(A \subseteq \Omega\)</span> is non-empty. Then <span class="math inline">\(\sigma(\varepsilon|_A) = \sigma(\epsilon)|_A\)</span>.</p>
<p><br></p>
<h4 id="theorem-1.88-measurability-of-continuous-maps">Theorem 1.88: Measurability of Continuous Maps</h4>
<p>Let <span class="math inline">\((\Omega, \tau)\)</span> and <span class="math inline">\((\Omega^\prime, \tau^\prime)\)</span> be topological spaces and let <span class="math inline">\(f: \Omega \rightarrow \Omega^\prime\)</span> be a continuous map. Then <span class="math inline">\(f\)</span> is <span class="math inline">\(B(\Omega)-B(\Omega^\prime)\)</span>-measurable.</p>
<p><br></p>
<h4 id="theorem-1.89-measurability-of-mathbbr-mathbbbarr-maps">Theorem 1.89: Measurability of <span class="math inline">\(\mathbb{R}, \mathbb{\bar{R}}\)</span> Maps</h4>
<p>If <span class="math inline">\(X\)</span> is a real or <span class="math inline">\(\mathbb{\bar{R}}-\)</span>valued measurable map, then the maps <span class="math inline">\(X^-, X^+\)</span>, <span class="math inline">\(|X|\)</span> and <span class="math inline">\(sign(X)\)</span> also are measurable.</p>
<p><br></p>
<h4 id="theorem-1.90-coordinate-maps-are-measurable">Theorem 1.90: Coordinate Maps are Measurable</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A})\)</span> be a measurable space and let <span class="math inline">\(f_1, ...., f_n : \Omega \rightarrow \mathbb{R}\)</span> be maps. Define <span class="math inline">\(f := (f_1, ...., f_n): \Omega \rightarrow \mathbb{R}^n\)</span>. Then:</p>
<p><span class="math display">\[f \text{ is $\mathbf{A}-B(\mathbb{R^n})$-measurable}\]</span></p>
<p>IFF</p>
<p><span class="math display">\[\text{each $f_i$ is $\mathbf{A}-B(\mathbb{R^n})$-measurable}\]</span></p>
<p>The analogous statement holds for <span class="math inline">\(f_i: \Omega \rightarrow \bar{\mathbb{R}}\)</span></p>
<p><br></p>
<h4 id="theorem-1.92-measurability-of-inf-sup-liminf-limsup">Theorem 1.92: Measurability of <span class="math inline">\(\inf, \sup, \lim\inf, \lim\sup\)</span></h4>
<p>Let <span class="math inline">\(X_1, ...\)</span> be measurable maps <span class="math inline">\((\Omega, \mathbf{A}) \rightarrow (\bar{\mathbb{R}}, B(\bar{\mathbb{R}}))\)</span>. Then the following maps are also measurable:</p>
<p><span class="math display">\[g(x) := \inf_n X_n(x) \quad g(x) := \sup_n X_n (x) \quad g(x) := \lim\inf_n X_n (x) \quad g(x) := \lim\sup_n X_n\]</span></p>
<p><br></p>
<h4 id="definition-1.93-simple-functions">Definition 1.93: Simple Functions</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A})\)</span> be a measurable space. A map <span class="math inline">\(f: \Omega \rightarrow \mathbb{R}\)</span> is called a <strong>simple function</strong> if there is an <span class="math inline">\(n \in \mathbb{N}\)</span> and mutually disjoint measurable sets <span class="math inline">\(A_1, ...., A_n \in \mathbf{A}\)</span>, as well as numbers <span class="math inline">\(\alpha_1, ..., \alpha_n \in \mathbb{R}\)</span>, s.t:</p>
<p><span class="math display">\[f = \sum^n_{i=1} \alpha_i I_{A_i}\]</span></p>
<p><br></p>
<h4 id="definition-1.98-image-measure">Definition 1.98: Image Measure</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A})\)</span> and <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime)\)</span> be measurable spaces and let <span class="math inline">\(\mu\)</span> be a measure on <span class="math inline">\((\Omega, \mathbf{A})\)</span>. Further, let <span class="math inline">\(X: \Omega \rightarrow \Omega^\prime\)</span> be a measurable map. The <strong>image measure</strong> of <span class="math inline">\(\mu\)</span> under the map <span class="math inline">\(X\)</span> is the measure <span class="math inline">\(\mu \circ X^{-1}\)</span> on <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime)\)</span> that is defined by:</p>
<p><span class="math display">\[\mu \circ X^{-1}: \mathbf{A}^\prime \rightarrow [0, \infty]\]</span></p>
<p><span class="math display">\[A^\prime \mapsto \mu(X^{-1}(A^\prime))\]</span></p>
<p><br></p>
<h4 id="definition-1.102-random-variables">Definition 1.102: Random Variables</h4>
<p>Let <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime)\)</span> be a measurable space and let <span class="math inline">\(X: \Omega \rightarrow \Omega^\prime\)</span> be measurable:</p>
<ol type="1">
<li><span class="math inline">\(X\)</span> is called a <strong>random variable</strong> with values in <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime)\)</span>. If <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime) = (\mathbb{R}, B(\mathbb{R}))\)</span>, then <span class="math inline">\(X\)</span> is called a <strong>real random variable or simply a random variable</strong>.</li>
<li>For <span class="math inline">\(A^\prime \in \mathbf{A}^\prime\)</span>, we denote <span class="math inline">\(\{X \in A^\prime\} := X^{-1}(A^\prime)\)</span> and <span class="math inline">\(P(X \in A^\prime) := P(X^{-1}(A^\prime))\)</span>. In particular, we let <span class="math inline">\(\{X \geq 0\} := X^{-1}([0, \infty))\)</span> and define <span class="math inline">\(\{X \leq b\}\)</span> similarly and so on.</li>
<li>If <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime) = (\mathbb{R}^d, B(\mathbb{R}^d))\)</span> and <span class="math inline">\(d &gt; 1\)</span>, then <span class="math inline">\(X\)</span> is called a <strong>random vector</strong>.</li>
</ol>
<p><br></p>
<h4 id="definition-1.103-distributions">Definition 1.103: Distributions</h4>
<p>Let <span class="math inline">\(X\)</span> be a random variable:</p>
<ol type="1">
<li>The probability measure <span class="math inline">\(P_X := P \circ X^{-1}\)</span> is called the <strong>distribution</strong> of <span class="math inline">\(X\)</span>.</li>
<li>For a real random variable <span class="math inline">\(X\)</span>, the map <span class="math inline">\(F_X: x \mapsto P(X \leq x)\)</span> is called the <strong>distribution function</strong> of <span class="math inline">\(X\)</span> or more precisely <span class="math inline">\(P_X\)</span>. We write <span class="math inline">\(X \sim \mu\)</span> if <span class="math inline">\(\mu = P_X\)</span> and say that <span class="math inline">\(X\)</span> has distribution <span class="math inline">\(\mu\)</span>. The distribution function of <span class="math inline">\(X\)</span> has several properties:
<ul>
<li><span class="math inline">\(F\)</span> is non-decreasing.</li>
<li><span class="math inline">\(\lim_{x \rightarrow \infty} F(x) = 1\)</span>, <span class="math inline">\(\lim_{x \rightarrow -\infty} F(x) = 0\)</span>.</li>
<li><span class="math inline">\(F\)</span> is right continuous: <span class="math inline">\(\lim_{y \rightarrow x^+} F(y) = F(x)\)</span>.</li>
<li>If <span class="math inline">\(F(x^-) := \lim_{y \rightarrow x^-} F(y)\)</span>, then <span class="math inline">\(F(x^-) = P(X &lt; x)\)</span>.</li>
<li><span class="math inline">\(P(X = x) = F(x) - F(x^-)\)</span>.</li>
</ul></li>
<li>A family <span class="math inline">\((X_i)_{i \in I}\)</span> of random variables is called <strong>identically distributed</strong> if <span class="math inline">\(P_{X_i} = P_{X_j} \; \forall i, j \in I\)</span>, we write <span class="math inline">\(X \overset{D}{=} Y\)</span> if <span class="math inline">\(P_{X} = P_{Y}\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-1.104-every-distribution-function-associates-a-random-variable">Theorem 1.104: Every Distribution Function Associates a Random Variable</h4>
<p>For any distribution function <span class="math inline">\(F\)</span>, there exists a real random variable <span class="math inline">\(X\)</span> with <span class="math inline">\(F_X = F\)</span>.</p>
<p><br></p>
<h4 id="definition-1.106-density">Definition 1.106: Density</h4>
<p>If the distribution function <span class="math inline">\(F: \mathbb{R}^n \rightarrow [0, 1]\)</span> is of the form:</p>
<p><span class="math display">\[F(x) = \int^{x_1}_{-\infty} \int^{x_n}_{-\infty} f(t_1, ...., t_n) d(t_1, ...., t_n)\]</span></p>
<p>for <span class="math inline">\(x = (x_1, ...., x_n) \in \mathbb{R}^n\)</span></p>
<p>for some integrable function <span class="math inline">\(f: \mathbb{R}^n \rightarrow [0, \infty)\)</span>, then <span class="math inline">\(f\)</span> is called the <strong>density</strong> of the distribution.</p>
<p><br></p>
<h4 id="definition-1.107-almost-surely">Definition 1.107: Almost Surely</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A}, P)\)</span> be a probability space, Let <span class="math inline">\(F \subseteq \mathbf{A}\)</span> be an event. If <span class="math inline">\(P(F^c) = 0\)</span>, then <span class="math inline">\(F\)</span> is said to happen almost surely.</p>
<p><br></p>
<h4 id="definition-1.108-almost-sure-equality-of-random-variables">Definition 1.108: Almost Sure Equality of Random Variables</h4>
<p>Two jointly random variables <span class="math inline">\(X, Y\)</span> are said to be <strong>equal almost surely</strong>, or equal with probability <span class="math inline">\(1\)</span>, designated as <span class="math inline">\(X = Y\)</span> a.s IFF:</p>
<p><span class="math display">\[P(\{\omega \in \Omega: X(\omega) \neq Y(\omega)\}) = 0\]</span></p>
<p>It can be shown that <span class="math inline">\(X = Y\)</span> a.s IFF the events <span class="math inline">\(X^{-1}(B)\)</span> and <span class="math inline">\(Y^{-1}(B)\)</span> are equal almost surely for each Borel set <span class="math inline">\(B \in B(\mathbb{R})\)</span>.</p>
<h3 id="integration">Integration</h3>
<p>Notations for special cases:</p>
<ul>
<li><span class="math inline">\((\mathbb{R}^d, B(\mathbb{R}^d), \lambda)\)</span>, we write <span class="math inline">\(\int f d\lambda\)</span> as: <span class="math display">\[\int f(x) dx\]</span></li>
<li><span class="math inline">\((\mathbb{R}, B(\mathbb{R}), \lambda), E = [a, b]\)</span>, we write <span class="math inline">\(\int_E f d\lambda\)</span> as: <span class="math display">\[\int^b_a f(x) dx\]</span></li>
<li><span class="math inline">\((\mathbb{R}, B(\mathbb{R}), \mu)\)</span> with <span class="math inline">\(\mu((a, b]) = G(b) - G(a)\)</span>, we write <span class="math inline">\(\int f d\mu\)</span> as: <span class="math display">\[\int f(x) dG(x)\]</span></li>
<li>When <span class="math inline">\(\Omega\)</span> is countable, <span class="math inline">\(\mathbf{F} = 2^\Omega\)</span> and <span class="math inline">\(\mu\)</span> is the counting measure, we write <span class="math inline">\(\int f d\mu\)</span> as: <span class="math display">\[\sum_{i \in \Omega} f(i)\]</span></li>
</ul>
<h4 id="theorem-1.5.1-jensens-inequality">Theorem 1.5.1: Jensen's Inequality</h4>
<p>Suppose <span class="math inline">\(\varphi\)</span> is <strong>convex</strong>, that is:</p>
<p><span class="math display">\[\lambda \varphi(x) + (1 + \lambda) \varphi(y) \geq \varphi(\lambda x + (1 - \lambda)y)\]</span></p>
<p>for all <span class="math inline">\(\lambda \in (0, 1)\)</span> and <span class="math inline">\(x, y \in \mathbb{R}\)</span>. If <span class="math inline">\(\mu\)</span> is a probability measure, and <span class="math inline">\(f, \varphi(f)\)</span> are integrable then:</p>
<p><span class="math display">\[\varphi(\int f d\mu) \leq \int \varphi(f) d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-1.5.2-fatous-lemma">Theorem 1.5.2: Fatou's Lemma</h4>
<p>If <span class="math inline">\(f_n \geq 0\)</span>, then:</p>
<p><span class="math display">\[\lim\inf_n \int f_n d\mu \geq \int (\lim\inf_n) d\mu\]</span></p>
<p><br></p>
<h3 id="independence">Independence</h3>
<h4 id="definition-2.3-independence-of-events">Definition 2.3: Independence of Events</h4>
<p>Let <span class="math inline">\(I\)</span> be an arbitrary index set and let <span class="math inline">\((A_i)_{i \in I}\)</span> be an arbitrary family of events. The family <span class="math inline">\((A_i)_{i\in I}\)</span> is called <strong>independent</strong> if for any finite subset <span class="math inline">\(J \subseteq I\)</span> the product formula holds:</p>
<p><span class="math display">\[P(\bigcap_{j \in J} A_n) = \prod_{j \in J} P(A_j)\]</span></p>
<p><br></p>
<h4 id="definition-2.7-borel-cantlli-lemma">Definition 2.7: Borel-Cantlli Lemma</h4>
<p>Let <span class="math inline">\(A_1, A_2, ...\)</span> be events and define <span class="math inline">\(A^* = \lim\sup_{n} A_n\)</span>:</p>
<ol type="1">
<li>If <span class="math inline">\(\sum^\infty_{n=1} P(A_n) &lt; \infty\)</span>, then <span class="math inline">\(P(A^*) = 0\)</span>. (Here <span class="math inline">\(P\)</span> could be an arbitrary measure on <span class="math inline">\((\Omega, \mathbf{A})\)</span>).</li>
<li>If <span class="math inline">\((A_n)_{n \in \mathbb{N}}\)</span> is independent <span class="math inline">\(\sum^\infty_{n=1} P(A_n) = \infty\)</span>, then <span class="math inline">\(P(A^*) = 1\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-2.11-independence-of-classes-of-events">Definition 2.11: Independence of Classes of Events</h4>
<p>Let <span class="math inline">\(I\)</span> be an arbitrary index set and let <span class="math inline">\(\varepsilon_i \subseteq \mathbf{A} \; \forall i \in I\)</span>. The family <span class="math inline">\((\varepsilon_i)_{i \in I}\)</span> is called <strong>independent</strong> if, for any finite subset <span class="math inline">\(J \in I\)</span> and any choice of <span class="math inline">\(E_j \in \varepsilon_j, \; j \in J\)</span>, we have:</p>
<p><span class="math display">\[P(\bigcap_{j \in J} E_j) = \prod_{j \in J} P(E_j)\]</span></p>
<p>In other words, all events are independent across all classes in the family.</p>
<p><br></p>
<h4 id="definition-2.14-independent-random-variables">Definition 2.14: Independent Random Variables</h4>
<p>Let <span class="math inline">\(I\)</span> ba an arbitrary index set, for each <span class="math inline">\(i \in I\)</span>, let <span class="math inline">\((\Omega_i, \mathbf{A}_i)\)</span> be a measurable space and let <span class="math inline">\(X_i: (\Omega, \mathbf{A}) \rightarrow (\Omega_i, \mathbf{A}_i)\)</span> be a random variable.</p>
<p>The family <span class="math inline">\((X_i)_{i \in I}\)</span> of random variables is called <strong>independent</strong> if the family <span class="math inline">\((\sigma(X_i))_{i \in I}\)</span> of <span class="math inline">\(\sigma\)</span>-algebras is independent.</p>
<p>We say that the family <span class="math inline">\((X_i)_{i \in I}\)</span> is <strong>independent and identically distributed (i.i.d)</strong> if it is independent and <span class="math inline">\(P_{X_i} = P_{X_j}, \; \forall i, j \in I\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.16-independent-generators">Theorem 2.16: Independent Generators</h4>
<p>For any <span class="math inline">\(i \in I\)</span>, let <span class="math inline">\(\varepsilon_i \subseteq \mathbf{A}_i\)</span> be a <span class="math inline">\(\pi-\)</span>system that generates <span class="math inline">\(\mathbf{A}_i\)</span>. If <span class="math inline">\((X^{-1}_i (\varepsilon_i))_{i \in I}\)</span> is independent, then <span class="math inline">\((X_i)_{i \in I}\)</span> is independent.</p>
<p><br></p>
<h4 id="definition-2.20-joint-distribution">Definition 2.20: Joint Distribution</h4>
<p>For any <span class="math inline">\(i \in I\)</span>, let <span class="math inline">\(X_i\)</span> be a real random variable. For any finite subset <span class="math inline">\(J \in I\)</span>, let</p>
<p><span class="math display">\[F_J := F_{(X_j)_{j \in J}}: \mathbb{R}^j \rightarrow [0, 1], \quad x \mapsto P(X_j \leq x_j \; \forall j \in J) = P(\bigcap_{j \in J} X^{-1}_j ((-\infty, x_j]))\]</span></p>
<p>Then <span class="math inline">\(F_j\)</span> is called the <strong>joint distribution function</strong> of <span class="math inline">\((X_j)_{j \in J}\)</span>. The probability measure <span class="math inline">\(P_{(X_j)_{j \in J}}\)</span> on <span class="math inline">\(\mathbb{R}^J\)</span> is called the <strong>joint distribution</strong> of <span class="math inline">\((X_j)_{j \in J}\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.21-independent-family-of-random-variables">Theorem 2.21: Independent Family of Random Variables</h4>
<p>A family of real random variable <span class="math inline">\(\{X_i\}_{i \in I}\)</span> is <strong>independent</strong> if and only if, for every finite <span class="math inline">\(J \subseteq I\)</span> and every <span class="math inline">\(x = (x_j)_{j \in J} \in \mathbb{R}^J\)</span>:</p>
<p><span class="math display">\[F_J (x) = \prod_{j \in J} F_{j} (x_j)\]</span></p>
<p><br></p>
<h4 id="theorem-2.22-independent-family-of-continuous-random-variables">Theorem 2.22: Independent Family of Continuous Random Variables</h4>
<p>In addition to the assumptions of Theorem 2.21, we assume that any <span class="math inline">\(F_j\)</span> has continuous density <span class="math inline">\(f_j = f_{(X_j)_{j \in J}}\)</span> (The joint density of <span class="math inline">\((X_j)_{j \in J}\)</span>). That is, there exists a continuous map <span class="math inline">\(f_J: \mathbb{R}^J \rightarrow [0, \infty)\)</span> s.t:</p>
<p><span class="math display">\[F_J (x) = \int^{x_{j_1}}_{-\infty} .... \int^{x_{j_n}}_{-\infty} f_J(t_1, ..., t_n) d(t_1, ...., t_n), \quad \forall x \in \mathbb{R}^J\]</span></p>
<p>Where <span class="math inline">\(J = \{j_1, ..., j_n\}\)</span>. In this case, the family <span class="math inline">\((X_i)_{i in I}\)</span> is independent if and only if, for any finite <span class="math inline">\(J \subseteq I\)</span>:</p>
<p><span class="math display">\[f_J (x) = \prod_{j \in J} f_j (x_j) \; \forall x \in \mathbb{R}^J\]</span></p>
<p><br></p>
<h3 id="generating-functions">Generating Functions</h3>
<h4 id="definition-3.1-probability-generating-function">Definition 3.1: Probability Generating Function</h4>
<p>Let <span class="math inline">\(X\)</span> be an <span class="math inline">\(\mathbb{N}_0\)</span>-valued random variable (natural number with 0, 0^0 = 1). The <strong>probability generating function</strong> of <span class="math inline">\(P_X\)</span> is the map <span class="math inline">\(\psi_{P_X} = \psi_{X}\)</span> defined by:</p>
<p><span class="math display">\[\psi _X: [0, 1] \rightarrow [0, 1], \; z \mapsto \sum^\infty_{n=0} P(X = n)z^n\]</span></p>
<p><br></p>
<h4 id="theorem-3.2-properties-of-pgf">Theorem 3.2: Properties of PGF</h4>
<ol type="1">
<li><span class="math inline">\(\psi_X\)</span> is <strong>continuous</strong> on <span class="math inline">\([0, 1]\)</span> and infinitly often continuously differentiable on <span class="math inline">\((0, 1)\)</span>. For <span class="math inline">\(n \in \mathbb{N}\)</span>, the nth derivative <span class="math inline">\(\psi^{(n)}_X\)</span> fulfills: <span class="math display">\[\lim_{z \rightarrow 1-} \psi^{(n)}_X (z) = \sum^\infty_{k=1} P(X = k) k(k - 1) .... (k - n - 1)\]</span> where both sides can equal <span class="math inline">\(\infty\)</span>.</li>
<li>The distribution <span class="math inline">\(P_X\)</span> is uniquely determined by <span class="math inline">\(\psi_X\)</span>.</li>
</ol>
<p><br></p>
<h2 id="convergence-theorem">Convergence Theorem</h2>
<p>Assume <span class="math inline">\((\Omega, \mathbf{A}, \mu)\)</span> is a <span class="math inline">\(\sigma\)</span>-finite measure space. <span class="math inline">\((E, d)\)</span> is a separable metric space.</p>
<h3 id="almost-sure-and-measure-convergence">Almost Sure and Measure Convergence</h3>
<h4 id="theorem-6.1">Theorem 6.1</h4>
<p>Let <span class="math inline">\(f, g: \Omega \rightarrow E\)</span> be <span class="math inline">\(\mathbf{A}-B(E)\)</span> measurable. Then the map <span class="math inline">\(H: \Omega \rightarrow [0, \infty), \omega \mapsto d(f(\omega), g(\omega))\)</span> is <span class="math inline">\(\mathbf{A}-B([0, \infty))\)</span>-measurable.</p>
<h4 id="definition-6.2-converges-in-mu-converges-almost-everywhere">Definition 6.2: Converges in <span class="math inline">\(\mu\)</span>, Converges Almost Everywhere</h4>
<p>Let <span class="math inline">\(f, f_1, .... : \Omega \rightarrow E\)</span> be measurable w.r.t <span class="math inline">\(\mathbf{A}-B(E)\)</span> (<span class="math inline">\(\{d(f_1, f_n) &gt; 0\} := \{\omega: d(f_1(\omega), f_n(\omega)) &gt; 0\}\)</span>). Then, we say that <span class="math inline">\((f_n)_{n \in \mathbb{N}}\)</span> converges to <span class="math inline">\(f\)</span>:</p>
<ol type="1">
<li>In <span class="math inline">\(\mu\)</span>-measure, symbolically <span class="math inline">\(f_n \overset{\mu}{\to} f\)</span>, if <span class="math inline">\(\forall \epsilon \geq 0\)</span>:
<ul>
<li>Globally: <span class="math display">\[\lim_{n \rightarrow \infty}\mu(\{d(f, f_n) &gt; \epsilon\}) = 0\]</span></li>
<li>Locally, <span class="math inline">\(\forall A \in \mathbf{A}\)</span> and <span class="math inline">\(\mu(A) &lt; \infty\)</span>: <span class="math display">\[\lim_{n \rightarrow \infty}\mu(\{\omega \in A: d(f(\omega), f_n (\omega))) &gt; \epsilon\}) = 0\]</span></li>
<li>If <span class="math inline">\(\mu(X) &lt; \infty\)</span>, above two definitions are equivalent [4]</li>
<li>If <span class="math inline">\(\mu\)</span> is a probability measure, then convergence above is called <strong>convergence in probability</strong>: <span class="math display">\[\lim_{n \rightarrow \infty} P(|f - f_n| &gt; \epsilon) = 0\]</span></li>
</ul></li>
<li><span class="math inline">\(\mu\)</span>-almost everywhere, symbolically <span class="math inline">\(f_n \overset{a.e}{\to} f\)</span>, if there exists a <span class="math inline">\(\mu\)</span>-null set <span class="math inline">\(N \in \mathbf{A}\)</span> s.t: <span class="math display">\[\lim_{n \rightarrow \infty}d(f(\omega), f_n(\omega)) = 0, \quad \forall \omega \in \Omega / N\]</span>
<ul>
<li>If <span class="math inline">\(\mu\)</span> is a probability measure, then convergence the sequence <strong>convergence almost surely</strong> if (<span class="math inline">\(|\cdot|\)</span> is a metric on <span class="math inline">\(\mathbb{R}\)</span>): <span class="math display">\[P(\lim_{n \rightarrow \infty} |f - f_n| = 0) = 1\]</span></li>
</ul></li>
<li>Almost everywhere convergence implies convergence in measure.</li>
</ol>
<p><br></p>
<h4 id="definition-6.8-mean-convergence">Definition 6.8: Mean Convergence</h4>
<p>Let <span class="math inline">\(f, f_1, .... \in L^1(\mu)\)</span>. We say that the sequence <span class="math inline">\((f_n)_{n \in \mathbb{N}}\)</span> <strong>converges in mean</strong> to <span class="math inline">\(f\)</span>:</p>
<p><span class="math display">\[f_n \overset{L^1}{\to}f\]</span></p>
<p>if <span class="math inline">\(\lim_{n \rightarrow \infty} \|f_n - f\|_1 = 0\)</span>. If <span class="math inline">\(\mu\)</span> is a probability measure, then converges in mean can be written as:</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} E[|f_n - f|] = 0\]</span></p>
<ul>
<li>If <span class="math inline">\(f_n \overset{L^1}{\to}f\)</span>, then in particular <span class="math inline">\(\lim_{n \rightarrow \infty}\int f_n d\mu = \int f d\mu\)</span></li>
<li>Mean convergence implies convergence in measure.</li>
</ul>
<p><br></p>
<h4 id="definition-6.12-fast-convergence">Definition 6.12: Fast Convergence</h4>
<p>Let <span class="math inline">\((E, d)\)</span> be a separable metric space. In order for the sequence <span class="math inline">\((f_n)_{n \in \mathbb{N}}\)</span> of measurable maps <span class="math inline">\(\Omega \rightarrow E\)</span> to converge <strong>almost everywhere</strong>, it is sufficient that one of the following conditions holds:</p>
<ul>
<li><span class="math inline">\(E = \mathbb{R}\)</span> and there is a <span class="math inline">\(p \in [1, \infty)\)</span> with <span class="math inline">\(f_n \in L^p(\mu)\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span> and there is an <span class="math inline">\(f \in L^p(\mu)\)</span> with <span class="math inline">\(\sum^\infty_{n=1} \|f_n - f\|_p &lt; \infty\)</span>.</li>
<li>There is a measurable <span class="math inline">\(f\)</span> with <span class="math inline">\(\sum^\infty_{n=1} \mu(A \cap \{d(f, f_n) &gt; \epsilon\}) &lt; \infty\)</span> for all <span class="math inline">\(\epsilon &gt; 0\)</span> and for all <span class="math inline">\(A \in \mathbf{A}\)</span> with <span class="math inline">\(\mu(A) &lt; \infty\)</span>. In both cases, we have <span class="math inline">\(f_n \overset{a.e}{\to} f\)</span>.</li>
</ul>
<p><br></p>
<h2 id="moments-and-law-of-large-numbers">Moments and Law of Large Numbers</h2>
<h3 id="moments">Moments</h3>
<h4 id="definition-5.1-moments">Definition 5.1: Moments</h4>
<p>Let <span class="math inline">\(X\)</span> be a <strong>real</strong>-valued random variable:</p>
<ul>
<li>If <span class="math inline">\(X \in L^1(P)\)</span>, then <span class="math inline">\(X\)</span> is called integrable and we call: <span class="math display">\[E[X] := \int X dP\]</span> The <strong>expectation or mean</strong> of <span class="math inline">\(X\)</span>. If <span class="math inline">\(E[X] = 0\)</span>, then <span class="math inline">\(X\)</span> is called <strong>centered</strong>.</li>
<li>If <span class="math inline">\(n \in \mathbb{N}\)</span> and <span class="math inline">\(X \in L^n (P)\)</span>, then the quantities: <span class="math display">\[m_k := E[X^k], \quad M_k := E[|X|^k], \quad \forall k = 1, ...., n\]</span> are called the <span class="math inline">\(k\)</span>th <strong>moments</strong> and <span class="math inline">\(k\)</span>th <strong>absolute moments</strong>, respectively, of <span class="math inline">\(X\)</span>.</li>
<li>If <span class="math inline">\(X \in L^2(P)\)</span>, then <span class="math inline">\(X\)</span> is called <strong>square integrable</strong> and: <span class="math display">\[Var[X] := E[X^2] - E[X]^2\]</span> is the <strong>variance</strong> of <span class="math inline">\(X\)</span>. The number <span class="math inline">\(\sigma := \sqrt{Var[X]}\)</span> is called <strong>standard deviation</strong> of <span class="math inline">\(X\)</span>. Formally, we sometimes write <span class="math inline">\(Var[X] = \infty\)</span> if <span class="math inline">\(E[X^2] = \infty\)</span>.</li>
<li>If <span class="math inline">\(X, Y \in L^2(P)\)</span>, then we define the <strong>covariance</strong> of <span class="math inline">\(X, Y\)</span> by: <span class="math display">\[Cov[X, Y] := E[(X - E[X])(Y - E[Y])]\]</span> <span class="math display">\[Cov[X, Y] = E[XY] - E[X]E[Y]\]</span> <span class="math inline">\(X, Y\)</span> are called <strong>uncorrelated</strong> if <span class="math inline">\(Cov[X, Y] = 0\)</span> and <strong>correlated</strong> o.w.</li>
</ul>
<p><br></p>
<h4 id="theorem-5.3-rules-of-expectations">Theorem 5.3: Rules of Expectations</h4>
<p>Let <span class="math inline">\(X, Y, X_n, Z_n, n \in \mathbb{N}\)</span>, be <strong>real</strong> integrable random variables on <span class="math inline">\((\Omega, \mathbf{A}, P)\)</span></p>
<ol type="1">
<li>If <span class="math inline">\(P_X = P_Y\)</span>, then <span class="math inline">\(E[X] = E[Y]\)</span>.</li>
<li><strong>Linearity</strong>: Let <span class="math inline">\(c \in \mathbb{R}\)</span>. Then <span class="math inline">\(cX \in L^1(P)\)</span> and <span class="math inline">\(X + Y \in L^1(P)\)</span> as well as: <span class="math display">\[E[cX] = cE[X], \quad E[X + Y] = E[X] + E[Y]\]</span></li>
<li>If <span class="math inline">\(X \geq 0\)</span> almost surely, then: <span class="math display">\[E[X] = 0 \Longleftrightarrow X = 0 \text{ almost surely}\]</span></li>
<li><strong>Monotonicity</strong>: If <span class="math inline">\(X \leq Y\)</span> almost surely, then <span class="math inline">\(E[X] \leq E[Y]\)</span> with equality if and only if <span class="math inline">\(X = Y\)</span> almost surely.</li>
<li><strong>Triangle Inequality</strong>: <span class="math inline">\(|E[X]| \leq E[|X|]\)</span></li>
<li>If <span class="math inline">\(X_n \geq 0\)</span> a.s for all <span class="math inline">\(n \in \mathbb{N}\)</span>, then <span class="math inline">\(E[\sum^\infty_{n=1} X_n] = \sum^\infty_{n=1}E[X_n]\)</span>.</li>
<li>If <span class="math inline">\(Z_n \uparrow Z\)</span> for some <span class="math inline">\(Z\)</span>, then <span class="math inline">\(E[Z] = \lim_{n \rightarrow \infty} E[Z_n] \in (-\infty, \infty]\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-5.4-independent-random-variables-are-uncorrelated">Theorem 5.4: Independent Random Variables are Uncorrelated</h4>
<p>Let <span class="math inline">\(X, Y \in L^1(P)\)</span> be independent. Then <span class="math inline">\((XY) \in L^1(P)\)</span> and <span class="math inline">\(E[XY] = E[X]E[Y]\)</span>. In particular, independent random variables are <strong>uncorrelated</strong>.</p>
<p><br></p>
<h4 id="theorem-5.6-variance-is-non-negative">Theorem 5.6: Variance is Non-negative</h4>
<p>Let <span class="math inline">\(X \in L^2 (P)\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(Var[X] = E[(X - E[X])^2] \geq 0\)</span></li>
<li><span class="math inline">\(Var[X] = 0 \Longleftrightarrow X = E[X]\)</span> a.s</li>
<li>The map <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}, x \mapsto E[(X - x)^2]\)</span> is minimal at <span class="math inline">\(x_0 = E[X]\)</span> with <span class="math inline">\(f(E[X]) = Var[X]\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-5.7-covariance-as-inner-product">Theorem 5.7: Covariance as Inner product</h4>
<p>The map <span class="math inline">\(Cov: L^2(P) \times L^2(P) \rightarrow \mathbb{R}\)</span> is a positive semidefinite symmetric bilinear form (Inner product) and <span class="math inline">\(Cov[X, Y] = 0\)</span> if <span class="math inline">\(Y\)</span> is a.s constant. In detail, Let <span class="math inline">\(X_1, ....., X_m\)</span>, <span class="math inline">\(Y_1, ...., Y_m \in L^2(P)\)</span> and <span class="math inline">\(\alpha_1, ...., \alpha_m, \beta_1, ...., \beta_n \in \mathbb{R}\)</span> as well as <span class="math inline">\(d, e \in \mathbb{R}\)</span>. Then:</p>
<p><span class="math display">\[Cov[d + \sum^m_{i=1} \alpha_i X_i, e + \sum^n_{i=1} \beta_j Y_j] = \sum_{i, j} \alpha_i \alpha_j Cov[X_i, Y_j]\]</span></p>
<p>In particular, <span class="math inline">\(Var[\alpha X] = \alpha^2 Var[X]\)</span> and the <strong>Bienayme formula</strong> holds:</p>
<p><span class="math display">\[Var[\sum^m_{i=1} X_i] = \sum^m_{i=1} Var[X_i] + \sum^m_{i, j = 1, i\neq j} Cov[X_i, Y_j]\]</span></p>
<p>For uncorrelated <span class="math inline">\(X_1, ..., X_m\)</span>, we have <span class="math inline">\(Var[\sum^{m}_{i=1} X_i] = \sum^m_{i=1} Var[X_i]\)</span></p>
<p><br></p>
<h4 id="theorem-5.8-cauchy-schwarz-inequality">Theorem 5.8: Cauchy-Schwarz Inequality</h4>
<p>If <span class="math inline">\(X, Y \in L^2(P)\)</span>, then</p>
<p><span class="math display">\[(Cov[X, Y])^2 \leq Var[X]Var[Y]\]</span></p>
<p>Equality holds if and only if there are <span class="math inline">\(a, b c \in \mathbb{R}\)</span> with <span class="math inline">\(|a| + |b| + |c| &gt; 0\)</span> and such that <span class="math inline">\(aX + bY + c = 0\)</span> a.s.</p>
<p><br></p>
<h3 id="weak-law-of-large-numbers">Weak Law of Large Numbers</h3>
<h4 id="theorem-5.11-markov-inequality-chebyshev-inequality">Theorem 5.11: Markov inequality, Chebyshev Inequality</h4>
<p>Let <span class="math inline">\(X\)</span> be a random variable and let <span class="math inline">\(f: [0, \infty) \rightarrow [0, \infty)\)</span> be monotone increasing. Then for any <span class="math inline">\(\epsilon &gt; 0\)</span> with <span class="math inline">\(f(\epsilon) &gt; 0\)</span>, the <strong>Markov inequality</strong> holds:</p>
<p><span class="math display">\[P(|X| \geq \epsilon) \leq \frac{E[f(|X|)]}{f(\epsilon)}\]</span></p>
<p>In particular if <span class="math inline">\(f(x) = x^2\)</span>, we get <span class="math inline">\(P[|X| \geq \epsilon] \leq \frac{E[X^2]}{\epsilon^2}\)</span>. In particular, if <span class="math inline">\(X \in L^2(P)\)</span>, the <strong>Chebyshev inequality</strong> holds:</p>
<p><span class="math display">\[P(|X - E[X]| \geq \epsilon) \leq \frac{Var[X]}{\epsilon^2}\]</span></p>
<p><br></p>
<h4 id="definition-5.12-weak-and-strong-law-of-large-numbers">Definition 5.12: Weak and Strong Law of Large Numbers</h4>
<p>Let <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> be a sequence of real random variables in <span class="math inline">\(L^1(P)\)</span> and let <span class="math inline">\(\tilde{S}_n = \sum^n_{i=1} (X_i - E[X_i])\)</span></p>
<ul>
<li>We say that <span class="math inline">\((X)_{n \in \mathbb{N}}\)</span> fulfills the <strong>weak law of large numbers</strong> if: <span class="math display">\[\lim_{n \rightarrow \infty} P(|\frac{1}{n} \tilde{S}_n| &gt; \epsilon)= 0, \; \forall \epsilon &gt; 0\]</span></li>
<li>We say that <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> fulfills the <strong>strong law of large numbers</strong> if:
<ul>
<li><span class="math display">\[P(\lim\sup_{n \rightarrow \infty} |\frac{1}{n} \tilde{S}_n| = 0) = 1\]</span></li>
<li><span class="math display">\[P(\lim\sup_{n \rightarrow \infty} \{\omega \in \Omega: |\frac{1}{n} \tilde{S}_n (\omega)| &gt; \epsilon\}) = 0\]</span></li>
<li><span class="math display">\[P(\lim_{n \rightarrow \infty} X_n = X) = 1 := P(\{\omega \in \Omega: \lim_{n \rightarrow \infty} X_n(\omega) = X(\omega)\}) = 1\]</span></li>
</ul></li>
</ul>
<p><br></p>
<h4 id="theorem-5.14-uncorrelated-random-variables-with-finite-variance-fulfills-wlln">Theorem 5.14: Uncorrelated Random Variables with Finite Variance Fulfills WLLN</h4>
<p>Let <span class="math inline">\(X_1, X_2, .....\)</span> be uncorrelated random variables in <span class="math inline">\(L^2(P)\)</span> with <span class="math inline">\(V:= \sup_{n \in \mathbb{N}} Var[X_n] &lt; \infty\)</span>. Then <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> fulfills the <strong>weak law of large numbers</strong>. More precisely, for any <span class="math inline">\(\epsilon &gt; 0\)</span>:</p>
<p><span class="math display">\[P(|\frac{1}{n}\tilde{S_n}| \geq \epsilon) \leq \frac{V}{\epsilon^2 n}\]</span></p>
<p><br></p>
<h4 id="theorem-5.16-pairwise-independence-finite-variance-and-identically-distributed-fulfills-slln-strong-assumption">Theorem 5.16: Pairwise Independence, Finite Variance and Identically Distributed Fulfills SLLN (Strong Assumption)</h4>
<p>Let <span class="math inline">\(X_1, .... \in L^2(P)\)</span> be pairwise independent and identically distributed. Then <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> fulfills the strong law of large numbers.</p>
<p><br></p>
<h4 id="theorem-5.17-etemadis-strong-law-of-large-numbers-weaker-assumption">Theorem 5.17: Etemadi's Strong Law of Large Numbers (Weaker Assumption)</h4>
<p>Let <span class="math inline">\(X_1, .... \in L^1(P)\)</span> be pairwise independent and identically distributed. Then <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> fulfills the SLLN.</p>
<p><br></p>
<h4 id="definition-5.22-empirical-distirbution-function">Definition 5.22: Empirical Distirbution Function</h4>
<p>Let <span class="math inline">\(X_1, ....\)</span> be real random variables. The map: <span class="math inline">\(F_n: \mathbb{R} \rightarrow [0, 1], x \mapsto \frac{1}{n} \sum^n_{i=1} \mathbb{1}_{X_i \leq x}\)</span> is called the <strong>empirical distribution function</strong> of <span class="math inline">\(X_1, ...., X_n\)</span>. In other words, given a sequence of samples, we estimate the CDF by counting the number of observations that are less than or equal to <span class="math inline">\(x\)</span>.</p>
<p><br></p>
<h4 id="theorem-5.23-glivenko-cantelli">Theorem 5.23: Glivenko-Cantelli</h4>
<p>Let <span class="math inline">\(X_1, ...\)</span> be i.i.d real random variables with distribution function <span class="math inline">\(F\)</span>, and let <span class="math inline">\(F_n\)</span>, <span class="math inline">\(n \in \mathbb{N}\)</span>, be the empirical distirbution functions. Then:</p>
<p><span class="math display">\[P(\lim\sup_{n \rightarrow \infty}\sup_{x \in \mathbb{R}} |F_n (x) - F(x)| = 0) = 1\]</span></p>
<p><br></p>
<h4 id="definition-5.25-entropy">Definition 5.25: Entropy</h4>
<p>Let <span class="math inline">\(p = (p_e)_{e \in E}\)</span> (<span class="math inline">\(p_e = P_X(e) = f_X (e)\)</span> the PMF of <span class="math inline">\(X\)</span> at <span class="math inline">\(e\)</span>) be a probability distribution on the countable set <span class="math inline">\(E\)</span>. For <span class="math inline">\(b &gt; 0\)</span>, define:</p>
<p><span class="math display">\[H_b (p) := - \sum_{e \in E} p_e \log_b (p_e)\]</span></p>
<p>with the convention <span class="math inline">\(0 \log_b (0) := 0\)</span>. We call <span class="math inline">\(H(p) := H_e(p)\)</span> (e = 2.71) the <strong>entropy</strong> and <span class="math inline">\(H_2(p)\)</span> the <strong>binary entropy</strong> of <span class="math inline">\(p\)</span>.</p>
<p>Note that for infinite <span class="math inline">\(E\)</span>, the entropy need note be finite.</p>
<p><br></p>
<h4 id="lemma-5.26-entropy-inequality">Lemma 5.26: Entropy Inequality</h4>
<p>Let <span class="math inline">\(b, p\)</span> be defined as above, let <span class="math inline">\(q\)</span> be a sub-probability distribution, that is <span class="math inline">\(q_e \geq 0\)</span> for all <span class="math inline">\(e \in E\)</span> and <span class="math inline">\(\sum_{e \in E} q_e \leq 1\)</span>. Then:</p>
<p><span class="math display">\[H_b (p) \leq - \sum_{e \in E} p_e \log_{b} (q_e)\]</span></p>
<p>with equality if and only if <span class="math inline">\(H_b (p) = \infty\)</span> or <span class="math inline">\(q = p\)</span>.</p>
<p><br></p>
<h4 id="theorem-1.6.9-change-of-variable">Theorem 1.6.9: Change of Variable</h4>
<p>Let <span class="math inline">\((\Omega, \mathbf{A})\)</span> and <span class="math inline">\((\Omega^\prime, \mathbf{A}^\prime)\)</span> be measurable spaces, let <span class="math inline">\(\mu\)</span> be a measure on <span class="math inline">\((\Omega, \mathbf{A})\)</span> and let <span class="math inline">\(X: \Omega \rightarrow \Omega^\prime\)</span> be measurable. Let <span class="math inline">\(\mu^\prime = \mu \circ X^{-1}\)</span> be the image measure of <span class="math inline">\(\mu\)</span> under the map <span class="math inline">\(X\)</span>. Assume that <span class="math inline">\(f: \Omega^\prime \rightarrow \mathbb{\bar{R}}\)</span> is <span class="math inline">\(\mu^\prime\)</span>-integrable, then:</p>
<p><span class="math display">\[f \circ X \in L^1(\mu)\]</span></p>
<p>and</p>
<p><span class="math display">\[\int (f \circ X) d\mu = \int f d(\mu \circ X^{-1})\]</span></p>
<p>In particular, if <span class="math inline">\(X\)</span> is a random variable on <span class="math inline">\((\Omega, \mathbf{A}, P)\)</span>, then:</p>
<p><span class="math display">\[\int f dP_X = \int_{\mathbb{R}} f(x) P_X(dx)\]</span></p>
<p>Thus, the expectation can be written as:</p>
<p><span class="math display">\[E[f(X)] = \int_{\mathbb{R}} f(x) P_X(dx)\]</span></p>
<p>In particular:</p>
<p><span class="math display">\[E[X] = \int_{\mathbb{R}} x P_X(dx)\]</span></p>
<p><br></p>
<h4 id="definition-1.7.0-pmf-discrete-random-variable">Definition 1.7.0: PMF, Discrete Random Variable</h4>
<p>A random variable is said to be <strong>discrete</strong> if its range is finite or countably infinite.</p>
<ul>
<li>The <strong>probability mass function</strong> <span class="math inline">\(f_X(x)\)</span> of a discrete random variable <span class="math inline">\(X\)</span> is the function on <span class="math inline">\(\mathbb{R}\)</span> given by: <span class="math display">\[f_X(x) = P(X = x)\]</span></li>
<li>The <strong>distribution measure <span class="math inline">\(P_X\)</span></strong> can be written as a sum: <span class="math display">\[P_X = \sum_{x} f_X(x) \delta_x\]</span> where <span class="math inline">\(\delta_x (B) = 1\)</span> if <span class="math inline">\(x \in B, 0\)</span> otherwise.</li>
<li>The Expected value of discrete random variable can be written as: <span class="math display">\[E[X] = \sum_x x f_X(x)\]</span></li>
</ul>
<p><br></p>
<h4 id="definition-1.7.1-continuous-random-variable">Definition 1.7.1: Continuous Random Variable</h4>
<p>A random variable is <strong>absolute continuous</strong> if there is a non-negative function <span class="math inline">\(f_X (x)\)</span> called the <strong>probability density function</strong> s.t (w.r.t the Lebesgue measure):</p>
<p><span class="math display">\[P(X \leq t) = \int^t_{-\infty} f_X(x) dx\]</span></p>
<p>If <span class="math inline">\(X\)</span> is an absolutely continuous random variable with density <span class="math inline">\(f(x)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(P(X = x) = 0, \;\forall x \in \mathbb{R}\)</span>.</li>
<li><span class="math inline">\(P(a \leq X \leq b) = \int^b_a f(x) dx\)</span>.</li>
<li>For any Borel subset <span class="math inline">\(C\)</span> of <span class="math inline">\(\mathbb{R}\)</span>, <span class="math inline">\(P_X (C) = P(X^{-1} (C)) = \int_C f(x) dx = \int_C f d\lambda\)</span></li>
<li><span class="math inline">\(\int^\infty_{-\infty} f(x) dx = 1\)</span>.</li>
<li>For absolutely continuous RV, <span class="math inline">\(P_X(dx) = f_X(x)dx\)</span>, so the expectation becomes if <span class="math inline">\(X \in L^1(P)\)</span>: <span class="math display">\[E[X] = \int^\infty_{-\infty} x f_X(x) dx\]</span></li>
</ol>
<h1 id="reference">Reference</h1>
<ol type="1">
<li>Definition 1.1 https://www.youtube.com/watch?v=PZ0UhM9IB_k</li>
<li>Theorem 1.2 https://proofwiki.org/wiki/Tail_of_Convergent_Series_tends_to_Zero#:~:text=%E2%88%9E%E2%88%91n%3DNan%20is%20convergent,convergent%20series%20tends%20to%20zero.</li>
<li>https://www.math.arizona.edu/~tgk/mc/prob_background.pdf</li>
<li>https://en.wikipedia.org/wiki/Convergence_in_measure#:~:text=If%20%CE%BC%20is%20%CF%83%2Dfinite%2C%20(fn)%20converges,to%20f%20locally%20in%20measure.</li>
<li>https://kconrad.math.uconn.edu/blurbs/analysis/entropypost.pdf</li>
</ol>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>td3</title>
    <url>/2021/06/23/td3/</url>
    <content><![CDATA[<h1 id="addressing-function-approximation-error-in-actor-critic-methods">Addressing Function Approximation Error in Actor-Critic Methods</h1>
<p>As in function approximation with discrete action space, overestimation property also exists in continuous control setting.</p>
<h2 id="background">Background</h2>
<p>The return is defined as the discounted sum of rewards:</p>
<p><span class="math display">\[R_t = \sum^{T}_{i=t} \gamma^{i - t} r(s_i, a_i)\]</span></p>
<p>The objective of RL is to find the optimal policy <span class="math inline">\(\pi_{\phi}\)</span> with parameters <span class="math inline">\(\phi\)</span> which is defined as:</p>
<p><span class="math display">\[J(\phi) = E_{s_i \sim P_{\pi_\phi}, a_i \sim \pi_{\phi}} [R_0]\]</span></p>
<p>In DPG, the policy's (actor) parameter can be updated:</p>
<p><span class="math display">\[\nabla_{\phi} J(\phi) = E_{s_i \sim \rho_{\pi_\phi}} [\nabla_{\phi} \pi_{\phi} \nabla_{a} Q^{\pi_{\phi}} (s, a) |_{a = \pi_{\phi}(s)}]\]</span></p>
<p>Where the critic is the action value function:</p>
<p><span class="math display">\[Q^{\pi_{\phi}} (s, a) = E_{s_i \sim P_{\pi_{\phi}}, a_i \sim \pi_{\phi}}[R_t | s, a] = \underbrace{r}_{\text{ reward is deterministic so the expectation is itself }} + \gamma E_{s^{\prime}, a^{\prime}} [Q^{\pi} (s^{\prime}, a^{\prime}) | s, a]\]</span></p>
<p>In large state space, the critic can be approached using FA methods for example DQN (Approximate value iteration) in an off policy fashion (replay buffer):</p>
<p><span class="math display">\[Q_{k + 1} = {\arg\min}_{Q} \|Q - \hat{T}^{\pi_{\phi}} Q_{k}\|^2_{\rho_{\pi_{\phi}}}\]</span></p>
<p>with <span class="math inline">\(Q_{k}\)</span> parameterized by a target network <span class="math inline">\(Q_{\theta^{\prime}}\)</span>, so the target <span class="math inline">\(\hat{T}^{\pi_{\phi}} Q_{\theta^{\prime}}\)</span> can be write as:</p>
<p><span class="math display">\[\hat{T}^{\pi_{\phi}} Q_{\theta^{\prime}} = r + \gamma Q_{\theta^{\prime}} (s^{\prime}, a^{\prime}), \quad \quad a^{\prime} \sim \pi_{\phi} (\cdot | s^{\prime})\]</span></p>
<p>In terms of DDPG with delayed parameters to provide stability, the delayed target <span class="math inline">\(\hat{T}^{\pi_{\phi^{\prime}}} Q_{\theta^{\prime}}\)</span> is used instead:</p>
<p><span class="math display">\[\hat{T}^{\pi_{\phi^{\prime}}} Q_{\theta^{\prime}} = r + \gamma Q_{\theta^{\prime}} (s^{\prime}, a^{\prime}), \quad \quad a^{\prime} \sim \pi_{\phi^{\prime}} (\cdot | s^{\prime})\]</span></p>
<p>The weights of a target network are either updated periodically to exactly match the weights of the current network or by some portion as in DDPG.</p>
<h2 id="overestimation-bias">Overestimation Bias</h2>
<p>In Q-learning with discrete actions, if the target is susceptible to error <span class="math inline">\(\epsilon\)</span>, then the maximum over the value alonge with its error will generally be greater than the true maximum even the error <span class="math inline">\(\epsilon\)</span> has zero mean:</p>
<p><span class="math display">\[E_{\epsilon} [\max_{a^{\prime}} (Q(s^{\prime}, a^{\prime}) + \epsilon)] \geq \max_{a^{\prime}} Q(s^{\prime}, a^{\prime})\]</span></p>
<p>This issue extends to actor critic setting where policy is updated via gradient descent.</p>
<h3 id="overestimation-bias-in-actor-critic">Overestimation Bias in Actor-Critic</h3>
<p>Assumptions:</p>
<ol type="1">
<li>Policy is updated using DPG.</li>
<li><span class="math inline">\(Z_1, Z_2\)</span> are chosen to normalize the gradient (i.e <span class="math inline">\(Z^{-1} \|E[\cdot]\| = 1\)</span>, only provides direction)</li>
</ol>
<p><br></p>
<p>Given current policy parameters <span class="math inline">\(\phi\)</span>, let:</p>
<ol type="1">
<li><p><span class="math inline">\(\phi_{approx}\)</span> be the parameters from the actor update induced by the maximization of the approximate critic <span class="math inline">\(Q_{\theta} (s, a)\)</span>. The resulting policy is <span class="math inline">\(\pi_{approx}\)</span>. <span class="math display">\[\phi_{approx} = \phi + \frac{\alpha}{Z_1} E_{s \sim \rho_{\pi_{\phi}}} [\nabla_{\phi} \pi_{\phi} \nabla_{a} Q_{\theta} (s, a) |_{a = \pi_{\phi}(s)}]\]</span></p></li>
<li><p><span class="math inline">\(\phi_{true}\)</span> be the parameters from the hypothetical actor update with respect to the true underlying value function <span class="math inline">\(Q^{\pi_{\phi}} (s, a)\)</span> (which is unknown during training). The resulting policy is <span class="math inline">\(\pi_{true}\)</span>. <span class="math display">\[\phi_{true} = \phi + \frac{\alpha}{Z_2} E_{s \sim \rho_{\pi_{\phi}}} [\nabla_{\phi} \pi_{\phi} \nabla_{a} Q^{\pi_{\phi}} (s, a) |_{a = \pi_{\phi}(s)}]\]</span></p></li>
</ol>
<p>Since gradient always point at the direction of maximum increase locally, so:</p>
<ol type="1">
<li><p><span class="math inline">\(\exists \epsilon_1\)</span>, such that if <span class="math inline">\(\alpha \leq \epsilon_1\)</span>, then the approximate value of <span class="math inline">\(\pi_{approx}\)</span> will be bounded by the approximate value of <span class="math inline">\(\pi_{true}\)</span>: <span class="math display">\[E[Q_{\theta} (s, \pi_{approx} (s))] \geq E[Q_{\theta} (s, \pi_{true} (s))]\]</span></p></li>
<li><p><span class="math inline">\(\exists \epsilon_2\)</span>, such that if <span class="math inline">\(\alpha \leq \epsilon_2\)</span>, then the true value of <span class="math inline">\(\pi_{approx}\)</span> will be bounded by the true value of <span class="math inline">\(\pi_{true}\)</span>: <span class="math display">\[E[Q^{\pi_{\phi}} (s, \pi_{true} (s))] \geq E[Q^{\pi_{\phi}} (s, \pi_{approx} (s))]\]</span></p></li>
</ol>
<p>If: <span class="math display">\[E[Q_{\theta} (s, \pi_{true} (s))] \geq E[Q^{\pi_{\phi}} (s, \pi_{true} (s))]\]</span></p>
<p>which means in expectation the approximated value function is greater than the true value function w.r.t policy <span class="math inline">\(\pi_{true}\)</span> (e.g for some state action pair (<span class="math inline">\(s, \pi_{true} (s)\)</span>)), the approximate value is much larger than the true value). At the same time, if <span class="math inline">\(\alpha &lt; \min(\epsilon_1, \epsilon_2)\)</span>, then: <span class="math display">\[E[Q_{\theta} (s, \pi_{approx} (s))] \geq E[Q^{\pi_{\phi}} (s, \pi_{approx} (s))]\]</span></p>
<p><strong>This implies that our policy improvement based on approximate value function would over-estimate certain actions and lead to sub-optimal policies.</strong></p>
<p><br></p>
<p>Consequences of overestimation:</p>
<ol type="1">
<li>Overestimation may develop into a more significant bias over many updates if left unchecked.</li>
<li>Inaccurate value estimate may lead to poor policy updates.</li>
</ol>
<p><strong>Feedback loops of actor and critic is prone to overestimation because suboptimal actions may highly rated by suboptimal critic and reinforcing the suboptimal action in the next policy update</strong>.</p>
<h3 id="clipped-double-q-learning-for-actor-critic-solution">Clipped Double Q-learning for Actor-Critic (Solution)</h3>
<p>In DDQN, the target is estimated using the greedy action from current value network rather than current target network. In an actor-critic setting (DPG), the update is:</p>
<p><span class="math display">\[y = r + Q_{\theta^{\prime}} (s^{\prime}, \pi_{\phi} (s^{\prime}))\]</span></p>
<p>However, slow-changing policy in actor-critic, the current and target networks were too similar to make an independent estimation and offered little improvement.</p>
<p>Instead, we can go back and use similar formulation as Double Q-learning with a pair of actors <span class="math inline">\((\pi_{\phi_1}, \pi_{\phi_2})\)</span> and critics <span class="math inline">\((Q_{\theta_1}, Q_{\theta_2})\)</span> where <span class="math inline">\(\pi_{\phi_1}\)</span> is optimized w.r.t <span class="math inline">\(Q_{\phi_1}\)</span> and <span class="math inline">\(\pi_{\phi_2}\)</span> is optimized w.r.t <span class="math inline">\(Q_{\phi_2}\)</span>:</p>
<p><span class="math display">\[y_1 = r + \gamma Q_{\theta^{\prime}_2} (s^{\prime}, \pi_{\phi_1} (s^{\prime}))\]</span> <span class="math display">\[y_2 = r + \gamma Q_{\theta^{\prime}_1} (s^{\prime}, \pi_{\phi_2} (s^{\prime}))\]</span></p>
<p><br></p>
<p><img src='/images/RL/pg/td3.png' width="600"></p>
<p>From above plot we can see that Double Q-learning AC is more effective, but it does not entirely eliminate the over-estimation. One cause can be the shared replay buffer, as a result, for some state <span class="math inline">\(s\)</span>, we would have <span class="math inline">\(Q_{\theta_2} (s, \pi_{\phi_1} (s)) &gt; Q_{\theta_1} (s, \pi_{\phi_1} (s))\)</span>. This is problematic because we know that <span class="math inline">\(Q_{\theta_1} (s, \pi_{\phi_1} (s))\)</span> will generally overestimate the true value, the overestimation is exaggerated.</p>
<p>One solution is to simply upper-bound the less biased value estimate <span class="math inline">\(Q_{\theta_2}\)</span> by the biased estimate <span class="math inline">\(Q_{\theta_1}\)</span>:</p>
<p><span class="math display">\[y_1 = r + \gamma \min_{i=1, 2} Q_{\theta^{\prime}_{i}} (s^{\prime}, \pi_{\phi_1} (s^{\prime}))\]</span></p>
<p>This algorithm is called <code>Clipped Double Q-learning</code> algorithm. With Clipped Double Q-learning, exaggeration of overestimation is eliminated. However, underestimation bias could occur.</p>
<p>In implementation, computational costs can be reduced by using a single actor optimized w.r.t <span class="math inline">\(Q_{\theta_1}\)</span>. We then use the same target <span class="math inline">\(y_2=y_1\)</span> for <span class="math inline">\(Q_{\theta_2}\)</span>. If <span class="math inline">\(Q_{\theta_2} &gt; Q_{\theta_1}\)</span> then the update is identical to the standard update and induces no additional bias. If <span class="math inline">\(Q_{\theta_2} &lt; Q_{\theta_1}\)</span>, this suggests overestimation has occurred.</p>
<h2 id="addressing-variance">Addressing Variance</h2>
<p>Besides impact on overestimation bias, high variance estimates provide a noisy gradient for the policy update which reduces learning speed and hurt performance in practice.</p>
<p>Since we never really learn <span class="math inline">\(Q^{\pi}\)</span> exactly (we learn <span class="math inline">\(Q_{\theta}\)</span> instead), there will always be some TD error in each update :</p>
<span class="math display">\[\begin{aligned}
r + \gamma E[Q_{\theta} (s^{\prime}, a^{\prime}) | s, a] - E[\delta(s, a) | s, a] &amp;= \gamma E[Q_{\theta} (s^{\prime}, a^{\prime}) | s, a] - \gamma E[Q_{\theta} (s^{\prime}, a^{\prime}) | s, a] + Q_{\theta} (s, a)\\
&amp;= Q_{\theta} (s, a)
\end{aligned}\]</span>
<p>Then:</p>
<span class="math display">\[\begin{aligned}
Q_{\theta} (s_t, a_t) &amp;= r_t + \gamma E[Q_{\theta} (s_{t+1}, a_{t+1}) | s_t, a_t] - E[\delta_{t} | s_t, a_t]\\
&amp;= r_t + \gamma E[r_{t+1} + \gamma E[Q_{\theta} (s_{t+2}, a_{t+2}) | s_{t+1}, a_{t+1}] - E[\delta_{t+1} | s_{t+1}, a_{t+1}] | s_t, a_t] - E[\delta_{t} | s_t, a_t]\\
&amp; = E_{s_i \sim P_{\pi}, a_i \sim \pi} [\sum^{T}_{i=t} \gamma^{i - t} (r_i - \delta_i)]
\end{aligned}\]</span>
<p>Thus, the value function we estimate <span class="math inline">\(Q_{\theta} (s_t, a_t)\)</span>, approximates the expected return minus the expected discounted sume of future TD-errors instead of the expected return <span class="math inline">\(Q^{\pi}\)</span>.</p>
<p>If the value estimate (sample of <span class="math inline">\(Q_{\theta}\)</span>) is a function of future reward and estimation error, it follows that the variance of the estimate will be proportional to the variance of future reward and estimation error. <strong>If the variance for <span class="math inline">\(\gamma^{i} (r_i - \delta_i)\)</span> is large, then the accumulative variance will be large especially when gamma is large.</strong></p>
<h3 id="target-networks-and-delayed-policy-updates">Target Networks and Delayed Policy Updates</h3>
<p><img src='/images/RL/pg/td_4.png' width="600"></p>
<p>One way to reduce the estimation error is to delay each update to the target network. Consider the graph above:</p>
<ol type="1">
<li>If <span class="math inline">\(\tau = 1\)</span>, we obtain batch semi-gradient TD algorithm for updating the critic, which may have high variance.</li>
<li>If <span class="math inline">\(\tau &lt; 1\)</span>, we obtain approximate value iteration.</li>
</ol>
<p>If target networks can be used to reduce the error over multiple updates, and policy updates on high-error states cause divergent behavior, then the policy network should be updated at a lower frequency than the value network, to first minimize error before introducing a policy update.</p>
<p>Thus, <code>delaying policy updates</code> can be helpful in minimizing the estimation error by updating the policy and target networks after a fixed number of updates <span class="math inline">\(d\)</span> to the critic. To ensure the TD-error remains small, target network is also slowly updated by <span class="math inline">\(\theta^{\prime} \leftarrow \tau \theta + (1 - \tau) \theta^{\prime}\)</span>.</p>
<h3 id="target-policy-smoothing-regularization">Target Policy Smoothing Regularization</h3>
<p>Since deterministic policies can overfit to narrow peaks in the value estimate, a regularization strategy is used for deep value learning, target policy smoothing which mimics the learning update from SARSA. The idea is that <strong>similar actions should have similar value</strong> (reduce the variance of target):</p>
<p><span class="math display">\[y = r + E_{\epsilon} [Q_{\theta^{\prime}} (s^{\prime}, \pi_{\phi^{\prime}} (s^{\prime}) + \epsilon)]\]</span></p>
<p>In practice, we can approximate this expectation over actions (<span class="math inline">\(\pi_{\phi^{\prime}} (s^{\prime}) + \epsilon\)</span>) by adding a small amount of random noise to the target policy and averaging over mini-batches:</p>
<p><span class="math display">\[y = r + \gamma Q_{\theta^{\prime}} (s^{\prime}, \pi_{\phi^{\prime}} (s^{\prime}) + \epsilon)\]</span></p>
<p><span class="math display">\[\epsilon \sim clip(N(0, \sigma), -c, c)\]</span></p>
<p>Where noise is clipped to have it close to the original action (make sure it is a small area around original action).</p>
<h2 id="algorithm">Algorithm</h2>
<p><img src='/images/RL/pg/td_5.png' width="600"></p>
<h2 id="conclusion">Conclusion</h2>
<p>The paper focus on resolve overestimation error in actor critic setting (DPG) and discusses that failure can occur due to the interplay between the actor and critic updates. Value estimates diverge through overestimation when the policy is poor, and the policy will become poor if the value estimate itself is inaccurate (high variance).</p>
<p>Solutions:</p>
<ol type="1">
<li><p>Overestimation Error in value estimation: using clipped double Q-learning to estimate the target value <span class="math inline">\(y_1, y_2\)</span> <span class="math display">\[y_1 = r + \gamma \min_{i=1, 2} Q_{\theta^{\prime}_{i}} (s^{\prime}, \pi_{\phi^{\prime}} (s^{\prime}))\]</span> <span class="math display">\[y_2 = y_1\]</span></p></li>
<li><p>Estimation Error (TD error) and High Variance in value estimation: By using delayed policy and value updates with target networks, we have more stable and more accurate estimate of the value function by updating the value function several times.</p></li>
<li><p>Overfitting in Value estimation: by forcing the value estimate to be similar for similar actions, we smooth out the value estimation. <span class="math display">\[y = r + \gamma Q_{\theta^{\prime}} (s^{\prime}, \pi_{\phi^{\prime}} (s^{\prime}) + \epsilon)\]</span> <span class="math display">\[\epsilon \sim clip(N(0, \sigma), -c, c)\]</span></p></li>
</ol>
<p>The general structure of the algorithm follows DDPG.</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>PG</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Continuous Action Space</tag>
        <tag>Policy Search</tag>
      </tags>
  </entry>
  <entry>
    <title>Stochastic Graph</title>
    <url>/2021/05/27/stochastic-graph/</url>
    <content><![CDATA[<h1 id="gradient-estimation-using-stochastic-computation-graphs">Gradient Estimation Using Stochastic Computation Graphs</h1>
<p>The backpropagation algorithm is only sufficient when the loss function is a deterministic, differentiable function of the parameter vector. The main practical result of this article is that to compute the gradient estimator, one just needs to make a simple modification to the backpropagation algorithm, where extra gradient signals are introduced at the stochastic nodes.</p>
<h2 id="preliminaries">Preliminaries</h2>
<h3 id="gradient-estimators-for-a-single-random-variable">Gradient Estimators for a Single Random Variable</h3>
<p>Suppose <span class="math inline">\(X\)</span> is a random variable, <span class="math inline">\(f\)</span> is a function, we are interested in computing</p>
<p><span class="math display">\[\frac{\partial}{\partial \theta} E_{X}[f(X)]\]</span></p>
<p>There are few different ways that the process for generating <span class="math inline">\(X\)</span> could be parameterized in terms of <span class="math inline">\(\theta\)</span>, which lead to different gradient estimators.</p>
<ul>
<li><p>We might be given a parameterized probability distribution <span class="math inline">\(X \sim p(\cdot ; \theta)\)</span>. In this case, we can use <strong>score function</strong> or <strong>REINFORCE</strong> or <strong>likelihood ratio estimator</strong> estimator:</p>
<p><span class="math display">\[\frac{\partial}{\partial \theta} E_{X \sim p(\cdot ; \theta)}[f(X)] = \int_x \frac{\frac{\partial}{\partial\theta} p(x; \theta)}{p(x; \theta)} p(x; \theta) f(x)dx = E_{X \sim p(\cdot ; \theta)}[f(X) \frac{\partial}{\partial\theta} log p(X; \theta)]\]</span></p>
<p>This equation is valid if <span class="math inline">\(p(x; \theta)\)</span> is a continuous function of <span class="math inline">\(\theta\)</span>; however it does not need to be a continuous function of <span class="math inline">\(x\)</span></p></li>
<li><p><span class="math inline">\(X\)</span> may be a deterministic, continuous function of <span class="math inline">\(\theta\)</span> and another random variable <span class="math inline">\(Z\)</span>, we can write as <span class="math inline">\(X(\theta, Z)\)</span>. Then we can use the <strong>pathwise derivative</strong> or <strong>stochastic backpropagation</strong> estimator:</p>
<p><span class="math display">\[E_{Z}[f(X(\theta, Z))] = E_{Z}[\frac{\partial}{\partial \theta} f(X(\theta, Z))]\]</span></p>
<p>We can swap the derivative and expectation iff <span class="math inline">\(f(X(\theta, Z))\)</span> is a continuous function of <span class="math inline">\(\theta\)</span> for all values of <span class="math inline">\(Z\)</span>. However, it is also sufficient that this function is almost-everywhere differentiable.</p></li>
<li><p>Finally, <span class="math inline">\(\theta\)</span> may be appeared both in the probability distribution and inside the expectation:</p>
<p><span class="math display">\[E_{Z \sim p(\cdot; \theta)}[f(X(\theta, Z))] = \int_z \frac{\partial}{\partial \theta} f(X(\theta, z)) p(z; \theta) dz = E_{Z \sim p(\cdot; \theta)}[\frac{\partial}{\partial \theta} f(X(\theta, Z)) + (\frac{\partial}{\partial \theta} log p(Z; \theta))f(X(\theta, Z))]\]</span></p></li>
</ul>
<span id="more"></span>
<h3 id="stochastic-computation-graphs">Stochastic Computation Graphs</h3>
<p><img src="/images/ML/scg_1.png" width="600"></p>
<p><img src="/images/ML/scg_2.png" width="600"></p>
<p>Where square denotes deterministic node, circle denotes stochastic node.</p>
<p><img src="/images/ML/scg_3.png" width="600"></p>
<p><strong>For simplification, <span class="math inline">\(E_Y [\cdot]\)</span> denotes that <span class="math inline">\(Y\)</span> are sampled from its distribution specified. P used for distribution, p for density function</strong></p>
<ol type="1">
<li><p><span class="math inline">\(x(\theta), Y \sim P_Y(\cdot | x(\theta)), E_{Y \sim P_Y(\cdot | x(\theta))}[f(Y)]\)</span> (<strong>the distribution depends on function of <span class="math inline">\(\theta\)</span></strong>)</p>
<p><span class="math display">\[\frac{\partial }{\partial \theta} E_{Y \sim P_Y(\cdot | x(\theta))}[f(Y)] = \int_y p(y | x(\theta)) \frac{\partial log p(y | x(\theta))}{\partial \theta}\frac{\partial x(\theta)}{\partial \theta} dy = E_Y[\frac{\partial log p(Y | x(\theta))}{\partial \theta}\frac{\partial x(\theta)}{\partial \theta}]\]</span><br/></p></li>
<li><p><span class="math inline">\(X \sim P_X(\cdot | \theta), Y(X), f(Y(X))\)</span> (<strong>the distribution depends on <span class="math inline">\(\theta\)</span></strong>)</p>
<p><span class="math display">\[\frac{\partial }{\partial \theta} E_X[f(Y(X))] = \int_x p(x | \theta) \frac{\partial }{\partial \theta} log p(x | \theta) f(Y(x)) dx = E_X [log p(X | \theta) f(Y(X))]\]</span><br/></p></li>
<li><p><span class="math inline">\(X \sim P_X(\cdot | \theta), Y \sim P_Y(\cdot | X), f(Y)\)</span> (<strong>the distribution depends on <span class="math inline">\(\theta\)</span></strong>)</p>
<p><span class="math display">\[\frac{\partial }{\partial \theta} E_{X, Y}[f(Y)] = \int_y \int_x p(x | \theta) p(y | x) f(y)\frac{\partial }{\partial \theta} log p(x | \theta) dx dy = E_{X, Y} [log p(X | \theta) f(Y)]\]</span><br/></p></li>
<li><p><span class="math inline">\(X \sim P_X(\cdot | \theta), y(\theta), f(X, y(\theta))\)</span> (<strong>the distribution depends on <span class="math inline">\(\theta\)</span> and the function <span class="math inline">\(f\)</span> depends on <span class="math inline">\(\theta\)</span></strong>)</p>
<p><span class="math display">\[\frac{\partial }{\partial \theta} E_{X}[f(X, y(\theta))] = \int_x p(x | \theta) \frac{\partial }{\partial \theta} log p(x | \theta) f(x, y(\theta)) + p(x | \theta) \frac{\partial f(x, y(\theta))}{\partial y(\theta)} \frac{\partial y(\theta)}{\partial \theta} dx = E_X [\frac{\partial }{\partial \theta} log p(X | \theta) f(X, y(\theta)) + \frac{\partial f(X, y(\theta))}{\partial y(\theta)} \frac{\partial y(\theta)}{\partial \theta}]\]</span><br/></p></li>
<li><p><span class="math inline">\(X_1 \sim P_{X_1}(\cdot | \theta, x_0), X_2 \sim P_{X_2}(\cdot | \theta, X_1), f_1 (X_1), f_2 (X_2)\)</span> (<strong>Notice that <span class="math inline">\(X_2\)</span> has no effect on the distribution of <span class="math inline">\(X_1\)</span>, this resembles a parameterized Markov reward process, and it illustrates that we’ll obtain score function terms of the form grad log-probability times future costs.</strong>)</p>
<span class="math display">\[\begin{aligned}
 \frac{\partial }{\partial \theta} E_{X_1, X_2}[f_1(X_1), f_2(X_2)] &amp;= \frac{\partial }{\partial \theta} (E_{X_1} [f_1(X_1)] +  E_{X_1, X_2} [f_2(X_2)]) \\
 &amp;= \int_{x_1} p(x_1 | \theta) \frac{\partial }{\partial \theta} log p(x_1 | \theta) f_1 (x_1) dx_1  + \int_{x_1} \int_{x_2} p(x_2 | \theta)p(x_1 | \theta)  \frac{\partial }{\partial \theta} log p(x_2 | \theta) f_2 (x_2) + p(x_2 | \theta)p(x_1 | \theta) \frac{\partial }{\partial \theta} log p(x_1 | \theta) f_2 (x_2)dx_2 dx_1 \\
 &amp;= E_{X_1, X_2}[\frac{\partial }{\partial \theta} log p(X_1 | \theta) (f(X_1) + f(X_2)) + \frac{\partial }{\partial \theta} log p(X_2 | \theta) f(X_2)]
 \end{aligned}\]</span></li>
</ol>
<h2 id="main-results">Main Results</h2>
<h3 id="gradient-estimation">Gradient Estimation</h3>
<h4 id="notations">Notations</h4>
<p><img src="/images/ML/scg_4.png" width="600"></p>
<ul>
<li><p>The set of cost nodes <span class="math inline">\(C\)</span> are <code>scalar-valued</code> and <code>deterministic</code> (There is no loss of generality in assuming that the costs are deterministic, if a cost is stochastic, we can simply append a deterministic node that applies hte identity function to it).</p></li>
<li><p>The relation <span class="math inline">\(v \prec w\)</span> means that <span class="math inline">\(\exists\)</span> a sequence of nodes <span class="math inline">\(a_1, ...., a_K\)</span> with <span class="math inline">\(K \leq 0\)</span> such that <span class="math inline">\((v, a_1), ...., (a_K, w)\)</span> are edges in the graph (Basicly, there exists a <code>path</code> from <span class="math inline">\(v\)</span> to <span class="math inline">\(w\)</span>)</p></li>
<li><p>The relation <span class="math inline">\(v \prec^D w\)</span> means that all sequence of nodes <span class="math inline">\(a_1, ...., a_K\)</span> are deterministic (Also, <strong>if (<span class="math inline">\(v\)</span>, <span class="math inline">\(w\)</span>) is an edge in the graph, then <span class="math inline">\(v \prec^D w\)</span></strong>)</p></li>
<li><p><span class="math inline">\(\hat{Q_v} \triangleq \sum_{ c \succ v, c \in C} \hat{c}\)</span>, this is the sum of costs influenced by node <span class="math inline">\(v\)</span>.</p></li>
<li><p>All <code>hats</code> are denoted as sample realizations of random variables and are regarded as <code>constant</code>.</p></li>
<li><p><span class="math inline">\(\text{DEPS}_{v} \triangleq \{ w \in \Theta \bigcup S \; | \; w \prec^D v \}\)</span>:</p>
<ul>
<li>If <span class="math inline">\(v \in S\)</span>, then we can write <span class="math inline">\(p(v \; | \; \text{DEPS}_{v})\)</span></li>
<li>If <span class="math inline">\(v \in D\)</span>, then we can write <span class="math inline">\(v\)</span> as function of <span class="math inline">\(\text{DEPS}_{v}\)</span>: <span class="math inline">\(v(\text{DEPS}_{v})\)</span></li>
</ul></li>
</ul>
<p><img src="/images/ML/scg_6.png" width="600"></p>
<p>In this case,</p>
<ul>
<li>If <span class="math inline">\(v\)</span> is deterministic, then it is a function that depends on <span class="math inline">\(v(a_1, a_2(a_3), a_4)\)</span> but not <span class="math inline">\(a_5\)</span>.</li>
<li>If <span class="math inline">\(v\)</span> is stochastic, then it's probability distribution depends on <span class="math inline">\(P( \cdot |a_1, a_2(a_3), a_4)\)</span> but not <span class="math inline">\(a_5\)</span></li>
</ul>
<p>Assume that:</p>
<p><img src="/images/ML/scg_5.png" width="600"></p>
<h4 id="theorem-1">Theorem 1</h4>
<p><img src="/images/ML/scg_7.png" width="600"></p>
<h5 id="proof">Proof</h5>
<p><strong>Consider only <span class="math inline">\(v \in S\)</span></strong>, <span class="math inline">\(E_{v \in S, v \prec c}[c]\)</span>:</p>
<span class="math display">\[\begin{aligned}
E_{v \in S, v \prec c}[c] &amp;= \int_{v} p(v_1 \; | \; \text{DEPS}_{v_1}) p(v_2 \; | \; \text{DEPS}_{v_2}) ... p(v_k \; | \; \text{DEPS}_{v_k})c(\text{DEPS}_{c})dv\\
&amp;= \int_{v} c(\text{DEPS}_{c}) \prod_{v} p(v \; | \; \text{DEPS}_{v})dv
\end{aligned}\]</span>
<p><br/></p>
<p>Here, <span class="math inline">\(c\)</span> is deterministic node, by definition it is a function of its dependencies. <span class="math inline">\(v = \{v_1, ..., v_k\}\)</span> is a set of stochastic nodes, so all of them have probability density or mass functions that depends on their dependencies.</p>
<p>Then the derivative <span class="math inline">\(\frac{\partial}{\partial \theta}E_{v \in S, v \prec c}[c]\)</span> w.r.t <span class="math inline">\(\theta\)</span> is:</p>
<span class="math display">\[\begin{aligned}
\frac{\partial}{\partial \theta} E_{v \in S, v \prec c}[c] &amp;= \frac{\partial}{\partial \theta} \int_{v} c(\text{DEPS}_{c}) \prod_{v} p(v \; | \; \text{DEPS}_{v})dv\\
&amp;=  \int_{v} \frac{\partial c(\text{DEPS}_{c})}{\partial \theta} \prod_{v} p(v \; | \; \text{DEPS}_{v})dv +  \int_{v} c(\text{DEPS}_{c}) \frac{\partial \prod_{v} p(v \; | \; \text{DEPS}_{v})}{\partial \theta}dv\\
&amp;=  \int_{v} \frac{\partial c(\text{DEPS}_{c})}{\partial \theta} \prod_{v} p(v \; | \; \text{DEPS}_{v})dv +  \int_{v} c(\text{DEPS}_{c})  \prod_{v} p(v \; | \; \text{DEPS}_{v}) \sum_{w \in S, w \prec c} \frac{\frac{\partial}{\partial \theta} p(w \; | \; \text{DEPS}_{w})}{p(w \; | \; \text{DEPS}_{w})}dv\\
&amp;=  \int_{v} \frac{\partial c(\text{DEPS}_{c})}{\partial \theta} \prod_{v} p(v \; | \; \text{DEPS}_{v})dv +  \int_{v} c(\text{DEPS}_{c})  \prod_{v} p(v \; | \; \text{DEPS}_{v}) \sum_{w \in S, w \prec c} \frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w}))dv\\
&amp;=  E_{v \in S, v \prec c} [\frac{\partial c(\text{DEPS}_{c})}{\partial \theta} + \hat{c} \sum_{w \in S, w \prec c} \frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w}))] \\
\end{aligned}\]</span>
<p><br/></p>
<p>Recall that if <span class="math inline">\(\theta \prec^D w\)</span> then <span class="math inline">\(\theta \in \text{DEPS}_{w}\)</span>. Notice here, terms in the sum <span class="math inline">\(\sum_{w \in S, w \prec c} \frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w}))\)</span> that do not depend on <span class="math inline">\(\theta\)</span> will have 0 gradients, thus, we can rewrite:</p>
<p><span class="math display">\[\sum_{w \in S, w \prec c} \frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w})) = \sum_{w \in S, w \prec c, \theta \prec^D w} \frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w}))\]</span><br/></p>
<p>At the same time, we can substitute <span class="math inline">\(\hat{c}\)</span> for <span class="math inline">\(c\)</span>, which does not affect the expectation.</p>
<p><strong>More generally</strong>, we can have <span class="math inline">\(v\)</span> being either stochastic or deterministic:</p>
<p><span class="math display">\[v \prec c\]</span></p>
<p>Then,</p>
<span class="math display">\[\begin{aligned}
\frac{\partial}{\partial \theta}E_{v \prec C}[\sum_{c \in c} c] &amp;= \frac{\partial}{\partial \theta} \sum_{c \in C} E_{v \prec c}[c]\\
&amp;= \sum_{c \in C} E_{v \prec c} [\frac{\partial c(\text{DEPS}_{c})}{\partial \theta} + \hat{c}\sum_{w \prec c, \theta \prec^D w} \frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w}))]\\
&amp;= E_{v \in S, v \prec c} [ \sum_{c \in C} \frac{\partial c(\text{DEPS}_{c})}{\partial \theta} + \sum_{c \in C}\hat{c} \sum_{w \prec c, \theta \prec^D w} (\frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w})))]\\
&amp;= E_{v \in S, v \prec c} [ \sum_{c \in C} \frac{\partial c(\text{DEPS}_{c})}{\partial \theta} + \sum_{w \prec S, \theta \prec^D w} (\frac{\partial}{\partial \theta} \log (p(w \; | \; \text{DEPS}_{w}))) \hat{Q}_{w}]\\
\end{aligned}\]</span>
<p><br/></p>
<p>The estimated expressions above have two terms:</p>
<ul>
<li>The first term is due to the influence of <span class="math inline">\(\theta\)</span> on the probability distributions.</li>
<li>The second term is due to the influence of <span class="math inline">\(\theta\)</span> on the cost variables through a chain of differentiable functions.</li>
</ul>
<h3 id="surrogate-loss-functions">Surrogate Loss Functions</h3>
<p>The next corollary lets us write down a <code>surrogate</code> objective <span class="math inline">\(L\)</span>, which is a function of the inputs that we can differentiate to obtain an unbiased gradient estimator.</p>
<p><img src="/images/ML/scg_8.png" width="600"></p>
<p>We now convert a stochastic computation graph to a deterministic computation graph, and we can apply automatic differentiation.</p>
<p><img src="/images/ML/scg_9.png" width="600"></p>
<h2 id="algorithm">Algorithm</h2>
<p><img src="/images/ML/scg_10.png" width="600"></p>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Policy Gradient</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Time Series (1)</title>
    <url>/2021/11/15/time-series-1/</url>
    <content><![CDATA[<h1 id="time-series-introduction">Time Series (Introduction)</h1>
<h2 id="characteristics-of-time-series">Characteristics of Time Series</h2>
<p>The primary objective of time series analysis is to develop mathematical models that provide plausible descriptions for sample data with time correlations. In order to provide a statistical setting for describing the character of data that seemingly fluctuate in a random fashion over time, we assume a time series can be defined as a collection of random variables indexed according to the order they are obtained in time. In general, a collection of random variables <span class="math inline">\(\{X_t\}\)</span> indexed by <span class="math inline">\(t\)</span> is referred to as a stochastic process. In this text, <span class="math inline">\(t\)</span> will typically be discrete and vary over the integers.</p>
<p><strong>Example of Series:</strong></p>
<blockquote>
<p><strong>White Noise</strong>: A collection of uncorrelated, independent and identically distributed random variables <span class="math inline">\(W_t\)</span> with mean 0 and finite variance <span class="math inline">\(\sigma^2_w\)</span>. A particular useful white noise is Gaussian white noise, that is <span class="math inline">\(W_t \overset{i.i.d}{\sim} N(0, \sigma^2_w)\)</span> <img src="/images/RL/background/ts_1_3_1.png" width="600"></p>
</blockquote>
<blockquote>
<p><strong>Moving Average</strong>: We might replace the white noise series <span class="math inline">\(W_t\)</span> by a moving average that smooths the series: <span class="math display">\[V_t = \frac{1}{3} (W_{t-1} + W_{t} + W_{t+1})\]</span> This introduces a smoother version of white noise series, reflecting the fact that the slower oscillations are more apparent and some of the faster oscillations are taken out. <img src="/images/RL/background/ts_1_3_2.png" width="600"></p>
</blockquote>
<blockquote>
<p><strong>Autoregressions</strong>: Suppose we consider the white noise series <span class="math inline">\(W_t\)</span> as input and calculate the output using the second-order equation: <span class="math display">\[X_t = X_{t-1} - 0.9 X_{t-2} + W_t\]</span> For <span class="math inline">\(t=1, ..., 500\)</span>. We can see the periodic behavior of the series. <img src="/images/RL/background/ts_1_3_3.png" width="600"></p>
</blockquote>
<span id="more"></span>
<h3 id="autocorrelation-and-cross-correlation">Autocorrelation and Cross-Correlation</h3>
<p>A complete description of a time series with <span class="math inline">\(N\)</span> random variables at arbitrary integer time points <span class="math inline">\(t_1, ..., t_N\)</span> is given by joint distribution function (joint CDF), evaluated as the probability that the values of the series are jointly less than the <span class="math inline">\(N\)</span> constants <span class="math inline">\(c_1, ..., c_N\)</span>:</p>
<p><span class="math display">\[F_{X_{t_1}, ..., X_{t_N}}(c_1, ...., c_N) = P(X_{t_1} \leq c_1, ..., X_{t_N} \leq c_N)\]</span></p>
<p>In practice, the multidimensional distribution function cannot usually be written easily unless the random variables are jointly normal. It is an unwieldy tool for displaying and analyzing time series data. On the other hand, the marginal distribution functions:</p>
<p><span class="math display">\[F_{X_t} (x_t) = P(X_t \leq x_t)\]</span></p>
<p>or the corresponding marginal density functions:</p>
<p><span class="math display">\[f_{X_t} (x_t) = \frac{\partial F_{X_t} (x_t)}{\partial x_t}\]</span></p>
<p>And The <strong>Mean Function</strong>:</p>
<p><img src="/images/RL/background/ts_1_4_1.png" width="600"></p>
<p>When they exist, are often informative for examining the marginal behavior of the series.</p>
<p><br></p>
<h4 id="autocovariance">Autocovariance</h4>
<p><img src="/images/RL/background/ts_1_4_2.png" width="600"></p>
<p>The autocovariance measures the linear dependence between two points on the same series observed at different times:</p>
<ol type="1">
<li>Very <strong>Smooth</strong> series exhibit autocovariance functions that stay large even when <span class="math inline">\(t\)</span> and <span class="math inline">\(s\)</span> are far apart</li>
<li>Very <strong>Choppy</strong> series tend to have auto covariance functions that are nearly zero for large separations.</li>
</ol>
<p><br></p>
<h4 id="autocorrelation">Autocorrelation</h4>
<p><img src="/images/RL/background/ts_1_4_3.png" width="600"></p>
<p>The ACF measures the linear predictability of the series at time <span class="math inline">\(t\)</span>, say <span class="math inline">\(X_t\)</span>, using only the value <span class="math inline">\(X_s\)</span>. iF we can predict <span class="math inline">\(X_t\)</span> perfectly from <span class="math inline">\(X_s\)</span> through a linear relationship <span class="math inline">\(X_t = \beta_0 + \beta_1 X_s\)</span>, then the correlation will be <span class="math inline">\(+1\)</span> or <span class="math inline">\(-1\)</span> depends on the sign of <span class="math inline">\(\beta_1\)</span>. Hence, we have a rough measure of the ability to forecast the series at time <span class="math inline">\(t\)</span> from the value at time <span class="math inline">\(s\)</span>.</p>
<p><br></p>
<h4 id="cross-covariance-and-cross-correlation">Cross-covariance and Cross-correlation</h4>
<p>Often, we want to measure the predictability of another series (different components) <span class="math inline">\(Y_t\)</span> from the series <span class="math inline">\(X_s\)</span>. Assuming both series have finite variances, we have the following definition:</p>
<p><img src="/images/RL/background/ts_1_4_4.png" width="600"></p>
<p><img src="/images/RL/background/ts_1_4_5.png" width="600"></p>
<p>We can easily extend the idea to multivariate time series where each sample contains r attributes:</p>
<p><span class="math display">\[X_{t} = &lt;X_{t1}, ...., X_{tR}&gt;\]</span></p>
<p>The extension of autocovariance is then:</p>
<p><span class="math display">\[\gamma_{jk} (s, t) = E[(X_{sj} - \mu_{sj}) (X_{tk} - \mu_{tk})]\]</span></p>
<h3 id="stationary-time-series">Stationary Time Series</h3>
<p>There may exist a sort of regularity over time in the behavior of a time series.</p>
<h4 id="strictly-stationarity">Strictly Stationarity</h4>
<p><img src="/images/RL/background/ts_1_5_1.png" width="600"></p>
<p><img src="/images/RL/background/ts_1_5_2.png" width="600"></p>
<p>When <span class="math inline">\(k = 1\)</span>, we can conclude that random variables are identically distributed and mean is constant regardless of time:</p>
<p><span class="math display">\[P(X_s \leq c) = P(X_t \leq c) = P(X_1 \leq c), \;\; \forall c, s, t \implies E[X_s]  = E[X_t] = \mu\]</span></p>
<p>When <span class="math inline">\(k = 2\)</span>, we can conclude that for any pairs of <span class="math inline">\(s, t\)</span>, the joint distribution is identical regardless of time:</p>
<p><span class="math display">\[P(X_{s} \leq c_1, X_{t} \leq c_2) = P(X_{s + h} \leq c_1, X_{t} \leq c_2), \; \forall h, c_1, c_2\]</span></p>
<blockquote>
<p><span class="math inline">\((X_1, X_2), (X_3, X_4), (X_8, X_9)\)</span> are identically distributed</p>
<p><span class="math inline">\((X_2, X_4), (X_3, X_5), (X_8, X_{10})\)</span> are identically distributed</p>
</blockquote>
<p>Thus, if the variance function of the process exists, we have autocovariance function of the series <span class="math inline">\(\{X_t\}\)</span> satisfies:</p>
<p><span class="math display">\[\gamma(s, t) = \gamma(s + h, t + h)\]</span></p>
<p>Same conclusions for all possible values of <span class="math inline">\(k\)</span>. The version of strictly stationarity is too strong for most applications and it is difficult to assess strict stationarity from a single data set.</p>
<h4 id="weak-stationarity">Weak Stationarity</h4>
<p><img src="/images/RL/background/ts_1_5_3.png" width="600"></p>
<p>Thus, <span class="math inline">\(\forall s, t, h\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(E[X_t] = E[X_s] = \mu\)</span></li>
<li><span class="math inline">\(\gamma(s, s + h) = Cov(X_s, X_{s+h}) = Cov(X_0, X_{h}) = \gamma(0, h) \;\)</span> or <span class="math inline">\(\; \gamma(s, t) = \gamma(s + h, t + h)\)</span></li>
</ol>
<p>From above, we can clearly see that a strictly stationary, finite variance, time series is also stationary. The converse is not true unless there are further conditions.</p>
<p><img src="/images/RL/background/ts_1_5_4.png" width="600"></p>
<p><img src="/images/RL/background/ts_1_5_5.png" width="600"></p>
<p>Several Properties:</p>
<ol type="1">
<li><span class="math inline">\(|\gamma(h)| \leq Var[X_t] = \gamma(0)\)</span></li>
<li><span class="math inline">\(\gamma(h) = \gamma(-h)\)</span></li>
<li><span class="math inline">\(\rho_{xy}(h) = \rho_{yx}(-h)\)</span></li>
<li><span class="math inline">\(\gamma(\cdot)\)</span> is <strong>non-negative definite</strong>, for all positive integers <span class="math inline">\(N\)</span> and vector <span class="math inline">\(&lt;X_1, ..., X_N&gt;^T \in \mathbb{R}^N\)</span>: <span class="math display">\[\sum^N_{i=1} \sum^N_{j=1} X_i \gamma(i - j) X_j \geq 0\]</span></li>
</ol>
<h4 id="gaussian-process">Gaussian Process</h4>
<p><img src="/images/RL/background/ts_1_5_6.png" width="600"></p>
<p>If a Gaussian Process is weakly stationary then it is also strictly stationary.</p>
<h4 id="linear-process">Linear Process</h4>
<p>A Linear process <span class="math inline">\(X_t\)</span> is a stationary process defined to be a linear combination of white noise variates <span class="math inline">\(X_t\)</span> and is given by:</p>
<p><span class="math display">\[X_t = \mu + \sum^\infty_{j=-\infty} \psi_j W_{t-j},  \quad \sum^{\infty}_{j=-\infty} |\psi_j| &lt; \infty\]</span></p>
<p>The autocovariance function for linear process is:</p>
<p><span class="math display">\[\gamma(h) = \sigma^2_w \sum^\infty_{j=-\infty} \psi_{j+h} \psi_j\]</span></p>
<h3 id="estimation-of-correlation">Estimation of Correlation</h3>
<p>If a time series is <strong>stationary</strong>, the mean function is constant, so that we can estimate it by the sample mean:</p>
<p><span class="math display">\[\bar{X} = \frac{1}{N} \sum^N_{t=1} X_t\]</span></p>
<p><br></p>
<p><img src="/images/RL/background/ts_1_6_1.png" width="600"></p>
<p>The sum runs over a restricted range because <span class="math inline">\(X_{t+h}\)</span> is not available for <span class="math inline">\(t+h &gt; n\)</span>. Thus, this estimator is a biased estimator of <span class="math inline">\(\gamma(h)\)</span>. The normalizing term <span class="math inline">\(\frac{1}{N}\)</span> guarantees a non-negative definite function because autocovariance function is non-negative definite for stationary series, so it is preferred over <span class="math inline">\(\frac{1}{N - h}\)</span>.</p>
<p><br></p>
<p><img src="/images/RL/background/ts_1_6_2.png" width="600"></p>
<p>The sample autocorrelation function has a sampling distribution that allows us to assess whether the data comes from a completely random or white series or whether correlations are statistically significant at some lags.</p>
<p><img src="/images/RL/background/ts_1_6_3.png" width="600"></p>
<p>Based on the property, we obtain a rough method of assessing whether peaks in <span class="math inline">\(\hat{\rho}(h)\)</span> are significant by determining whether the observed peak is outside the interval <span class="math inline">\(0 \pm \frac{2}{\sqrt{N}}\)</span> (95% of data should be within 2 s.e of a standard normal distribution).</p>
<p><br></p>
<p><img src="/images/RL/background/ts_1_6_4.png" width="600"></p>
<p><img src="/images/RL/background/ts_1_6_5.png" width="600"></p>
<h3 id="vector-valued-and-multidimensional-series">Vector-Valued and Multidimensional Series</h3>
<p>Consider the notion of a vector time series <span class="math inline">\(\mathbf{X}_t = &lt;X_{t1}, ...., X_{tp}&gt;^T \in \mathbb{R}^p\)</span> that contains <span class="math inline">\(p\)</span> univariate time series. For the stationary case, the mean vector <span class="math inline">\(\boldsymbol{\mu}\)</span> is:</p>
<p><span class="math display">\[\boldsymbol{\mu} = E[\mathbf{X}_t] = &lt;\mu_{t1}, ...., \mu_{tp}&gt;^T\]</span></p>
<p>And the <span class="math inline">\(p\times p\)</span> autocovariance matrix is denoted as:</p>
<p><span class="math display">\[\Gamma (h) = E[(\mathbf{X}_{t+h} - \boldsymbol{\mu}) (\mathbf{X}_t - \boldsymbol{\mu})^T]\]</span> <span class="math display">\[\gamma_{ij} (h) = E[(X_{t+h, i} - \mu_i) (X_{t, j} - \mu_j)], \;\; i,j = 1, ...., p\]</span></p>
<p>Since, <span class="math inline">\(\gamma_{ij}(h) = \gamma_{ji} (-h)\)</span>:</p>
<p><span class="math display">\[\Gamma(-h) = \Gamma^T(h)\]</span></p>
<p>The sample autocovariance matrix is defined as:</p>
<p><span class="math display">\[\hat{\Gamma}(h) = \frac{1}{N}\sum^{N-h}_{t=1} (\mathbf{X}_{t+h} - \bar{\mathbf{X}}) (\mathbf{X}_t - \bar{\mathbf{X}})^T\]</span> <span class="math display">\[\hat{\Gamma} (-h) = \hat{\Gamma}^T(h)\]</span></p>
<p>Where <span class="math inline">\(\bar{\mathbf{X}} = \frac{1}{N} \sum^{N}_{t=1} \mathbf{X}_t\)</span> is the sample mean vector.</p>
<p>In many applied problems, an observed series may be indexed by more than one time alone. For example, the position in space of an experimental unit might be described by two coordinates. We may proceed in these cases by defining a <strong>multidimensional process</strong> (does not have multiple dependent variables as multivariate case)<span class="math inline">\(\mathbf{X}_\mathbf{s}\)</span> as a function of the <span class="math inline">\(r \times 1\)</span> vector <span class="math inline">\(\mathbf{s} = &lt;s_1, ..., s_r&gt;^T\)</span>, where <span class="math inline">\(s_i\)</span> denotes the coordinate of the <span class="math inline">\(i\)</span>th index. The autocovariance function of a stationary multidimensional process, <span class="math inline">\(X_{\mathbf{s}}\)</span> can be defined as a function of the multidimensional lag vector, <span class="math inline">\(\mathbf{h} = &lt;h_1, ..., h_r&gt;^T\)</span> as:</p>
<p><span class="math display">\[\gamma (\mathbf{h}) = E[(X_{\mathbf{s} + \mathbf{h}}) - \mu) (X_{\mathbf{s}} - \mu)]\]</span></p>
<p>Where <span class="math inline">\(\mu = E[X_{\mathbf{s}}]\)</span></p>
<p>The multidimensional sample autocovariance function is defined as:</p>
<p><span class="math display">\[\hat{\gamma}(\mathbf{h}) = (S_1S_2...S_r)^{-1} \sum_{s_1} .... \sum_{s_r} (X_{\mathbf{s} + \mathbf{h}} - \bar{X})(X_{\mathbf{s}} - \bar{X})\]</span></p>
<p>Where each summation has range <span class="math inline">\(1 \leq s_i \leq S_i - h_i, \;\; \forall i=1, ..., r\)</span></p>
<p><span class="math display">\[\bar{X} = (S_1 ... S_r)^{-1} \sum_{s_1} ... \sum_{s_r} X_{\mathbf{s}}\]</span></p>
<p>Where each summation has range <span class="math inline">\(1 \leq s_i \leq S_i, \;\; \forall i=1, ..., r\)</span></p>
<p>The multidimensional sample autocorrelation function follows:</p>
<p><span class="math display">\[\hat{\rho}(\mathbf{h}) = \frac{\hat{\gamma}(\mathbf{h})}{\hat{\gamma}(\mathbf{0})}\]</span></p>
<p><img src="/images/RL/background/ts_1_7_1.png" width="600"></p>
<h2 id="eda">EDA</h2>
<p>In general, it is necessary for time series data to be stationary, so averaging lagged products over time will be a sensible thing to do (fixed mean). Hence, to achieve any meaningful statistical analysis of time series data, it will be crucial that the mean and the autocovariance functions satisfy the conditions of stationarity.</p>
<h3 id="trend">Trend</h3>
<h4 id="detrend">Detrend</h4>
<p>The easiest form of nonstationarity to work with is the trend stationary model wherein the process has stationary behavior around a trend. We define this as:</p>
<p><span class="math display">\[X_t = \mu_t + Y_t\]</span></p>
<p>Where <span class="math inline">\(X_t\)</span> are the observations, <span class="math inline">\(\mu_t\)</span> denotes the trend, and <span class="math inline">\(Y_t\)</span> is a stationary process. Strong trend will obscure the behavior of the stationary process <span class="math inline">\(Y_t\)</span>. Hence, there is some advantage to removing the trend as a first step in an exploratory analysis of such time series. The steps involved are to obtain a reasonable estimate of the trend component, and then work with the residuals:</p>
<p><span class="math display">\[\hat{Y}_t = X_t - \hat{\mu}_t\]</span></p>
<blockquote>
<p><span class="math inline">\(\hat{\mu} = -11.2 + 0.006t \implies \hat{Y}_t = X_t + 11.2 - 0.006t\)</span></p>
</blockquote>
<h4 id="differencing">Differencing</h4>
<p>Differencing can be used to produce a stationary time series. The first difference operator is a <strong>linear operator</strong> denoted as:</p>
<p><span class="math display">\[\nabla X_t = X_t - X_{t-1}\]</span></p>
<p>If <span class="math inline">\(\mu_t = \beta_1 + \beta_2 t\)</span>, then:</p>
<p><span class="math display">\[\nabla X_t = (\mu_t + Y_t) - (\mu_{t-1} + Y_{t-1}) = \beta_2 + Y_t - Y_{t-1} \implies Z_t = X_t - \beta_2\]</span></p>
<p>Where <span class="math inline">\(Z_t = Y_t - Y_{t-1}\)</span> is a stationary time series given <span class="math inline">\(Y_t\)</span> is a stationary time series.</p>
<p>One advantage of differencing over detrending to remove trend is that no parameters are estimated in the differencing operation. One disadvantage, however, is that differencing does not yield an estimate of the stationary process <span class="math inline">\(Y_t\)</span> as detrending. If an estimate of <span class="math inline">\(Y_t\)</span> is essential, then detrending may be more appropriate. If the goal is to coerce the data to be stationarity, then differencing is more appropriate.</p>
<h5 id="backshift-operator">Backshift Operator</h5>
<p><img src="/images/RL/background/ts_2_2_1.png" width="600"></p>
<p>Backshift Operator is <strong>linear</strong>. We can rewrite first difference as:</p>
<p><span class="math display">\[\nabla X_t = X_t - X_{t-1} = (1 - B) X_t\]</span></p>
<p>And second difference as:</p>
<p><span class="math display">\[\nabla^2 (X_t) = \nabla (\nabla X_t) = (1 - B)^2 X_t\]</span></p>
<p><img src="/images/RL/background/ts_2_2_2.png" width="600"></p>
<h4 id="transformations">Transformations</h4>
<p>If a time series presents nonstationary as well as nonlinear behavior, transformations may be useful to equalize the variability over the length of a single series. A particular useful transformation is the log transformation:</p>
<p><span class="math inline">\(Y_t = \log X_t\)</span>$</p>
<p>Which tends to suppress larger fluctuations that occur over portions of the series where the underlying values are larger.</p>
<h3 id="smoothing">Smoothing</h3>
<p>Smoothing is useful in discovering certain traits in a time series, such as long-term trend and seasonal components.</p>
<h4 id="moving-average-smoother">Moving Average Smoother</h4>
<p>If <span class="math inline">\(X_t\)</span> represents the observations, then</p>
<p><span class="math display">\[M_t = \sum^k_{j=-k} a_j x_{t-j}\]</span></p>
<p>Where <span class="math inline">\(a_j = a_{j} \geq 0\)</span> and <span class="math inline">\(\sum^k_{j=-k} a_j = 1\)</span> is a <strong>symmetric moving average</strong> of the data centered at <span class="math inline">\(X_t\)</span>.</p>
<h4 id="kernel-smoothing">Kernel Smoothing</h4>
<p>Kernel smoothing is a moving average smoother that uses a weight function or kernel to average the observations:</p>
<p><span class="math display">\[\hat{f}_t = \sum^N_{i=1} w_i(t) X_i\]</span></p>
<p><span class="math display">\[w_i (t) = \frac{K(\frac{t - i}{b})}{\sum^N_{j=1} K(\frac{t - j}{b})}\]</span></p>
<p>Where <span class="math inline">\(b\)</span> is a bandwidth parameter, the wider the bandwidth, the smoother the result. <span class="math inline">\(K(\cdot)\)</span> is a kernel function that is often the normal kernel:</p>
<p><span class="math display">\[K(z) = \frac{1}{\sqrt{2\pi}}\exp(\frac{-z^2}{2})\]</span></p>
<h4 id="lowess-and-nearest-neighbor-regression">Lowess and Nearest Neighbor Regression</h4>
<p>Another approach to smooth a time series is <strong>nearest neighbor regression</strong>. The technique is based on <span class="math inline">\(k\)</span>-nearest neighbors linear regression, wherein one uses the neighbouring data <span class="math inline">\(\{X_{t-\frac{k}{2}}, ..., X_t, ..., X_{t + \frac{k}{2}}\}\)</span> to predict <span class="math inline">\(X_t\)</span> using a linear regression. The result is <span class="math inline">\(\hat{f}_t\)</span>.</p>
<p><strong>Lowess</strong> is a method of smoothing that is complex but similar to nearest neighbor regression:</p>
<ol type="1">
<li>A certain proportion of nearest neighbors to <span class="math inline">\(X_t\)</span> are included in a weighting scheme, values closer to <span class="math inline">\(X_t\)</span> in time get more weight.</li>
<li>A robust weighted regression is used to predict <span class="math inline">\(X_t\)</span> and obtain the smoothed estimate of <span class="math inline">\(f_t\)</span>.</li>
</ol>
<h3 id="visualization">Visualization</h3>
<h4 id="lagged-scatterplot-matrices-non-linearity-and-lag-correlation">Lagged Scatterplot Matrices (Non-linearity and Lag correlation)</h4>
<p>In the definition of the ACF, we are essentially interested in relations between <span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_{t-h}\)</span>. The autocorrelation function tells us whether a substantial linear relation exists between the series and its own lagged values. The ACF gives a profile of the linear correlation at all possible lags and shows which values of <span class="math inline">\(h\)</span> leads to the best predictability. The restriction of this idea to linear predictability, however, may mask a possible nonlinear relation between current values and past values. Thus, to check for nonlinear relationship of this form, it is convenient to display a <strong>lagged scatterplot matrix</strong>.</p>
<blockquote>
<p>The plot displays values <span class="math inline">\(S_t\)</span> on the vertical axis plotted against <span class="math inline">\(S_{t-h}\)</span> on the horizontal axis.The sample autocorrelations are displayed in the upper right-hand corner and superimposed on the sctterplots are <strong>locally weighted scatterplot smoothing lines (LOWESS)</strong> that can be used to help discover any nonlinearities. <img src="/images/RL/background/ts_2_2_3.png" width="600"></p>
</blockquote>
<h2 id="ref">Ref</h2>
<p>Time Series Analysis and Its Applications With R Examples by Robert H.Shumway and David S.Stoffer</p>
<p>https://www.math-stat.unibe.ch/e237483/e237655/e243381/e281679/files281692/Chap13_ger.pdf</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>TCN</title>
    <url>/2021/12/25/tcn/</url>
    <content><![CDATA[<h1 id="temporal-convolutional-networks">Temporal Convolutional Networks</h1>
<p>Characteristics of TCN:</p>
<ol type="1">
<li>The convolutions in the architecture are causal.</li>
<li>The architecture can take a sequence of any length and map it to an output sequence of same length.</li>
<li>The ability of long term memories using a combination of very deep networks (with residual layers) and dilated convolutions.</li>
</ol>
<h2 id="fully-convolutional-network">Fully Convolutional Network</h2>
<p>Fully convolutional networks replace the fully connected layers with convolution layers. The TCN uses a <span class="math inline">\(1D\)</span> fully-convolutional network architecture, where each hidden layer is the same length as the input layer and zero padding of length (kernel - 1) in the front of the sequence is added to keep subsequent layers the same length as previous ones.</p>
<h2 id="causal-convolutions">Causal Convolutions</h2>
<p>To achieve the causality, the TCN uses causal convolutions, convolutions where an output at time <span class="math inline">\(t\)</span> is convolved only with elements from time <span class="math inline">\(t\)</span> and earlier in the previous layer. Thus:</p>
<p><span class="math display">\[\text{TCN} = 1D\text{FCN} + \text{causal convolutions}\]</span></p>
<p>The major disadvantage of this design is that we need an extremely deep network or very large filters to achieve a long effective history size.</p>
<h2 id="dilated-convolutions">Dilated Convolutions</h2>
<p>The solution is to introduce dilated convolutions:</p>
<p><span class="math display">\[F_d(\mathbf{x}, s) = \sum^{k-1}_{i=0} f(i) \cdot \mathbf{x}_{s - d\cdot i}\]</span></p>
<p>Where <span class="math inline">\(f(i)\)</span> is the <span class="math inline">\(i\)</span>th component of the 1D filter with length <span class="math inline">\(k - 1, i=0, ...., k-1\)</span> and <span class="math inline">\(d\)</span> is the dilation factor, <span class="math inline">\(k\)</span> is the filter size, and <span class="math inline">\(s - d \cdot i\)</span> accounts for the direction of the past. Using large dilation enables an output at the top level to represent a wider range of inputs, thus effectively expanding the receptive field of a ConvNet. Thus, we can choose to: 1. Larger filter size <span class="math inline">\(k\)</span>. 2. Choose larger Dilation factor <span class="math inline">\(d\)</span>. Usually it is increased exponentially with the depth of the network <span class="math inline">\(d = 2^i\)</span> at level <span class="math inline">\(i\)</span> of the network. This ensures that there is some filter that hits each input within the effective history, while also allowing for an extremely large effective using deep networks.</p>
<p><img src="/images/ML/tcn_1.jpg"></p>
<h2 id="residual-connections">Residual Connections</h2>
<p>To allow faster learning , a residual block is introduced with weight norm and dropout inbetween to replace the convolution layer:</p>
<p><img src="/images/ML/tcn_2.jpg"></p>
<p>In TCN, the input and output of the residual block could have different widths (channels), to account for discrepant input-output widths, we use an additional <span class="math inline">\(1 \times 1\)</span> convolution to ensure that elementwise addition will work.</p>
<h2 id="advantages-of-tcn">Advantages of TCN</h2>
<ol type="1">
<li><strong>Parallelism</strong>:</li>
<li><strong>Flexible Receptive Field Size</strong></li>
<li><strong>Stable Gradients</strong></li>
<li><strong>Low Memory Requirement for Training</strong></li>
<li><strong>Variable length inputs</strong></li>
</ol>
<h2 id="disadvantages-of-tcn">Disadvantages of TCN</h2>
<ol type="1">
<li><strong>Data storage during evaluation</strong>:</li>
<li><strong>Potential parameter change for a transfer of domain</strong>:</li>
</ol>
]]></content>
      <categories>
        <category>DL</category>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Network Architectures</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer</title>
    <url>/2021/12/25/transformer/</url>
    <content><![CDATA[<h1 id="attention-is-all-you-need">Attention is all you need</h1>
<p><img src="/images/ML/transformer_2.jpg" align="center" width=600></p>
<p><img src="/images/ML/transformer_4.jpg" align="center" width=600></p>
<h2 id="structure">Structure</h2>
<h3 id="encoder">Encoder</h3>
<p>The encoder consists of 6 identical layers. Each layer consists of two sub-layers: 1. Multihead self-attention 2. Feed forward fully connected network</p>
<p>residual connection (skip connection) are employed around each of the two sub-layers followed by layer normalization. The output of each sub-layer is:</p>
<p><span class="math display">\[\text{LayerNorm}(x + \text{Sublayer}(x))\]</span></p>
<p>Where <span class="math inline">\(\text{Sublayer}(x)\)</span> is the function implemented by the sub-layer itself. All sub-layers and embedding layers have output of dimension <span class="math inline">\(d_{model} = 512\)</span></p>
<h3 id="decoder">Decoder</h3>
<p>The decoder consists of 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack as key, value and the previous decoder output as query. The first self-attention sub-layer is modified to mask the future during training, this ensures that the predictions for position <span class="math inline">\(i\)</span> can depend only on the known outputs at positions less than <span class="math inline">\(i\)</span>.</p>
<h2 id="self-attention">Self Attention</h2>
<p>Given input <span class="math inline">\(X \in \mathbb{R}^{n_b \times n_s \times d_{model}}\)</span> and trainable parameters <span class="math inline">\(W_q \in \mathbb{R}^{d_{model} \times d_{k}}, W_k \in \mathbb{R}^{d_{model} \times d_{k}}, W_v \in \mathbb{R}^{d_{model} \times d_{v}}\)</span>, matrices query <span class="math inline">\(Q \in \mathbb{R}^{n_b \times n_s \times d_k}\)</span>, key <span class="math inline">\(K \in \mathbb{R}^{n_b \times n_s \times d_k}\)</span>, value <span class="math inline">\(V \in \mathbb{R}^{n_b \times n_s \times d_v}\)</span> are defined as:</p>
<p><span class="math display">\[Q = XW_q, \;\; K = XW_k, \;\; V = XW_v\]</span></p>
<h3 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h3>
<p><img src="/images/ML/transformer_1.jpg"></p>
<p><span class="math display">\[\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}}) V\]</span></p>
<p>The scale is used to prevent the large magnitude of the dot product so that the gradient of softmax vanishes.</p>
<h3 id="multi-head-self-attention">Multi-head Self Attention</h3>
<p><img src="/images/ML/transformer_3.jpg"></p>
<p>Instead of using a single attention function, <span class="math inline">\(h\)</span> of parallel attention functions with different <span class="math inline">\(W^q_i, W^k_i, W^v_i\)</span> are used and concatenated into single self attention matrix. The final self attention matrix is then multiplied by a weight matrix <span class="math inline">\(W_o \in \mathbb{R}^{hd_v \times d_{model}}\)</span>:</p>
<p><span class="math display">\[\text{MultiHead} (Q, K, V) = \text{Concat} (\text{head}_1, ...., \text{head}_h) W_o\]</span></p>
<p>Where</p>
<p><span class="math display">\[\text{head}_i = \text{Attention}(QW^Q_i, KW^k_i, VW^V_i)\]</span></p>
<p><strong>In this paper <span class="math inline">\(h = 8, d_{model} = 512, d_{model} / h = d_k = d_v = 64\)</span> and in a multi-head self-attention layer, all the keys, values and queries come from same place which is the output of the previous layer in the encoder. (i.e <span class="math inline">\(Q = K = V = X\)</span> where <span class="math inline">\(X\)</span> is the output from previous layer)</strong></p>
<h3 id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</h3>
<p>In addition to attention sub-layers, each of the layers in the encoder and decoder contains a fully connected feed-forward network. This consists of two linear transformations with a ReLU activation in between:</p>
<p><span class="math display">\[\text{FFN}(\mathbf{x}) = max(0, \mathbf{x} W_1 + \mathbf{b}_1) W_2 + \mathbf{b}_2\]</span></p>
<p>The parameters are different for different layers. The dimensionality of input and output is <span class="math inline">\(d_{model} = 512\)</span>, and the inner-layer has dimensionality <span class="math inline">\(d_{ff} = 2048, W_1 \in \mathbb{R}^{502 \times 2048}, W_2 \in \mathbf{2048 \times 502}\)</span></p>
<h3 id="positional-encoding">Positional Encoding</h3>
<p>Since the model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. Thus, we add <strong>positional encodings</strong> to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension <span class="math inline">\(d_{model}\)</span> as the embeddings, so that the two can be summed:</p>
<p><span class="math display">\[PE_{(pos, 2i)} = \sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\]</span> <span class="math display">\[PE_{(pos, 2i+1)} = \cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\]</span></p>
<p>Where <span class="math inline">\(i\)</span> is the dimension, <span class="math inline">\(pos\)</span> is the position. For example <span class="math inline">\(PE(1) = [\sin(\frac{1}{10000^{\frac{0}{d_{model}}}}), \cos(\frac{1}{10000^{\frac{2}{d_{model}}}}), \sin(\frac{1}{10000^{\frac{4}{d_{model}}}}) ....]\)</span></p>
<p>It has several properties:</p>
<ol type="1">
<li>For each time-step, it outputs a unique encoding.</li>
<li>The distance between two time-steps is consistent across sentences with different lengths.</li>
<li>Deterministic</li>
<li><span class="math inline">\(PE_{pos+k}\)</span> can be represented linearly using <span class="math inline">\(PE_{pos}\)</span>, so it generalizes easily to unseen length sequences.</li>
</ol>
<h2 id="ref">Ref</h2>
<p>https://jalammar.github.io/illustrated-transformer/</p>
<p>https://theaisummer.com/self-attention/</p>
<p>https://zhuanlan.zhihu.com/p/98641990</p>
<p>https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#the-intuition</p>
]]></content>
      <categories>
        <category>DL</category>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Network Architectures</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM</title>
    <url>/2021/07/19/svm/</url>
    <content><![CDATA[<h1 id="support-vector-machine">Support Vector Machine</h1>
<p>Given dataset <span class="math inline">\(D = \{(\mathbf{x}_1, y_1) ....., (\mathbf{x}_N, y_N); \; \mathbf{x} \in \mathbb{R}^m, \; y_i \in \{-1, 1\}\}\)</span>. Let <span class="math inline">\(\mathbf{w}^T \mathbf{x} + b = 0\)</span> be a hyperplane, we classify a new point <span class="math inline">\(\mathbf{x}_i\)</span> by</p>
<p><span class="math display">\[
\hat{y}_i (\mathbf{x}_i) =
\begin{cases}
\mathbf{w}^T \mathbf{x}_i + b \geq 0, \quad \;\;\; 1\\
\mathbf{w}^T \mathbf{x}_i + b &lt; 0, \quad -1\\
\end{cases}
\]</span></p>
<p>Suppose that our data is <strong>linear separable</strong>. Then, <span class="math inline">\(\exists\)</span> at least one possible combination of parameters <span class="math inline">\(\{\mathbf{w}, b\}\)</span>, such that:</p>
<p><span class="math display">\[\hat{\gamma}_i = y_i \hat{y}_i(\mathbf{x}_i) &gt; 0, \; \forall i=1, ...., N\]</span></p>
<p>When <span class="math inline">\(y_i = 1\)</span>, a confident classifier would have <span class="math inline">\(\hat{y}_i(\mathbf{x}_i)\)</span> as large as possible. On the other hand, when <span class="math inline">\(y_i = -1\)</span>, the confident classifier would have <span class="math inline">\(\hat{y}_i(\mathbf{x}_i)\)</span> as negative as possible. Thus, we want <span class="math inline">\(\hat{\gamma}_i\)</span> as large as possible, this <span class="math inline">\(\hat{\gamma}_i\)</span> is called <code>functional margin</code> associated with training example for specific set of parameters <span class="math inline">\(\{\mathbf{w}, b\}\)</span>. And <code>functional margin</code> of <span class="math inline">\(\{\mathbf{w}, b\}\)</span> is defined as minimum of these functions margins:</p>
<p><span class="math display">\[\hat{\gamma} = \min_{i=1, ..., N} \hat{\gamma}_i\]</span></p>
<p><strong>In support vector machines the decision boundary is chosen to be the one for which the functional margin (confidence) is maximized.</strong></p>
<h2 id="distance-to-plane">Distance to Plane</h2>
<p>Let <span class="math inline">\(\mathbf{x}_i\)</span> be a sample that has label <span class="math inline">\(y_i = 1\)</span>, thus, it is on the positive side of the hyperplane <span class="math inline">\(\mathbf{w}^T \mathbf{x} + b = 0\)</span>. Define <span class="math inline">\(r\)</span> to be the shortest distance between point <span class="math inline">\(\mathbf{x}_i\)</span> and the hyperplane. Then <span class="math inline">\(r\)</span> is the distance between <span class="math inline">\(\mathbf{x}_i\)</span> to its projection on the hyperplane <span class="math inline">\(\mathbf{x}^{\prime}_i\)</span>.</p>
<p><img src='/images/ML/svm_1.png' width="600"></p>
<p>Since <span class="math inline">\(\mathbf{w}\)</span> is the normal vector that is orthogonal to the plane and <span class="math inline">\(\frac{\mathbf{w}}{\|\mathbf{w}\|_2}\)</span> is the unit vector that represents its direction. We can write the <span class="math inline">\(r\)</span> as:</p>
<p><span class="math display">\[\mathbf{x}_i - \mathbf{x}^{\prime}_i = r \frac{\mathbf{w}}{\|\mathbf{w}\|_2}\]</span></p>
<p><span class="math display">\[\implies r = \frac{\mathbf{x}_i - \mathbf{x}^{\prime}_i}{\frac{\mathbf{w}}{\|\mathbf{w}\|_2}}\]</span></p>
<h2 id="goal">Goal</h2>
<p>The concept of the margin is intuitively simple: it is the distance of the separating hyperplane to the closest examples in the dataset, assuming that our dataset is <strong>linearly separable.</strong> That is:</p>
<span class="math display">\[\begin{aligned}
&amp;\max \quad &amp;&amp; \hat{\gamma}\\
&amp;\;\text{s.t} \quad &amp;&amp;y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq \hat{\gamma} \quad \quad \forall i=1, ...., N
\end{aligned}\]</span>
<p>This optimization problem is unbounded, because one can make the functional margin large by simply scaling the parameters by a constant <span class="math inline">\(c\)</span>, <span class="math inline">\(\{c\mathbf{w}, cb\}\)</span>:</p>
<p><span class="math display">\[y_i (c\mathbf{w}^T \mathbf{x}_i + cb) &gt; y_i (\mathbf{w}^T \mathbf{x}_i + b) = \hat{\gamma}\]</span></p>
<p>This has no effect on the decision plane because:</p>
<p><span class="math display">\[\mathbf{w}^T \mathbf{x}_i + b = c\mathbf{w}^T \mathbf{x}_i + cb = 0\]</span></p>
<p>Thus, we need to transform the optimization problem to <strong>maximize the distance between the samples and decision boundary</strong> instead of maximizing functional margin. Suppose we let all functional margins to be at least 1 (can easily achieve by multiplying parameters by a constant):</p>
<p><span class="math display">\[y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq 1\]</span></p>
<p><span class="math display">\[\implies \mathbf{w}^T \mathbf{x}_i + b \geq 1\]</span></p>
<p><span class="math display">\[\implies \mathbf{w}^T \mathbf{x}_i + b \leq -1\]</span></p>
<p>Then, for point <span class="math inline">\(\mathbf{x}_i\)</span> on <span class="math inline">\(\mathbf{w}^T \mathbf{x}_i + b = 1\)</span>, we have its distance to the decision plane:</p>
<p><span class="math display">\[\mathbf{w}^T \mathbf{x}_i + b - r \frac{\|\mathbf{w}\|^2_2}{\|\mathbf{w}\|_2} = 0\]</span></p>
<p><span class="math display">\[\implies r = \frac{1}{\|\mathbf{w}\|}\]</span></p>
<p>Then, we can formulate our objective as:</p>
<span class="math display">\[\begin{aligned}
&amp;\max_{\mathbf{w}, b} \quad &amp;&amp; \frac{1}{\|\mathbf{w}\|_2}\\
&amp;\;\text{s.t} \quad &amp;&amp;y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq 1 \quad \quad \forall i=1, ...., N
\end{aligned}\]</span>
<p>Which is equivalent to:</p>
<span class="math display">\[\begin{aligned}
&amp;\min_{\mathbf{w}, b} \quad &amp;&amp; \frac{1}{2}\|\mathbf{w}\|^2_2\\
&amp;\;\text{s.t} \quad &amp;&amp;y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq 1 \quad \quad \forall i=1, ...., N
\end{aligned}\]</span>
<p><br></p>
<p><img src='/images/ML/svm_2.png' width="600"></p>
<h2 id="soft-margin-svm">Soft Margin SVM</h2>
<h3 id="slack-variables">Slack Variables</h3>
<p>Notice, in the above formulation, we have hard constraints on the margins which do not allow misclassification of points. However, in real world, data points are rarely linear separable and there will be outliers in the dataset, we may wish to allow some examples to be on the wrong side of the hyperplane or to have margin less than 1 .</p>
<p><img src='/images/ML/svm_3.png' width="600"></p>
<p>To resolve this problem, we can introduce slack variables one for each data point to relax the hard constraints:</p>
<p><span class="math display">\[y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq 1 - \xi_i\]</span> <span class="math display">\[\quad\xi_i \geq 0, \; \; \forall i=1, ...., N\]</span></p>
<p>To encourage correct classification of the samples, we add <span class="math inline">\(\xi_i\)</span> to the objective:</p>
<span class="math display">\[\begin{aligned}
&amp;\min_{\mathbf{w}, b, \boldsymbol{\xi}} \quad &amp;&amp; \frac{1}{2}\|\mathbf{w}\|^2_2 + C\sum^{N}_{n=1} \xi_i\\
&amp;\;\text{s.t} \quad &amp;&amp;y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq 1 - \xi_i  \quad &amp;&amp;&amp;\forall i=1, ...., N\\
&amp; &amp;&amp; \xi_i \geq 0, &amp;&amp;&amp;\forall i=1, ...., N
\end{aligned}\]</span>
<p>Thus, sample points are now permitted to have margin less than 1, and if an example <span class="math inline">\(\mathbf{x}_i\)</span> has slack variable greater than 0, we would have penalty in the objective function <span class="math inline">\(C\xi_i\)</span>. The parameter <span class="math inline">\(C\)</span> controls the relative weighting between the twin goals of making the <span class="math inline">\(\|\mathbf{w}\|\)</span> small and of ensuring that most examples have functional margin at least 1.</p>
<p><br></p>
<h3 id="dual-problem">Dual Problem</h3>
<p>Using <strong>Lagrange Multiplier</strong>, we can transform the constrained problem into an unconstrained concave problem:</p>
<p><span class="math display">\[\max_{\boldsymbol{\alpha}, \boldsymbol{\eta}}\;\min_{\mathbf{w}, b, \boldsymbol{\xi}} \; \frac{1}{2}\|\mathbf{w}\|^2_2 + C\sum^{N}_{n=1} \xi_i - \sum^N_{i=1} \alpha_i [y_i (\mathbf{w}^T \mathbf{x}_i + b) - 1 + \xi_i] - \sum^{N}_{i=1} \eta_i \xi_i\]</span></p>
<p>Where the inner minimization is the dual function and the maximization w.r.t <span class="math inline">\(\alpha\)</span> is called dual problem.</p>
<h3 id="kkt">KKT</h3>
<p>For an unconstrained convex optimization problem, we know we are at global minimum if the gradient is zero. The KKT conditions are the equivalent conditions for the global minimum of a constrained convex optimization problem. <span class="math inline">\(\forall i=1, ...., N\)</span>:</p>
<ol type="1">
<li><p><strong>Stationarity</strong>, If the strong duality holds, <span class="math inline">\((\mathbf{w}^*, \boldsymbol{\alpha}^*)\)</span> is optimal, then <span class="math inline">\(\mathbf{w}^*\)</span> minimizes <span class="math inline">\(L(\mathbf{w}^*, \boldsymbol{\alpha}^*)\)</span> (same for <span class="math inline">\(b^*, \xi^*\)</span> which are formulated as constraints in the dual problem):</p>
<p><span class="math display">\[\nabla_{\mathbf{w}} L(\mathbf{w}^*, \boldsymbol{\alpha}^*) = 0\]</span> <span class="math display">\[\implies \mathbf{w}^* = \sum_{i=1}^{n} \alpha^*_i y_i \mathbf{x}_i\]</span></p></li>
<li><p><strong>Complementary Slackness</strong>: <span class="math display">\[\alpha_i [y_i (\mathbf{w}^T \mathbf{x}_i + b) - 1 + \xi_i] = 0\]</span></p></li>
<li><p><strong>Primal Feasibility</strong>: <span class="math display">\[y_i (\mathbf{w}^T \mathbf{x}_i + b) - 1 + \xi_i \geq 0\]</span> <span class="math display">\[\eta_i\xi_i = 0\]</span></p></li>
<li><p><strong>Dual Feasibility</strong>: <span class="math display">\[\alpha_i, \eta_i, \xi_i \geq 0\]</span></p></li>
</ol>
<h4 id="solving-dual-problem">Solving Dual Problem</h4>
<p>We now solve for the dual function by fixing <span class="math inline">\(\{\alpha_i\, \eta_i\}\)</span> (satisfying Stationarity condition):</p>
<p><span class="math display">\[\min_{\mathbf{w}, b, \boldsymbol{\xi}} \frac{1}{2}\|\mathbf{w}\|^2_2 + C\sum^{N}_{n=1} \xi_i - \sum^N_{i=1} \alpha_i [y_i (\mathbf{w}^T \mathbf{x}_i + b) - 1 + \xi_i] - \sum^{N}_{i=1} \eta_i \xi_i\]</span></p>
<span class="math display">\[\begin{aligned}
&amp; \frac{\partial L(\mathbf{w}, b, \boldsymbol{\xi})}{\partial \mathbf{w}} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0 \\
&amp; \implies \mathbf{w}^* = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \\
&amp; \frac{\partial L(\mathbf{w},, b, \boldsymbol{\xi})}{\partial b} =\sum_{i=1}^{n} \alpha_i y_i = 0 \\
&amp; \implies \sum_{i=1}^{n} \alpha_i y_i = 0 \\
&amp; \frac{\partial L(\mathbf{w}, b, \boldsymbol{\xi})}{\partial \xi_n} = C - \alpha_n - \eta_n = 0 \\
&amp; \implies \alpha_n = C - \eta_n
\end{aligned}\]</span>
<p>Substitute back to the original equation, we obtain the dual function:</p>
<p><span class="math display">\[g(\boldsymbol{\alpha}) = -\frac{1}{2}\sum_{i=1}^{N}\sum_{k=1}^{N}\alpha_i \alpha_k {\mathbf{x}_i}^T \mathbf{x}_k y_i y_k + \sum_{i=1}^{N} \alpha_i\]</span></p>
<p>Then, we have the dual problem:</p>
<span class="math display">\[\begin{aligned}
&amp; \underset{\boldsymbol{\alpha}}{\text{max}}
&amp; &amp;  g(\boldsymbol{\alpha}) = -\frac{1}{2}\sum_{i=1}^{N}\sum_{k=1}^{N}\alpha_i \alpha_k {\mathbf{x}_i}^T \mathbf{x}_k y_i y_k + \sum_{i=1}^{N} \alpha_i\\
&amp; \text{subject to}
&amp; &amp; 0 \leq \alpha_i \leq C \\
&amp; &amp; &amp; \sum_{i=1}^{n} \alpha_i y_i = 0 \\
\end{aligned}\]</span>
<p>This is a quadratic programming problem that we can solve using quadratic programming.</p>
<h3 id="interpretation">Interpretation</h3>
<p>We could conclude:</p>
<ol type="1">
<li><p>if <span class="math inline">\(0 &lt; \alpha_i &lt; C \implies y_i(w^T x_i + b) = 1 - \xi_i\)</span> Since <span class="math inline">\(\alpha_i = C - \mu_i, \mu_i \geq 0\)</span>, we have <span class="math inline">\(\xi_i =0 \implies\)</span> the points are with <span class="math inline">\(0 &lt; \alpha_i &lt; C\)</span> are on the margin</p></li>
<li><p>if <span class="math inline">\(\alpha_i = C\)</span></p>
<ul>
<li><span class="math inline">\(0 &lt; \xi_i &lt; 1\)</span>: the points are inside the margin on the correct side</li>
<li><span class="math inline">\(\xi_i = 1\)</span>: the points are on the decision boundary</li>
<li><span class="math inline">\(\xi_i &gt; 1\)</span>: the points are inside the wrong side of the margin and misclassified</li>
</ul></li>
<li><p>if <span class="math inline">\(\alpha_i = 0\)</span>, the points are not support vectors, have no affect on the weight.</p></li>
</ol>
<p>After finding the optimal values for <span class="math inline">\(\boldsymbol{\alpha}\)</span>, we obtain optimal <span class="math inline">\(\mathbf{w}^*\)</span> by solving:</p>
<p><span class="math display">\[\mathbf{w}^* = \sum_{i=1}^{n} \alpha^*_i y_i \mathbf{x}_i\]</span></p>
<p>We obtain optimal <span class="math inline">\(b^*\)</span> by realizing that the points on the margins have <span class="math inline">\(0 &lt; \alpha_i &lt; C\)</span>. Let <span class="math inline">\(\mathbf{x}_i\)</span> be one of those points, then:</p>
<p><span class="math display">\[{\mathbf{w^*}}^T \mathbf{x}_i + b = y_i\]</span></p>
<p>Let <span class="math inline">\(M\)</span> be the set of all points that lies exactly on the margin, a more stable solution is obtained by averaging over all points:</p>
<p><span class="math display">\[b^* = \frac{1}{N_m} \sum^{N_m}_{i=1} (y_i - {\mathbf{w^*}}^T\mathbf{x}_i)\]</span></p>
<h2 id="kernel-tricks">Kernel Tricks</h2>
<h1 id="implementation">Implementation</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> cvxopt <span class="keyword">import</span> matrix, solvers</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> qpsolvers <span class="keyword">import</span> solve_qp</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVM</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, c=<span class="number">1</span>, kernel=<span class="string">&#x27;linear&#x27;</span></span>):</span></span><br><span class="line">        self.c = c</span><br><span class="line">        self.kernel = kernel</span><br><span class="line">        self.b = <span class="literal">None</span></span><br><span class="line">        self.dual_coef_ = <span class="literal">None</span></span><br><span class="line">        self.decision_matrix = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        n, d = X.shape</span><br><span class="line">        y = y.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        yyt = np.matmul(y, y.T)</span><br><span class="line">        P = np.zeros((n, n))</span><br><span class="line">        q = matrix(-np.ones((n, <span class="number">1</span>)))</span><br><span class="line">        a = matrix(y.T, tc=<span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">        b = matrix([<span class="number">0.0</span>])</span><br><span class="line">        G = matrix(np.row_stack([np.diag([-<span class="number">1</span>] * n), np.diag([<span class="number">1</span>] * n)]), tc=<span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">        h = matrix(np.row_stack([np.array([<span class="number">0</span>] * n).reshape(n, <span class="number">1</span>),</span><br><span class="line">                                 np.array([self.c] * n).reshape(n, <span class="number">1</span>)]), tc=<span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                P[i][j] = self.apply_kernel(X[i], X[j])</span><br><span class="line"></span><br><span class="line">        P = matrix(P * yyt)</span><br><span class="line">        alpha = np.array(solvers.qp(P, q, G, h , a, b)[<span class="string">&#x27;x&#x27;</span>])</span><br><span class="line">        alpha[alpha &lt; np.mean(alpha) * <span class="number">0.1</span>] = <span class="number">0</span></span><br><span class="line">        temp_x = np.column_stack([X, alpha, y])</span><br><span class="line">        m = temp_x[(temp_x[:, -<span class="number">2</span>] &gt; <span class="number">0</span>) &amp; (temp_x[:, -<span class="number">2</span>] &lt; self.c)]</span><br><span class="line">        N_m = <span class="built_in">len</span>(m)</span><br><span class="line">        self.decision_matrix = m[:, :-<span class="number">2</span>]</span><br><span class="line">        self.b = <span class="number">0</span></span><br><span class="line">        self.dual_coef_ = m[:, -<span class="number">1</span>] * m[:, -<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">## get b</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N_m):</span><br><span class="line">            self.b += m[i, -<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(N_m):</span><br><span class="line">                self.b -= m[j, -<span class="number">2</span>] * m[j, -<span class="number">1</span>] * self.apply_kernel(m[i, :-<span class="number">2</span>], m[j, :-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        self.b = self.b / N_m</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply_kernel</span>(<span class="params">self, x_1, x_2</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.kernel == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x_1, x_2)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decision_function</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        pred_results = np.array([])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">            pred = self.b</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.decision_matrix)):</span><br><span class="line">                pred += self.dual_coef_[j] * self.apply_kernel(X[i], self.decision_matrix[j])</span><br><span class="line"></span><br><span class="line">            pred_results = np.append(pred_results, pred)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pred_results</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        pred_results = self.decision_function(X)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> np.where(pred_results &gt;= <span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="ref">Ref</h1>
<p>https://www.ccs.neu.edu/home/vip/teach/MLcourse/6_SVM_kernels/lecture_notes/svm/svm.pdf</p>
<p>http://www.cs.cmu.edu/~guestrin/Class/10701-S06/Slides/svms-s06.pdf</p>
<p>MML book</p>
<p>Lagrangian Duality for Dummies, David Knowles</p>
<p>PRML Chapter 7</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>time-series-3</title>
    <url>/2022/05/28/time-series-3/</url>
    <content><![CDATA[<h1 id="time-series-3">Time Series (3)</h1>
<h2 id="spectral-analysis-and-filtering">Spectral Analysis and Filtering</h2>
<p>We define a cycle as one complete period of a sine or cosine function defined over a unit time interval:</p>
<p><span class="math display">\[X_t = A\cos(2\pi\omega t + \phi) \quad \quad (4.1)\]</span></p>
<p>for <span class="math inline">\(t = 0, \pm 1, \pm 2, ...\)</span>, where:</p>
<ul>
<li><span class="math inline">\(\omega\)</span> is a <strong>frequency index</strong>, defined in cycles per unit time, so if <span class="math inline">\(\omega = 2\)</span>, for every 1 time unit, we have <span class="math inline">\(2\)</span> cycles, this is fixed.</li>
<li><span class="math inline">\(A\)</span> determining the height or <strong>amplitude</strong> of the function, this is <strong>random</strong>.</li>
<li><span class="math inline">\(\phi\)</span> determining the <strong>start point</strong> of the cosine function, this is <strong>random</strong>.</li>
</ul>
<p><br></p>
<p>Using the trigonometric identity, we can write above equation as:</p>
<p><span class="math display">\[X_t = U_1 \cos (2 \pi \omega t) + U_2 \sin (2 \pi \omega t) \quad \quad (4.2)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(U_1 = A \cos \phi\)</span> is often taken to be normally distributed random variable.</li>
<li><span class="math inline">\(U_2 = - A \sin \phi\)</span> is often taken to be normally distributed random variable.</li>
<li><span class="math inline">\(A = \sqrt{U_1^2 + U_2^2}\)</span></li>
<li><span class="math inline">\(\phi = \tan^{-1} (-\frac{U_2}{U_1})\)</span></li>
</ul>
<p><br></p>
<span id="more"></span>
<p>Now consider a generalization of above equation that allows mixtures of periodic series with multiple frequencies and amplitudes:</p>
<p><span class="math display">\[X_t = \sum^q_{k=1} [U_{k_1} \cos(2\pi\omega_k t) + U_{k_2}\sin (2\pi\omega_k t)] \quad \quad (4.3)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(U_{k_1}, U_{k_2}\)</span>, for <span class="math inline">\(k = 1, 2, ...., q\)</span> are independent zero-mean random variables with variances <span class="math inline">\(\sigma^2_k\)</span></li>
<li><span class="math inline">\(\omega_k\)</span> are distinct frequencies</li>
<li><span class="math inline">\(\gamma(h) = \sum^q_{k=1} \sigma^2_k \cos(2\pi \omega_k h) \quad \quad (4.4)\)</span></li>
<li><span class="math inline">\(\gamma(0) = \sum^{q}_{k=1} \sigma^2_k\)</span>, the variance of the process is the sum of each individual parts.</li>
</ul>
<p><br></p>
<h3 id="the-spectral-density">The Spectral Density</h3>
<h4 id="theorem-c1">Theorem C1:</h4>
<p>A function <span class="math inline">\(\gamma(h)\)</span>, for <span class="math inline">\(h = 0, \pm 1, \pm 2, ...\)</span> is <strong>non-negative-definite</strong> IFF it can be expressed as:</p>
<p><span class="math display">\[\gamma(h) = \int^{\frac{1}{2}}_{-\frac{1}{2}}e^{2\pi i \omega h} dF(\omega)\]</span></p>
<p>where <span class="math inline">\(F(\cdot)\)</span> is non-decreasing. The function <span class="math inline">\(F(\cdot)\)</span> is right continuous, bounded in <span class="math inline">\([-\frac{1}{2}, \frac{1}{2}]\)</span>, and uniquely determined by the conditions <span class="math inline">\(F(-\frac{1}{2}) = 0, F(\frac{1}{2}) = \gamma(0)\)</span></p>
<p><br></p>
<h4 id="theorem-c2">Theorem C2</h4>
<p>If <span class="math inline">\(X_t\)</span> is a mean-zero stationary process, with spectral distribution <span class="math inline">\(F(\omega)\)</span> as given</p>
<p><br></p>
<h4 id="property-4.1-spectral-representation-of-a-stationary-process">Property 4.1: Spectral Representation of a Stationary Process</h4>
<p>In non-technical terms, Theorem C2 states taht any stationary time series may be thought of, approximately, as the random superposition of sines and cosines oscillating at various frequencies.</p>
<p><br></p>
<h4 id="property-4.2-spectral-density">Property 4.2: Spectral Density</h4>
<p>If the autocovariance function, <span class="math inline">\(\gamma(h)\)</span>, of a stationary process satisfies:</p>
<p><span class="math display">\[\sum^\infty_{h=-\infty} |\gamma(h)| &lt; \infty \quad \quad (4.10)\]</span></p>
<p>then it has the representation:</p>
<p><span class="math display">\[\gamma(h) = \int^{\frac{1}{2}}_{-\frac{1}{2}}e^{2\pi i \omega h} f(\omega)d\omega \quad \quad h = 0, \pm 1, \pm 2, ... \quad \quad (4.11)\]</span></p>
<p>as the inverse transform of the spectral density, which has the representation:</p>
<p><span class="math display">\[f(\omega) = \sum^\infty_{h=-\infty} \gamma(h) e^{-2\pi i \omega h} \quad \quad -\frac{1}{2}\leq \omega \leq \frac{1}{2} \quad \quad (4.12)\]</span></p>
<p><span class="math inline">\(f(\omega)\)</span> is called the spectral density.</p>
<p><br></p>
<p>Since <span class="math inline">\(f(\omega) = f(- \omega)\)</span>, we can see that the spectral density is an even function of period one. Because of the evenness, we will typically only plot <span class="math inline">\(f(\omega)\)</span> for <span class="math inline">\(\omega \geq 0\)</span>. In addition, putting <span class="math inline">\(h=0\)</span>, we have:</p>
<p><span class="math display">\[\gamma(0) = Var[X_t] = \int^{\frac{1}{2}}_{-\frac{1}{2}} f(\omega) d\omega\]</span></p>
<p>which expresses the total variance as the integrated spectral density over all of the frequencies. <strong>When the conditions in property 4.2 are satisfied, the autocovariance function <span class="math inline">\(\gamma(h)\)</span> and the spectral density function <span class="math inline">\(f(\omega)\)</span> contain the same information</strong>.</p>
<p><br></p>
<h4 id="definition-4.1-discrete-fourier-transform-dft">Definition 4.1 Discrete Fourier Transform (DFT)</h4>
<p>Given data <span class="math inline">\(x_t, ...., x_n\)</span>, we define the <strong>discrete Fourier transform (DFT)</strong> to be:</p>
<p><span class="math display">\[d(\omega_j) = \frac{1}{\sqrt{n}} \sum^n_{t=1} x_t e^{-2\pi i \omega_j t}\]</span></p>
<p>for <span class="math inline">\(j = 0, 1, ...., n - 1\)</span>, the frequencies <span class="math inline">\(\omega_j = \frac{j}{n}\)</span> are called the <strong>Fourier or Fundamental frequencies</strong>.</p>
<p>For a inverse DFT, we have:</p>
<p><span class="math display">\[x_t = \frac{1}{\sqrt{n}} \sum^{n-1}_{j=0} d(\omega_j) e^{2\pi i \omega_j t}\]</span></p>
<p><br></p>
<h4 id="definition-4.2-periodogram">Definition 4.2: Periodogram</h4>
<p>Given data <span class="math inline">\(x_1, ...., x_n\)</span>, we define the periodogram to be:</p>
<p><span class="math display">\[I(\omega_j) = |d(\omega_j)|^2 = d(\omega_j)\overline{d(\omega_j)}\]</span></p>
<p>for <span class="math inline">\(j = 0, 1, 2, ...., n - 1\)</span>.</p>
<p>Notice that <span class="math inline">\(I(0) = n \bar{x}^2\)</span> where <span class="math inline">\(\bar{x}\)</span> is the sample mean.</p>
<p><br></p>
<h2 id="state-space-models">State Space Models</h2>
<p>In general, the state space model is characterized by two principles.</p>
<ul>
<li>There is a hidden or latent process <span class="math inline">\(X_t\)</span> called the state process, the state process is assumed to be a Markov process, this means that the feature <span class="math inline">\(\{X_s: s &gt; t\}\)</span> and the past <span class="math inline">\(\{X_s: s &lt; t\}\)</span> are independent conditional on the present <span class="math inline">\(X_t\)</span>.</li>
<li>The observations <span class="math inline">\(Y_t\)</span> are independent given the states <span class="math inline">\(X_t\)</span>.</li>
</ul>
<p>This means that the dependence among the observations is generated by current states <span class="math inline">\(X_t\)</span>.</p>
<h3 id="linear-gaussian-model">Linear Gaussian Model</h3>
<p>The <strong>linear Gaussian state space model</strong> or <strong>Dynamic linear model</strong>, in its basic form, employs an order one, <span class="math inline">\(p\)</span>-dimensional vector autoregression as the <strong>state equation</strong>,</p>
<p><span class="math display">\[X_t = \Phi X_{t-1} + W_t\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(W_t\)</span> are <span class="math inline">\(p \times 1\)</span> i.i.d, zero mean normal vectors with covariance matrix <span class="math inline">\(Q\)</span>, <span class="math inline">\(W_t \overset{i.i.d}{\sim} N_p(\boldsymbol{0}, Q)\)</span>.</li>
<li>The process starts with a normal vector <span class="math inline">\(X_0 \sim N_p(\boldsymbol{\mu_0}, \Sigma_0)\)</span>.</li>
<li><span class="math inline">\(p\)</span> is called <strong>state dimension</strong>.</li>
</ul>
<p><br></p>
<p>We assume we do not observe the state vector <span class="math inline">\(X_t\)</span> directly, but only a noisy version of it called <strong>observation equation</strong>:</p>
<p><span class="math display">\[Y_t = A_t X_t + v_t\]</span></p>
<p>Where</p>
<ul>
<li><span class="math inline">\(A_t\)</span> is a <span class="math inline">\(q \times p\)</span> <strong>measurement or observation matrix</strong>.</li>
<li><span class="math inline">\(Y_t\)</span> is <span class="math inline">\(q \times 1\)</span> which <span class="math inline">\(q\)</span> can be larger or smaller than <span class="math inline">\(p\)</span>.</li>
<li><span class="math inline">\(V_t \overset{i.i.d}{\sim} N_q(\boldsymbol{0}, R)\)</span> is the additive observation noise.</li>
</ul>
<p><br></p>
<h4 id="filtering-smoothing-forecasting">Filtering, Smoothing, Forecasting</h4>
<p>A primary aim of any analysis involving the state space model, would be to produce estimators for the underlying unobserved signal <span class="math inline">\(X_t\)</span>, given the data <span class="math inline">\(y_{1:s} = \{y_1, ...., y_s\}\)</span> to time <span class="math inline">\(s\)</span>, when:</p>
<ul>
<li><span class="math inline">\(s &lt; t\)</span>, the problem is called <strong>forecasting</strong>.</li>
<li><span class="math inline">\(s = t\)</span>, the problem is called <strong>filtering</strong>.</li>
<li><span class="math inline">\(s &gt; t\)</span>, the problem is called <strong>smoothing</strong>.</li>
</ul>
<p>Notations throughout this chapter:</p>
<ul>
<li><span class="math inline">\(x_t^s = E[X_t | y_{1:s}]\)</span></li>
<li><span class="math inline">\(P^s_{t1, t2} = E[(X_{t_1} - x^s_{t_1}) (X_{t_2} - x^s_{t_2})^T)]\)</span>, when <span class="math inline">\(t_1 = t_2\)</span>, we write <span class="math inline">\(P^s_{t1}\)</span></li>
</ul>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>topology</title>
    <url>/2021/08/20/topology/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Time Series (2)</title>
    <url>/2021/11/19/time-series-2/</url>
    <content><![CDATA[<h1 id="time-series-arima">Time Series (ARIMA)</h1>
<h2 id="autoregressive-moving-average-models-arma">Autoregressive Moving Average Models (ARMA)</h2>
<h3 id="autoregressive-models">Autoregressive Models</h3>
<p>Autoregressive models are based on the idea that the current value of the series <span class="math inline">\(X_t\)</span> can be explained as a function of <span class="math inline">\(p\)</span> past values, <span class="math inline">\(X_{t-1}, X_{t-2}, ..., X_{t-p}\)</span> where <span class="math inline">\(p\)</span> determines the number of steps into the past needed to forecast the current value.</p>
<p>An autoregressive model of order <span class="math inline">\(p\)</span>, abbreviated <span class="math inline">\(AR(p)\)</span> with <span class="math inline">\(E[X_t] = 0\)</span>, is of the form:</p>
<p><span class="math display">\[X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + ... + \phi_p X_{t-p} + W_t\]</span></p>
<p>Where <span class="math inline">\(X_t\)</span> is stationary, <span class="math inline">\(\phi_1, ..., \phi_p \neq 0\)</span> are constants, <span class="math inline">\(W_t\)</span> is a Gaussian white noise series with mean zero and variance <span class="math inline">\(\sigma^2_w\)</span>. <strong>We assume above equation <span class="math inline">\(X_t\)</span> has mean zero</strong>, if it has non zero mean <span class="math inline">\(\mu\)</span>, we can replace it by:</p>
<p><span class="math display">\[X_t - \mu = \phi(X_{t-1} - \mu) + \phi_2(X_{t-2} - \mu) + ... + \phi_p (X_{t-p} - \mu) + W_t\]</span> <span class="math display">\[\implies X_t = \alpha + \phi_1 X_{t-1} + \phi_2 X_{t-2} + ... + \phi_p X_{t-p} + W_t\]</span></p>
<p>Where <span class="math inline">\(\alpha = \mu(1 - \phi_1 - ... - \phi_p)\)</span>.</p>
<p>We can also use the backshift operator to rewrite the zero mean <span class="math inline">\(AR(p)\)</span> process as:</p>
<p><span class="math display">\[(1 - \phi_1 B - \phi_2 B^2 - ... - \phi_p B^p) X_t = W_t\]</span></p>
<p>or using <strong>autoregressive operator</strong>:</p>
<p><span class="math display">\[\phi(B)X_t = W_t\]</span></p>
<span id="more"></span>
<h4 id="autoregressive-operator">Autoregressive Operator</h4>
<p>The Autoregressive operator is defined to be:</p>
<p><span class="math display">\[\phi_p(B) = 1 - \phi_1 B - \phi_2 B^2 - ... - \phi_p B^p\]</span></p>
<p><br></p>
<p>We can write the <span class="math inline">\(AR\)</span> models as a <strong>linear process</strong>. Start with <span class="math inline">\(AR(1)\)</span> with zero mean, given by <span class="math inline">\(X_t = \phi_1 X_{t-1} + W_t\)</span> and iterating backwards <span class="math inline">\(k\)</span> times, we get:</p>
<span class="math display">\[\begin{aligned}
X_t &amp;= \phi_1 X_{t-1} + W_t = \phi (\phi X_{t-2} + W_{t-1}) + W_t\\
&amp;= \phi^2 X_{t-2} + \phi W_{t-1} + W_t\\
&amp; \; .\\
&amp; \; .\\
&amp; \; .\\
&amp;= \phi^k X_{t-k} + \sum^{k-1}_{j=0}\phi^j W_{t-j}\\
\end{aligned}\]</span>
<p>If we keep iterating, we have:</p>
<p><span class="math display">\[X_t = \sum^{\infty}_{j=0} \phi^j W_{t-j}\]</span></p>
<p>If <span class="math inline">\(|\phi_j| &lt; 1\)</span>, we have the infinite sum defined and the process is a linear process (with <span class="math inline">\(\psi_j = \phi^j\)</span>).</p>
<p>To calculate the mean, autocovariance and autocorrelation of the <span class="math inline">\(AR(1)\)</span> process:</p>
<p><strong>Mean</strong>:</p>
<p><span class="math display">\[E[\sum^{\infty}_{j=0} \phi^j W_{t-j}] = 0\]</span></p>
<p><strong>Autocovariacne</strong></p>
<p><span class="math display">\[\gamma(h) = \sigma^2_w \sum^\infty_{j=0} \phi^{j + h} \phi^{j} = \sigma^2_w \phi^h \sum^\infty_{j=0} \phi^{2j} = \frac{\sigma^2_w \phi^h}{1 - \phi^2}, \;\; h \geq 0\]</span></p>
<p><strong>Autocorrelation</strong>:</p>
<p><span class="math display">\[\rho(h) = \frac{\gamma(h)}{\gamma(0)} = \phi^h\]</span></p>
<p><img src="/images/RL/background/ts_3_1_1.png" width="600"></p>
<h3 id="moving-average-models">Moving Average Models</h3>
<p>The moving average model of order <span class="math inline">\(q\)</span>, abbreviated as <span class="math inline">\(MA(q)\)</span>, assumes the white noise <span class="math inline">\(W_t\)</span> on the right-hand side of the defining equation are combined linearly to form the observed data.</p>
<p><br></p>
<p>The <strong>Moving Average</strong> or <span class="math inline">\(MA(q)\)</span> model is defined to be:</p>
<p><span class="math display">\[X_t = W_t + \theta_1W_{t-1} + \theta_2 W_{t-2} + ... + \theta_q W_{t-q}\]</span></p>
<p>Where there are <span class="math inline">\(q\)</span> lags in the moving average and <span class="math inline">\(\theta_1, ..., \theta_q (\theta_q \neq 0)\)</span> are parameters. Assume <span class="math inline">\(W_{t}\)</span> is a Gaussian white noise series with mean zero and variance <span class="math inline">\(\sigma^2_w\)</span>.</p>
<p><br></p>
<p>The system is the same as the linear process with <span class="math inline">\(\psi_j = \theta_j, \psi_0 = 1, \; \; \forall j=0, 1, ..., q\)</span> and <span class="math inline">\(\psi_j = 0\)</span> for all other values of <span class="math inline">\(j\)</span>.</p>
<h4 id="moving-average-operator">Moving Average Operator</h4>
<p>The <strong>Moving Average Operator</strong> is:</p>
<p><span class="math display">\[\theta_q(B) = 1 + \theta_1 B + \theta_2 B^2 + .... + \theta_q B^q\]</span></p>
<p>The model can be written in terms of operator:</p>
<p><span class="math display">\[X_t = \theta_q(B) W_t\]</span></p>
<p>Unlike the autoregressive process, <strong>the moving average process is stationary for any values of <span class="math inline">\(\theta\)</span>.</strong></p>
<p><br></p>
<p>Consider the <span class="math inline">\(MA(1)\)</span> model <span class="math inline">\(X_t = W_t + \theta W_{t-1}\)</span>. Then <span class="math inline">\(E[X_t] = 0\)</span> and the autocovariance:</p>
<p><span class="math display">\[\gamma(0) = (\psi_0^2 + \psi_1^2)\sigma^2_w = (1 + \theta^2)\sigma^2_w\]</span> <span class="math display">\[\gamma(1) = (\psi_0\psi_1 + 0 * \psi_1) \sigma^2_w = \theta\sigma^2_w\]</span> <span class="math display">\[\gamma(i) = 0, \;\; \forall i &gt; 1\]</span></p>
<p>The autocorrelation:</p>
<p><span class="math display">\[\rho(1) = \frac{\theta}{1 + \theta^2}\]</span> <span class="math display">\[\rho(i) = 0, \;\; \forall i &gt; 1\]</span></p>
<p>In contrast with <span class="math inline">\(AR(1)\)</span> model, the autocorrelation only exists between <span class="math inline">\(X_t, X_{t-1}\)</span> and <span class="math inline">\(|\rho(1)| \leq 0.5, \; \forall \theta\)</span></p>
<p><img src="/images/RL/background/ts_3_1_2.png" width="600"></p>
<h3 id="altogether-arma">Altogether: ARMA</h3>
<p>We now proceed with the general development of autoregressive, moving average and mixed autoregressive moving average models for stationary series.</p>
<p><br></p>
<p>A time series <span class="math inline">\(\{X_t; \; t=0, \pm 1, \pm 2, ....\}\)</span> is <span class="math inline">\(\mathbf{ARMA(p, q)}\)</span> if it is stationary and:</p>
<p><span class="math display">\[X_t = \phi_1 X_{t-1} + ... + \phi_p X_{t-p} + W_t + \theta_1 W_{t-1} + .... + \theta_q W_{t-q}\]</span> <span class="math display">\[\phi(B)X_t = \theta(B) W_t\]</span></p>
<p>With <span class="math inline">\(W_t\)</span> being a Gaussian white noise with mean zero, variance <span class="math inline">\(\sigma^2_w\)</span> and <span class="math inline">\(\theta_q \neq 0\)</span>, <span class="math inline">\(\phi_q \neq 0\)</span> and <span class="math inline">\(\sigma^2_w &gt; 0\)</span>. The parameters <span class="math inline">\(p, q\)</span> are called the autoregressive and moving average orders respectively. If <span class="math inline">\(X_t\)</span> has non-zero mean <span class="math inline">\(\mu\)</span>, we set <span class="math inline">\(\alpha = \mu(1 - \phi_1 - .... - \phi_p)\)</span> and write the model as:</p>
<p><span class="math display">\[X_t = \alpha + \phi_1 X_{t-1} + ... + \phi_p X_{t-p} + W_t + \theta_1 W_{t-1} + .... + \theta_q W_{t-q}\]</span></p>
<p><br></p>
<p>Problems with general definitions of <span class="math inline">\(\mathbf{ARMA(p, q)}\)</span>:</p>
<ol type="1">
<li>Parameter redundant models</li>
<li>Stationary AR models that depend on the future (Causal)</li>
<li>MA models that are not unique (Invertibility)</li>
</ol>
<p>To overcome these problems, we will require some additional restrictions on the model parameters.</p>
<h4 id="ar-and-ma-polynomials">AR and MA Polynomials</h4>
<p><img src="/images/RL/background/ts_3_2_1.png" width="600"></p>
<p>To address the parameter redundancy, we will henceforth refer to an <span class="math inline">\(ARMA(p, q)\)</span> model to mean that <strong>it is in its simplest form</strong>. That is, in addition to the original definition, we will also require that <span class="math inline">\(\phi(z)\)</span> and <span class="math inline">\(\theta(z)\)</span> have no common factors (<span class="math inline">\(z\)</span> is often <span class="math inline">\(B\)</span> the backshift operator, <strong>we can treat <span class="math inline">\(B\)</span> as complex number here</strong>).</p>
<blockquote>
<p>The process <span class="math display">\[X_t = 0.5X_{t-1} - 0.5W_{t-1} + W_t \implies (1 - 0.5B)X_t = (1 - 0.5B)W_t \implies X_t = W_t\]</span> is not <span class="math inline">\(ARMA(1, 1)\)</span> process because the original process has common factor <span class="math inline">\((1 - 0.5B)\)</span>. In its reduced form, <span class="math inline">\(X_t\)</span> is a white noise.</p>
</blockquote>
<h4 id="causality">Causality</h4>
<p>An <span class="math inline">\(ARMA(p, q)\)</span> model is said to be <strong>causal</strong>, if the time series <span class="math inline">\(\{X_t; t = 0, \pm 1, \pm 2 ...\}\)</span> can be written as a one-sided linear process:</p>
<p><span class="math display">\[X_t = \sum^\infty_{j=0} \psi_jW_{t-j} = \psi (B) W_t\]</span></p>
<p>Where <span class="math inline">\(\psi(B) = \sum^\infty_{j=0} \psi_j B^j\)</span> and <span class="math inline">\(\sum^\infty_{j=0} |\psi_j| &lt; \infty\)</span>, we set <span class="math inline">\(\psi_0 = 1\)</span></p>
<h5 id="property-3.1-causality-of-an-armap-q-process">Property 3.1 Causality of an <span class="math inline">\(ARMA(p, q)\)</span> Process</h5>
<p>An <span class="math inline">\(ARMA(p, q)\)</span> model is causal if and only if <span class="math inline">\(\phi(z) \neq 0\)</span> for <span class="math inline">\(|z| \leq 1\)</span>. The coefficient of the linear process above can be determined by solving:</p>
<p><span class="math display">\[\psi(z) = \sum^\infty_{j=0} \psi_j z^j = \frac{\theta(z)}{\phi(z)}, \;\; |z| \leq 1\]</span></p>
<p>Another way to phrase the property is that an <span class="math inline">\(ARMA(p, q)\)</span> process is <strong>causal</strong> only when the roots of <span class="math inline">\(\phi(z)\)</span> lie outside the unit circle:</p>
<p><span class="math display">\[\phi(z) = 0 \implies |z| &gt; 1\]</span></p>
<blockquote>
<p>Consider the <span class="math inline">\(AR(1)\)</span> process: <span class="math display">\[X_t = \phi X_{t-1} + W_t\]</span> This process is causal only when <span class="math inline">\(|\phi| &lt; 1\)</span>. Equivalently, the process is causal only when the root of <span class="math inline">\(\phi(z) = 1 - \phi z = 0\)</span> is bigger than one in absolute value. That is: <span class="math display">\[1 - \phi z = 0 \implies z = \frac{1}{\phi}\]</span> Since <span class="math inline">\(|\phi| &lt; 1\)</span>, we have <span class="math inline">\(|z| &gt; 1\)</span></p>
</blockquote>
<h4 id="invertible-and-uniqueness">Invertible and Uniqueness</h4>
<p>To address the problem of uniqueness, we choose the model that allows an infinite autoregressive representation.</p>
<p><br></p>
<p>An <span class="math inline">\(ARMA(p, q)\)</span> model is said to be <strong>invertible</strong>, if the time series <span class="math inline">\(\{X_t; t = 0, \pm 1, \pm 2 ...\}\)</span> can be written as:</p>
<p><span class="math display">\[\pi(B)X_t = \sum^\infty_{j=0} \pi_j X_{t-j} = W_t\]</span></p>
<p>Where <span class="math inline">\(\pi(B) = \sum^\infty_{j=0} \pi_j B^j\)</span> and <span class="math inline">\(\sum^\infty_{j=0} |\pi_j| &lt; \infty\)</span>. We set <span class="math inline">\(\pi_0 = 1\)</span></p>
<h5 id="property-3.2-invertibility-of-an-armap-q-process">Property 3.2 Invertibility of an <span class="math inline">\(ARMA(p, q)\)</span> Process</h5>
<p>An <span class="math inline">\(ARMA(p, q)\)</span> model is invertible if and only if <span class="math inline">\(\theta(z) \neq 0\)</span> for <span class="math inline">\(|z| \leq 1\)</span>. The coefficient <span class="math inline">\(\pi_j\)</span> above can be determined by solving:</p>
<p><span class="math display">\[\pi(z) = \sum^\infty_{j=0} \pi_j z^j = \frac{\phi(z)}{\theta(z)}, \;\; |z| \leq 1\]</span></p>
<p>Another way to phrase the property is that an <span class="math inline">\(ARMA(p, q)\)</span> process is <strong>invertible</strong> only when the roots of <span class="math inline">\(\theta(z)\)</span> lies outside the unit circle:</p>
<p><span class="math display">\[\theta(z) = 0 \implies |z| &gt; 1\]</span></p>
<blockquote>
<p>Consider the process: <span class="math display">\[X_t = 0.4 X_{t-1} + 0.45 X_{t-2} + W_t + W_{t-1} + 0.25 W_{t-2}\]</span> In operator form: <span class="math display">\[\phi(B)X_t = \theta(B)W_t\]</span> Where: <span class="math display">\[\phi(B) = 1 - 0.4B - 0.45 B^2\]</span> <span class="math display">\[\theta(B) = 1 + B + 0.25 B^2\]</span> At first, this appears to be an <span class="math inline">\(ARMA(2, 2)\)</span> process: <span class="math display">\[\phi(z) = (1 + 0.5z) (1 - 0.9z) \implies |z| &gt; 1\]</span> <span class="math display">\[\theta(z) = (1 + 0.5z)^2 \implies |z| &gt; 1\]</span> however, the polynomial has common factor <span class="math inline">\((1 + 0.5z)\)</span>, so the model is not an <span class="math inline">\(ARMA(2, 2)\)</span> process. After cancellation, the model is an <span class="math inline">\(ARMA(1, 1)\)</span> model. It is causal and invertible. Using properties 3.2 and 3.1, we can find the coefficients for linear process: <span class="math display">\[\phi(z) \psi(z) = \theta(z) \implies (1 - 0.9z) (\psi_0 + \psi z + ...) = (1 + 0.5z) \implies X_t = W_t + 1.4 \sum^\infty_{j=1} 0.9^{j-1}W_{t-j}\]</span> <span class="math display">\[\theta(z) \psi(z) = \phi(z) \implies X_t = 1.4\sum^\infty_{j=1} (-0.5)^{j-1} X_{t-j} + W_t\]</span></p>
</blockquote>
<p><br></p>
<h3 id="difference-equations">Difference Equations</h3>
<p>The study of the behavior of <span class="math inline">\(ARMA\)</span> process and their ACFs is greatly enhanced by a basic knowledge of <strong>difference equations</strong>.</p>
<p><img src="/images/RL/background/ts_3_3_1.png"></p>
<h4 id="homogeneous-difference-equation-of-order-1">Homogeneous Difference Equation of Order 1</h4>
<p>Suppose we have a sequence of numbers <span class="math inline">\(u_0, u_1, ....\)</span> s.t:</p>
<p><span class="math display">\[u_n - \alpha u_{n-1} = 0, \;\; \alpha \neq 0, \; n = 1, 2, ....\]</span></p>
<p>This equation represents a homogeneous difference equation of order 1. To solve the equation, we write:</p>
<p><span class="math display">\[u_1 = \alpha u_0\]</span> <span class="math display">\[u_2 = \alpha u_1 = \alpha^2 u_0\]</span> <span class="math display">\[u_n = \alpha^n u_0\]</span></p>
<p>Given the initial condition <span class="math inline">\(u_0 = c\)</span>, we may solve <span class="math inline">\(u_n = \alpha^n c\)</span>. In operator notation:</p>
<p><span class="math display">\[u_n - \alpha u_{n-1} = 0 \implies (1 - \alpha B) u_n = 0\]</span></p>
<p>The polynomial associated with this is <span class="math inline">\(\alpha(z) = 1 - \alpha z\)</span>. We know that <span class="math inline">\((1 - \alpha z) = 0 \implies z = \frac{1}{\alpha} \implies \alpha = \frac{1}{z}\)</span>. Thus, a solution can be obtained given the initial condition <span class="math inline">\(u_0 = c\)</span>:</p>
<p><span class="math display">\[u_n = \alpha^n c = (z^{-1})^n c\]</span></p>
<p>If we know the root <span class="math inline">\(z\)</span>, we will know the solution to the equation. In other words, the solution ot the difference equation above depends only on the initial condition and the inverse of the root to the associated polynomial <span class="math inline">\(\alpha(z)\)</span>.</p>
<h4 id="homogeneous-difference-equation-of-order-2">Homogeneous Difference Equation of Order 2</h4>
<p>Suppose that the sequence satisfies:</p>
<p><span class="math display">\[u_n - \alpha_1 u_{n-1} - \alpha_2 u_{n-2} = 0, \;\; \alpha_2 \neq 0, \; n=2, 3, ...\]</span></p>
<p>This equation is a homogeneous difference equation of order 2. The corresponding polynomial is:</p>
<p><span class="math display">\[\alpha(z) = 1 - \alpha_1 z - \alpha_2 z^2\]</span></p>
<p>which has two roots say <span class="math inline">\(z_1, z_2\)</span> s.t <span class="math inline">\(\alpha(z_1) = \alpha(z_2) = 0\)</span>. We will consider 2 cases:</p>
<h5 id="case-1-z_1-neq-z_2">Case 1: <span class="math inline">\(z_1 \neq z_2\)</span></h5>
<p>In this case, the general solution to the difference equation is:</p>
<p><span class="math display">\[u_n = c_1 z_1^{-n} + c_2 z_2^{-n}\]</span></p>
<p>Given two initial conditions <span class="math inline">\(u_0, u_1\)</span>, we may solve for <span class="math inline">\(c_1, c_2\)</span>:</p>
<p><span class="math display">\[u_0 = c_1 + c_2\]</span> <span class="math display">\[u_1 = c_1 z_1^{-1} + c_2 z_2^{-1}\]</span></p>
<p>In case of distinct roots, the solution to the homogeneous difference equation of degree two is:</p>
<p><span class="math display">\[u_n = z_1^{-n} \times \text{(a polynomial in $n$ of degree $m_1 - 1$)} + z_2^{-n} \times \text{(a polynomial in $n$ of degree $m_2 - 1$)}\]</span></p>
<p>Where <span class="math inline">\(m_1\)</span> is the multiplicity of the root <span class="math inline">\(z_1\)</span> and <span class="math inline">\(m_2\)</span> is the multiplicity of the root <span class="math inline">\(z_2\)</span>. In this case <span class="math inline">\(m_1 = m_2 = 1\)</span> (zero degree polynomial is represented as <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span>)</p>
<h5 id="case-2-z_1-z_2-z_0">Case 2: <span class="math inline">\(z_1 = z_2 = z_0\)</span></h5>
<p>In this case, the general solution to the difference equation is:</p>
<p><span class="math display">\[u_n = z_0^{-n} (c_1 + c_2 n)\]</span></p>
<p>Given two initial conditions <span class="math inline">\(u_0, u_1\)</span>, we may solve for <span class="math inline">\(c_1, c_2\)</span>:</p>
<p><span class="math display">\[u_0 = c_1, u_1 = (c_1 + c_2)z_0^{-1}\]</span></p>
<p>In the case of repeated root, the solution is:</p>
<p><span class="math display">\[u_n = z_0^{-n} \times \text{(a polynomial in $n$ of degree $m_0 - 1$)}\]</span></p>
<p>Where <span class="math inline">\(m_0\)</span> is the multiplicity of the root <span class="math inline">\(z_0\)</span> that is <span class="math inline">\(m_0 = 2\)</span> (first degree polynomial is represented as <span class="math inline">\(c_1 + c_2 n\)</span>)</p>
<h3 id="autocorrelation-and-partial-autocorrelation">Autocorrelation and Partial Autocorrelation</h3>
<p>For a causal <span class="math inline">\(ARMR(p, q)\)</span> model, <span class="math inline">\(\phi(B)X_t = \theta(B)W_t\)</span>, where the roots of <span class="math inline">\(\phi(z)\)</span> are outside of unit circle, write:</p>
<p><span class="math display">\[X_t  = \sum^{\infty}_{j=0} \psi_j W_{t-j}\]</span></p>
<p>It follows immediately that <span class="math inline">\(E[X_t] = 0\)</span> and the autocovariance function of <span class="math inline">\(X_t\)</span> can be write as:</p>
<p><span class="math display">\[\gamma(h) = Cov(X_{t+h}, X_{t}) = \sigma^2_w \sum^{\infty}_{j=0} \psi_j \psi_{j+h}, \; \; h\geq 0\]</span></p>
<p>We could obtain a homogeneous difference equation direcrtly in terms of <span class="math inline">\(\gamma(h)\)</span> to solve for the <span class="math inline">\(\psi\)</span> weights. First, we write:</p>
<span class="math display">\[\begin{aligned}
\gamma(h) &amp;= Cov(X_{t+h}, X_{t}) \\
&amp;= Cov(\sum^{p}_{j=1} \phi_j X_{t+h-j} + \sum^{q}_{j=0} \theta_j W_{t+h-j}, X_t)\\
&amp;= \sum^{p}_{j=1} \phi_j Cov(X_{t+h-j}, X_t) + \sum^p_{j=0} \theta_j Cov(W_{t+h-j}, \sum^{\infty}_{k=0}\psi_k W_{t-k})\\
&amp;= \sum^{p}_{j=1} \phi_j \gamma(h - j) + \sum^p_{j=h}\theta_j \sigma^2_w \psi_{j-h}
\end{aligned}\]</span>
<p>Where, white noise with different index has zero covariance:</p>
<p><span class="math display">\[Cov(W_{t+h-j}, \sum^{\infty}_{k=0}\psi_k W_{t-k}) = \psi_{j-h} \sigma^2_w\]</span></p>
<p>Then we can write the general difference equation of the autocovariance function:</p>
<p><span class="math display">\[\gamma(h) - \phi_1\gamma(h - 1) - ... - \phi_p\gamma(h - p) = 0, \;\; h \geq \max(p, q + 1)\]</span></p>
<p>With initial conditions:</p>
<p><span class="math display">\[\gamma(h) -  \sum^{p}_{j=1} \phi_j \gamma(h - j) = \sum^p_{j=h}\theta_j \sigma^2_w \psi_{j-h}, \;\; 0 \leq h \leq \max(p, q)\]</span></p>
<p>Dividing the <span class="math inline">\(\gamma(h)\)</span> by <span class="math inline">\(\gamma(0)\)</span>, we have the ACF.</p>
<h4 id="partial-autocorrelation-function-pacf">Partial Autocorrelation Function (PACF)</h4>
<p>Consider a causal <span class="math inline">\(AR(1)\)</span> model <span class="math inline">\(X_t = \phi X_{t-1} + W_t\)</span>, the covariance function for lag 2 is:</p>
<p><span class="math display">\[\gamma(2) = \frac{\sigma^2_w \phi^2}{1 - \phi^2} = \sigma^2_w \gamma(0)\]</span></p>
<p>The correlation between <span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_{t-2}\)</span> is not zero, as it would be for <span class="math inline">\(MA(1)\)</span> process, because <span class="math inline">\(X_t\)</span> is dependent on <span class="math inline">\(X_{t-2}\)</span> through <span class="math inline">\(X_{t-1}\)</span>. Suppose we break this chain of dependence by removing the effect of <span class="math inline">\(X_{t-1}\)</span>, in other words, we consider the correlation between <span class="math inline">\(X_{t} - \phi X_{t-1}\)</span> and <span class="math inline">\(X_{t-2} - \phi X_{t-1}\)</span>, because it is the correlation between <span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_{t-2}\)</span> with the linear dependence of each on <span class="math inline">\(X_t\)</span> removed. In this way, we have broken the dependence chain between <span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_{t-2}\)</span>:</p>
<p><span class="math display">\[Cov(X_{t} - \phi X_{t-1}, X_{t-2} - \phi X_{t-1}) = 0\]</span></p>
<p>Hence, the tool we need is <strong>partial autocorrelation</strong>, which is the correlation between <span class="math inline">\(X_s, X_t\)</span> with everything in the middle removed.</p>
<p><br></p>
<p>The <strong>partial autocorrelation function (PACF)</strong> of a stationary process <span class="math inline">\(X_t\)</span>, denoted <span class="math inline">\(\phi_{hh}\)</span>, for <span class="math inline">\(h = 1, 2, ...\)</span> is:</p>
<p><span class="math display">\[\phi_{11} = \rho(1)\]</span> <span class="math display">\[\phi_{hh} = Corr(X_{t+h} - \hat{X}_{t+h}, X_{t} - \hat{X}_{t}), \;\; h \geq 2\]</span></p>
<p>Where <span class="math inline">\(\hat{X}_{t+h}\)</span> denotes the regression of a zero mean stationary time series <span class="math inline">\(X_{t+h}\)</span> on <span class="math inline">\(\{X_{t+h-1}, ...., X_{t+1}\}\)</span> which we write as:</p>
<p><span class="math display">\[\hat{X}_{t+h} = \beta_1 X_{t+h-1} + \beta_2 X_{t+h-2} + .. + \beta_{h-1} X_{t+1}\]</span></p>
<p>And <span class="math inline">\(\hat{X}_t\)</span> denotes the regression of <span class="math inline">\(X_t\)</span> on <span class="math inline">\(\{X_t, ...., X_{t+h-1}\}\)</span>:</p>
<p><span class="math display">\[\hat{X}_t = \beta_1 X_{t+1} + \beta_2 X_{t+2} + .. + \beta_{h-1} X_{t+h-1}\]</span></p>
<p>These <span class="math inline">\(\beta\)</span> are the same for both regressions and are found by minimizing the expected mean squared error:</p>
<p><span class="math display">\[E[X_{t-h} - \sum^{h-1}_{j=1}\beta_j X_{t+j}]^2\]</span></p>
<p>Both <span class="math inline">\(X_{t+h} - \hat{X}_{t+h}\)</span> and <span class="math inline">\(X_{t} - \hat{X}_{t}\)</span> are uncorrelated with <span class="math inline">\(\{X_{t+1}, ..., X_{t+h-1}\}\)</span>. The PACF, <span class="math inline">\(\phi_{hh}\)</span> is <strong>the correlation between <span class="math inline">\(X_{t+h}\)</span> and <span class="math inline">\(X_t\)</span> with the linear dependence of <span class="math inline">\(\{X_{t+1}, ..., X_{t+h-1}\}\)</span> on each removed</strong>.</p>
<blockquote>
<p>Consider the PACF of the <span class="math inline">\(AR(1)\)</span> process given by <span class="math inline">\(X_t = \phi X_{t-1} + W_t\)</span> with <span class="math inline">\(|\phi| &lt; 1\)</span>. By definition, <span class="math inline">\(\phi_{11} = \rho(1) = \phi\)</span>. To calculate <span class="math inline">\(\phi_{22}\)</span>, consider regression of <span class="math inline">\(\hat{X}_{t+2} = \beta X_{t+1}\)</span>. We choose <span class="math inline">\(\beta\)</span> to minimize: <span class="math display">\[E[X_{t+2} - \hat{X}_{t+2}]^2 = E[(X_{t+2} - \beta X_{t+1})^2] - Var[X_{t+2} - \hat{X}_{t+2}] = \gamma(0) - 2 \beta \gamma(1) + \beta^2 \gamma(0)\]</span> Taking the derivative w.r.t <span class="math inline">\(\beta\)</span>, setting the result to zero, we have: <span class="math display">\[\beta = \frac{\gamma(1)}{\gamma(0)} = \rho(1) = \phi\]</span> Hence, <span class="math display">\[\phi_{22} = Corr(X_{t+2} - \hat{X}_{t+2}, X_t - \hat{X}_t) = Corr(X_{t+2} - \phi X_{t+1}, X_{t} - \phi {X}_{t+1}) = 0\]</span> <strong>In fact for <span class="math inline">\(AR(p)\)</span> model, <span class="math inline">\(\phi_{hh} = 0, \;\; \forall h &gt; p\)</span></strong> <img src="/images/RL/background/ts_3_4_1.png"></p>
</blockquote>
<p><img src="/images/RL/background/ts_3_4_2.png"></p>
<p><br></p>
<h3 id="forecasting">Forecasting</h3>
<p>In forecasting, the goal is to predict future values of a time series, <span class="math inline">\(X_{n+m}, \; m= 1, 2, ...\)</span> based on the data collected to the present, <span class="math inline">\(\mathbf{X} = \{X_n, ...., X_1\}\)</span>. <strong>We begin by assuming that <span class="math inline">\(X_t\)</span> is stationary and model parameters are known.</strong></p>
<h4 id="minimum-mean-square-error-prediction">Minimum Mean-Square Error Prediction</h4>
<p>The minimum mean square error predictor of <span class="math inline">\(X_{n+m}\)</span> is:</p>
<p><span class="math display">\[X^n_{n+m} = E[X_{n+m} | \mathbf{X}]\]</span></p>
<p>Because the conditional expectation minimizes the mean square error. More formally:</p>
<p>Let <span class="math inline">\(X^n_{n+m} = E[X_{n+m} | \mathbf{X}]\)</span> be the conditional expectation of <span class="math inline">\(X_{n+m}\)</span> given <span class="math inline">\(\mathbf{X}\)</span>. Then:</p>
<p><span class="math display">\[E[(X_{n+m} - X^n_{n+m})^2] \leq E[(X_{n+m} - \pi(\mathbf{X}))^2]\]</span></p>
<p>Where <span class="math inline">\(\pi(\mathbf{X})\)</span> is any function of the history <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p><br></p>
<p><strong>Proof</strong>:</p>
<span class="math display">\[\begin{aligned}
E[(X_{n+m} - \pi(\mathbf{X}))^2] &amp;= E[((X_{n+m} - X^n_{n+m}) - (X^{n}_{n+m} - \pi(\mathbf{X})))^2]\\
&amp;=E[(X_{n+m} - X^n_{n+m})^2] + 2E[(X_{n+m} - X^n_{n+m})(X^{n}_{n+m} - \pi(\mathbf{X}))] + E[(X^{n}_{n+m} - \pi(\mathbf{X}))^2]\\
\end{aligned}\]</span>
<p>For clarification, replace <span class="math inline">\(\mathbf{X}\)</span> with <span class="math inline">\(\mathbf{Y}\)</span> and let <span class="math inline">\(\hat{\mathbf{Y}} = X^n_{n+m} = E[X_{n+m} | \mathbf{Y}]\)</span> with pdf <span class="math inline">\(P_{\mathbf{Y}}(\mathbf{y}), \pi(\mathbf{X}) = \pi(\mathbf{Y})\)</span></p>
The second term:
<span class="math display">\[\begin{aligned}
2E[(X_{n+m} - X^n_{n+m})(X^{n}_{n+m} - \pi(\mathbf{X}))] &amp;= 2\int_{x} \int_{\mathbf{y}}(x - \hat{\mathbf{y}})(\hat{\mathbf{y}} - \pi(\mathbf{y})) p_{\mathbf{Y}, X_{n+m}} (\mathbf{y}, x) d\mathbf{y}dx\\
&amp;= 2\int_{\mathbf{y}} \underbrace{\{\int_{x}(x - \hat{\mathbf{y}})p_{X_{n+m} | \mathbf{Y}} (x | \mathbf{y}) dx\}}_{E[X | \mathbf{Y}=\mathbf{y}] - E[X | \mathbf{Y}=\mathbf{y}] = 0} (\hat{\mathbf{y}} - \pi(\mathbf{y})) p_{\mathbf{Y}} (\mathbf{y}) d\mathbf{y}\\
&amp;= 0
\end{aligned}\]</span>
<p>Thus, we have:</p>
<p><span class="math display">\[E[(X_{n+m} - \pi(\mathbf{X}))^2] = E[(X_{n+m} - X^n_{n+m})^2] + E[(X^{n}_{n+m} - \pi(\mathbf{X}))^2] \geq E[(X_{n+m} - X^n_{n+m})^2]\]</span></p>
<p><br></p>
<h4 id="property-3.3-best-linear-prediction-for-stationary-processes">Property 3.3: Best Linear Prediction for Stationary Processes</h4>
<p>Given data <span class="math inline">\(X_1, ..., X_n\)</span>, the <strong>best linear predictor (BLP)</strong>, <span class="math inline">\(X^n_{n+m} = \alpha_0 + \sum^N_{k=1} \alpha_k X_k\)</span>, of <span class="math inline">\(X_{n+m}\)</span> for <span class="math inline">\(m \geq 1\)</span>, is found by solving:</p>
<p><span class="math display">\[E[(X_{n+m} - X^n_{n+m})x_k] = 0, \;\;\; k = 0, 1, ...., n\]</span></p>
<p>Where <span class="math inline">\(X_0 = 1\)</span>, for <span class="math inline">\(\alpha_0, ..., \alpha_n\)</span>.</p>
<p><br></p>
<p>The equation above is called the <strong>prediction equations</strong>, and they are used to solve for the coefficients <span class="math inline">\(\{\alpha_0, ..., \alpha_n\}\)</span>. If <span class="math inline">\(E[X_t] = \mu\)</span>, the first equation (<span class="math inline">\(k=0\)</span>) implies:</p>
<p><span class="math display">\[E[X_{n+m} - X^n_{n+m}] = 0 \implies E[X_{n+m}] = E[X^n_{n+m}] = \mu\]</span></p>
<p>By expanding the expectation:</p>
<p><span class="math display">\[E[X^n_{n+m}] = \mu = E[\alpha_0 + \sum^N_{k=1} \alpha_k X_k] = \alpha_0 + \sum^N_{k=1} \alpha_k \mu\]</span></p>
<p>Thus, for <span class="math inline">\(k=0\)</span> the BLP has the form:</p>
<p><span class="math display">\[X^n_{n+m} = \mu + \sum^n_{k=1} \alpha_k (X_k - \mu)\]</span></p>
<p><strong>If the process is Gaussian, minimum mean square error predictors and BLP are the same</strong>.</p>
<h4 id="one-step-ahead-prediction">One-step-ahead Prediction</h4>
<p>Then consider one-step-ahead prediction with <span class="math inline">\(m = 1\)</span>. The BLP of <span class="math inline">\(X_{n+1}\)</span> is of the form:</p>
<p><span class="math display">\[X^{n}_{n+1} = \phi_{n1} X_n + .... + \phi_{nn} X_1\]</span></p>
<p>Where the original coefficients <span class="math inline">\(\alpha_k\)</span> are replaced by <span class="math inline">\(\phi_{n, n+1-k}\)</span> for <span class="math inline">\(k=1, ..., n\)</span> which will become clear later. Then the coefficients satisfies:</p>
<p><span class="math display">\[E[(X_{n+1} - \sum^{n}_{j=1} \phi_{nj} X_{n + 1 - j})X_{n+1-k}] = 0, \;\; k = 1, 2, ... , n\]</span></p>
<p>or:</p>
<p><span class="math display">\[\sum^n_{j=1} \phi_{nj} \gamma(k - j) = \gamma(k), \;\; k = 1, 2, ... , n\]</span></p>
<p>In matrix form we have:</p>
<p><span class="math display">\[\Gamma_n \boldsymbol{\phi}_n = \boldsymbol{\gamma}_n\]</span></p>
<p>Where <span class="math inline">\(\Gamma_n = \{\gamma(k - j)\}^n_{j, k = 1}\)</span> is a <span class="math inline">\(n \times n\)</span> matrix, <span class="math inline">\(\boldsymbol{\phi}_n = [\phi_{n1} ,..., \phi_{nn}]^T\)</span> is a <span class="math inline">\(n \times 1\)</span> vector, and <span class="math inline">\(\boldsymbol{\gamma}_n = [\gamma(1), ..., \gamma(n)]^T\)</span> is a <span class="math inline">\(n \times 1\)</span> vector. If the elements of <span class="math inline">\(\boldsymbol{\phi}_n\)</span> are unique and <span class="math inline">\(\Gamma_n\)</span> is invertible (<strong>For ARMA models, <span class="math inline">\(\Gamma_n\)</span> is positive definite, so it is invertible</strong>), the coefficients can be found by:</p>
<p><span class="math display">\[\boldsymbol{\phi}_n = \Gamma^{-1}_n \boldsymbol{\gamma}_n\]</span></p>
<p>Similarly, the BLP of one step forecasting can be written in matrix form:</p>
<p><span class="math display">\[X^n_{n+1} = \boldsymbol{\phi}^T_n \mathbf{X}\]</span></p>
<p>Where <span class="math inline">\(\boldsymbol{X} = [X_n, ...., X_1]^T\)</span></p>
<p>The mean square one-step prediction error is:</p>
<p><span class="math display">\[P^n_{n+1} = E[X_{n+1} - X^{n}_{n+1}]^2 = \gamma(0) - \boldsymbol{\gamma}^T_n \Gamma^{-1}_n \boldsymbol{\gamma}_n\]</span></p>
<h5 id="prediction-arp">Prediction: <span class="math inline">\(AR(p)\)</span></h5>
<p>If the time series is a causal <span class="math inline">\(AR(p)\)</span> process, then, for <span class="math inline">\(n \geq p\)</span>:</p>
<p><span class="math display">\[X^n_{n+1} = \phi_1 X_n + ... + \phi_p X_{n - p + 1}\]</span></p>
<h5 id="the-durbin-levinson-algorithm">The Durbin-Levinson Algorithm</h5>
<p><img src="/images/RL/background/ts_3_5_1.png"></p>
<h5 id="the-innovations-algorithm">The Innovations Algorithm</h5>
<p><img src="/images/RL/background/ts_3_5_2.png"></p>
<h5 id="iterative-solution-for-the-pcaf">Iterative Solution for the PCAF</h5>
<p>The PCAF of a stationary process <span class="math inline">\(X_t\)</span>, can be obtained iteratively using Durbin-Levinson Algorithm as <span class="math inline">\(\phi_{nn}\)</span> for <span class="math inline">\(n = 1, 2, ...\)</span></p>
<p>Thus, we know that the last coefficient of <span class="math inline">\(AR(p)\)</span> model is the partial autocorrelation at lag <span class="math inline">\(p\)</span>, <span class="math inline">\(\phi_p = \phi_{pp}\)</span>.</p>
<p><br></p>
<h4 id="m-step-ahead-prediction"><span class="math inline">\(m\)</span>-step-ahead Prediction</h4>
<p>Property 3.3 allows us to calculate the BLP of <span class="math inline">\(X_{n+m}\)</span> for any <span class="math inline">\(m \geq 1\)</span>. Given data, the <span class="math inline">\(m\)</span>-step-ahead predictor is:</p>
<p><span class="math display">\[X^n_{n+m} = \phi^{(m)}_{n1} X_n + \phi^{(m)}_{n2} X_{n-1} + ,..., + \phi^{(m)}_{nn} X_1\]</span></p>
<p>Where the coefficients <span class="math inline">\(\boldsymbol{\phi}^{(m)}_n\)</span> satisfies:</p>
<p><span class="math display">\[\sum^n_{j=1} \phi^{(m)}_{nj} \gamma(k - j) = \gamma(m + k - 1), \;\; k = 1, 2, ... , n\]</span></p>
<p>The prediction equation in matrix form:</p>
<p><span class="math display">\[\Gamma_n \boldsymbol{\phi}^{(m)}_n = \boldsymbol{\gamma}^{(m)}_n\]</span></p>
<p>Where <span class="math inline">\(\boldsymbol{\gamma}^{(m)}_n = [\gamma(m), ...., \gamma(m + n - 1)]^T\)</span> and <span class="math inline">\(\boldsymbol{\phi}^{(m)}_n = [\phi^{(m)}_{n1}, ..., \phi^{(m)}_{nn}]^T\)</span></p>
<p>The mean square <span class="math inline">\(m\)</span>-step-ahead prediction error is:</p>
<p><span class="math display">\[P^n_{n+m} = E[X_{n + m} - X^n_{n + m}]^2 = \gamma(0) -  \boldsymbol{\gamma}^{(m)^T}_n \Gamma^{-1}_n \boldsymbol{\gamma}^{(m)}_n\]</span></p>
<p>Given the data <span class="math inline">\(X_1, ..., X_n\)</span>, the innovations algorithm can be calculated successively for <span class="math inline">\(t=1\)</span> then <span class="math inline">\(t=2\)</span> and so on. The <span class="math inline">\(m\)</span>-step-ahead predictor and its mean-square error based on the innovative algorithm are given by:</p>
<p><img src="/images/RL/background/ts_3_5_3.png"></p>
<h4 id="forecasting-arma-processes">Forecasting <span class="math inline">\(ARMA\)</span> Processes</h4>
<p>The general prediction equations of BLP provides little insight into forecasting for <span class="math inline">\(ARMA\)</span> models in general especially when <span class="math inline">\(n\)</span> is large, we need to invert a <span class="math inline">\(n \times n\)</span> matrix which is computationally expensive. There are a number of different ways to express these forecasts, and each aids in understanding the special structure of <span class="math inline">\(ARMA\)</span> prediction. Throughout, we assume <span class="math inline">\(X_t\)</span> is a causal and invertible zero-mean <span class="math inline">\(ARMA\)</span> process, <span class="math inline">\(\phi(B)X_t = \theta(B)W_t\)</span>, where <span class="math inline">\(W_t \overset{i.i.d}{\sim} N(0, \sigma^2_w)\)</span>.</p>
<p>We denote the predictor of <span class="math inline">\(X_{n+m}\)</span> based on the infinite past as:</p>
<p><span class="math display">\[\tilde{X}_{n+m} = E[X_{n+m} | X_n, ...., X_1, X_0, X_{-1}, ...]\]</span></p>
<p>In general, <span class="math inline">\(\tilde{X}_{n+m}\)</span> is not the same as the minimum mean square error predictor <span class="math inline">\(X^n_{n+m}\)</span>, but for large samples <span class="math inline">\(\tilde{X}_{n+m}\)</span> will provide a good approximation to it. We now write the process in invertible and causal forms:</p>
<p><span class="math display">\[X_{n+m} = \sum^\infty_{j=0} \psi_j W_{n+m-j}, \;\; \psi_0 = 1\]</span> <span class="math display">\[W_{n+m} = \sum^{\infty}_{j=0} \pi_j X_{n+m-j}, \;\; \pi_0 = 1\]</span></p>
<p>Then by taking the conditional expectation on infinite past, we have:</p>
<p><span class="math display">\[\tilde{X}_{n+m} = \sum^\infty_{j=0}\psi_j \tilde{W}_{n+m-j} = \sum^{\infty}_{j=m}\psi_j W_{n+m-j}\]</span></p>
<p>Since by causality and invertibility:</p>
<p><span class="math display">\[\tilde{W}_t = E[W_t | X_n, ...., X_0, ....] = E[\sum^{\infty}_{j=0} \pi_j X_{t-j} | X_n, ..., X_0, ...] = 
\begin{cases}
0 &amp; t &gt; n\\
&amp;\\  % blank row
W_{t} &amp; t \leq n 
\end{cases}\]</span></p>
<p>Similarly, using the second equation we have:</p>
<p><span class="math display">\[E[W_{n+m}] = 0 = E[\sum^\infty_{j=0} \pi_j X_{n+m-j} | X_n ,...., X_0, ..] = \sum^{\infty}_{j=0}\pi_j \tilde{X}_{n+m-j} = \tilde{X}_{n+m} + \sum^{\infty}_{j=1}\pi_j \tilde{X}_{n+m-j}\]</span></p>
<p>Since <span class="math inline">\(E[X_{t} | X_n ,..., X_0, ...] = X_{t}\)</span> for <span class="math inline">\(t \leq n\)</span>, we have:</p>
<p><span class="math display">\[\tilde{X}_{n+m} = -\sum^{\infty}_{j=1}\pi_j \tilde{X}_{n+m-j} = -\sum^{m-1}_{j=1} \pi_j \tilde{X}_{n+m-j} - \sum^{\infty}_{k=m} \pi_k X_{n + m -k}\]</span></p>
<p><strong>Prediction is accomplished recursively using the above equation, starting from <span class="math inline">\(m=1\)</span>, and then continuing for $m=2, 3, .. $. When <span class="math inline">\(n\)</span> is large, we would use this by truncating, because we only observe <span class="math inline">\(X_1, X_2, ..., X_n\)</span> but not the whole history <span class="math inline">\(X_n, ..., X_0, X_{-1}, ...\)</span>. In this case, we can truncate the above equation by setting <span class="math inline">\(\sum^{\infty}_{j=n+m} \pi_j X_{n+m-j} = 0\)</span>:</strong></p>
<p><span class="math display">\[\tilde{X}^n_{n+m} =  -\sum^{m-1}_{j=1} \pi_j \tilde{X}^n_{n+m-j} - \sum^{n + m - 1}_{k=m} \pi_k X_{n + m -k}\]</span></p>
<p><br></p>
<p>Hence, we can write the mean square prediction error as:</p>
<p><span class="math display">\[P^n_{n+m} = E[(X_{n+m} - \tilde{X}_{n+m})^2] = Var[(X_{n+m} - \tilde{X}_{n+m})^2] + E^2[X_{n+m} - \tilde{X}_{n+m}] = \sigma^2_w\sum^{m-1}_{j=0}\psi^2_j\]</span></p>
<p>Where <span class="math inline">\(X_{n+m} - \tilde{X}_{n+m} = \sum^\infty_{j=0} \psi_j W_{n+m-j} - \sum^{\infty}_{j=m}\psi_j W_{n+m-j} = \sum^{m-1}_{j=0}\psi_j W_{n+m-j}\)</span></p>
<p><strong>The <span class="math inline">\(ARMA\)</span> forecasts quickly settle to the mean with a constant prediction error as the forecast horizon <span class="math inline">\(m\)</span> grows.</strong></p>
<p><img src="/images/RL/background/ts_3_5_4.png" width="800"></p>
<h3 id="integrated-models-for-nonstationary-data">Integrated Models for Nonstationary Data</h3>
<p>If <span class="math inline">\(X_t\)</span> is a random walk, <span class="math inline">\(X_t = X_{t-1} + W_t\)</span>, then by differencing <span class="math inline">\(X_t\)</span>, we find that <span class="math inline">\(\nabla X_t = X_{t} - X_{t-1} = W_t\)</span> is stationary. In many situations, time series can be thought of as being composed of two components:</p>
<ol type="1">
<li>A nonstationary trend component.</li>
<li>A zero-mean stationary component.</li>
</ol>
<p>The <strong>intergrated ARMA (ARIMA)</strong> model is a broadening of the class of <span class="math inline">\(ARMA\)</span> models to include differencing.</p>
<h4 id="definition-arima">Definition: <span class="math inline">\(ARIMA\)</span></h4>
<p>A process <span class="math inline">\(X_t\)</span> is said to be <span class="math inline">\(\mathbf{ARIMA}(p, d, q)\)</span> if:</p>
<p><span class="math display">\[\nabla^d X_t = (1 - B)^d X_t\]</span></p>
<p>is a <span class="math inline">\(ARMA(p, q)\)</span>. In general, we will write the model as:</p>
<p><span class="math display">\[\phi(B) (1 - B)^d X_t = \theta (B) W_t\]</span></p>
<p>If <span class="math inline">\(E[\nabla^d X_t] = \mu\)</span>, we write the model as:</p>
<p><span class="math display">\[\phi(B) (1 - B)^d X_t = \theta (B) W_t + \delta\]</span></p>
<p>Where:</p>
<p><span class="math display">\[\delta = \mu(1 - \phi_1 - ... - \phi_p)\]</span></p>
<p><br></p>
<p>For <span class="math inline">\(ARIMA\)</span> model, since <span class="math inline">\(Y_t = \nabla^d X_t\)</span> is a <span class="math inline">\(ARMA\)</span> model, we can use the forecasting methods to obtain forecasts for <span class="math inline">\(Y_t\)</span> which in turn leads to forecasts for <span class="math inline">\(X_t\)</span>.</p>
<blockquote>
<p>If <span class="math inline">\(d=1\)</span>, given forecasts <span class="math inline">\(Y^n_{n+m}\)</span> for <span class="math inline">\(m=1, 2, ...\)</span>, we have <span class="math display">\[Y^n_{n+m} = X^n_{n+m} - X^n_{n+m-1}\]</span> <span class="math display">\[\implies X^n_{n+m} =  X^n_{n+m-1} + Y^n_{n+m}\]</span> With initial condition: <span class="math display">\[X^n_{n+1} = X_{n} + Y^n_{n+1}\]</span> Since: <span class="math display">\[X^n_{n} = X_n\]</span></p>
</blockquote>
<p>For <span class="math inline">\(ARIMA\)</span> models, the mean-squared error can be approximated by:</p>
<p><span class="math display">\[P^n_{n+m} = \sigma^2_w \sum^{m-1}_{j=0} {\psi^*_j}^2\]</span></p>
<p>Where <span class="math inline">\(\psi^*_j\)</span> is the coefficient of <span class="math inline">\(z^j\)</span> in <span class="math inline">\(\psi^*(z) = \frac{\theta(z)}{\phi(z)(1 - z)^d}\)</span></p>
<h4 id="ema">EMA</h4>
<p>The <strong>Exponentially Weighted Moving Average(EWMA)</strong> is defined as a <span class="math inline">\(ARIMA(0, 1, 1)\)</span> model:</p>
<p><span class="math display">\[X_t = X_{t-1} + W_t- \lambda W_{t-1}\]</span></p>
<p>Where <span class="math inline">\(|\lambda| &lt; 1\)</span> for <span class="math inline">\(t = 1, 2, ...\)</span> and <span class="math inline">\(X_0 = 0\)</span>.</p>
]]></content>
      <categories>
        <category>Background</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
      </tags>
  </entry>
  <entry>
    <title>Trees</title>
    <url>/2021/06/14/tree/</url>
    <content><![CDATA[<h1 id="trees">Trees</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, key=<span class="literal">None</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span>, p=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.key = key</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line">        self.p = p</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinarySearchTree</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.root = root</span><br></pre></td></tr></table></figure>
<h2 id="binary-search-tree">Binary Search Tree</h2>
<p>A binary search tree node consists of:</p>
<ol type="1">
<li><span class="math inline">\(key: \;\)</span> value of the node</li>
<li><span class="math inline">\(left: \;\)</span> left children</li>
<li><span class="math inline">\(right: \;\)</span> right children</li>
<li><span class="math inline">\(p: \;\)</span> parent</li>
</ol>
<p>If a child or the parent is missing, the appropriate attribute contains the value <code>None</code>. The root node is the only node in the tree whose parent is <code>None</code>.</p>
<p>The keys in a binary search tree are always stored in such a way as to satisfy the <code>binary search tree property</code>:</p>
<blockquote>
<p>For any node <span class="math inline">\(x\)</span>, the keys in the left subtree of <span class="math inline">\(x\)</span> are at most <span class="math inline">\(x.key\)</span>, and the keys in the right subtree of <span class="math inline">\(x\)</span> are at least <span class="math inline">\(x.key\)</span>.</p>
</blockquote>
<p>The binary search tree property allows us to print out all the keys in a binary search tree in sorted order by <code>inorder tree walk</code> (Inorder traversal). This algorithm prints the key of the root of a subtree betweeen printing the values in its left subtree and printing those in its right subtree. Similarly, a <code>preorder tree walk</code> prints the root before the values in either subtree and a <code>postorder tree walk</code> prints the root after the values in its subtrees.</p>
<h3 id="inorder-traversal">Inorder Traversal</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inorder_tree_walk</span>(<span class="params">tree</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorder</span>(<span class="params">root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        inorder(root.left)</span><br><span class="line">        <span class="built_in">print</span>(root.val)</span><br><span class="line">        inorder(root.right)</span><br><span class="line">        </span><br><span class="line">    inorder(tree)</span><br></pre></td></tr></table></figure>
<h3 id="preorder-traversal">Preorder Traversal</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preorder_tree_walk</span>(<span class="params">tree</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preorder</span>(<span class="params">root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(root.val)</span><br><span class="line">        preorder(root.left)</span><br><span class="line">        preorder(root.right)</span><br><span class="line">        </span><br><span class="line">    preorder(tree)</span><br></pre></td></tr></table></figure>
<h3 id="postorder-traversal">Postorder Traversal</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postorder_tree_walk</span>(<span class="params">tree</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postorder</span>(<span class="params">root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        postorder(root.left)</span><br><span class="line">        postorder(root.right)</span><br><span class="line">        <span class="built_in">print</span>(root.val)</span><br><span class="line">        </span><br><span class="line">    postorder(tree)</span><br></pre></td></tr></table></figure>
<h3 id="search">Search</h3>
<p>We use the following procedure to search for a node with a given key in a binary search tree. Given a pointer to the root of the tree and a key <span class="math inline">\(k\)</span>, it returns a pointer to a node with key <span class="math inline">\(k\)</span> if one exists, otherwise it returns <code>None</code>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_search</span>(<span class="params">tree, k</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">root, val</span>):</span></span><br><span class="line">        <span class="comment"># base case</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root <span class="keyword">or</span> root.key == val:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> root.key &lt; val:</span><br><span class="line">            target = search(root.right, val)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target = search(root.left, val)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> target</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> search(tree, k)</span><br></pre></td></tr></table></figure>
<h3 id="minimum">Minimum</h3>
<p>We can always find an element in a binary search tree whose key is a minimum by following <span class="math inline">\(left\)</span> child pointers from the root until we encounter a <code>None</code>. The following procedure returns a pointer to the minimum element in the subtree rooted at a given node <span class="math inline">\(x\)</span>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_minimum</span>(<span class="params">tree</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minimum</span>(<span class="params">root</span>):</span></span><br><span class="line">        <span class="comment"># base case</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> minimum(root.left)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> minimum(tree)</span><br></pre></td></tr></table></figure>
<h3 id="maximum">Maximum</h3>
<p>The maximum is symmetric as minimum:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_maximum</span>(<span class="params">tree</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maximum</span>(<span class="params">root</span>):</span></span><br><span class="line">        <span class="comment"># base case</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> maximum(root.right)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> maximum(tree)</span><br></pre></td></tr></table></figure>
<h3 id="successor-and-predecessor">Successor and Predecessor</h3>
<p>Given a node in a binary search tree, sometimes we need to find its successor in the sorted order determined by an inorder tree walk. If all keys are distinct, the successor of a node <span class="math inline">\(x\)</span> is the node with the smallest key greater than <span class="math inline">\(x.key\)</span>. The procedure breaks into several cases:</p>
<ol type="1">
<li>If node <span class="math inline">\(x\)</span> has right subtree, then the successor must be the smallest element in the right subtree.</li>
<li>If node <span class="math inline">\(x\)</span> does not have right subtree and itself is a leftsubtree of its parent, then the successor must be its parent.</li>
<li>If node <span class="math inline">\(x\)</span> does not have right subtree and itself is a rightsubtree of its parent, then the successor must be the lowest ancestor of <span class="math inline">\(x\)</span> whose left child is also an ancestor of <span class="math inline">\(x\)</span>.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_successor</span>(<span class="params">node</span>):</span></span><br><span class="line">    <span class="comment"># case 1</span></span><br><span class="line">    <span class="keyword">if</span> node.right:</span><br><span class="line">        <span class="keyword">return</span> tree_minimum(node)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># case 2, 3</span></span><br><span class="line">    curr_p = node.p</span><br><span class="line">    <span class="keyword">while</span> curr_p:</span><br><span class="line">        <span class="keyword">if</span> curr_p.left == node:</span><br><span class="line">            <span class="keyword">return</span> curr_p</span><br><span class="line">        </span><br><span class="line">        node = curr_p</span><br><span class="line">        curr_p = node.p</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p><strong>Predecessor is symmetric</strong></p>
<h3 id="insertion">Insertion</h3>
<p>To insert a new node <span class="math inline">\(z\)</span> into a binary search tree <span class="math inline">\(T\)</span> we use the following procedure:</p>
<ol type="1">
<li>Begin at root of the tree, we maintain two pointers <span class="math inline">\(y, x\)</span> representing parent and current node respectively.</li>
<li>Go down the tree and compare every node encounter with <span class="math inline">\(z\)</span>, if it is greater than <span class="math inline">\(z\)</span> we go to the left, if smaller we go to the right, until we reach <code>None</code>.</li>
<li>We replace <span class="math inline">\(y.left\)</span> or <span class="math inline">\(y.right\)</span> with <span class="math inline">\(x\)</span> and fill <span class="math inline">\(z.p = y\)</span>.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_insert</span>(<span class="params">T, z</span>):</span></span><br><span class="line">    <span class="comment"># initialize y, x representing parent and current node</span></span><br><span class="line">    y, x = <span class="literal">None</span>, T</span><br><span class="line">    <span class="comment"># step 2</span></span><br><span class="line">    <span class="keyword">while</span> x:</span><br><span class="line">        y = x</span><br><span class="line">        <span class="keyword">if</span> z.key &lt; x.key:</span><br><span class="line">            x = x.left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x = x.right</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># step 3</span></span><br><span class="line">    z.p = y</span><br><span class="line">    <span class="comment"># if tree is empty</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> y:</span><br><span class="line">        T.root = z</span><br><span class="line">    <span class="keyword">elif</span> z.key &lt; y.key:</span><br><span class="line">        y.left = z</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y.right = z</span><br></pre></td></tr></table></figure>
<h3 id="deletion">Deletion</h3>
<p>The overall strategy for deleting a node <span class="math inline">\(z\)</span> from a binary search tree <span class="math inline">\(T\)</span> has three basic cases:</p>
<ol type="1">
<li>If <span class="math inline">\(z\)</span> has no children, then we can simply remove it by modifying its parent to replace <span class="math inline">\(z\)</span> with <code>None</code> as its child.</li>
<li>If <span class="math inline">\(z\)</span> has just on child, then we elevate that child to take <span class="math inline">\(z\)</span>'s position in the tree by modifying <span class="math inline">\(z\)</span>'s parent to replace <span class="math inline">\(z\)</span> by <span class="math inline">\(z\)</span>'s child.</li>
<li>If <span class="math inline">\(z\)</span> has two children, then we find <span class="math inline">\(z\)</span>'s successor <span class="math inline">\(y\)</span> which must be the minimum item in <span class="math inline">\(z\)</span>'s right subtree (with no left child). Now have two cases:
<ol type="1">
<li>If <span class="math inline">\(y\)</span> is <span class="math inline">\(z\)</span>'s right child: We replace <span class="math inline">\(z\)</span> by <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span>'s left child becomes <span class="math inline">\(y\)</span>'s left child.</li>
<li>If <span class="math inline">\(y\)</span> is not <span class="math inline">\(z\)</span>'s right child: We first replace <span class="math inline">\(y\)</span> by its right child, then we replace <span class="math inline">\(z\)</span> by <span class="math inline">\(y\)</span></li>
</ol></li>
</ol>
<p><br></p>
<p>In order to move subtrees around, we define a helper function <code>transplant</code> that replaces the subtree rooted at node <span class="math inline">\(u\)</span> with the subtree rooted at node <span class="math inline">\(v\)</span>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transplant</span>(<span class="params">T, u, v</span>):</span></span><br><span class="line">    <span class="comment"># if u is the root</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> u.p:</span><br><span class="line">        T.root = v</span><br><span class="line">    <span class="keyword">elif</span> u.p.left == u:</span><br><span class="line">        u.p.left = v</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        u.p.right = v</span><br><span class="line"></span><br><span class="line">    <span class="comment"># replace v with u</span></span><br><span class="line">    <span class="keyword">if</span> v:</span><br><span class="line">        v.p = u.p</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_delete</span>(<span class="params">T, z</span>):</span></span><br><span class="line">    <span class="comment"># case 1</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> z.left <span class="keyword">and</span> <span class="keyword">not</span> z.right:</span><br><span class="line">        transplant(T, z, <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># case 2</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> z.left <span class="keyword">and</span> z.right:</span><br><span class="line">        transplant(T, z, z.right)</span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> z.right <span class="keyword">and</span> z.left:</span><br><span class="line">        transplant(T, z, z.left)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y = tree_successor(z)</span><br><span class="line">        <span class="comment"># case 3.2</span></span><br><span class="line">        <span class="keyword">if</span> z.right != y:</span><br><span class="line">            transplant(T, y, y.right)</span><br><span class="line">            y.right = z.right</span><br><span class="line">            y.right.p = y</span><br><span class="line">            </span><br><span class="line">        transplant(T, z, y)</span><br><span class="line">        y.left = z.left</span><br><span class="line">        y.left.p = y</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<h3 id="complexcity">Complexcity</h3>
<ul>
<li>Tree walks: <span class="math inline">\(\; \Theta(n)\)</span></li>
<li>Search, Minimum, Maximum, Successor, Predecessor, Insert, Delete: <span class="math inline">\(\; O(h)\)</span></li>
</ul>
]]></content>
      <categories>
        <category>CS Basics</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
      </tags>
  </entry>
  <entry>
    <title>Value Iteration</title>
    <url>/2021/05/03/value-iteration/</url>
    <content><![CDATA[<h1 id="value-iteration">Value Iteration</h1>
<p>VI is one of the fundamental algorithms for planning. Many RL algorithms are essentially the sample-based variants of VI (DQN). We directly use the results of fixed points proposition and contraction property of the Bellman operator we proved in <a href="/2021/05/03/bellman-optimality-equations/" title="Bellman Optimality Equations">Bellman Optimality Equations</a>.</p>
<h2 id="idea">Idea</h2>
<p>Starting from <span class="math inline">\(V_0 \in B(X)\)</span>, we compute a sequence of <span class="math inline">\((V_{k})_{k \geq 0}\)</span> by:</p>
<p><span class="math display">\[V_{k+1} \leftarrow T^{\pi} V_{k}\]</span></p>
<p>By the contraction property of the Bellman operator and Uniqueness of fixed points proposition :</p>
<p><span class="math display">\[lim_{k \rightarrow \infty} \| V_k - V^{\pi}\|_{\infty} = 0\]</span></p>
<p>similar for <span class="math inline">\(Q\)</span>:</p>
<p><span class="math display">\[lim_{k \rightarrow \infty} \| Q_k - Q^{\pi}\|_{\infty} = 0\]</span></p>
<span id="more"></span>
<p>Also, if we compute a sequence of <span class="math inline">\((V_{k})_{k \geq 0}\)</span> by:</p>
<p><span class="math display">\[V_{k+1} \leftarrow T^{*} V_{k}\]</span></p>
<p><span class="math display">\[Q_{k+1} \leftarrow T^{*} Q_{k}\]</span></p>
<p>By the contraction property of the Bellman operator and Uniqueness of fixed points proposition, it is guaranteed that</p>
<p><span class="math display">\[lim_{k \rightarrow \infty} \| V_k - V^{*}\|_{\infty} = 0\]</span></p>
<p><span class="math display">\[lim_{k \rightarrow \infty} \| Q_k - Q^{*}\|_{\infty} = 0\]</span></p>
<p><img src='/images/RL/dp/value_iteration_1.png'> <img src='/images/RL/dp/value_iteration_2.png'> <img src='/images/RL/dp/value_iteration_3.png'></p>
<p>After finding <span class="math inline">\(Q^{*}\)</span>, finding optimal policy is straightforward:</p>
<p><span class="math display">\[\pi^{*} (a | x) = argmax_{a \in A} Q^{*} (x, a)\]</span></p>
<h2 id="algorithm">algorithm</h2>
<p>One generic implementation can be found in intro to RL book:</p>
<p><img src='/images/RL/dp/value-iteration.png'></p>
<h2 id="implementation">Implementation</h2>
<p>Below is one implementation of Value iteration (using Q):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># part of code from rl-algo.dp</span></span><br><span class="line"><span class="comment"># link: https://github.com/swag1ong/rl-algo</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ValueIter</span>(<span class="params">DpBase</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        dynamics = self.env.env.P</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line">            delta = <span class="number">0</span></span><br><span class="line">            <span class="comment"># Calculate Q^*, V^* (s) = max_a Q^* (s, a)</span></span><br><span class="line">            <span class="keyword">for</span> s <span class="keyword">in</span> dynamics.keys():</span><br><span class="line">                prev_val = self._val[s].copy()</span><br><span class="line">                curr_val = self._val[s]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> a <span class="keyword">in</span> dynamics[s].keys():</span><br><span class="line">                    temp_val = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> p, s_prime, r, _ <span class="keyword">in</span> dynamics[s][a]:</span><br><span class="line">                        temp_val = temp_val + p * (r + self.gamma * np.<span class="built_in">max</span>(self._val[s_prime]))</span><br><span class="line"></span><br><span class="line">                    curr_val[a] = temp_val</span><br><span class="line"></span><br><span class="line">                curr_delta = np.linalg.norm(np.array(prev_val) - np.array(curr_val))</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> curr_delta &gt; delta:</span><br><span class="line">                    delta = curr_delta</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> delta &lt; self.threshold:</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>RL</category>
        <category>DP</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>Dynamic Programming</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning From Stream of Data</title>
    <url>/2021/05/07/value-function-learning/</url>
    <content><![CDATA[<h1 id="learning-from-stream-of-data-introduction">Learning From Stream of Data (Introduction)</h1>
<p>In previous DP settings, we know the transition distribution <span class="math inline">\(P\)</span> and reward distribution <span class="math inline">\(R\)</span>. Everything about the environment dynamics are given. However, in RL setting, we have no access to the environment dynamics, instead, we observe data from agent interacting with its environment.</p>
<p>A stream of data (rollout or trajectory):</p>
<p><span class="math display">\[X_1, A_1, R_1, X_2, A_2, R_2, ...\]</span></p>
<p>with <span class="math inline">\(A_t \sim \pi(\cdot | X_t), X_{t+1} \sim P(\cdot | A_t, X_t), X_1 \sim \rho(\cdot), R_t \sim R(\cdot | X_t, A_t)\)</span></p>
<p>The questions are:</p>
<ol type="1">
<li>How can we learn a value of a policy <span class="math inline">\(\pi\)</span>?</li>
<li>How can we find the optimal policy <span class="math inline">\(\pi^{*}\)</span>?</li>
</ol>
<span id="more"></span>
<h2 id="stochastic-approximation-of-mean">Stochastic Approximation of Mean</h2>
<p>Let <span class="math inline">\(Z_1, ..., Z_t\)</span> be i.i.d R.V drawn from distribution <span class="math inline">\(v\)</span>, how can we estimate the expectation of <span class="math inline">\(Z_i\)</span>? One way is stochastic approximation.</p>
<p>Define:</p>
<p><span class="math display">\[\theta_{t+1} = (1 - \alpha_t)\theta_t + \alpha_t Z_t\]</span></p>
<p>Note that <span class="math inline">\(\theta_{t+1}\)</span> is a random variable, because <span class="math inline">\(Z_t\)</span> is a random variable.</p>
<h3 id="expectation">Expectation</h3>
<p>Assume <span class="math inline">\(\alpha_t = \alpha\)</span> is fixed, <span class="math inline">\(E[Z_t] = m\)</span>:</p>
<span class="math display">\[\begin{aligned}
E[\theta_{t+1}] &amp;= E[(1 - \alpha) \theta_t + \alpha Z_t]\\
&amp;= (1 - \alpha) E[\theta_t] + \alpha E[Z_t]\\
&amp;= (1 - \alpha) E[\theta_t] + \alpha m\\
\end{aligned}\]</span>
<p>Let <span class="math inline">\(E[\theta_t] = \bar{\theta_t}\)</span>, then:</p>
<p><span class="math display">\[E[\theta_{t+1}] = (1 - \alpha) E[\theta_t] + \alpha m \implies \bar{\theta_{t+1}} = (1 - \alpha) \bar{\theta_t} + \alpha m\]</span></p>
<p>Let <span class="math inline">\(\theta_0 = 0\)</span>, that is, <span class="math inline">\(\bar{\theta_0} = 0\)</span>:</p>
<span class="math display">\[\begin{aligned}
\bar{\theta_{1}} &amp;= \alpha m\\
\bar{\theta_{2}}&amp;= (1 - \alpha) \alpha m + \alpha m\\
...\\
...\\
\bar{\theta_{t}}&amp;= \alpha \sum_{i=0}^{t-1} (1 - \alpha)^i m = \frac{\alpha m (1 - (1 - \alpha)^t)}{1 - (1 - \alpha)} = m[1 - (1 - \alpha)^t]\\
\end{aligned}\]</span>
<p>As <span class="math inline">\(t \rightarrow \infty\)</span>, if <span class="math inline">\(0 \geq \alpha &lt; 1\)</span></p>
<p><span class="math display">\[lim_{t \rightarrow \infty} \bar{\theta_{t}} = lim_{t \rightarrow \infty} m[1 - (1 - \alpha)^t] = m\]</span></p>
<p><strong>This implies <span class="math inline">\(\theta_t\)</span> converges to <span class="math inline">\(m\)</span> in expectation</strong></p>
<h3 id="variance">Variance</h3>
<p>Since all <span class="math inline">\(Z_i\)</span> are i.i.d:</p>
<p><span class="math display">\[V[\theta_{t+1}] = (1 - \alpha)^2 V[\theta_t] + \alpha^2 V[Z_t] \geq \alpha^2 V[Z_t] = \alpha^2 \theta^2\]</span></p>
<p>We can show that:</p>
<p><span class="math display">\[lim_{t \rightarrow \infty} V[\theta_t] = \frac{\alpha \theta^2}{2 - \alpha}\]</span></p>
<p>For a constant <span class="math inline">\(\alpha\)</span>, the variance <span class="math inline">\(\theta_t\)</span>is not going to converge to zero. This means that <span class="math inline">\(\theta_t\)</span> fluctuates around its mean.</p>
<h3 id="sa-condition">SA Condition</h3>
<p>In order to make <span class="math inline">\(\theta_t\)</span> converge, we need a time dependent <span class="math inline">\(\alpha_t \rightarrow 0\)</span> with some schedule:</p>
<p><span class="math display">\[\sum_{t=0}^{\infty} \alpha_t = \infty \]</span></p>
<p><span class="math display">\[\sum_{t=0}^{\infty} \alpha_t^2 &lt; \infty \]</span></p>
<h2 id="epsilon---greedy-policy"><span class="math inline">\(\epsilon\)</span> - Greedy policy</h2>
<h3 id="problem-with-greedy-policy">Problem With Greedy Policy</h3>
<p>By selecting</p>
<p><span class="math display">\[a \rightarrow \pi_g (x; Q) = argmax_{a \in A} Q(x, a)\]</span></p>
<p>We would choose the optimal action at state <span class="math inline">\(x\)</span>. However, if <span class="math inline">\(Q(x, a)\)</span> is inaccurate estimate of <span class="math inline">\(Q^{\pi} (x, a)\)</span>, we may select a suboptimal action. It is also possible we get stuck in choosing this action forever, without any chance to improve its estimate.</p>
<h3 id="solution">Solution</h3>
<p>One solution for this problem it to force the agent regularly picks actions other than the one suggested by the greedy policy.</p>
<p>Thus, for <span class="math inline">\(\epsilon \geq 0, x \in X\)</span>, a function <span class="math inline">\(\hat{V}\)</span>, we define <span class="math inline">\(\pi_{\epsilon}\)</span> as:</p>
<p><span class="math display">\[
\pi_\epsilon (\cdot | x; \hat{V})=
\begin{cases}
\pi_g(x; \hat{V}), \text{w. p } 1 - \epsilon \\
Uniform(A), \text{w. p } \epsilon \\
\end{cases}
\]</span></p>
<ul>
<li>The uniform choice of action in the <span class="math inline">\(\epsilon\)</span>-greedy helps the agent <code>explore</code> all actions, even if the action is seemingly suboptimal.</li>
<li>The greedy part of its action select mechanism <code>exploits</code> the current knowledge about the reward function, and chooses the action that has the highest estimated reward.</li>
</ul>
<h3 id="exploration-and-exploitation-tradeoff">Exploration and Exploitation Tradeoff</h3>
<p>Exploiting our knowledge is a reasonable choice when our knowledge about the world is <code>accurate</code>. (ie. If we have <span class="math inline">\(Q^{*}\)</span> we should always choose the greedy action at each state to have a maximized return)</p>
<p>However, when we have uncertainty about the world, we should not be overconfident of our knowledge and exploit it at all time. (ie. If we only have <span class="math inline">\(\hat{Q}\)</span> of <span class="math inline">\(Q^{*}\)</span>, it is possible that <span class="math inline">\(argmax_{a \in A} \hat Q (x, a) \neq argmax_{a \in A} Q^{*} (x, a)\)</span>) But, instead explore other available actions, which might happen to be better.</p>
<p>The tradeoff between exploration and exploitation is a major topic in RL and is an area of active research.</p>
<h3 id="off-policy-and-on-policy-sampling-scenarios">Off Policy and On Policy Sampling Scenarios</h3>
<p>Suppose we have a rollout or trajectory following some policy <span class="math inline">\(\pi_b\)</span> (ie. an <span class="math inline">\(\epsilon\)</span>-greedy policy):</p>
<p><span class="math display">\[X_1, A_1, R_1, X_2, ....\]</span></p>
<p>And we have some policy <span class="math inline">\(\pi\)</span> that we want to evaluate (ie. the greedy policy):</p>
<ul>
<li>If <span class="math inline">\(\pi_b = \pi\)</span>, we are in the <code>on-policy</code> sampling scenario, in which the agent is evaluating the same policy that it is following.</li>
<li>If <span class="math inline">\(\pi_b \neq \pi\)</span>, we are in the <code>off-policy</code> sampling scenario, which the agent is evaluating a policy that is different from the one it is following.</li>
</ul>
<h2 id="further">Further</h2>
<p>From here, we have all we need to start learning from streams of data!</p>
]]></content>
      <categories>
        <category>RL</category>
        <category>MC</category>
        <category>TD</category>
      </categories>
      <tags>
        <tag>RL Basics</tag>
        <tag>MC</tag>
        <tag>Tabular Methods</tag>
        <tag>TD</tag>
      </tags>
  </entry>
  <entry>
    <title>Xavier Initialization</title>
    <url>/2021/07/05/xavier/</url>
    <content><![CDATA[<h1 id="understanding-the-difficulty-of-training-deep-feedforward-neural-networks">Understanding the Difficulty of Training Deep Feedforward Neural Networks</h1>
<p>The analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations.</p>
<h2 id="experimental-setting">Experimental Setting</h2>
<p>Feedforward neural networks with one to five hidden layers, one thousand hidden units per layer and a softmax logistic regression for the output layer are optimized. The cost function is the negative log-liklihood <span class="math inline">\(-\log p_{Y | X}(y | x)\)</span>, where <span class="math inline">\((x, y)\)</span> is the (input image, target class) ordered pair. The neural networks were optimized with stochastic back-propagation on mini-batches of size ten. An average gradient over the mini-batch are used to update parameters <span class="math inline">\(\theta\)</span> in that direction, with <span class="math inline">\(\theta \leftarrow \theta - \epsilon g\)</span>.</p>
<p>We varied the type of non-linear activation function in the hidden layers:</p>
<ol type="1">
<li>Sigmoid: <span class="math inline">\(\frac{1}{(1 + e^{-x})}\)</span></li>
<li>Hyperbolic tangent: <span class="math inline">\(tanh (x)\)</span></li>
<li>Softsign: <span class="math inline">\(\frac{x}{(1 + |x|)}\)</span> (similar to tanh but approaches asymptotes much slower, softer slope)</li>
</ol>
<p>The initial weights <span class="math inline">\(W_{i, j} \sim U[-\frac{1}{\sqrt{n}}, \frac{1}{\sqrt{n}}]\)</span>, biases are initialized to 0. Where <span class="math inline">\(n\)</span> is the size of the previous layer.</p>
<span id="more"></span>
<h2 id="effect-of-activation-functions-and-saturation-during-training">Effect of Activation Functions and Saturation During Training</h2>
<h3 id="experiments-with-the-sigmoid">Experiments with the Sigmoid</h3>
<p><img src='/images/ML/xavier_1.png' width="600"></p>
<p>The graph shows the mean and standard deviation of activations after apply sigmoid function for each layer(activations are computed using a fixed set of 300 test examples at different time during training). We can see very clearly that the deepest layer (top layer) at the beginning have all activation values around lower saturation value of 0. Inversely, the others layers have a mean activation value that is above 0.5 and decreasing as we go from the output layer to the input layer.</p>
<p>With random initialization, the lower layers of the network computes initially is not useful to the classification task, so the output layer <span class="math inline">\(softmax(b + Wh)\)</span> might initially rely more on the bias <span class="math inline">\(b\)</span> (which are learned very quickly) than on the top hidden activations <span class="math inline">\(h\)</span> derived from the input image (because <span class="math inline">\(h\)</span> may not be predictive at beginning due to random initialization). Thus, the error gradient would tend to push <span class="math inline">\(Wh\)</span> towards 0, which can be achieved by pushing <span class="math inline">\(h\)</span> towards 0 (saturation regime of the sigmoid activation function). Then, this will prevent gradients to flow backward and prevent the lower layers form learning useful features. Eventually but slowly, the lower layers move toward more useful features and the top hidden layer then moves out of the saturation regime.</p>
<h3 id="experiments-with-the-tanh-and-softsign">Experiments with the Tanh and Softsign</h3>
<p>The hyperbolic tangent networks do not suffer from the kind of saturation behavior of the top hidden layer observed with sigmoid network (tanh (0) has large gradient norm). However, sequentially saturation can occur starting with layer 1 and propagating up in the network (one by one).</p>
<p><img src='/images/ML/xavier_2.png' width="600"></p>
<p>The softsign is similar to tanh but behave differently in terms of saturation because of its smoother asymptotes. We can see that the saturation does not occur one layer after the other like for the tanh, it is faster at the beginning and then slow, and all layers move together towards larger weights.</p>
<p><img src='/images/ML/xavier_3.png' width="600"></p>
<h2 id="studying-gradients-and-their-propagation">Studying Gradients and their Propagation</h2>
<h3 id="effect-of-the-cost-function">Effect of the Cost Function</h3>
<p>The loss function is very important in terms of better learning. In classification, cross entropy (negative log-likelihood) couped with softmax outputs worked much better than quadratic cost. The plateaus in the traning criterion are less present with the log-likelihood cost-function.</p>
<p><img src='/images/ML/xavier_4.png' width="600"></p>
<h3 id="gradients-at-initialization">Gradients at Initialization</h3>
<p>We will start by studying the linear regime (activation). For a dense artificial NN using symmetric activation function <span class="math inline">\(f\)</span> with unit derivative at 0 (ie. <span class="math inline">\(f^{\prime} (0) = 1\)</span>). If we write <span class="math inline">\(\mathbf{z}^{i}\)</span> for the activation vector of layer <span class="math inline">\(i\)</span> (row vector), and <span class="math inline">\(\mathbf{s}^i\)</span> the argument vector of the activation function at layer <span class="math inline">\(i\)</span>, we have (<strong>denominator layout</strong>):</p>
<p><span class="math display">\[\mathbf{s}^{i}_{1 \times d} = \mathbf{z}^{i} W^i + \mathbf{b}^{i}\]</span></p>
<p>and <span class="math inline">\(\mathbf{z}^{i+1} = f(\mathbf{s}^{i})\)</span>, Then:</p>
<span class="math display">\[\begin{aligned}
{\frac{\partial Cost}{\partial s^{i}_{k}}}_{1 \times 1} &amp;= \frac{\partial \mathbf{z}^{i + 1}}{\partial s^{i}_{k}}\frac{\partial \mathbf{s}^{i+1}}{\partial \mathbf{z}^{i + 1}}\frac{\partial Cost}{\partial \mathbf{s}^{i+1}}\\
&amp;= [\frac{\partial z^{i + 1}_1}{\partial s^{i}_{k}} ... \frac{\partial z^{i + 1}_k}{\partial s^{i}_{k}} ... \frac{\partial z^{i + 1}_d}{\partial s^{i}_{k}}] W^{i} \frac{\partial Cost}{\partial \mathbf{s}^{i+1}}\\
&amp;= [0 ... f^{\prime} (s^{i}_{k}) ... 0] W^{i + 1} \frac{\partial Cost}{\partial \mathbf{s}^{i+1}}\\
&amp;= [f^{\prime} (s^{i}_{k}) W^{i + 1}_{k, \cdot}]_{1 \times d} \frac{\partial Cost}{\partial \mathbf{s}^{i+1}}_{d \times 1}\\
\\
\frac{\partial Cost}{\partial w^{i}_{l, k}}_{1 \times 1} &amp;= \frac{\partial \mathbf{s}^{i}}{\partial w^{i}_{l, k}}_{1 \times d} \frac{\partial Cost}{\partial \mathbf{s}^{i}}_{d \times 1}\\
&amp;= [0 ... \frac{\partial s^{i}_{k}}{\partial w^{i}_{l, k}} ... 0] \frac{\partial Cost}{\partial \mathbf{s}^{i}}\\
&amp;= z^{i}_{l} \frac{\partial Cost}{\partial s^{i}_{k}}\\
\end{aligned}\]</span>
<p>Assume that we are in a linear regime (activation) at the initialization, that the weights are initialized i.i.d with mean zero , same variance (i.e <span class="math inline">\(Var[w^{l}_1] = Var[w^l_i] = Var[w^l]\)</span>) and that the inputs features have mean zero and variances are the same (i.e <span class="math inline">\(Var[x_1] = Var[x_i] = Var[x]\)</span>), we can say that with <span class="math inline">\(n_i\)</span> the size of layer <span class="math inline">\(i\)</span> and <span class="math inline">\(\mathbf{x}\)</span> the network input:</p>
<p><span class="math display">\[f^{\prime} (s^i_k) \approx 1\]</span></p>
<p><span class="math display">\[Var[\mathbf{z}^{1}] = Var[\mathbf{x}W^{0} + \mathbf{b}^{0}] = n_{0}[Var[x]Var[w^{0}]]_{1 \times d} = n_0 Var[\mathbf{x}] Var[W^0]\]</span></p>
<p><span class="math display">\[Var[\mathbf{z}^{i}] = Var[\mathbf{z^{i - 1}}W^{i - 1} + \mathbf{b}^{i - 1}] = Var[\mathbf{x}] \prod^{i - 1}_{i^{\prime} = 0} n_{i^{\prime}}Var[W]^{i^{\prime}}\]</span></p>
<p>Where <span class="math inline">\(Var[W^{l}] = [Var[w^l]]_{n_{l - 1} \times n_{l}}\)</span> is the shared scalar variance of all weights at layer <span class="math inline">\(l\)</span>. Then for a network with <span class="math inline">\(d\)</span> layers:</p>
<span class="math display">\[\begin{aligned}
Var[\frac{\partial Cost}{\partial \mathbf{s}^{i}}] &amp;= Var[\frac{\partial \mathbf{z}^{i + 1}}{\partial \mathbf{s}^{i}} W^{i + 1} \frac{\partial Cost}{\partial \mathbf{s}^{i+1}}]\\
&amp;= Var[W^{i + 1} \frac{\partial Cost}{\partial \mathbf{s}^{i+1}}]\\
&amp;= Var[W^{i + 1}W^{i + 2}\frac{\partial Cost}{\partial \mathbf{s}^{i+2}}]\\
&amp;= (\prod^{d}_{i^{\prime} = i} n_{i^{\prime} + 1} Var[W^{i^{\prime}}]) Var[\frac{\partial Cost}{\partial \mathbf{s}^{d}}] 
\\
\\
\\
Var[\frac{\partial Cost}{\partial w^{i}_{l, k}}] &amp;= Var[z^{i}_{l} \frac{\partial Cost}{\partial s^{i}_{k}}]\\
&amp;= Var[x] \prod^{i - 1}_{i^{\prime} = 0} n_{i^{\prime}} Var[w^{i^{\prime}}]  \prod^{d}_{i^{\prime} = i} n_{i^{\prime} + 1} Var[w^{i^{\prime}}]\\
&amp;= \prod^{i - 1}_{i^{\prime} = 0} n_{i^{\prime}} Var[w^{i^{\prime}}] \prod^{d}_{i^{\prime} = i} n_{i^{\prime} + 1}  Var[w^{i^{\prime}}] \times Var[x] Var[\frac{\partial Cost}{\partial s^{d}}]
\end{aligned}\]</span>
<p><br></p>
<p>From a forward-propagation point of view (We want to make sure that we have similar variance initialization at deeper layers as all layers, so we do not stuck at small gradients at beginning), we would like to keep things flowing (want inputs to have similar mean and variance, similar distribution):</p>
<p><span class="math display">\[Var[z^{i}] = Var[z^{i^{\prime}}]\]</span></p>
<p>This transforms to:</p>
<p><span class="math display">\[Var[x] \prod^{i - 1}_{k = 0} n_{k} Var[w^{k}] = Var[x] \prod^{i^{\prime} - 1}_{j = 0} n_{j} Var[w^{j}]\]</span></p>
<p><span class="math display">\[\implies \prod^{\max (i - 1, i^{\prime} - 1)}_{j = \max (i - 1, i^{\prime} - 1) - \min (i - 1, i^{\prime} - 1)} n_j Var(w^j) = 1 \]</span></p>
<p>If we let <span class="math inline">\(Var[w^i] = \frac{1}{n_i}\)</span>, then the above condition is satisfied for <span class="math inline">\((i, i^{\prime})\)</span>.</p>
<p><br></p>
<p>From a back-propagation point of view (We want to have similar variance so no gradients exploding or vanishing at the beginning), we would similarly like to have the gradients to have similar variance as we backpropagate through layers:</p>
<p><span class="math display">\[Var[\frac{\partial Cost}{\partial s^{i^{\prime}}}] = Var[\frac{\partial Cost}{\partial s^{i}}]\]</span></p>
<p><span class="math display">\[\implies (\prod^{d}_{j = i^{\prime}} n_{j + 1} Var[w^{j}]) Var[\frac{\partial Cost}{\partial s^{d}}] = (\prod^{d}_{k = i} n_{k + 1} Var[w^{k}]) Var[\frac{\partial Cost}{\partial s^{d}}]\]</span></p>
<p><span class="math display">\[\implies \prod^{\max (i - 1, i^{\prime} - 1)}_{j = \min (i - 1, i^{\prime} - 1)} n_{j + 1} Var(w^j) = 1\]</span></p>
<p>If we let <span class="math inline">\(Var[w^i] = \frac{1}{n_{i + 1}}\)</span>, then the above condition is satisfied for <span class="math inline">\((i, i^{\prime})\)</span>.</p>
<p><br></p>
<p>Thus, we have two conditions (to ensure no gradient exploding and vanishing):</p>
<p><span class="math display">\[Var[w^i] = \frac{1}{n_{i + 1}} \quad \quad Var[w^i] = \frac{1}{n_i}\]</span></p>
<p>When all layers have same size, we can satisfy both conditions. However, in most cases, we do not have this condition satisfied. Thus, by combining and compromising, we have:</p>
<p><span class="math display">\[Var[w^i] = \frac{2}{n_{i} + n_{i + 1}}\]</span></p>
<p>This initialization is called <code>normalized initialization</code>.</p>
<p><br></p>
<p>Example:</p>
<blockquote>
<p>If we have initialization <span class="math inline">\(w^{i} \sim U[-\frac{1}{\sqrt{n_{i - 1}}}, \frac{1}{\sqrt{n_{i - 1}}}]\)</span>, then the variance is <span class="math inline">\(Var[w^{i}] = \frac{1}{3 n_{i - 1}}\)</span>. <strong>This will cause the variance to depend on the layer and decreasing</strong>. The normalization factor may therefore be important when initializing deep networks because of the multiplicative effect through layers. Thus, we can refine this to be: <span class="math display">\[w^{i} \sim U[-\frac{\sqrt{6}}{\sqrt{n_{i + 1} + n_{i}}}, \frac{\sqrt{6}}{\sqrt{n_{i + 1} + n_{i}}}]\]</span> then the variance <span class="math inline">\(Var[w^{i}] = \frac{2}{n_{i} + n_{i + 1}}\)</span></p>
</blockquote>
<h3 id="back-propagated-gradients-during-learning">Back-propagated Gradients During Learning</h3>
<p>The dynamic of learning in NN is complex and we would like to develop better tools to analyze and track it. In particular, we cannot use simple variance calculations like above because the weights values are not anymore independent of the activation values and the linearity hypothesis is also violated.</p>
<p><img src='/images/ML/xavier_5.png' width="600"></p>
<p>From the above graph, we can see that at the beginning of training:</p>
<ol type="1">
<li>The gradient variance gets smaller as it is propagated downwards.</li>
<li>The distribution of gradient is roughly the same using <code>normalized initialization</code>.</li>
</ol>
<h2 id="conclusions">Conclusions</h2>
<ol type="1">
<li>The more classical NN with sigmoid or hyperbolic tangent units and standard initialization fare rather poorly, converging more slowly and apparently towards ultimately poorer local minima.</li>
<li>The softsign networks seem to be more robust to the initialization procedure than the tanh network.</li>
<li>For tanh networks, the proposed <code>normalized initialization</code> can be quite helpful, because the layer to layer transformation maintain magnitudes of activations and gradients.</li>
<li>Sigmoid activations should be avoided when initializing from small random weights, because they yield poor learning dynamics with initial saturation of the top hidden layer.</li>
<li>Keeping the layer to layer transformations such that both activations and gradients flow well (i.e with a jacobian around 1) appears helpful.</li>
</ol>
]]></content>
      <categories>
        <category>DL</category>
        <category>Techniques</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Initialization</tag>
      </tags>
  </entry>
  <entry>
    <title>variational_inference</title>
    <url>/2022/06/06/variational-inference/</url>
    <content><![CDATA[<h1 id="variational-inference-a-review-for-statisticians">Variational Inference: A Review for Statisticians</h1>
<h2 id="general-problem-setting">General Problem Setting:</h2>
<p>Consider a joint density of latent variables <span class="math inline">\(\mathbf{z} = z_{1:m}\)</span> and observations <span class="math inline">\(\mathbf{x} = x_{1:n}\)</span>:</p>
<p><span class="math display">\[p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{x}|\mathbf{z})\]</span></p>
<p>The main idea behind variational inference is to use optimization to compute the conditional density of the latent variables given the observations:</p>
<p><span class="math display">\[p(\mathbf{z} | \mathbf{x}) = \frac{p(\mathbf{z}) p(\mathbf{x}|\mathbf{z})}{p(\mathbf{x})}\]</span></p>
<p>This conditional can be used to produce point or interval estimates of the latent variables, form predictive densities of new data <span class="math inline">\(p(x^* | \mathbf{x})\)</span> and more.</p>
<p>The quantity:</p>
<p><span class="math display">\[p(\mathbf{x}) = \int_\mathbf{z} p(\mathbf{z}, \mathbf{x}) d\mathbf{z}\]</span></p>
<p>is called the evidence, for many models, the evidence integral is unavailable in closed form or requires exponential time to compute.</p>
<h3 id="evidence-lower-bound">Evidence Lower Bound</h3>
<p>In variational inference, we specify a family <span class="math inline">\(\Theta\)</span> of densities over the latent variables. Each <span class="math inline">\(q(\mathbf{z})\)</span> is a candidate approximation to the exact conditional. Our goal is to find the best candidate, the one closest in KL divergence to the exact conditional. Inference now amounts to solving the following optimization problem:</p>
<p><span class="math display">\[q^*(\mathbf{z}) = \arg\min_{q(\mathbf{z}) \in \Theta} KL(q(\mathbf{z}) \;||\; p(\mathbf{z} | \mathbf{x})) = \int_{z} q(\mathbf{z})\log\frac{q(\mathbf{z})}{p(\mathbf{z}| \mathbf{x})} = E_{\mathbf{z} \sim q(\mathbf{z})}[\log q(\mathbf{z})] - E_{\mathbf{z} \sim q(\mathbf{z})}[\log p(\mathbf{z} | \mathbf{x})] = E_{\mathbf{z} \sim q(\mathbf{z})}[\log q(\mathbf{z})] - E_{\mathbf{z} \sim q(\mathbf{z})}[\log p(\mathbf{z}, \mathbf{x})] + \log p(\mathbf{x})\]</span></p>
<p>However, this objective is not computable because it requires computing the evidence <span class="math inline">\(\log p(\mathbf{x})\)</span>. Since we cannot compute KL, we optimize an alternative objective that is equivalent ot the KL up to an added constant:</p>
<p><span class="math display">\[ELBO(q) = E_{\mathbf{z} \sim q(\mathbf{z})} [\log p(\mathbf{z}, \mathbf{x})] - E_{\mathbf{z} \sim q(\mathbf{z})}[\log q(\mathbf{z})]\]</span></p>
<p>This function is called the evidence lower bound (ELBO), <strong>ELBO is the negative KL divergence plus a constant <span class="math inline">\(\log p(\mathbf{x})\)</span> w.r.t <span class="math inline">\(q(\mathbf{z})\)</span></strong>. Maximizing ELBO is equivalent to minimizing the KL divergence.</p>
<p><br></p>
<h4 id="property-1-elbo-is-the-balance-between-likelihood-and-prior">Property 1: ELBO is the Balance Between Likelihood and Prior</h4>
<p>Continue from above equation of <span class="math inline">\(ELBO(q)\)</span>, we can rewrite it as (<span class="math inline">\(E[\cdot] := E_{\mathbf{z} \sim q(\mathbf{z})}[\cdot]\)</span>):</p>
<p><span class="math display">\[ELBO(q) = E[\log p(\mathbf{z})] - E[\log q(\mathbf{z})] + E[\log p(\mathbf{x} | \mathbf{z})] = -KL(q(\mathbf{z}) | p(\mathbf{z})) + E[\log p(\mathbf{x} | \mathbf{z})]\]</span></p>
<p>In order to find a <span class="math inline">\(q(\mathbf{z})\)</span> that maximize ELBO, we have to maximize the expected log likelihood of the data given the hidden variables and minimize the distance to the prior (so the prior acts as a regularizer).</p>
<h4 id="property-2-elbo-is-the-lower-bound-of-the-log-evidence">Property 2: ELBO is the Lower Bound of the Log Evidence</h4>
<p>ELBO lower bounds the log evidence:</p>
<p><span class="math display">\[\log p(\mathbf{x}) = KL(q(\mathbf{z}) \;||\; p(\mathbf{z} | \mathbf{x})) \geq ELBO (q), \quad \quad \forall q \in \Theta\]</span></p>
<h2 id="ref">REF</h2>
<p>https://arxiv.org/pdf/2205.14415.pdf</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Value Function Approximation (2)</title>
    <url>/2021/07/13/vfa-2/</url>
    <content><![CDATA[<h1 id="value-function-approximation-algorithms">Value Function Approximation (Algorithms)</h1>
<h2 id="approximate-value-iteration">Approximate Value Iteration</h2>
<h3 id="population-version">Population Version</h3>
<p>Recall that the procedure for VI is:</p>
<p><span class="math display">\[V_{k+1} \leftarrow T^{\pi}V_{k}\]</span> <span class="math display">\[V_{k+1} \leftarrow T^{*}V_{k}\]</span></p>
<p>One way to develop its approximation version is to perform each step only approximately (i.e find <span class="math inline">\(V_{k+1} \in \mathbf{F}\)</span>) such that:</p>
<p><span class="math display">\[V_{k+1} \approx TV_{k}\]</span></p>
<p>Where <span class="math inline">\(T\)</span> can be <span class="math inline">\(T^*\)</span> or <span class="math inline">\(T^\pi\)</span>.</p>
<p>We start from a <span class="math inline">\(V_0 \in \mathbf{F}\)</span>, and then at each iteration <span class="math inline">\(k\)</span> of AVI, we solve (i.e <span class="math inline">\(p\)</span> is often 2):</p>
<p><span class="math display">\[V_{k+1} \leftarrow \underset{V \in \mathbf{F}}{\arg\min} \|V - TV_{k}\|^p_{p, \mu}\]</span></p>
<p>At each iteration, <span class="math inline">\(TV_k\)</span> (our target) may not be within <span class="math inline">\(\mathbf{F}\)</span> anymore even though <span class="math inline">\(V_{k} \in \mathbf{F}\)</span>, we may have some approximation error at each iteration of AVI. The amount of error depends on how expressive <span class="math inline">\(\mathbf{F}\)</span> is and how much <span class="math inline">\(T\)</span> can push a function within <span class="math inline">\(\mathbf{F}\)</span> outside that space.</p>
<h3 id="batch-version">Batch Version</h3>
<p>The objective of AVI cannot be computed because:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is unknown</li>
<li>Environment <span class="math inline">\(R, P\)</span> is often not available, thus <span class="math inline">\(TQ_k\)</span> cannot be computed.</li>
</ul>
<p>If we have samples in the form of <span class="math inline">\((X, A, R, X^{\prime})\)</span>, we can compute the unbiased sample of <span class="math inline">\(TQ_k\)</span>:</p>
<p><span class="math display">\[\hat{T}^{\pi}Q_k = R + \gamma Q(X^{\prime}, A^{\prime})\]</span> <span class="math display">\[\hat{T}^{*} Q_k = R + \gamma \max_{a^{\prime} \in A} Q(X^{\prime}, a^{\prime}) \]</span></p>
<p>Where <span class="math inline">\(A^{\prime} \sim \pi(\cdot | X^{\prime})\)</span></p>
<p><br></p>
<p><strong>The question is: can we replace <span class="math inline">\(TQ_k\)</span> with <span class="math inline">\(\hat{T}Q_k\)</span>?</strong></p>
Given any <span class="math inline">\(Z = (X, A)\)</span>
<span class="math display">\[\begin{aligned}
E_{\hat{T}Q_k}[|Q(Z) - \hat{T}Q_k (Z)|^2 | Z] &amp;= E_{\hat{T}Q_k}[|Q(Z) - TQ_k (Z) + TQ_k (Z) - \hat{T}Q_k (Z)|^2 | Z]\\
&amp;= E_{\hat{T}Q_k}[|Q(Z) - TQ_k (Z)|^2 | Z] + E_{\hat{T}Q_k}[|TQ_k (Z) - \hat{T}Q_k(Z)|^2 | Z] + 2 E_{\hat{T}Q_k}[(Q(Z) - TQ_k (Z))(TQ_k (Z) - \hat{T}Q_k (Z)) | Z]\\
&amp;= E_{\hat{T}Q_k}[|Q(Z) - TQ_k (Z)|^2 | Z] + E_{\hat{T}Q_k}[|TQ_k (Z) - \hat{T}Q_k(Z)|^2 | Z]
\end{aligned}\]</span>
<p>Since <span class="math inline">\(Z \sim \mu\)</span>:</p>
<span class="math display">\[\begin{aligned}
E_{\mu} [E_{\hat{T}Q_k}[|Q(Z) - TQ_k (Z)|^2 | Z] + E_{\hat{T}Q_k}[|TQ_k (Z) - \hat{T}Q_k(Z)|^2 | Z]] &amp;= E_{\mu, \hat{T}Q_k} [|Q(Z) - TQ_k (Z)|^2] + E_{\mu, \hat{T}Q_k} [|TQ_k (Z) - \hat{T}Q_k(Z)|^2]\\
&amp;= \|Q(Z) - TQ_k (Z)\|^2_{2, \mu} + E_{\mu} [Var[\hat{T}Q_k (Z) | Z]]
\end{aligned}\]</span>
<p>Since the expectation of variance term does not depend on <span class="math inline">\(Q\)</span>, the solution to the surrogate objective is the same as the original objective:</p>
<p><span class="math display">\[\underset{Q \in \mathbf{F}}{\arg\min} \; E_{\mu, \hat{T}Q_k}[|Q(Z) - \hat{T}Q_k (Z)|^2] = \underset{Q \in \mathbf{F}}{\arg\min} \; \|Q(Z) - TQ_k (Z)\|^2_{2, \mu}\]</span></p>
<p>Similar to ERM, we do not know the environment dynamics <span class="math inline">\(R, P\)</span> and distribution <span class="math inline">\(\mu\)</span>. We can use samples and estimate the expectation:</p>
<p><span class="math display">\[\frac{1}{N} \sum^{N}_{i=1} |Q(X_i, A_i) - \hat{T}Q_k (X_i, A_i)|^2 = \|Q - \hat{T}Q_k\|^2_{2, D_n}\]</span></p>
<p><strong>This is the basis of DQN</strong>.</p>
<h2 id="bellman-residual-minimization">Bellman Residual Minimization</h2>
<h3 id="population-version-1">Population Version</h3>
<p>Recall that:</p>
<p><span class="math display">\[V = T^{\pi}V \implies V = V^{\pi}\]</span></p>
<p>Under FA, we may not achieve this exact equality, instead:</p>
<p><span class="math display">\[V \approx V^{\pi}\]</span></p>
<p>Thus, we can formulate our objective:</p>
<p><span class="math display">\[V = \underset{V \in \mathbf{F}}{\arg\min} \|V - T^{\pi}V\|^p_{p, \mu} = \|BR(V)\|^p_{p, \mu}\]</span></p>
<p>By minimizing this objective (<span class="math inline">\(p\)</span> is usually 2), we have <code>Bellman Residual Minimization</code>.</p>
<p>This procedure is different from AVI in that we do not mimic the iterative process of VI (which is convergent in the exact case without any FA), but instead directly go for the solution of fixed-point equation (<span class="math inline">\(V - T^{\pi}V\)</span> instead of <span class="math inline">\(V - T^{\pi}V_k\)</span>).</p>
<p><img src='/images/RL/vfa/brm_1.png' width="600"></p>
<p>If there exists a <span class="math inline">\(V \in \mathbf{F}\)</span> that makes <span class="math inline">\(\|V - T^{\pi}V\|^2_{2, \mu} = 0\)</span> and if we assume <span class="math inline">\(\mu(x) &gt; 0, \; \forall x \in \chi\)</span>, we can conclude that <span class="math inline">\(V(x) = V^{\pi}(x), \; \forall x \in \chi\)</span> so <span class="math inline">\(V = V^{\pi}\)</span>.</p>
<h3 id="batch-version-1">Batch Version</h3>
<p>Similar to AVI, we may want to replace <span class="math inline">\(TV\)</span> or <span class="math inline">\(TQ\)</span> by <span class="math inline">\(\hat{T}Q\)</span>. Thus, our empirical objective is:</p>
<p><span class="math display">\[Q = \underset{Q \in \mathbf{F}}{\arg\min} \frac{1}{N} \sum^N_{i=1} |Q(X_i, A_i) - \hat{T}^{\pi} Q (X_i, A_i)|^2 = \|Q - \hat{T}^{\pi}Q\|^2_{2, D_n}\]</span></p>
<p>Using <span class="math inline">\(D_n = \{(X_i, A_i, R_i, X^{\prime}_i)\}^N_{i=1}\)</span></p>
<p>We can see that <span class="math inline">\(Q\)</span> appears in both <span class="math inline">\(\hat{T}^{\pi}Q\)</span> and <span class="math inline">\(Q\)</span>, which is different from AVI and ERM. <strong>This causes an issue: the minimizer of <span class="math inline">\(\|Q - T^{\pi}Q\|^2_{2, \mu}\)</span> and <span class="math inline">\(\|Q - \hat{T}^{\pi}Q\|^2_{2, \mu}\)</span> are not necessarily the same for stochastic dynamics.</strong></p>
<p><br></p>
<p>To see this, for any <span class="math inline">\(Q\)</span> and <span class="math inline">\(Z = (X, A)\)</span> we compute:</p>
<p><span class="math display">\[E_{\hat{T}^{\pi}Q} [|Q(Z) - \hat{T}Q(Z)|^2 | Z]\]</span></p>
<p>Then:</p>
<span class="math display">\[\begin{aligned}
E_{\hat{T}^{\pi}Q}[|Q(Z) - \hat{T}^{\pi}Q (Z)|^2 | Z] &amp;= E_{\hat{T}^{\pi}Q}[|Q(Z) - T^{\pi}Q (Z) + T^{\pi}Q (Z) - \hat{T}^{\pi}Q (Z)|^2 | Z]\\
&amp;= E_{\hat{T}^{\pi}Q}[|Q(Z) - T^{\pi}Q (Z)|^2 | Z] + E_{\hat{T}^{\pi}Q}[|T^{\pi}Q (Z) - \hat{T}^{\pi}Q(Z)|^2 | Z] + 2 E_{\hat{T}^{\pi}Q}[(Q(Z) - T^{\pi}Q (Z))(T^{\pi}Q (Z) - \hat{T}^{\pi}Q (Z)) | Z]\\
&amp;= E_{\hat{T}^{\pi}Q}[|Q(Z) - T^{\pi}Q (Z)|^2 | Z] + E_{\hat{T}^{\pi}Q}[|T^{\pi}Q (Z) - \hat{T}^{\pi}Q(Z)|^2 | Z]
\end{aligned}\]</span>
<p>Since <span class="math inline">\(Z \sim \mu\)</span>, the first term is:</p>
<p><span class="math display">\[E_{\hat{T}^{\pi}Q, \mu}[|Q(Z) - T^{\pi}Q (Z)|^2] = \|Q - T^{\pi}Q\|^2_{2, \mu}\]</span></p>
<p>The second term is:</p>
<p><span class="math display">\[E_{\mu}[E_{\hat{T}^{\pi}Q}[|T^{\pi}Q (Z) - \hat{T}^{\pi}Q(Z)|^2 | Z]] = E_{\mu}[Var[\hat{T}^{\pi}Q(Z) | Z]]\]</span></p>
<p>We can see that the variance term <span class="math inline">\(Var[\hat{T}^{\pi}Q(Z)\)</span> depends on <span class="math inline">\(Q\)</span>, <strong>as we minimize the objective w.r.t <span class="math inline">\(Q\)</span> in stochastic dynamical systems (for deterministic ones, it is zero)</strong>, we have $ E_{}[Var[^{}Q(Z) | Z]] $, so the minimizer of the batch version objective is not the same as population version for BRM in stochastic dynamics.</p>
<h2 id="projected-bellman-error">Projected Bellman Error</h2>
<p>From BRM, we know that even though <span class="math inline">\(V \in \mathbf{F}\)</span>, <span class="math inline">\(T^{\pi} V\)</span> may not be in <span class="math inline">\(\mathbf{F}\)</span>. Thus, a good approximator <span class="math inline">\(V \in \mathbf{F}\)</span> should have distance to <span class="math inline">\(T^{\pi}V\)</span> small. Thus, we want to find <span class="math inline">\(V \in \mathbf{F}\)</span> such that <span class="math inline">\(V\)</span> is the projection of <span class="math inline">\(T^{\pi}V\)</span> onto the space <span class="math inline">\(\mathbf{F}\)</span>.</p>
<p><img src='/images/RL/vfa/pbe_1.png' width="600"></p>
<p>We want to find a <span class="math inline">\(V \in \mathbf{F}\)</span> such that:</p>
<p><span class="math display">\[V = \prod_{\mathbf{F}, \mu} T^{\pi}V\]</span></p>
<p>Where <span class="math inline">\(\prod_{\mathbf{F}, \mu}\)</span> is the projection operator.</p>
<p>TRhe projectio operator <span class="math inline">\(\prod_{\mathbf{F}, \mu}\)</span> is a linear operator that takes <span class="math inline">\(V \in B(\chi)\)</span> and maps it to closest point on <span class="math inline">\(F\)</span> measured according to its <span class="math inline">\(L_{2} (\mu)\)</span> norm:</p>
<p><span class="math display">\[\prod_{\mathbf{F}, \mu} V \triangleq \underset{V^{\prime} \in \mathbf{F}}{\arg\min} \|V^{\prime} - V\|^2_{2, \mu}\]</span></p>
<p>It has some properties:</p>
<ol type="1">
<li>The projection belongs to function space <span class="math inline">\(\mathbf{F}\)</span>: <span class="math display">\[\prod_{\mathbf{F}, \mu} V \in \mathbf{F}\]</span></li>
<li>If <span class="math inline">\(V \in \mathbf{F}\)</span>, the projection is itself: <span class="math display">\[V \in \mathbf{F} \implies \prod_{\mathbf{F}, \mu} V = V\]</span></li>
<li>The projection operator onto a subspace is a non-expansion: <span class="math display">\[\|\prod_{\mathbf{F}, \mu} V_1 - \prod_{\mathbf{F}, \mu} V_2\|^2_{2, \mu} \leq \|V_1 - V_2\|^2_{2, \mu}\]</span></li>
</ol>
<h3 id="population-version-2">Population Version</h3>
<p>We can define a loss function based on <span class="math inline">\(V = \prod_{\mathbf{F}, \mu} T^{\pi}V\)</span>:</p>
<p><span class="math display">\[\|V - \prod_{\mathbf{F}, \mu} T^{\pi}V\|^2_{2, \mu}\]</span></p>
<p>This is called <code>Projected Bellman Error</code> or <code>Mean Square Projected Bellman Error</code>.</p>
<p>We find the value function by solving the following optimization problem:</p>
<p><span class="math display">\[V = \underset{V \in \mathbf{F}}{\arg\min} \|V - \prod_{\mathbf{F}, \mu} T^{\pi}V\|^2_{2, \mu}\]</span></p>
<p>Since <span class="math inline">\(V \in \mathbf{F}\)</span>, the projection operator is linear:</p>
<span class="math display">\[\begin{aligned}
V -  \prod_{\mathbf{F}, \mu} T^{\pi}V &amp;= \prod_{\mathbf{F}, \mu} V - \prod_{\mathbf{F}, \mu} T^{\pi}V\\
&amp;= \prod_{\mathbf{F}, \mu} (V - T^{\pi}V)\\
&amp;= - \prod_{\mathbf{F}, \mu} (T^{\pi}V - V)\\
&amp;= - \prod_{\mathbf{F}, \mu} (BR(V))
\end{aligned}\]</span>
<p>So the objective can be rewritten as:</p>
<p><span class="math display">\[V = \underset{V \in \mathbf{F}}{\arg\min}  \|\prod_{\mathbf{F}, \mu} BR(V)\|^2_{2, \mu}\]</span></p>
<p>Which is the norm of the projection of the Bellman Residual onto <span class="math inline">\(\mathbf{F}\)</span>.</p>
<p><br></p>
<p>We can think of solving the projected bellman error objective as solving the <strong>two coupled optimization problems</strong>:</p>
<ol type="1">
<li>Find the projection point given value function <span class="math inline">\(V^{\prime}\)</span>: <span class="math display">\[V^{\prime\prime} = \underset{V^{\prime\prime} \in \mathbf{F}}{\arg\min} \|V^{\prime\prime} - T^{\pi}V^{\prime}\|^2_{2, \mu}\]</span></li>
<li>Find the value function <span class="math inline">\(V^{\prime}\)</span> on <span class="math inline">\(\mathbf{F}\)</span> that is closest to the projection point <span class="math inline">\(V^{\prime\prime}\)</span>: <span class="math display">\[V^{\prime} = \underset{V^{\prime} \in \mathbf{F}}{\arg\min} \|V^{\prime} - V^{\prime\prime}\|^2_{2, \mu}\]</span></li>
</ol>
<h3 id="least-square-temporal-difference-learning-population-version">Least Square Temporal Difference Learning (Population Version)</h3>
<p>If <span class="math inline">\(\mathbf{F}\)</span> is a linear FA with basis functions <span class="math inline">\(\phi_1, ...., \phi_p\)</span>:</p>
<p><span class="math display">\[\mathbf{F}: \{x \rightarrow \boldsymbol{\phi}(x)^T \mathbf{w}; \; \mathbf{w} \in \mathbb{R}^p\}\]</span></p>
<p>We can find a direct solution to the PBE objective, that is we want to find <span class="math inline">\(V \in \mathbf{F}\)</span> s.t:</p>
<p><span class="math display">\[V = \prod_{\mathbf{F}, \mu} T^{\pi}V\]</span></p>
<p>We assume that:</p>
<ul>
<li><span class="math inline">\(\chi\)</span> is finite and <span class="math inline">\(|\chi| = N\)</span>, <span class="math inline">\(N \gg p\)</span>, each <span class="math inline">\(\boldsymbol{\phi}_i = [\phi_i(x_1) .... \phi_i(x_N)]^T\)</span> is a <span class="math inline">\(N\)</span>-dimentional vector.</li>
</ul>
<p>Then, we define <span class="math inline">\(\Phi_{N\times p}\)</span> as the matrix of concatenating all features:</p>
<p><span class="math display">\[\Phi = [\boldsymbol{\phi}_1 .... \boldsymbol{\phi}_p]_{N\times p}\]</span></p>
<p>The value function <span class="math inline">\(V \in \mathbf{F}\)</span> is then:</p>
<p><span class="math display">\[V_{N \times 1} = \Phi_{N\times p} \mathbf{w}_{p \times 1}\]</span></p>
<p>Our <strong>goal</strong> is to find a weight vector <span class="math inline">\(\mathbf{w} \in \mathbb{R}^p\)</span> such that:</p>
<p><span class="math display">\[V = \prod_{\mathbf{F}, \mu} T^{\pi}V \implies \Phi\mathbf{w} = \prod_{\mathbf{F}, \mu} T^{\pi}(\Phi \mathbf{w})\]</span></p>
<p>Let <span class="math inline">\(M = \text{diag}(\mu)\)</span>, since:</p>
<p><span class="math display">\[\|V\|^2_{2, \mu} = &lt;V, V&gt;_{\mu} = \sum_{x \in \chi} |V(x)|^2\mu(x) = V^TMV\]</span></p>
<p><span class="math display">\[&lt;V_1, V_2&gt;_{\mu} = \sum_{x \in \chi} V_1(x)V_2(x) = V^T_1 M V_2\]</span></p>
<p>Then, the projection operator onto the linear <span class="math inline">\(\mathbf{F}\)</span> would be:</p>
<span class="math display">\[\begin{aligned}
\prod_{\mathbf{F}, \mu} V &amp;= \underset{V^{\prime} \in \mathbf{F}}{\arg\min}\|V^{\prime} - V\|^2_{2, \mu}\\
&amp;= \underset{\mathbf{w} \in \mathbb{R}^p}{\arg\min}\|\Phi\mathbf{w} - V\|^2_{2, \mu}\\
&amp;= \underset{\mathbf{w} \in \mathbb{R}^p}{\arg\min} (\Phi\mathbf{w} - V)^T M (\Phi\mathbf{w} - V)
\end{aligned}\]</span>
<p>By taking the derivative and setting it to zero (assuming that <span class="math inline">\(\Phi^TM\Phi\)</span> is invertible):</p>
<p><span class="math display">\[\frac{\partial \prod_{\mathbf{F}, \mu} V}{\partial \mathbf{w}} = \Phi^TM(\Phi\mathbf{w} - V) = 0\]</span> <span class="math display">\[\implies \mathbf{w^{*}} = (\Phi^TM\Phi)^{-1}\Phi^TMV\]</span></p>
<p>Then the projection is:</p>
<p><span class="math display">\[\prod_{\mathbf{F}, \mu} V = \Phi \mathbf{w} = \Phi (\Phi^TM\Phi)^{-1}\Phi^TMV\]</span></p>
<p>Since <span class="math inline">\(T^{\pi} V = r^{\pi} (x) + \gamma \sum_{x \in \chi, a \in \mathbf{A}}P^{\pi}(x^{\prime} | x, a) \pi(a | s) V(x^{\prime})\)</span>, we can write it in vector form for all states:</p>
<p><span class="math display">\[(T^{\pi}V)_{N\times 1} = \mathbf{r}^{\pi}_{N \times 1} + \gamma P^{\pi}_{N\times N} V_{N \times 1}\]</span> <span class="math display">\[\implies (T^{\pi}\Phi\mathbf{w})_{N\times 1} = \mathbf{r}^{\pi}_{N \times 1} + \gamma P^{\pi}_{N\times N} \Phi_{N\times p}\mathbf{w}_{p \times 1}\]</span></p>
<p>Substitute the equation of <span class="math inline">\(T^{\pi}\Phi\mathbf{w}\)</span> into <span class="math inline">\(V\)</span> in the projection equation:</p>
<p><span class="math display">\[\prod_{\mathbf{F}, \mu} T^{\pi}\Phi\mathbf{w} = \Phi \mathbf{w} = \Phi (\Phi^TM\Phi)^{-1}\Phi^TM(T^{\pi}\Phi\mathbf{w})\]</span> <span class="math display">\[\implies \Phi \mathbf{w} = [\Phi (\Phi^TM\Phi)^{-1}\Phi^TM][\mathbf{r}^{\pi} + \gamma P^{\pi} \Phi\mathbf{w}]\]</span></p>
<p>Multiply both sides by <span class="math inline">\(\Phi^T M\)</span> and simply:</p>
<p><span class="math display">\[\Phi^T M \Phi \mathbf{w} = [\Phi^T M\Phi (\Phi^TM\Phi)^{-1}\Phi^TM][\mathbf{r}^{\pi} + \gamma P^{\pi} \Phi\mathbf{w}]\]</span> <span class="math display">\[\implies \Phi^T M \Phi \mathbf{w} = \Phi^TM[\mathbf{r}^{\pi} + \gamma P^{\pi} \Phi\mathbf{w}]\]</span> <span class="math display">\[\implies \Phi^T M \Phi \mathbf{w} - \Phi^TM[\mathbf{r}^{\pi} + \gamma P^{\pi} \Phi\mathbf{w}] = 0\]</span> <span class="math display">\[\implies  \Phi^T M[\mathbf{r}^{\pi} + \gamma P^{\pi} \Phi\mathbf{w} - \Phi \mathbf{w}] = 0\]</span> <span class="math display">\[\implies \mathbf{w}_{TD} = [\Phi^T M (\Phi - \gamma P^{\pi}\Phi)]^{-1}\Phi^T M \mathbf{r}^{\pi}\]</span></p>
<p>The solution <span class="math inline">\(\mathbf{w}_{TD}\)</span> is called <code>Least Square Temporal Difference Method (LSTD)</code>.</p>
<p>Notice that the term <span class="math inline">\(\mathbf{r}^{\pi} + \gamma P^{\pi} \Phi\mathbf{w} - \Phi \mathbf{w} = T^{\pi} V - V = BR(V)\)</span>. Hence:</p>
<p><span class="math display">\[\Phi^TM (BR(V)) = 0\]</span> <span class="math display">\[\implies &lt;\mathbf{\phi}_i, BR(V)&gt; = 0\]</span></p>
<p>Thus, <strong>LSTD</strong> finds a <span class="math inline">\(\mathbf{w}\)</span> s.t the <strong>Bellman Residual is orthogonal</strong> to the basis of <span class="math inline">\(\mathbf{F}\)</span> which is exactly what we want.</p>
<h3 id="batch-version-2">Batch Version</h3>
<p>We have showed that the solution to <span class="math inline">\(V = \prod_{\mathbf{F}, \mu} T^{\pi}V\)</span> with linear FA <span class="math inline">\(V = \Phi\mathbf{w}\)</span> is:</p>
<p><span class="math display">\[\mathbf{w}_{TD} = A^{-1}_{p\times p} \mathbf{b}_{p \times 1}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(A^{-1} = \Phi^T M (\Phi - \gamma P^{\pi}\Phi)]^{-1}\)</span></li>
<li><span class="math inline">\(\mathbf{b} = \Phi^T M \mathbf{r}^{\pi}\)</span></li>
</ul>
<p>Expand <span class="math inline">\(A\)</span> and <span class="math inline">\(\mathbf{b}\)</span> in terms of summations, we have:</p>
<p><span class="math display">\[A_{ij} = \sum^{N}_{n=1} \Phi^T_{in} \mu(n) (\Phi - \gamma P^{\pi}\Phi)_{ij}\]</span> <span class="math display">\[b_i = \sum^N_{n=1} \Phi^T_{in} \mu(n) r^{\pi}_n\]</span></p>
<p>Thus, in terms of current state <span class="math inline">\(x\)</span> and next state <span class="math inline">\(x^{\prime}\)</span>:</p>
<p><span class="math display">\[A = \sum_{x \in \chi} \mu (x) \boldsymbol{\phi} (x) [\boldsymbol{\phi}(x) - \gamma \sum_{x^{\prime} \in \chi} P^{\pi}(x^{\prime} | x)\boldsymbol{\phi}(x^{\prime})]^T = E_{\mu}[\boldsymbol{\phi}(X) [\boldsymbol{\phi}(X) - \gamma E_{P^{\pi}}[\boldsymbol{\phi} (X^{\prime})]]^T]\]</span></p>
<p><span class="math display">\[\mathbf{b} = \sum_{x \in \chi} \mu(x) \boldsymbol{\phi} (x) r^{\pi}(x) = E_{\mu} [\boldsymbol{\phi}(X)r^{\pi}(X)]\]</span></p>
<p>Given data set <span class="math inline">\(D_n = \{X_i, R_i, X^{\prime}_i\}^{M}_{i=1}\)</span> with <span class="math inline">\(X_i \sim \mu\)</span>, <span class="math inline">\(X^{\prime} \sim P^{\pi}(\cdot | X_i)\)</span> and <span class="math inline">\(R_i \sim R^{\pi}(\cdot | X_i)\)</span>, we define the empirical estimator <span class="math inline">\(\hat{A}_n, \hat{ \mathbf{b}}_n\)</span> as:</p>
<p><span class="math display">\[\hat{A}_n = \frac{1}{M} \sum^{M}_{i=1} \boldsymbol{\phi}(X_i) [\boldsymbol{\phi}(X_i) - \gamma \boldsymbol{\phi} (X^{\prime}_i)]^T\]</span> <span class="math display">\[\hat{\mathbf{b}}_n = \frac{1}{M} \sum^{M}_{i=1} \boldsymbol{\phi}(X)R_i\]</span></p>
<p><br></p>
<p>We can use LSTD to define an approximate policy iteration procedure to obtain a close to optimal policy (LSPI):</p>
<p><img src='/images/RL/vfa/lstd_1.png' width="600"></p>
<h2 id="semi-gradient-td">Semi-Gradient TD</h2>
<p>Suppose that we know the true value function <span class="math inline">\(V^{\pi}\)</span> and we want to find an approximation <span class="math inline">\(\hat{V}\)</span>, parameterized by <span class="math inline">\(\mathbf{w}\)</span>. The population loss:</p>
<p><span class="math display">\[V = \underset{\hat{V} \in \mathbf{F}}{\arg\min} \frac{1}{2}\|V^{\pi} - \hat{V}\|^2_{2, \mu}\]</span></p>
<p>Using samples <span class="math inline">\(X_t \sim \mu\)</span>, we can define an SGD procedure that updates <span class="math inline">\(\mathbf{w}_t\)</span> as follows:</p>
<span class="math display">\[\begin{aligned}
\mathbf{w}_{t+1} &amp;\leftarrow \mathbf{w}_t - \alpha_t \nabla_{\mathbf{w}_t} [\frac{1}{2} |V^{\pi} (X_t) - \hat{V}(X_t; \mathbf{w}_t)|^2]\\
&amp;= \mathbf{w}_t + \alpha_t (V^{\pi} (X_t) - \hat{V}(X_t; \mathbf{w}_t))\nabla_{\mathbf{w}_t} \hat{V}(X_t; \mathbf{w}_t)
\end{aligned}\]</span>
<p>If we select proper step size <span class="math inline">\(\alpha_t\)</span>, then the SGD converges to the stationary point.</p>
<p>When we do not know <span class="math inline">\(V^{\pi}\)</span>, we can use bootstrapped estimate (TD estimate <span class="math inline">\(\hat{T}^{\pi}V_t\)</span>) instead:</p>
<p><span class="math display">\[\mathbf{w}_{t+1} \leftarrow \mathbf{w}_t + \alpha_t (\hat{T}^{\pi}V_t - \hat{V}(X_t; \mathbf{w}_t))\nabla_{\mathbf{w}_t} \hat{V}(X_t; \mathbf{w}_t)\]</span> <span class="math display">\[\mathbf{w}_{t+1} \leftarrow \mathbf{w}_t + \alpha_t (R_t + \hat{V}(X^{\prime}_t; \mathbf{w}_t) - \hat{V}(X_t; \mathbf{w}_t))\nabla_{\mathbf{w}_t} \hat{V}(X_t; \mathbf{w}_t)\]</span></p>
<p><strong>The substitution of <span class="math inline">\(V^{\pi}(X_t)\)</span> with <span class="math inline">\(\hat{T}^{\pi}V_t (X_t)\)</span> does not follow from the SGD of any loss function. The TD update is note a true SGD update, that is, we call it a semi-gradient update.</strong></p>
]]></content>
      <categories>
        <category>RL</category>
        <category>VFA</category>
      </categories>
  </entry>
  <entry>
    <title>Value Function Approximation (1)</title>
    <url>/2021/06/12/vfa-1/</url>
    <content><![CDATA[<h1 id="value-function-approximation-introduction">Value Function Approximation (Introduction)</h1>
<p>In real-world problem, the state space <span class="math inline">\(\chi\)</span> or the state-action space <span class="math inline">\(\chi \times A\)</span> is large that we cannot represent quantities such as the value function or policy exactly.</p>
<ul>
<li><span class="math inline">\(\chi \subseteq \mathbb{R}^d\)</span> with <span class="math inline">\(d \geq 1\)</span>. Exact representation of an arbitrary function on <span class="math inline">\(\mathbb{R}^d\)</span> on a computer is infeasible.</li>
<li><span class="math inline">\(\chi\)</span> is finite, but very large (millions or billions)</li>
</ul>
<p>We need to approximate those functions using a representation that is feasible to manipulate on a computer. This is called <strong>function approximation</strong>.</p>
<p>Function approximation also helps with the generalization.</p>
<h2 id="linear-function-approximation">Linear Function Approximation</h2>
<p>We may use a linear function approximator defined based on a set of basis functions:</p>
<p><span class="math display">\[\hat{V} (x) = \phi (x)^T w = \sum^p_{i=1} \phi_i (x) w_i\]</span></p>
<p>with <span class="math inline">\(w \in \mathbb{R}^p\)</span> and <span class="math inline">\(\phi: \chi \rightarrow \mathbb{R}^p\)</span></p>
<p>Any <span class="math inline">\(\hat{V}\)</span> belongs to the space of functions <span class="math inline">\(\mathbf{F}\)</span>:</p>
<p><span class="math display">\[\mathbf{F} = \{x \mapsto  \phi (x)^T w : w \in \mathbb{R}^p\}\]</span></p>
<p>The function space <span class="math inline">\(\mathbf{F}\)</span> is called the <code>linear value function space</code>, in this case it is a span of a set of features.</p>
<span id="more"></span>
<h2 id="l_p-v-norms-of-value-function"><span class="math inline">\(L_p (v)\)</span>-norms of Value Function</h2>
<p>For a probability distribution <span class="math inline">\(v \in M(\chi)\)</span>, and a measurable function <span class="math inline">\(V \in \mathbf{F}\)</span>, we define the <span class="math inline">\(L_p (v)\)</span>-norm of <span class="math inline">\(V\)</span> with <span class="math inline">\(1 \leq p &lt; \infty\)</span> as:</p>
<p><span class="math display">\[\|V\|^p_{p, v} \triangleq \int_{x \in \chi} |V(x)|^p dv(x)\]</span></p>
<p>The <span class="math inline">\(L_{\infty} (\chi)\)</span> norm is:</p>
<p><span class="math display">\[\|V\|_{\infty} \triangleq \sup_{x \in \chi} |V(x)|\]</span></p>
<h2 id="goal">Goal</h2>
<p>Suppose that we happen to know <span class="math inline">\(V^{\pi}, Q^{\pi}, Q^*, V^*\)</span> and we want to represent it with a function <span class="math inline">\(V \in \mathbf{F}\)</span>, our goal is to find:</p>
<p><span class="math display">\[V \approx V^{\pi}\]</span></p>
<p>To quantify <span class="math inline">\(V \approx V^{\pi}\)</span>, we have to pick a distance function <span class="math inline">\(d\)</span> between function <span class="math inline">\(V\)</span> and <span class="math inline">\(V^{\pi}\)</span>, given such a distance function, we can express our goal as:</p>
<p><span class="math display">\[V = \underset{V \in \mathbf{F}}{\arg\min} \; d(V, V^{\pi})\]</span></p>
<p>One common used family of distances are based on <span class="math inline">\(L_p (\mu)\)</span>-norm w.r.t a probability measure <span class="math inline">\(\mu \in M(\chi)\)</span>:</p>
<p><span class="math display">\[V = \underset{V \in \mathbf{F}}{\arg\min} \; \|V - V^{\pi}\|^p_{p, \mu}\]</span> <span class="math display">\[Q = \underset{Q \in \mathbf{F}}{\arg\min} \; \|Q - Q^{\pi}\|^p_{p, \mu}\]</span></p>
<p>A common choice is <span class="math inline">\(p=2\)</span> which is similar to mean squared loss function in regression.</p>
<h2 id="batch-rl">Batch RL</h2>
<p>In general, <span class="math inline">\(V^{\pi}, Q^{\pi}, Q^*, V^*\)</span> are unknown quantities and need to estimate them using data. We consider the <strong>batch data</strong> setting:</p>
<ul>
<li><p>The data is already collected and we are interested in using it to estimate quantities such as <span class="math inline">\(Q^{\pi}, Q^{*}\)</span></p></li>
<li><p>Suppose that we have: <span class="math display">\[D_N = \{(X_i, A_i, R_i, X^{\prime}_i)\}^N_{i=1}\]</span></p>
<p>with <span class="math inline">\((X_i, A_i) \sim \mu\)</span> and <span class="math inline">\(X^{\prime}_i \sim P(\cdot | X_i, A_i)\)</span> and <span class="math inline">\(R_i \sim R(\cdot | X_i, A_i)\)</span> (<span class="math inline">\(\mu\)</span> can be any distribution that the <span class="math inline">\(L_p (\mu)\)</span>-norm is referring to, it is often the stationary distribution following policy <span class="math inline">\(\pi\)</span>)</p></li>
<li><p>The data could also be generated by following a behaviour policy <span class="math inline">\(\pi_b\)</span>.</p></li>
<li><p>In the batch setting, the agent does not interact with the environment while it it computing <span class="math inline">\(Q^{\pi}, Q^{*}\)</span> which contrasted with the online method such as TD or Q-learning where the agent updates its estimate of the value function as each data point arrives.</p></li>
</ul>
<p><strong>Batch RL may collect a batch of data, process them, and then collect a new batch of data, possibly based on a policy resulted from the previous batch processing computation.</strong></p>
<h2 id="empirical-risk-minimization">Empirical Risk Minimization</h2>
<p>Suppose, we have a batch of data:</p>
<p><span class="math display">\[D_N = \{(X_i, A_i, G^{\pi}_i (X_i, A_i))\}^{N}_{i=1}\]</span></p>
<p>Where <span class="math inline">\(G^{\pi}_i (X_i, A_i)\)</span> is the return starting from state <span class="math inline">\(X_i\)</span> and taking action <span class="math inline">\(A_i\)</span> and following the policy <span class="math inline">\(\pi\)</span> afterwards (<span class="math inline">\((X_i, A_i) \sim \mu\)</span>). The return can be obtain using initial-state only MC by selecting <span class="math inline">\((X_i, A_i) \sim \mu\)</span> and then following <span class="math inline">\(\pi\)</span> until the end of the episode.</p>
<p>Recall the loss function:</p>
<p><span class="math display">\[Q = \underset{Q \in \mathbf{F}}{\arg\min} \; \|Q - Q^{\pi}\|^p_{p, \mu}\]</span></p>
<ul>
<li>We do not know the distribution <span class="math inline">\(\mu\)</span> and only have samples from it.</li>
<li>We do not know <span class="math inline">\(Q^{\pi}\)</span> and only have unbiased estimate of it at a finite number of data points.</li>
</ul>
<p><br></p>
<p><strong>The question is: can we replace <span class="math inline">\(Q^{\pi}\)</span> with <span class="math inline">\(G^{\pi}\)</span>?</strong></p>
<p>For any <span class="math inline">\(Q\)</span>, we can decompose:</p>
<span class="math display">\[\begin{aligned}
E_{\mu, G^{\pi}}[|Q(X, A) - G^{\pi}(X, A)|^2] &amp;= E_{\mu, G^{\pi}}[|Q(X, A) - Q^{\pi} (X, A) + Q^{\pi} (X, A) - G^{\pi} (X, A)|^2]\\
&amp;= E_{\mu, G^{\pi}}[|Q(X, A) - Q^{\pi}(X, A)|^2] + E_{\mu, G^{\pi}}[|Q^{\pi}(X, A) - G^{\pi}(X, A)|^2] + 2 E_{\mu, G^{\pi}}[(Q(X, A) - Q^{\pi} (X, A))(Q^{\pi} (X, A) - G^{\pi} (X, A))]\\
\end{aligned}\]</span>
<p>The first term:</p>
<p><span class="math display">\[E_{\mu, G^{\pi}}[|Q(X, A) - Q^{\pi}(X, A)|^2] = \int_{x, a} |Q(X, A) - Q^{\pi}(X, A)|^2 d\mu(x, a) = \|Q - Q^{\pi}\|^2_{2, \mu}\]</span></p>
<p>The second term:</p>
<p><span class="math display">\[E_{\mu, G^{\pi}}[|Q^{\pi}(X, A) - G^{\pi}(X, A)|^2] = E_{\mu}[E_{G^{\pi}}[|Q^{\pi}(X, A) - G^{\pi}(X, A)|^2 | X, A]] = E_{\mu}[Var[G^{\pi} (X, A) | X, A]]\]</span></p>
<p>The third term:</p>
<span class="math display">\[\begin{aligned}
2 E_{\mu, G^{\pi}}[(Q(X, A) - Q^{\pi} (X, A))(Q^{\pi} (X, A) - G^{\pi} (X, A))] &amp;= 2E_{\mu}[E_{G^{\pi}} [(Q(X, A) - Q^{\pi} (X, A))(Q^{\pi}(X, A) - G^{\pi} (X, A)) | X, A]]\\
&amp;= 2E_{\mu}[(Q(X, A) - Q^{\pi} (X, A))(Q^{\pi}(X, A) - \underbrace{E[G^{\pi} (X, A)) | X, A]}_{Q^{\pi} (X, A)})]\\
&amp;= 0
\end{aligned}\]</span>
<p>Thus:</p>
<span class="math display">\[\begin{aligned}
\underset{Q \in \mathbf{F}}{\arg\min} \; E_{\mu, G^{\pi}}[|Q(X, A) - G^{\pi}(X, A)|^2] &amp;= \underset{Q \in \mathbf{F}}{\arg\min} \; \|Q - Q^{\pi}\|^2_{2, \mu} + E_{\mu}[Var[G^{\pi} (X, A) | X, A]]\\
&amp;= \underset{Q \in \mathbf{F}}{\arg\min} \; \|Q - Q^{\pi}\|^2_{2, \mu}
\end{aligned}\]</span>
<p><br></p>
<p>We can see that, if we could find the solution to <span class="math inline">\(\underset{Q \in \mathbf{F}}{\arg\min} \; E_{\mu, G^{\pi}}[|Q - G^{\pi}|^2]\)</span>, the solution would be the same as the minimizer of our target. However, we could not compute the expectation because we do not know <span class="math inline">\(\mu\)</span> and environment <span class="math inline">\(R, P\)</span>, we only have samples from it. A common solution in ML to address this issue is to use the <code>emprical risk minimization</code>, which prescribes that we solve:</p>
<p><span class="math display">\[\frac{1}{N} \sum^{N}_{i=1} |Q(X_i, A_i) - G^{\pi} (X_i, A_i)|^2 = \|Q - G^{\pi}\|^2_{2, D_n}\]</span></p>
<p>This is indeed a regression problem with the squared error loss.</p>
<h1 id="next-avi-brm-lstd-etc..">Next: AVI, BRM, LSTD etc..</h1>
]]></content>
      <categories>
        <category>RL</category>
        <category>VFA</category>
      </categories>
  </entry>
</search>
