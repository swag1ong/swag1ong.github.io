<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="1xbHmVEsS5Fta14x1d1FXkHFr93LRr1pMxipdYVcNI4">
  <meta name="baidu-site-verification" content="code-Srzz2vTuzA">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;swag1ong.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;Searching...&quot;,&quot;empty&quot;:&quot;We didn&#39;t find any results for the search: ${query}&quot;,&quot;hits_time&quot;:&quot;${hits} results found in ${time} ms&quot;,&quot;hits&quot;:&quot;${hits} results found&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:3,&quot;unescape&quot;:false,&quot;preload&quot;:true}}</script>
<meta property="og:type" content="website">
<meta property="og:title" content="GoGoGogo!">
<meta property="og:url" content="https://swag1ong.github.io/index.html">
<meta property="og:site_name" content="GoGoGogo!">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhu, Zhaoyang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://swag1ong.github.io/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>GoGoGogo!</title><script src="/js/config.js"></script>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?852b005027c5efa81663f6f5c4c5b7fd"></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">GoGoGogo!</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-igloo fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">110</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">16</span></a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">25</span></a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-address-card fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhu, Zhaoyang"
      src="/images/others/favicon.jpeg">
  <p class="site-author-name" itemprop="name">Zhu, Zhaoyang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">110</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/swag1ong" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;swag1ong" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhaoyang.zhu@mail.utoronto.ca" title="E-Mail → mailto:zhaoyang.zhu@mail.utoronto.ca" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhuzhaoyangzzyu0616" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhuzhaoyangzzyu0616" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2030/05/30/aa_welcome/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2030/05/30/aa_welcome/" class="post-title-link" itemprop="url">Welcome</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2030-05-30 23:59:13" itemprop="dateCreated datePublished" datetime="2030-05-30T23:59:13+08:00">2030-05-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-05-29 13:40:28" itemprop="dateModified" datetime="2022-05-29T13:40:28+08:00">2022-05-29</time>
      </span>

  
    <span id="/2030/05/30/aa_welcome/" class="post-meta-item leancloud_visitors" data-flag-title="Welcome" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>1.7k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>2 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="welcome">Welcome</h1>
<p><img src="../about/mingren.gif"/></p>
<p><strong>Welcome to my website, hope you enjoy it, most of the notes are listed below</strong>:</p>
<p><br></p>
<p><strong>Some backgrounds</strong>:</p>
<ol type="1">
<li><a href="/2021/05/11/probability/" title="Probability (1)">Probability (1)</a></li>
<li><a href="/2021/05/11/probability-2/" title="Probability (2)">Probability (2)</a></li>
<li><a href="/2021/07/15/probability-3/" title="Probability (3)">Probability (3)</a></li>
<li><a href="/2022/03/10/rigorous-probability-1/" title="Advanced Probability (1)">Advanced Probability (1)</a></li>
<li><a href="/2022/05/02/rigorous-probability-2/" title="Advanced Probability (2)">Advanced Probability (2)</a></li>
<li><a href="/2021/05/14/calculus/" title="Calculus (1)">Calculus (1)</a></li>
<li><a href="/2021/07/06/cal-2/" title="Calculus (2)">Calculus (2)</a></li>
<li><a href="/2021/07/18/cnn/" title="Backpropagation in CNN">Backpropagation in CNN</a></li>
<li><a href="/2021/08/02/rnn/" title="RNN">RNN</a></li>
<li><a href="/2021/12/25/real-analysis-1/" title="Real Analysis (1)">Real Analysis (1)</a></li>
<li><a href="/2022/01/01/real-analysis-2/" title="Real Analysis (2)">Real Analysis (2)</a></li>
<li><a href="/2022/01/01/real-analysis-3/" title="Real Analysis (3)">Real Analysis (3)</a></li>
<li><a href="/2022/01/06/real-analysis-4/" title="Real Analysis (4)">Real Analysis (4)</a></li>
<li><a href="/2022/02/13/mira/" title="Measure Integral and Real Analysis (1)">Measure Integral and Real Analysis (1)</a></li>
<li><a href="/2022/02/27/mira-2/" title="Measure Integral and Real Analysis (2)">Measure Integral and Real Analysis (2)</a></li>
<li><a href="/2022/03/14/mira-3/" title="Measure Integral and Real Analysis (3)">Measure Integral and Real Analysis (3)</a></li>
<li><a href="/2022/03/30/mira-4/" title="Measure Integral and Real Analysis (4)">Measure Integral and Real Analysis (4)</a></li>
<li><a href="/2021/11/15/time-series-1/" title="Time Series (1)">Time Series (1)</a></li>
<li><a href="/2021/11/19/time-series-2/" title="Time Series (2)">Time Series (2)</a></li>
<li><a href="/2022/05/28/time-series-3/" title="Time Series (3)">Time Series (3)</a></li>
<li><a href="/2022/01/06/linear-algebra/" title="Linear Algebra (1)">Linear Algebra (1)</a></li>
<li><a href="/2022/01/09/linear-algebra-2/" title="Linear Algebra (2)">Linear Algebra (2)</a></li>
<li><a href="/2022/01/19/linear-algebra-3/" title="Linear Algebra (3)">Linear Algebra (3)</a></li>
<li><a href="/2022/01/25/linear-algebra-4/" title="Linear Algebra (4)">Linear Algebra (4)</a></li>
<li><a href="/2022/02/04/linear-algebra-5/" title="Linear Algebra (5)">Linear Algebra (5)</a></li>
</ol>
<p><strong>Some RL backgrounds</strong>:</p>
<ol type="1">
<li><a href="/2021/05/03/MDP/" title="MDP">MDP</a></li>
<li><a href="/2021/05/03/bellman-equations/" title="Bellman Equations">Bellman Equations</a></li>
<li><a href="/2021/05/03/bellman-optimality-equations/" title="Bellman Optimality Equations">Bellman Optimality Equations</a></li>
<li><a href="/2021/05/03/dp/" title="Dynamic Programming">Dynamic Programming</a></li>
<li><a href="/2021/05/03/value-iteration/" title="Value Iteration">Value Iteration</a></li>
<li><a href="/2021/05/03/policy-iteration/" title="Policy Iteration">Policy Iteration</a></li>
<li><a href="/2021/05/07/value-function-learning/" title="Learning From Stream of Data">Learning From Stream of Data</a></li>
<li><a href="/2021/05/15/mc/" title="Monte Carlo Methods">Monte Carlo Methods</a></li>
<li><a href="/2021/05/15/td/" title="Temporal Difference Learning">Temporal Difference Learning</a></li>
<li><a href="/2021/05/16/sarsa/" title="SARSA">SARSA</a></li>
<li><a href="/2021/05/16/q-learning/" title="Q Learning">Q Learning</a></li>
<li><a href="/2021/06/12/vfa-1/" title="Value Function Approximation (1)">Value Function Approximation (1)</a></li>
<li><a href="/2021/07/13/vfa-2/" title="Value Function Approximation (2)">Value Function Approximation (2)</a></li>
<li><a href="/2021/05/23/policy-gradient/" title="Policy Gradient (1)">Policy Gradient (1)</a></li>
<li><a href="/2021/05/30/policy-gradient-2/" title="Policy Gradient (2)">Policy Gradient (2)</a></li>
<li><a href="/2021/06/05/policy-gradient-3/" title="Policy Gradient (3)">Policy Gradient (3)</a></li>
<li><a href="/2021/05/30/average-reward-setting/" title="Average Reward Setting (Under Construction)">Average Reward Setting (Under Construction)</a></li>
<li><a href="/2021/06/28/semi-mdp/" title="Semi MDP (Under Construction)">Semi MDP (Under Construction)</a></li>
</ol>
<p><strong>Some interesting RL algorithms</strong>:</p>
<ol type="1">
<li><a href="/2021/05/06/DPG/" title="DPG">DPG</a></li>
<li><a href="/2021/06/09/DDPG/" title="DDPG">DDPG</a></li>
<li><a href="/2021/05/07/DDQN/" title="DDQN">DDQN</a></li>
<li><a href="/2021/06/23/td3/" title="TD3">TD3</a></li>
<li><a href="/2021/05/13/Dueling/" title="Dueling DQN">Dueling DQN</a></li>
<li><a href="/2021/06/11/TRPO/" title="TRPO">TRPO</a></li>
<li><a href="/2021/06/11/PPO/" title="PPO">PPO</a></li>
<li><a href="/2021/05/20/prior-exp-replay/" title="Prioritized Experience Replay">Prioritized Experience Replay</a></li>
<li><a href="/2021/06/25/instrinsic-motivation/" title="Intrinsic Motivation">Intrinsic Motivation</a></li>
<li><a href="/2021/06/25/go-explore/" title="Go Explore">Go Explore</a></li>
<li><a href="/2021/06/03/natural-actor-critic/" title="Natural Actor Critic (Under Construction)">Natural Actor Critic (Under Construction)</a></li>
<li><a href="/2021/06/03/off-policy-actor-critic/" title="Off Policy Actor Critic (Under Construction)">Off Policy Actor Critic (Under Construction)</a></li>
<li><a href="/2021/07/22/sac/" title="SAC (Under Construction)">SAC (Under Construction)</a></li>
</ol>
<p><strong>Some Deep Learning algorithms and models</strong>:</p>
<ol type="1">
<li><a href="/2021/05/25/drop-out/" title="Dropout">Dropout</a></li>
<li><a href="/2021/05/26/batch-norm/" title="Batch Normalization">Batch Normalization</a></li>
<li><a href="/2021/06/02/layer-norm/" title="Layer Normalization">Layer Normalization</a></li>
<li><a href="/2021/07/05/xavier/" title="Xavier Initialization">Xavier Initialization</a></li>
<li><a href="/2021/06/23/kaiming-init/" title="Kaiming Initialization">Kaiming Initialization</a></li>
<li><a href="/2021/07/05/LReLU/" title="LReLU">LReLU</a></li>
<li><a href="/2021/06/22/alex-net/" title="Alex Net">Alex Net</a></li>
<li><a href="/2021/06/25/overfeat/" title="Overfeat (Under Construction)">Overfeat (Under Construction)</a></li>
<li><a href="/2021/06/24/VGG/" title="VGG (Under Construction)">VGG (Under Construction)</a></li>
<li><a href="/2021/07/29/momentum/" title="Momentum">Momentum</a></li>
<li><a href="/2021/07/29/adaptive-lr/" title="Basic Adaptive LR Methods">Basic Adaptive LR Methods</a></li>
<li><a href="/2021/07/29/adam/" title="Adam">Adam</a></li>
<li><a href="/2021/08/06/attention/" title="Attention">Attention</a></li>
<li><a href="/2021/12/25/tcn/" title="TCN">TCN</a></li>
<li><a href="/2021/12/25/transformer/" title="Transformer">Transformer</a></li>
</ol>
<p><strong>Some old school ML algorithms</strong>:</p>
<ol type="1">
<li><a href="/2021/07/19/pca/" title="PCA">PCA</a></li>
<li><a href="/2021/07/19/logistic-regression/" title="Logistic Regression">Logistic Regression</a></li>
<li><a href="/2021/07/19/naive-bayes/" title="Naive Bayes">Naive Bayes</a></li>
<li><a href="/2021/07/19/decision-trees/" title="Decision Trees">Decision Trees</a></li>
<li><a href="/2021/07/19/random-forests/" title="Random Forest (Under Construction)">Random Forest (Under Construction)</a></li>
<li><a href="/2021/07/19/adaboost/" title="AdaBoost">AdaBoost</a></li>
<li><a href="/2021/07/19/gbdt/" title="GBDT">GBDT</a></li>
<li><a href="/2021/07/19/k-means/" title="K-means">K-means</a></li>
<li><a href="/2021/07/19/knn/" title="KNN (Under Construction)">KNN (Under Construction)</a></li>
<li><a href="/2021/07/19/svm/" title="SVM (Under Construction)">SVM (Under Construction)</a></li>
<li><a href="/2021/07/21/em/" title="EM Algorithm">EM Algorithm</a></li>
<li><a href="/2021/08/09/roc/" title="ROC">ROC</a></li>
<li><a href="/2021/09/06/lgb/" title="LGBM">LGBM</a></li>
<li><a href="/2021/09/09/graphical-models/" title="Graphical Models (Under Construction)">Graphical Models (Under Construction)</a></li>
<li><a href="/2021/09/16/hmm/" title="Sequential Data Modeling (Under Construction)">Sequential Data Modeling (Under Construction)</a></li>
</ol>
<p><strong>Some CS</strong>:</p>
<ol type="1">
<li><a href="/2021/05/18/leet-code-1/" title="LeetCode (1)">LeetCode (1)</a></li>
<li><a href="/2021/06/05/leet-code-2/" title="LeetCode (2)">LeetCode (2)</a></li>
<li><a href="/2021/06/16/leet-code-3/" title="LeetCode (3)">LeetCode (3)</a></li>
<li><a href="/2021/07/13/leet-code-4/" title="LeetCode (4)">LeetCode (4)</a></li>
<li><a href="/2021/07/19/heaps/" title="Heaps">Heaps</a></li>
<li><a href="/2021/06/06/sort/" title="Sorts">Sorts</a></li>
<li><a href="/2021/06/14/tree/" title="Trees">Trees</a></li>
</ol>
<p><br></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2023/01/27/fourier-analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/01/27/fourier-analysis/" class="post-title-link" itemprop="url">Fourier Analysis (1)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-01-27 11:42:50" itemprop="dateCreated datePublished" datetime="2023-01-27T11:42:50+08:00">2023-01-27</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-06-12 23:14:29" itemprop="dateModified" datetime="2023-06-12T23:14:29+08:00">2023-06-12</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2023/01/27/fourier-analysis/" class="post-meta-item leancloud_visitors" data-flag-title="Fourier Analysis (1)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>19k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>18 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>Base on Fourier Analysis: an Introduction by Elias M. Stein &amp; Rami Shakarchi</strong></p>
<h1 id="fourier-analysis-1">Fourier Analysis (1)</h1>
<h2 id="basic-properties-of-fourier-series">Basic Properties of Fourier Series</h2>
<h3 id="key-takeaway">Key Takeaway</h3>
<h3 id="preliminary">Preliminary</h3>
<h3 id="useful-identities">Useful Identities</h3>
<ul>
<li><span class="math inline">\(e^{ix} = \cos(x) + i\sin(x)\)</span></li>
<li><span class="math inline">\(\cos(x) = \frac{e^{ix} + e^{-ix}}{2}\)</span></li>
<li><span class="math inline">\(\sin(x) = \frac{e^{ix} - e^{-ix}}{2i}\)</span></li>
</ul>
<p><br></p>
<h4 id="complex-trigonometric-polynomial">Complex Trigonometric Polynomial</h4>
<p>Any function <span class="math inline">\(T\)</span> of the form:</p>
<p><span class="math display">\[T(x) = a_0 + \sum^N_{n=1}a_n \cos(nx) + \sum^N_{n=1} b_n \sin(nx)\]</span></p>
<p>with <span class="math inline">\(a_n, b_n \in \mathbb{C}, 0 \leq n \leq \mathbb{N}, x \in \mathbb{R}\)</span> is called a <strong>Complex Trigonometric Polynomial</strong>, it can also be written as:</p>
<p><span class="math display">\[T(x) = \sum^N_{n=-N} c_n e^{inx}\]</span></p>
<p><br></p>
<h4 id="everywhere-continuous-functions">Everywhere continuous functions</h4>
<p>These are the complex-valued functions <span class="math inline">\(f\)</span> which are continuous at every point of the segment <span class="math inline">\([0, L]\)</span>. Continuous functions on the circle satisfy the additional condition <span class="math inline">\(f(0) = f(L)\)</span>. (starting point = end point)</p>
<p><br></p>
<h4 id="piecewise-continuous-functions">Piecewise continuous functions</h4>
<p>These are bounded functions on <span class="math inline">\([0, L]\)</span> which have only finitely many discontinuities.</p>
<p><br></p>
<h4 id="riemann-integrable-functions">Riemann integrable functions</h4>
<p>Refer to Theorem 3.34 of MIRA(2). We say that a complex-valued function is integrable (Riemann) if its real and imaginary parts are integrable. The sum and product of two integrable functions are integrable.</p>
<p><br></p>
<h4 id="functions-on-the-circle">Functions on the circle</h4>
<p>A point <strong>on</strong> the unit circle takes the form <span class="math inline">\(e^{i\theta}\)</span> (mapping from real number to number on a unit circle), where <span class="math inline">\(\theta\)</span> is a real number unique up to integer multiples of <span class="math inline">\(2\pi\)</span>. If <span class="math inline">\(F\)</span> is a function on the circle, then we may define for every <span class="math inline">\(\theta \in \mathbb{R}\)</span>:</p>
<p><span class="math display">\[f(\theta) = F(e^{i\theta})\]</span></p>
<p><span class="math display">\[f(\theta + 2\pi) = f(\theta), \quad \forall \theta \in \mathbb{R}\]</span></p>
<p><strong>In conclusion, functions on <span class="math inline">\(\mathbb{R}\)</span> that <span class="math inline">\(2\pi-\)</span>periodic, and functions on an interval of length <span class="math inline">\(2\pi\)</span> that take on the same value at its end-points are two equivalent descriptions of the same mathematical objects, namely, functions on the circle.</strong></p>
<p><br></p>
<h3 id="main-definitions">Main Definitions</h3>
<ul>
<li><strong>All functions are assumed to be integrable (Riemann).</strong></li>
</ul>
<h4 id="def-1.1.1-fourier-coefficient-and-fourier-series-of-a-function">Def 1.1.1: Fourier Coefficient and Fourier Series of a Function</h4>
<p>If <span class="math inline">\(f\)</span> is an integrable function given on an interval <span class="math inline">\([a, b]\)</span> of length <span class="math inline">\(L = b - a\)</span>, then the <span class="math inline">\(n\)</span>th <strong>Fourier coefficient</strong> of <span class="math inline">\(f\)</span> is defined by:</p>
<p><span class="math display">\[\hat{f}(n) = \frac{1}{L} \int^b_a f(x) e^{-2\pi inx / L} dx, \quad n \in \mathbb{Z}\]</span></p>
<p><em>If f is period, then the <span class="math inline">\(\hat{f}(n)\)</span> is independent of the choice of interval (same for all intervals).</em></p>
<p>The <strong>Fourier series</strong> of <span class="math inline">\(f\)</span> is given by :</p>
<p><span class="math display">\[\sum^{\infty}_{n=-\infty} \hat{f}(n) e^{2\pi inx / L}\]</span></p>
<p><br></p>
<h4 id="def-1.1.2-dirichlet-kernel">Def 1.1.2: Dirichlet Kernel</h4>
<p>The trigonometric polynomial defined for <span class="math inline">\(x \in [-\pi, \pi]\)</span> by:</p>
<p><span class="math display">\[D_N(x) = \sum^N_{n=-N} e^{inx} = \frac{\sin((N + \frac{1}{2})x)}{\sin(\frac{x}{2})}\]</span></p>
<p>is called the <span class="math inline">\(Nth\)</span> <strong>Dirichlet kernel</strong>. The Fourier coefficients <span class="math inline">\(a_n\)</span> have the property that <span class="math inline">\(a_n = 1\)</span> if <span class="math inline">\(|n| \leq N\)</span> and <span class="math inline">\(a_n = 0\)</span> otherwise.</p>
<p><br></p>
<h4 id="def-1.1.3-poisson-kernel">Def 1.1.3: Poisson Kernel</h4>
<p>The function <span class="math inline">\(P_r(\theta)\)</span>, is called the <strong>Poisson kernel</strong>, is defined for <span class="math inline">\(\theta \in [-\pi, \pi]\)</span> and <span class="math inline">\(0 \leq r &lt; 1\)</span> by the absolutely and uniformly convergent series:</p>
<p><span class="math display">\[P_r(\theta) = \sum^\infty_{n=-\infty} r^{|n|}e^{in\theta}\]</span></p>
<p><br></p>
<h3 id="uniqueness-of-fourier-series">Uniqueness of Fourier Series</h3>
<h4 id="theorem-2.1-continuous-points-have-value-zero-when-all-fourier-coefficients-are-zeros">Theorem 2.1 Continuous points have value zero when all Fourier coefficients are zeros</h4>
<p>Suppose that <span class="math inline">\(f\)</span> is an integrable function on the circle with <span class="math inline">\(\hat{f}(n) = 0\)</span> for all <span class="math inline">\(n \in \mathbb{Z}\)</span>. Then <span class="math inline">\(f(\theta_0) = 0\)</span> whenever <span class="math inline">\(f\)</span> is continuous at the point <span class="math inline">\(\theta_0\)</span>.</p>
<h4 id="corollary-2.2">Corollary 2.2:</h4>
<p>If <span class="math inline">\(f\)</span> is continuous on the circle and <span class="math inline">\(\hat{f}(n) = 0\)</span> for all <span class="math inline">\(n \in \mathbb{Z}\)</span>, then <span class="math inline">\(f = 0\)</span>.</p>
<h4 id="theorem-2.3-if-series-of-fourier-coefficients-converges-absolutely-then-fourier-series-converges-to-f">Theorem 2.3: If series of Fourier Coefficients converges absolutely, then Fourier Series converges to <span class="math inline">\(f\)</span></h4>
<p>Suppose that <span class="math inline">\(f\)</span> is a continuous function <strong>on the circle</strong> and that the Fourier coefficients of <span class="math inline">\(f\)</span> is absolutely convergent, <span class="math inline">\(\sum^\infty_{n = -\infty} |\hat{f}(n)| &lt; \infty\)</span>. Then, the Fourier series converges uniformly to <span class="math inline">\(f\)</span>, that is:</p>
<p><span class="math display">\[\lim_{N\rightarrow \infty} S_N (f) (\theta) = f(\theta)\]</span></p>
<p>uniformly in <span class="math inline">\(\theta\)</span>.</p>
<p><strong>What conditions on f would guarantee the absolute convergence of its Fourier series? As it turns out, the smoothness of f is directly related to the decay of the Fourier coefficients, and in general, the smoother the function, the faster this decay. As a result, we can expect that relatively smooth functions equal their Fourier series.</strong></p>
<h4 id="ck"><span class="math inline">\(C^k\)</span></h4>
<p>We say that <span class="math inline">\(f\)</span> belongs to the <strong>class</strong> <span class="math inline">\(C^k\)</span> if <span class="math inline">\(f\)</span> is <span class="math inline">\(k\)</span> times continuously differentiable. This is a way to describe the <strong>smoothness</strong> of a function.</p>
<h4 id="convolution">Convolution</h4>
<p>Given two <span class="math inline">\(2\pi\)</span>-periodic integrable functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> on <span class="math inline">\(\mathbb{R}\)</span>, we define their <strong>convolution</strong> <span class="math inline">\(f * g\)</span> on <span class="math inline">\([-\pi, \pi]\)</span> by:</p>
<p><span class="math display">\[(f * g) (x) = \frac{1}{2\pi} \int^{\pi}_{-\pi} f(y) g(x - y) dy\]</span></p>
<p>For <span class="math inline">\(2\pi\)</span>-periodic functions, these two forms are equivalent:</p>
<p><span class="math display">\[(f * g) (x) = \frac{1}{2\pi} \int^{\pi}_{-\pi} f(x - y) g(y) dy\]</span></p>
<p>Loosely speaking, convolutions correspond to "weighted averages", if <span class="math inline">\(g = 1\)</span>, then <span class="math inline">\(f * g (x) = \frac{1}{2\pi} \int^\pi_{-\pi} f(y) dy\)</span> is a constant that represents the average value of <span class="math inline">\(f\)</span> on the circle.</p>
<h4 id="partial-sums-of-fourier-series-of-2pi-periodic-function-as-convolution">Partial Sums of Fourier Series of <span class="math inline">\(2\pi\)</span> periodic function as Convolution</h4>
<p>Given a <span class="math inline">\(2\pi\)</span>-periodic integrable function <span class="math inline">\(f\)</span>, the Fourier Series of <span class="math inline">\(f\)</span> can be expressed as:</p>
<p><span class="math display">\[S_N(f) (x) = \frac{1}{2\pi} \int^\pi_{-\pi} f(y) (\sum^N_{n=-N} e^{in(x - y)}) dy = (f * D_N) (x)\]</span></p>
<p>where <span class="math inline">\(D_N(x)\)</span> is the Dirichlet kernel.</p>
<h4 id="proposition-3.1">Proposition 3.1:</h4>
<p>Suppose that <span class="math inline">\(f, g, h\)</span> are <span class="math inline">\(2\pi\)</span> periodic integrable functions. Then:</p>
<ol type="1">
<li><span class="math inline">\(f * (g + h) = (f * g) + (f * h)\)</span> (linearity)</li>
<li><span class="math inline">\((cf) * g = c(f * g) = f * (cg), \;\;\forall c \in \mathbb{C}\)</span> (commutativity)</li>
<li><span class="math inline">\(f * g = g * f\)</span></li>
<li><span class="math inline">\((f * g) * h = f * (g * h)\)</span> (associativity)</li>
<li><span class="math inline">\((f * g)\)</span> is continuous. (The convolution of two integrable function is more regular.)</li>
<li><span class="math inline">\(\widehat{f * g} (n) = \hat{f}(n) \hat{g}(n)\)</span></li>
</ol>
<h4 id="good-kernels">Good Kernels</h4>
<p>A family of kernels <span class="math inline">\(\{K_n(x)\}^\infty_{n=1}\)</span> <strong>on the circle</strong> is said to be a family of <strong>good kernels</strong> if it satisfies the following properties:</p>
<ol type="1">
<li>For all <span class="math inline">\(n \geq 1\)</span>, (The average value on the circle is 1) <span class="math display">\[\frac{1}{2\pi} \int^{\pi}_{-\pi} K_n(x) dx = 1\]</span></li>
<li>There exists <span class="math inline">\(M &gt; 0\)</span> s.t for all <span class="math inline">\(n \geq 1\)</span> (The integral is bounded), <span class="math display">\[\int^\pi_{-\pi} |K_n(x)|dx \leq M\]</span></li>
<li>For every <span class="math inline">\(\delta &gt; 0\)</span>, <span class="math display">\[\int_{\delta \leq |x|\leq \pi} |K_n(x)|dx \rightarrow 0, \;\; \text{as} \; n \rightarrow \infty\]</span></li>
</ol>
<h4 id="theorem-4.1-approximation-to-identity">Theorem 4.1: Approximation to Identity</h4>
<p>Let <span class="math inline">\(\{K_n\}^\infty_{n=1}\)</span> be a family of good kernels, and <span class="math inline">\(f\)</span> an integrable function <strong>on the circle</strong>. Then,</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} (f * K_n) (x) = f(x)\]</span></p>
<p>whenever <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(x\)</span>. if <span class="math inline">\(f\)</span> is continuous everywhere, then the above limit is uniform. Because of this result, the family <span class="math inline">\(\{K_n\}\)</span> is sometimes referred to as an <strong>approximation to the identity</strong>.</p>
<p><img src='/images/RL/background/fa_4_1.png' width="600"></p>
<p>The Dirichlet kernel satisfies condition 1 of the good kernel but does not satisfy condition 2:</p>
<p><span class="math display">\[D_N(x) \geq c\log N\]</span></p>
<p><br></p>
<h3 id="convergence-of-fourier-series">Convergence of Fourier Series</h3>
<h4 id="mean-square-convergence-on-circle">Mean-square Convergence on Circle</h4>
<p>If <span class="math inline">\(f\)</span> is integrable on the circle, then:</p>
<p><span class="math display">\[\frac{1}{2\pi} \int^{2\pi}_{0} |f(\theta) - S_N(f)(\theta)|^2 d\theta \rightarrow 0, \;\; n \rightarrow \infty\]</span></p>
<p>or</p>
<p><span class="math display">\[\lim_{N \rightarrow \infty} E[(f - S_N(f))^2]\]</span></p>
<p><br></p>
<h3 id="fourier-transform">Fourier Transform</h3>
<p>The theory of Fourier series applies to functions on the circle. In this section we develop an analogous theory for functions on the entire real line which are non-periodic. Roughly speaking, the Fourier Transform is a continuous version of the Fourier coefficients. The Fourier inversion formula is a continuous version of the Fourier series.</p>
<h4 id="elementary-theory-of-the-fourier-transform">Elementary Theory of The Fourier Transform</h4>
<p>Given the notion of the integral of a function on a closed and bounded interval, the most natural extension of this definition to continuous functions over <span class="math inline">\(\mathbb{R}\)</span> is:</p>
<p><span class="math display">\[\int^\infty_{-\infty} f(x)dx = \lim_{N \rightarrow \infty} \int^N_{-N} f(x) dx\]</span></p>
<p>The limit may not exists (e.g., $f(x ) = 1 $), but if we let <span class="math inline">\(f\)</span> decay enough as <span class="math inline">\(|x| \rightarrow \infty\)</span>, it will exist.</p>
<p>A function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(\mathbb{R}\)</span> is said to be of <strong>moderate decreasing</strong> if <span class="math inline">\(f\)</span> is continuous and there exists a constant <span class="math inline">\(A &gt; 0\)</span> so that:</p>
<p><span class="math display">\[|f(x)| \leq \frac{A}{1 + x^{1 + \epsilon}}, \;\; \forall x \in \mathbb{R}\]</span></p>
<p>The function of moderate decreasing is bounded (by <span class="math inline">\(A\)</span>) and decays at infinity at least as fast as <span class="math inline">\(1 / x^2\)</span>, we denote the set of all moderate decreasing functions as <span class="math inline">\(M(\mathbb{R})\)</span>, we can show that it is a <strong>vector space</strong> over <span class="math inline">\(\mathbb{C}\)</span>.</p>
<p>If the function is moderate decreasing, then we can be sure that the limit exists and the sequence of integral converges.</p>
<h4 id="theorem-5.1-properties-of-improper-integral">Theorem 5.1: Properties of Improper Integral</h4>
<p>The integral of a function of <strong>moderate decrease</strong> (i.e., <span class="math inline">\(f \in M(\mathbb{R})\)</span>) satisfies the following properties:</p>
<ol type="1">
<li><strong>Linearity</strong>: If <span class="math inline">\(f, g \in M(\mathbb{R})\)</span> and <span class="math inline">\(a, b \in \mathbb{C}\)</span>, then: <span class="math display">\[\int^\infty_{-\infty} (af(x) + bg(x))dx = a\int^\infty_{-\infty} f(x)dx + b\int^\infty_{-\infty} g(x)dx\]</span></li>
<li><strong>Translation Invariance</strong>: For every <span class="math inline">\(h \in \mathbb{R}\)</span> we have: <span class="math display">\[\int^\infty_{-\infty} f(x - h) dx = \int^\infty_{-\infty} f(x) dx\]</span></li>
<li><strong>Scaling under dilations</strong>: If <span class="math inline">\(\delta &gt; 0\)</span>, then: <span class="math display">\[\delta \int^\infty_{-\infty} f(\delta x)dx = \int^\infty_{-\infty} f(x) dx\]</span></li>
<li><strong>Continuity</strong>: If <span class="math inline">\(f \in M(\mathbb{R})\)</span>, then: <span class="math display">\[\int^\infty_{-\infty} |f(x - h) - f(x)| dx \rightarrow 0, \;\; \text{as } h \rightarrow 0\]</span></li>
</ol>
<h4 id="definition-of-the-fourier-transform">Definition of the Fourier transform</h4>
<p>If <span class="math inline">\(f \in M(\mathbb{R})\)</span>, we define the <strong>Fourier transform</strong> for <span class="math inline">\(\xi \in \mathbb{R}\)</span> by:</p>
<p><span class="math display">\[\hat{f}(\xi) = \int^{\infty}_{-\infty} f(x) e^{-2\pi \xi x i} dx\]</span></p>
<p>Notice that, <span class="math inline">\(\hat{f}\)</span> is <strong>continuous</strong> and <strong>bounded</strong>, <span class="math inline">\(|e^{-2\pi \xi x i}| = 1\)</span>.</p>
<h4 id="the-schwartz-space">The Schwartz Space</h4>
<p>The <strong>Schwartz space</strong> on <span class="math inline">\(\mathbb{R}\)</span> consists of the set of all indefinitely differentiable functions <span class="math inline">\(f\)</span> so that <span class="math inline">\(f\)</span> and all its derivatives <span class="math inline">\(f^\prime, f^{\prime\prime}, ...., f^{l}, ...\)</span> are <strong>rapidly decreasing</strong>, in the sense that:</p>
<p><span class="math display">\[\sup_{x \in \mathbb{R}} |x|^k |f^{l} (x)| &lt; \infty, \;\; \forall k, l &gt; 0\]</span></p>
<p>We denote this space by <span class="math inline">\(S = S(\mathbb{R})\)</span>:</p>
<ul>
<li><span class="math inline">\(S\)</span> is a vector space</li>
<li>If <span class="math inline">\(f \in \mathbb{R}\)</span>, then <span class="math inline">\(f^{\prime} \in S(\mathbb{R})\)</span> (closed under differentiation), <span class="math inline">\(x f(x) \in \mathbb{R}\)</span> (closed under polynomial).</li>
<li><span class="math inline">\(f(x) = e^{-ax^2}, \; a &gt; 0\)</span> is an example of the elements in <span class="math inline">\(S\)</span>.</li>
</ul>
<p><br></p>
<h4 id="fourier-transform-on-s">Fourier Transform on <span class="math inline">\(S\)</span></h4>
<p>The <strong>Fourier Transform</strong> of a function <span class="math inline">\(f \in S(\mathbb{R})\)</span>, <span class="math inline">\(F(f) = \hat{f}: S(\mathbb{R}) \rightarrow S(\mathbb{R})\)</span> is defined by:</p>
<p><span class="math display">\[\hat{f}(\xi) = \int^{\infty}_{-\infty} f(x) e^{-2\pi i x \xi} dx\]</span></p>
<p>Some properties hold for <strong>Fourier Transform</strong> of a function <span class="math inline">\(f \in S(\mathbb{R})\)</span>, we denote the fourier transform of <span class="math inline">\(f\)</span> by:</p>
<p><span class="math display">\[f(x) \rightarrow \hat{f}(\xi)\]</span></p>
<ul>
<li><span class="math inline">\(f(x + h) \rightarrow \hat{f}(\xi) e^{2\pi i h \xi}, \;\; \forall h \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(f(x) e^{-2\pi i x h} \rightarrow \hat{f} (\xi + h), \;\; \forall h \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(f(\delta x) \rightarrow \delta^{-1} \hat{f}(\delta^{-1}\xi), \;\; \forall h \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(f^{\prime}(x) \rightarrow 2\pi i \xi \hat{f}(\xi)\)</span></li>
<li><span class="math inline">\(-2\pi i x f(x) \rightarrow \frac{d}{d\xi} \hat{f}(\xi)\)</span></li>
<li><span class="math inline">\(\hat{\bar{f}} (x) = \overline{\hat{f}(-\xi)}\)</span></li>
</ul>
<h4 id="theorem-5.2">Theorem 5.2</h4>
<p>If <span class="math inline">\(f \in S(\mathbb{R})\)</span>, then <span class="math inline">\(\hat{f} \in S(\mathbb{R})\)</span>.</p>
<p><br></p>
<h4 id="gaussians-e-ax2-are-good-kernels">Gaussians (<span class="math inline">\(e^{-ax^2}\)</span>) are Good Kernels</h4>
<p><span class="math display">\[\int^{\infty}_{-\infty} e^{-\pi x^2} dx = 1\]</span></p>
<h4 id="theorem-5.4-the-fourier-transform-of-e-pi-x2-is-itself">Theorem 5.4 The Fourier Transform of <span class="math inline">\(e^{-\pi x^2}\)</span> is itself</h4>
<p>If <span class="math inline">\(f(x) = e^{-\pi x^2}\)</span>, then <span class="math inline">\(\hat{f}(\xi) = f(\xi)\)</span></p>
<h4 id="theorem-5.5">Theorem 5.5</h4>
<p>If <span class="math inline">\(\delta &gt; 0\)</span> and <span class="math inline">\(K_{\delta} (x) = \delta^{-\frac{1}{2}} e^{\frac{-\pi x^2}{\delta}}\)</span>, then <span class="math inline">\(\hat{K}_{\delta}(\xi) = e^{-\pi \delta \xi^2}\)</span></p>
<h5 id="proof-of-theorem-5.5">Proof of Theorem 5.5</h5>
<p><span class="math display">\[K_{\delta} (x) = \delta^{-\frac{1}{2}} e^{\frac{-\pi x^2}{\delta}} = \delta^{-\frac{1}{2}}f(\delta^{-\frac{1}{2}} x)\]</span></p>
<p>where <span class="math inline">\(f(\delta^{-\frac{1}{2}} x) = e^{-\pi \frac{x^2}{\delta}}\)</span></p>
<p>Then:</p>
<p><span class="math display">\[\hat{K}_\delta(x) = \delta^{\frac{1}{2}}\hat{f}^\prime(\delta^{\frac{1}{2}}\xi) = e^{-\pi \delta \xi^2}\]</span></p>
<p><br></p>
<h4 id="theorem-5.6-k_delta_delta-0-is-a-family-of-good-kernels">Theorem 5.6: <span class="math inline">\(\{K_{\delta}\}_{\delta &gt; 0}\)</span> is a Family of Good Kernels</h4>
<p><span class="math inline">\(\{K_{\delta} (x)\}_{\delta \in \mathbb{R^+}} = \delta^{-\frac{1}{2}} e^{\frac{-\pi x^2}{\delta}}\)</span> is a family of good kernels as <span class="math inline">\(\delta \rightarrow 0\)</span>.</p>
<p><br></p>
<h4 id="convolution-on-mathbbr">Convolution on <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>If <span class="math inline">\(f, g \in S(\mathbb{R})\)</span>, then the <strong>convolution</strong> is defined by:</p>
<p><span class="math display">\[(f * g) (x) = \int^{\infty}_{-\infty} f(x - t) g(t) dt\]</span></p>
<p>for a fixed value <span class="math inline">\(x\)</span>, the function <span class="math inline">\(f(x - t) g(t)\)</span> is <strong>rapid decrease</strong> in <span class="math inline">\(t\)</span>.</p>
<h4 id="theorem-5.7">Theorem 5.7</h4>
<p>If <span class="math inline">\(f \in S(\mathbb{R})\)</span>, then</p>
<p><span class="math display">\[(f * K_{\delta}) (x) \rightarrow f(x), \;\; \text{uniformly in $x$ as $\delta \rightarrow 0$}\]</span></p>
<p><br></p>
<h4 id="the-fourier-inversion">The Fourier Inversion</h4>
<h4 id="theorem-5.8-the-multiplication-formula">Theorem 5.8: The Multiplication Formula</h4>
<p>If <span class="math inline">\(f, g \in S(\mathbb{R})\)</span>, then</p>
<p><span class="math display">\[\int^{\infty}_{-\infty} f(x)\hat{g}(x) dx = \int^{\infty}_{-\infty} \hat{f}(y) g(y) dy\]</span></p>
<h4 id="theorem-5.9-fourier-inversion">Theorem 5.9: Fourier Inversion</h4>
<p>If <span class="math inline">\(f \in S(\mathbb{R})\)</span>, we define the inversion <span class="math inline">\(F^* (\hat{f}) : S(\mathbb{R}) \rightarrow S(\mathbb{R})\)</span> by</p>
<p><span class="math display">\[F^* (\hat{f}) (x)= \int^{\infty}_{-\infty} \hat{f}(\xi) e^{2\pi i x\xi} dx\]</span></p>
<p>Then:</p>
<p><span class="math display">\[F^*(\hat{f}) (x) = f(x)\]</span></p>
<h4 id="theorem-5.10-fourier-transform-is-a-bijective-mapping-on-the-schwartz-space">Theorem 5.10: Fourier Transform is a Bijective Mapping on the Schwartz Space</h4>
<p>The Fourier transform is a bijective mapping on the Schwartz space.</p>
<h4 id="theorem-5.11-convolutions-of-schwartz-functions">Theorem 5.11: Convolutions of Schwartz Functions</h4>
<p>If <span class="math inline">\(f, g \in S(\mathbb{R})\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(f * g \in S(\mathbb{R})\)</span></li>
<li><span class="math inline">\(f * g = g * f\)</span></li>
<li><span class="math inline">\((\widehat{f * g}) (\xi) = \hat{f}(\xi)\hat{g}(\xi)\)</span></li>
</ol>
<h4 id="inner-product-in-schwartz-space">Inner Product in Schwartz Space</h4>
<p>The Schwartz space can be equipped with a Hermitian inner product:</p>
<p><span class="math display">\[&lt;f, g&gt; = \int^{\infty}_{-\infty} f(x) \bar{g}(x) dx\]</span></p>
<p>whose associated norm is:</p>
<p><span class="math display">\[\|f\| = \sqrt{\int^{\infty}_{-\infty} |f(x)|^2 dx}\]</span></p>
<h4 id="theorem-5.12-plancherel-the-norm-of-fourier-transform-preserves">Theorem 5.12: Plancherel, The Norm of Fourier Transform Preserves</h4>
<p>If <span class="math inline">\(f \in S(\mathbb{R})\)</span> then <span class="math inline">\(\|\hat{f}\| = \|f\|\)</span></p>
<h4 id="extension-to-functions-of-moderate-decrease">Extension to Functions of Moderate Decrease</h4>
<p>All properties hold for <span class="math inline">\(f \in M(\mathbb{R})\)</span></p>
<h4 id="monomial-xalpha">Monomial <span class="math inline">\(x^\alpha\)</span></h4>
<p>Given a <span class="math inline">\(d\)</span>-tuple <span class="math inline">\(\alpha = (\alpha_1, ...., \alpha_d)\)</span> of non-negative integers (<strong>multi-index</strong>), the <strong>monomial</strong> <span class="math inline">\(x^\alpha\)</span> is defined by:</p>
<p><span class="math display">\[x^\alpha = x_1^{\alpha_1} x_2^{\alpha_2} ... x_d^{\alpha_d}\]</span></p>
<h4 id="rotation-in-mathbbrd">Rotation in <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>A <strong>rotation</strong> in <span class="math inline">\(\mathbb{R}^d\)</span> is a linear transformation <span class="math inline">\(R: \mathbb{R}^d \rightarrow \mathbb{R}^d\)</span> which preserves the inner product. In the other words,</p>
<ul>
<li><span class="math inline">\(R(ax + by) = aR(x) + bR(y) \;\; \forall x, y \in \mathbb{R}^d, \; a, b \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(R(x) \cdot R(y) = x \cdot y, \;\; \forall x, y \in \mathbb{R}^d\)</span></li>
</ul>
<p>If <span class="math inline">\(\det{(R)} = 1\)</span>, <span class="math inline">\(R\)</span> is a <strong>proper rotation</strong>, otherwise, we say that <span class="math inline">\(R\)</span> is an <strong>improper rotation</strong>.</p>
<h4 id="rapid-decreasing-of-complex-function-on-mathbbrd">Rapid Decreasing of Complex Function on <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>A continuous complex-valued function <span class="math inline">\(f\)</span> on <span class="math inline">\(\mathbb{R}^d\)</span> is said to be <strong>rapidly decreasing</strong> if for every multi-index <span class="math inline">\(\alpha\)</span> the function <span class="math inline">\(|x^\alpha f(x)|\)</span> is bounded. Equivalently, a continuous function is of rapid decrease if:</p>
<p><span class="math display">\[\sup_{x \in \mathbb{R}^d} |x|^k |f(x)| &lt; \infty, \quad\quad \forall k = 0, 1, 2, ...\]</span></p>
<p>Given a function of rapid decrease, we define:</p>
<p><span class="math display">\[\int_{\mathbb{R}^d} f(x) dx = \lim_{N \rightarrow \infty} \int_{Q_N} f(x) dx\]</span></p>
<p>Where <span class="math inline">\(Q_N\)</span> denotes the closed cube centered at the origin, with sides of length <span class="math inline">\(N\)</span> parallel to the coordinate axis, that is,</p>
<p><span class="math display">\[Q_N = \{x \in \mathbb{R}^d: |x_i| \leq \frac{N}{2} \quad \quad i = 1, ..., d\}\]</span></p>
<p>Actually, the limit exists if we can show that <span class="math inline">\(f\)</span> is continuous and</p>
<p><span class="math display">\[\sup_{x \in \mathbb{R}^d} |x|^{d + \epsilon} |f(x)| &lt; \infty, \quad \text{for some $\epsilon &gt; 0$}\]</span></p>
<p>If the function <span class="math inline">\(f\)</span> satisfies the condition with <span class="math inline">\(\epsilon = 1\)</span>, we say that the function is <strong>moderate decrease</strong> on <span class="math inline">\(\mathbb{R}^d\)</span>.</p>
<h4 id="properties-of-moderate-decreasing-functions">Properties of Moderate Decreasing Functions</h4>
<p>If <span class="math inline">\(f\)</span> is of moderate decrease, then:</p>
<ol type="1">
<li>Translation Invariant:</li>
</ol>
<p><span class="math display">\[\int_{\mathbb{R}^d} f(x + h) dx = \int_{\mathbb{R}^d} f(x) dx \quad \forall h \in \mathbb{R}^d\]</span></p>
<ol start="2" type="1">
<li>Scaling Invariant:</li>
</ol>
<p><span class="math display">\[\delta^d \int_{\mathbb{R}^d} f(\delta x) dx = \int_{\mathbb{R}^d} f(x) dx \quad \forall \delta &gt; 0\]</span></p>
<ol start="3" type="1">
<li>Rotation Invariant:</li>
</ol>
<p><span class="math display">\[\int_{\mathbb{R}^d} f(R(x)) dx = \int_{\mathbb{R}^d} f(x) \quad \text{$\forall$ rotation $R$}\]</span></p>
<h4 id="schwartz-space-in-mathbbrd">Schwartz Space in <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>The <strong>Schwartz space</strong> <span class="math inline">\(S(\mathbb{R}^d)\)</span> consists of all indefinitely differentiable functions <span class="math inline">\(f\)</span> on <span class="math inline">\(\mathbb{R}^d\)</span> such that</p>
<p><span class="math display">\[\sup_{x \in \mathbb{R}^d} |x^\alpha (\frac{\partial }{\partial x})^\beta f(x)| &lt; \infty\]</span></p>
<p>for every multi-index <span class="math inline">\(\alpha, \beta\)</span>. In other words, <span class="math inline">\(f\)</span> and all its derivative are required to be rapidly decreasing.</p>
<h4 id="fourier-transform-on-mathbbrd">Fourier Transform on <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>The Fourier transform of a Schwartz function <span class="math inline">\(f\)</span> is defined by:</p>
<p><span class="math display">\[\hat{f}(\xi) = \int_{\mathbb{R}^d} f(x) e^{-2\pi ix \cdot \xi} dx \quad \quad \text{for } \xi \in \mathbb{R}^d\]</span></p>
<p>This resembles with the formula in one-dimension, except we have dot product between <span class="math inline">\(\xi\)</span> and <span class="math inline">\(x\)</span> now.</p>
<h4 id="properties-of-fourier-transform-in-mathbbrd">Properties of Fourier Transform in <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>Let <span class="math inline">\(f \in \mathbb{R}^d\)</span></p>
<ol type="1">
<li><span class="math inline">\(f(x + h) \rightarrow \hat{f}(\xi) e^{2\pi i \xi \cdot h}, \quad h \in \mathbb{R}^d\)</span></li>
<li><span class="math inline">\(f(x) e^{-2\pi i x h} \rightarrow \hat{f} (\xi + h), \quad h \in \mathbb{R}^d\)</span></li>
<li><span class="math inline">\(f(\delta x) \rightarrow \delta^{-d} \hat{f}(\delta^{-1} \xi), \quad \delta &gt; 0\)</span></li>
<li><span class="math inline">\((\frac{\partial }{\partial x})^\alpha f(x) \rightarrow (2\pi i \xi)^\alpha \hat{f}(\xi)\)</span></li>
<li><span class="math inline">\((-2\pi i x)^\alpha f(x) \rightarrow (\frac{\partial }{\partial x})^\alpha \hat{f}(\xi)\)</span></li>
<li><span class="math inline">\(f(Rx) \rightarrow \hat{f}(R\xi), \quad R \text{ is a rotation}\)</span></li>
</ol>
<h4 id="fourier-inversion-in-mathbbrd">Fourier Inversion in <span class="math inline">\(\mathbb{R}^d\)</span></h4>
<p>Suppose <span class="math inline">\(f \in S(\mathbb{R}^d)\)</span>. Then:</p>
<p><span class="math display">\[f(x) = \int_{\mathbb{R}^d} \hat{f}(\xi) e^{2\pi i x \cdot \xi} d\xi\]</span></p>
<p>Moreover</p>
<p><span class="math display">\[\int_{\mathbb{R}^d} |\hat{f}(x)|^2 d\xi = \int_{\mathbb{R}^d} |f(x)|^2 dx\]</span></p>
<p><br></p>
<h3 id="finite-fourier-analysis">Finite Fourier Analysis</h3>
<h4 id="binary-relation">Binary Relation</h4>
<p>A <strong>binary (two element) relation</strong> from a set <span class="math inline">\(X\)</span> to a set <span class="math inline">\(Y\)</span> is a subset of the cartesian product <span class="math inline">\(X \times Y\)</span>, where <span class="math inline">\(X\)</span> is called domain and <span class="math inline">\(Y\)</span> is called the codomain. If an ordered pair <span class="math inline">\((x, y)\)</span> is in a relation <span class="math inline">\(R\)</span>, then the relation holds true for <span class="math inline">\((x, y)\)</span>. A binary relation on a set <span class="math inline">\(S\)</span> is a subset of the cartesian product <span class="math inline">\(S \times S\)</span>. We use <span class="math inline">\(xRy\)</span> or <span class="math inline">\(x \sim y\)</span> to denote the ordered pair <span class="math inline">\((x, y)\)</span> is in relation <span class="math inline">\(R\)</span>.</p>
<blockquote>
<p>If <span class="math inline">\(S = \{1, 2, 3\}\)</span> then <span class="math inline">\(x &lt; y\)</span> on <span class="math inline">\(S\)</span> is a relation <span class="math inline">\(R = \{(1, 2), (2, 3)\}\)</span>.</p>
</blockquote>
<h4 id="equivalence-class-and-equivalence-relation">Equivalence Class and Equivalence Relation</h4>
<p>A relation <span class="math inline">\(\sim\)</span> on a set <span class="math inline">\(S\)</span> is an equivalence relation if:</p>
<ol type="1">
<li>(Reflexivity) <span class="math inline">\(s \sim s \; \forall s \in S\)</span>.</li>
<li>(Symmetry) <span class="math inline">\(\forall \; s, t \in S\)</span>, if <span class="math inline">\(s \sim t\)</span>, then <span class="math inline">\(t \sim s\)</span>.</li>
<li>(Transitivity) <span class="math inline">\(\forall \; s, t, u \in S\)</span>, if <span class="math inline">\(s \sim t\)</span> and <span class="math inline">\(t \sim u\)</span>, then <span class="math inline">\(s \sim u\)</span>.</li>
</ol>
<p>An equivalence relation is meant to capture the idea of things "being the same" for the purposes of a given discussion.</p>
<h4 id="congruent-mod-n">Congruent mod <span class="math inline">\(n\)</span></h4>
<p>Let <span class="math inline">\(n \in \mathbb{Z}^+\)</span> be a positive integer, integers <span class="math inline">\(x, y\)</span> are <strong>congruent mod <span class="math inline">\(n\)</span></strong> if <span class="math inline">\(x - y\)</span> is divisible by <span class="math inline">\(n\)</span>. Congruent mod <span class="math inline">\(n\)</span> is an equivalence relation on <span class="math inline">\(\mathbb{Z}\)</span>.</p>
<h4 id="residue-class">Residue Class</h4>
<p>A residue class <span class="math inline">\(R(r)\)</span> is a complete set of integers that are congruent modulo <span class="math inline">\(n\)</span> with reminder <span class="math inline">\(r\)</span> (ie. <span class="math inline">\(a = kn + r \implies a \in R(r), \; k \in \mathbb{Z}, n \in \mathbb{Z}^+, 0 \leq r \in \mathbb{Z} leq n - 1\)</span>). In module <span class="math inline">\(n\)</span>, there are exactly <span class="math inline">\(n\)</span> different residue classes.</p>
<p><img src='/images/RL/background/fa_7_1_2.png' width="600"></p>
<h4 id="binary-operation">Binary Operation</h4>
<p>A binary operation on a set <span class="math inline">\(S\)</span> is a mapping of the elements of the Cartesian product <span class="math inline">\(S \times S\)</span> to <span class="math inline">\(S\)</span>:</p>
<p><span class="math display">\[f: S \times S \rightarrow S\]</span></p>
<h4 id="the-group-zn">The group <span class="math inline">\(Z(N)\)</span></h4>
<p>Let <span class="math inline">\(N\)</span> be a positive integer. A complex number <span class="math inline">\(z\)</span> is an <span class="math inline">\(N^{th}\)</span> <strong>root of unity</strong> if <span class="math inline">\(z^N = 1\)</span>. The set of <span class="math inline">\(N^{th}\)</span> roots of unity is precisely:</p>
<p><span class="math display">\[\{1, e^{2\pi i / N}, e^{2\pi i 2 / N}, ...., e^{2\pi i (N - 1) / N}\}\]</span></p>
<p>This is uniform partition of the circle.</p>
<p><img src='/images/RL/background/fa_7_1_1.png' width="600"></p>
<p>The set has the following properties:</p>
<ol type="1">
<li>If <span class="math inline">\(z, w \in Z(N)\)</span>, then <span class="math inline">\(zw \in Z(N)\)</span> and <span class="math inline">\(zw = wz\)</span></li>
<li><span class="math inline">\(1 \in Z(N)\)</span></li>
<li>If <span class="math inline">\(z \in Z(N)\)</span>, then <span class="math inline">\(z^{-1} = \frac{1}{z} \in Z(N)\)</span> and <span class="math inline">\(z z^{-1} = 1\)</span></li>
</ol>
<p>The group <span class="math inline">\(Z(N)\)</span> is equivalent to the group of <strong>integers modulo <span class="math inline">\(N\)</span></strong> which contains integers $0 n + m $</p>
<p>Let <span class="math inline">\(V, W\)</span> denote the vector spaces of complexed-valued functions on the group of integers modulo <span class="math inline">\(N\)</span> and the <span class="math inline">\(N\)</span>th roots of unity. Then, the identification given above carries over to <span class="math inline">\(V, W\)</span> as follows:</p>
<p><span class="math display">\[F(k) \longleftrightarrow f(e^{2\pi i k/N})\]</span></p>
<p>Where <span class="math inline">\(F\)</span> is a function on <span class="math inline">\(V\)</span> and <span class="math inline">\(f\)</span> is a function on the <span class="math inline">\(W\)</span>. These spaces can be represented as <span class="math inline">\(\mathbb{Z}(N)\)</span>, because they are equivalent.</p>
<h4 id="orthogonal-bases-in-mathbbzn">Orthogonal Bases in <span class="math inline">\(\mathbb{Z}(N)\)</span></h4>
<p>The family <span class="math inline">\(\{e_{0}, ...., e_{N-1}\}\)</span> is an orthogonal basis of vector space <span class="math inline">\(\mathbb{Z}(N)\)</span> equipped with inner product</p>
<p><span class="math display">\[&lt;F, G&gt; = \sum^{N-1}_{k=0} F(k) \overline{G(k)}\]</span></p>
<p>and corresponding norm:</p>
<p><span class="math display">\[\|F\| = \sqrt{\sum^{N-1}_{k=0} F(k) \overline{F(k)}} =  \sqrt{\sum^{N-1}_{k=0} |F(k)|^2}\]</span></p>
<p>where:</p>
<p><span class="math display">\[e_{l} (k) = e^{2\pi i lk/n}\]</span></p>
<p>and: <span class="math display">\[
&lt;e_m, e_l&gt;  =
\begin{cases}
N &amp; \quad \text{If $m = l$} \\
0 &amp; \quad \text{If $m \neq l$}
\end{cases}
\]</span></p>
<p>Since all <span class="math inline">\(e_l\)</span> has norm <span class="math inline">\(\sqrt{N}\)</span>, if we normalize it by <span class="math inline">\(\frac{1}{\sqrt{N}}\)</span>, we will have an orthnormal basis <span class="math inline">\(\{e^*_0, ...., e^*_{N-1}\}\)</span>:</p>
<p><span class="math display">\[e^*_l = \frac{1}{\sqrt{N}} e_l\]</span></p>
<p>Thus, for any <span class="math inline">\(F \in V\)</span>, we have:</p>
<p><span class="math display">\[F = \sum^{N-1}_{n=0} &lt;F, e^*_n&gt; e^*_n\]</span></p>
<p>and</p>
<p><span class="math display">\[\|F\|^2 = \sum^{N-1}_{n=0} |&lt;F, e^*_n&gt;|^2\]</span></p>
<h4 id="fourier-coefficient-in-mathbbzn">Fourier Coefficient in <span class="math inline">\(\mathbb{Z}(N)\)</span></h4>
<p>Define <span class="math inline">\(n\)</span>th Fourier Coefficient of <span class="math inline">\(F\)</span> by:</p>
<p><span class="math display">\[a_n = \frac{1}{N} &lt;F, e_n&gt; = \frac{1}{N} \sum^{N-1}_{k=0} F(k) e^{-2\pi i k n /N}\]</span></p>
<p>At the same time:</p>
<p><span class="math display">\[a_n = \frac{1}{\sqrt{N}} &lt;F, e^*_n&gt;\]</span></p>
<p>The function <span class="math inline">\(\hat{F}(n) = a_n\)</span> is the Fourier transform of <span class="math inline">\(F\)</span> on <span class="math inline">\(\mathbb{Z}(N)\)</span>.</p>
<h4 id="inversion-formula">Inversion Formula</h4>
<p>If <span class="math inline">\(F\)</span> is a function on <span class="math inline">\(\mathbb{Z}(N)\)</span>, then:</p>
<p><span class="math display">\[F(k) = \sum^{N-1}_{n=0} &lt;F, e^*_n&gt; e^*_n = \sum^{N-1}_{n=0} a_n e^{2\pi i n k / N} = \sum^{N-1}_{n=0} \hat{F}(n) e^{2\pi i n k / N}\]</span></p>
<p>It is possible to recover the Fourier inversion on the circle for sufficiently smooth function by letting <span class="math inline">\(N \rightarrow \infty\)</span> in the finite model <span class="math inline">\(\mathbb{Z}(N)\)</span>.</p>
<h4 id="discrete-fourier-transform">Discrete Fourier Transform</h4>
<p>When a signal is discrete and periodic, we don't need the continuous Fourier Transform. Instead, we use discrete Fourier Transform or DFT. Suppose our signal is <span class="math inline">\(a_n\)</span> for <span class="math inline">\(n = 0, ...., N-1\)</span> and <span class="math inline">\(a_n = a_{n + jN}\)</span> ofr all <span class="math inline">\(n, j\)</span>. The DFT of <span class="math inline">\(a\)</span>, also known as the <strong>spectrum</strong> of <span class="math inline">\(a\)</span> is <span class="math inline">\(F(n)\)</span>:</p>
<p><span class="math display">\[\hat{F}(k) = A_k =  &lt;a, e_k&gt; = \sum^{N-1}_{n=0} e^{-2\pi i kn / N} a_n\]</span></p>
<p>The sequence <span class="math inline">\(a_n\)</span> is the inverse discrete Fourier Transform of the sequence <span class="math inline">\(A_k\)</span>:</p>
<p><span class="math display">\[a_n = \frac{1}{N}\sum^{N-1}_{k=0} &lt;a, e_k&gt; e_k =  \frac{1}{N} \sum^{N-1}_{k=0} \hat{F}(k) e^{2\pi i n k / N}\]</span></p>
<h5 id="two-point-dft">Two Point DFT</h5>
<p><span class="math inline">\(N = 2\)</span>, <span class="math inline">\(e_1 (k) = e^{-i \pi} = -1, \forall k\)</span>, then:</p>
<p><span class="math display">\[A_k = (-1)^{kn} a_n = a_0 - (-1)^k a_1\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[A_0 = a_0 + a_1\]</span> <span class="math display">\[A_1 = a_0 - a_1\]</span></p>
<p><span class="math display">\[
A
=
\begin{bmatrix}
1 &amp; 1\\
1 &amp; -1 
\end{bmatrix}
\begin{bmatrix}
a_0 \\
a_1
\end{bmatrix}
\]</span></p>
<h5 id="four-point-dft">Four Point DFT</h5>
<p><img src='/images/RL/background/dft.png' width="600"></p>
<h1 id="ref">REF</h1>
<ol type="1">
<li>https://sites.millersville.edu/bikenaga/math-proof/relations/relations.html</li>
<li>https://math.libretexts.org/Bookshelves/Combinatorics_and_Discrete_Mathematics/Elementary_Number_Theory_(Barrus_and_Clark)/01%3A_Chapters/1.21%3A_Residue_Classes_and_the_Integers_Modelo_m</li>
<li>Fourier Transforms and the ast Fourier Transform (FFT) Algorithm</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/07/18/convex-opt-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/18/convex-opt-1/" class="post-title-link" itemprop="url">convex-opt</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-18 22:13:35" itemprop="dateCreated datePublished" datetime="2022-07-18T22:13:35+08:00">2022-07-18</time>
    </span>

  
    <span id="/2022/07/18/convex-opt-1/" class="post-meta-item leancloud_visitors" data-flag-title="convex-opt" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/07/18/convex-opt/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/18/convex-opt/" class="post-title-link" itemprop="url">convex-opt</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-18 22:13:35" itemprop="dateCreated datePublished" datetime="2022-07-18T22:13:35+08:00">2022-07-18</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-08-01 20:30:47" itemprop="dateModified" datetime="2022-08-01T20:30:47+08:00">2022-08-01</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/07/18/convex-opt/" class="post-meta-item leancloud_visitors" data-flag-title="convex-opt" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>1.8k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>2 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="convex-optimization-1">Convex Optimization (1)</h1>
<h2 id="convex-sets">Convex Sets</h2>
<h3 id="lines-and-line-segments">Lines and Line Segments</h3>
<p>Suppose <span class="math inline">\(x_1 \neq x_2\)</span> are two points in <span class="math inline">\(\mathbb{R}^n\)</span>. Points of the form:</p>
<p><span class="math display">\[y = \theta x_1 + (1 - \theta) x_2\]</span></p>
<p>Where <span class="math inline">\(\theta \in \mathbb{R}\)</span>, form the <strong>line</strong> passing through <span class="math inline">\(x_1, x_2\)</span>. The parameter value <span class="math inline">\(\theta = 0\)</span> corresponds to <span class="math inline">\(y = x_2\)</span>, and the parameter value <span class="math inline">\(\theta = 1\)</span> corresponds to <span class="math inline">\(y = x_1\)</span>. Values of the parameter <span class="math inline">\(\theta\)</span> between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> correspond to the closed <strong>line segment</strong> between <span class="math inline">\(x_1, x_2\)</span>.</p>
<p><br></p>
<h3 id="affine-sets">Affine Sets</h3>
<p>A set <span class="math inline">\(C \subseteq \mathbb{R}^n\)</span> is <strong>affine</strong> if the line through any two distinct points in <span class="math inline">\(C\)</span> lies in <span class="math inline">\(C\)</span> (For any <span class="math inline">\(x_1, x_2 \in C\)</span> and <span class="math inline">\(\theta \in \mathbb{R}, y = \theta x_1 + (1 - \theta)x_2 \in C\)</span>), in other words, <span class="math inline">\(C\)</span> contains linear combination of any two points in <span class="math inline">\(C\)</span>, provided the coefficients in the linear combination sum to <span class="math inline">\(1\)</span>.</p>
<p><br></p>
<p>We refer to a point of the form <span class="math inline">\(\theta_1 x_1 + .... + \theta_k x_k, \; \theta_1 + .... + \theta_k = 1\)</span> as an <strong>affine combination</strong> of the points <span class="math inline">\(x_1, ...., x_k\)</span>. It can be shown that an affine set contains every affine combination of its points. That is, if <span class="math inline">\(C\)</span> is an affine set, <span class="math inline">\(x_1, ...., x_k \in C\)</span>, and <span class="math inline">\(\theta_1 + .... + \theta_k = 1\)</span>, then the point <span class="math inline">\(\theta_1x_1 + .... + \theta_k x_k\)</span> also belongs to <span class="math inline">\(C\)</span>.</p>
<p>If <span class="math inline">\(C\)</span> is an affine set and <span class="math inline">\(x_0 \in C\)</span>, then the set:</p>
<p><span class="math display">\[V = C - x_0 = \{x - x_0 | x \in C\}\]</span></p>
<p>is a <strong>subspace</strong> (closed under additional and multiplication and contains <span class="math inline">\(0\)</span>). The <strong>dimension</strong> of an affine set <span class="math inline">\(C\)</span> is defined as the dimension of the subspace <span class="math inline">\(V = C - x_0\)</span> where <span class="math inline">\(x_0\)</span> is any element of <span class="math inline">\(C\)</span>.</p>
<p><br></p>
<p>The set of all affine combinations of points in some set <span class="math inline">\(C \subseteq \mathbb{R}^n\)</span> is called the <strong>affine hull</strong> of <span class="math inline">\(C\)</span>:</p>
<p><span class="math display">\[\text{aff} C = \{\theta_1 x_1 + .... + \theta_k x_k  | x_1, ...., x_k \in C, \theta_1 + .... + \theta_k = 1\}\]</span></p>
<p>The affine hull is <strong>the smallest affine set that contains <span class="math inline">\(C\)</span></strong>, in the following sense: if <span class="math inline">\(S\)</span> is any affine set with <span class="math inline">\(C \subseteq S\)</span>, then <span class="math inline">\(\text{aff} C \subseteq S\)</span>.</p>
<p><br></p>
<h3 id="affine-dimension-and-relative-interior">Affine Dimension and Relative Interior</h3>
<p>The <strong>Affine Dimension</strong> of a set <span class="math inline">\(C\)</span> is defined to be the dimension of its affine hull.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/07/11/vae/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/11/vae/" class="post-title-link" itemprop="url">VAE</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-11 21:06:28" itemprop="dateCreated datePublished" datetime="2022-07-11T21:06:28+08:00">2022-07-11</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-07-18 21:02:10" itemprop="dateModified" datetime="2022-07-18T21:02:10+08:00">2022-07-18</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
    <span id="/2022/07/11/vae/" class="post-meta-item leancloud_visitors" data-flag-title="VAE" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>3.8k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>3 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="variational-autoencoders">Variational Autoencoders</h1>
<p>Generative modeling is a broad area of machine learning which deals with models of distributions <span class="math inline">\(P(X)\)</span>, defined over datapoints <span class="math inline">\(X\)</span> in some potentially high-dimensional space <span class="math inline">\(\mathbf{X}\)</span>. For example, images are popular kind of data for which we might create generative models, the job of the generative model is to capture the dependencies between pixels and model the joint distribution between them. One straight forward kind of generative model is simply to compute the probability measure <span class="math inline">\(P(X)\)</span> numerically, given a <span class="math inline">\(X\)</span>, we can tell the probability that <span class="math inline">\(X\)</span> is a real image from the distribution. But we often care about producing more examples that are like those already in a database, that is, we can formalize the setup by saying that:</p>
<p>we get examples <span class="math inline">\(X\)</span> distributed according ot some unknown distribution <span class="math inline">\(P_{gt} (X)\)</span>, and our goal is to learn a model <span class="math inline">\(P\)</span> which we can sample from , such that <span class="math inline">\(P\)</span> is as similar as possible to <span class="math inline">\(P_{gt}\)</span>.</p>
<p>Formally, say we have a vector of latent variables <span class="math inline">\(\mathbf{z}\)</span> that have values in some high-dimensional space <span class="math inline">\(\mathbf{Z}\)</span> which we can easily sample according to some probability density function <span class="math inline">\(P(\mathbf{z})\)</span> defined over <span class="math inline">\(\mathbf{Z}\)</span>. Then, say we have a family of deterministic functions <span class="math inline">\(f(\mathbf{z}; \theta)\)</span>, parameterized by a vector <span class="math inline">\(\theta\)</span> values in some space <span class="math inline">\(\Theta\)</span>, where:</p>
<p><span class="math display">\[f(\mathbf{z}; \theta);\quad f: \mathbf{Z} \times \Theta \rightarrow \mathbf{X}\]</span></p>
<p><span class="math inline">\(f\)</span> is deterministic, but if <span class="math inline">\(\mathbf{z}\)</span> is random, then <span class="math inline">\(f(\mathbf{z}; \theta) := f(\cdot; \theta) \circ \mathbf{z}\)</span> is a random variable with values in <span class="math inline">\(\mathbf{X}\)</span>. <strong>We wish to optimize <span class="math inline">\(\theta\)</span> s.t we can sample <span class="math inline">\(\mathbf{z}\)</span> from <span class="math inline">\(P(\mathbf{z})\)</span> and with high probability <span class="math inline">\(f(\mathbf{z}; \theta)\)</span> will be like the <span class="math inline">\(X\)</span>s' in our datasets.</strong> That is, we aim to maximize the probability of each <span class="math inline">\(X\)</span> in the training set under the entire generative process (Maximize the likelihood):</p>
<p><span class="math display">\[P(X) = \int P(X| \mathbf{z}; \theta) P(\mathbf{z}) d\mathbf{z} \quad \quad (1)\]</span></p>
<p>The intuition behind this framework: If the model is likely to produce training examples, then it is likely to produce similar samples and unlikely to produce dissimilar ones.</p>
<p><br></p>
<p>In VAE, conditional density <span class="math inline">\(P(X | \mathbf{z};\theta)\)</span> is often parameterized by Multivariate Gaussian (with parameterized mean function, we can approach <span class="math inline">\(X\)</span> for some <span class="math inline">\(\mathbf{z}\)</span>, gradually making the training data more likely under the generative model.):</p>
<p><span class="math display">\[P(X | \mathbf{z}; \theta) = N(X | f(\mathbf{z}\; \theta), \sigma^2 I)\]</span></p>
<p>But it is not required to be Gaussian, if <span class="math inline">\(X\)</span> is binary, <span class="math inline">\(P(X | \mathbf{z})\)</span> might be a Bernoulli, <strong>the important property is simply that <span class="math inline">\(P(X | \mathbf{z})\)</span> can be computed and is continuous in <span class="math inline">\(\theta\)</span>.</strong></p>
<p><br></p>
<h2 id="setting-up-the-objective">Setting up the Objective</h2>
<p>How can we estimate equation 1 using sampling? In practice, for most <span class="math inline">\(\mathbf{z}\)</span>, <span class="math inline">\(P(X | \mathbf{z})\)</span> will be nearly zero, so it contributes nothing to <span class="math inline">\(P(X)\)</span>. The key idea behind the VAE is to attempt to sample values <span class="math inline">\(\mathbf{z}\)</span> that are likely to have produced <span class="math inline">\(X\)</span>, and compute <span class="math inline">\(P(X)\)</span> from there. This means we need a new function <span class="math inline">\(Q(\mathbf{z} | X)\)</span> which can take a value of <span class="math inline">\(X\)</span> and give us a distribution over <span class="math inline">\(\mathbf{z}\)</span> values that are likely to produce <span class="math inline">\(X\)</span>. Thus, computing <span class="math inline">\(E_{ \mathbf{z} \sim Q} [P(X | \mathbf{z})]\)</span> is much easier than <span class="math inline">\(E_{ \mathbf{z} \sim P( \mathbf{z})}[P(X | \mathbf{z})]\)</span>.</p>
<p>The KL divergence between <span class="math inline">\(Q(\mathbf{z} | X)\)</span> and <span class="math inline">\(P(\mathbf{z} | X)\)</span> is:</p>
<p><span class="math display">\[D[Q(\mathbf{z} | X) || P(\mathbf{z} | X)] = E_{z \sim Q} [\log Q(\mathbf{z} | X) - \log P(\mathbf{z} | X)]\]</span></p>
<p>Use bayes rule:</p>
<p><span class="math display">\[\log P(X) - D[Q(\mathbf{z} | X) || P(\mathbf{z} | X)] = E_{z \sim Q} [\log P(X | \mathbf{z})] - D[Q(\mathbf{z} | X) || P(\mathbf{z})]\]</span></p>
<p><strong>Starting from left-hand side, we are maximizing the log evidence while simultaneously minimizing the distribution regularization term. The right-hand side (ELBO) is similar to auto-encoder, where we map <span class="math inline">\(X \rightarrow \mathbf{z}\)</span> using <span class="math inline">\(Q\)</span>, then decode back to <span class="math inline">\(X\)</span> using <span class="math inline">\(P\)</span>.</strong></p>
<p>The right-hand side can be optimized using gradient decent.</p>
<p><br></p>
<h2 id="optimize-the-objective">Optimize the Objective</h2>
<p>How can we optimize the right-hand side (ELBO) ? we first need to be a bit more specific about the form that <span class="math inline">\(Q(\mathbf{z} | X)\)</span> will take. The usual choice is to say that <span class="math inline">\(Q(\mathbf{z} | X) = N(\mathbf{z} | \mu(X), \Sigma(X))\)</span>, in practice, <span class="math inline">\(\mu, \Sigma\)</span> are parametrized using NN.</p>
<p><img src="/images/RL/background/vae_1.png" width="600"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/06/12/gaussian-process/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/12/gaussian-process/" class="post-title-link" itemprop="url">gaussian-process</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-12 17:16:10" itemprop="dateCreated datePublished" datetime="2022-06-12T17:16:10+08:00">2022-06-12</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-06-14 22:32:02" itemprop="dateModified" datetime="2022-06-14T22:32:02+08:00">2022-06-14</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
    <span id="/2022/06/12/gaussian-process/" class="post-meta-item leancloud_visitors" data-flag-title="gaussian-process" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>1.6k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="gaussian-process">Gaussian Process</h1>
<h2 id="notations">Notations</h2>
<p><img src='/images/RL/background/gp_notations_1.png' width="600"> <img src='/images/RL/background/gp_notations_2.png' width="600"></p>
<h2 id="gaussian-identities">Gaussian Identities</h2>
<p>The multivariate Gaussian distribution has a joint probability density (Bayesian):</p>
<p><span class="math display">\[p(\mathbf{x} | \mathbf{m}, \Sigma) = (2\pi)^{-\frac{D}{2}} |\Sigma|^{-\frac{1}{2}} e^{-\frac{1}{2} (\mathbf{x} - \mathbf{m})^T \Sigma^{-1} (\mathbf{x} - \mathbf{m})}\]</span></p>
<p>Where <span class="math inline">\(\mathbf{m}\)</span> is the <strong>mean</strong> vector of length <span class="math inline">\(D\)</span> and <span class="math inline">\(\Sigma\)</span> is the symmetric <span class="math inline">\(D \times D\)</span>, positive definite covariance matrix. As a shorthand, we write <span class="math inline">\(\mathbf{x} \sim N(\mathbf{m}, \Sigma)\)</span></p>
<p><br></p>
<p>Let <span class="math inline">\(\mathbf{x}, \mathbf{y}\)</span> be jointly Gaussian random vectors:</p>
<p>$$$$</p>
<h2 id="regression">Regression</h2>
<h3 id="a-function-space-view">A Function Space View</h3>
<h4 id="definition-2.1-gaussian-process">Definition 2.1: Gaussian Process</h4>
<p>A <strong>Gaussian Process</strong> is a collection of random variables, any finite number of which have joint Gaussian distribution.</p>
<p><br></p>
<p>A Gaussian process is completely specified by its mean function and covariance function. We define mean function <span class="math inline">\(m(\mathbf{x})\)</span> and the covariance function <span class="math inline">\(k(\mathbf{x}, \mathbf{x}^\prime)\)</span> of a real process <span class="math inline">\(f(\mathbf{x})\)</span> as:</p>
<p><span class="math display">\[m(\mathbf{x}) = E[f(\mathbf{x})] \quad \quad k(\mathbf{x}, \mathbf{x}^\prime) = E[(f(\mathbf{x}) - m(\mathbf{x}))(f(\mathbf{x}^\prime) - m(\mathbf{x}^\prime))]\]</span></p>
<p>and given <span class="math inline">\(N\)</span> examples, we write the Gaussian process <span class="math inline">\(f := (f(\mathbf{x}_1) , ...., f(\mathbf{x}_N))\)</span> as:</p>
<p><span class="math display">\[f(\mathbf{x}) \sim GP(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}^\prime))\]</span></p>
<p>where the random variables represent the value of the function <span class="math inline">\(f\)</span> at location <span class="math inline">\(\mathbf{x}\)</span>. Often Gaussian process are defined over time, where the index set of the random variables is time. This is not the case in our use of GPs, here the index set <span class="math inline">\(\mathbb{X}\)</span> is the set of possible inputs. In our case, we identify the random variables s.t <span class="math inline">\(f_i := f(\mathbf{x}_i)\)</span> corresponding to training example <span class="math inline">\((\mathbf{x}_i, y_i)\)</span>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/06/12/kernels/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/12/kernels/" class="post-title-link" itemprop="url">kernels</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-12 15:49:24" itemprop="dateCreated datePublished" datetime="2022-06-12T15:49:24+08:00">2022-06-12</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-06-14 21:37:02" itemprop="dateModified" datetime="2022-06-14T21:37:02+08:00">2022-06-14</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/06/12/kernels/" class="post-meta-item leancloud_visitors" data-flag-title="kernels" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>939</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="kernels">Kernels</h1>
<h2 id="kernel-functions">kernel Functions</h2>
<p>We define a <strong>kernel function</strong> to be a real-valued function of two arguments <span class="math inline">\(k(\mathbf{x}, \mathbf{x}^\prime) = &lt;\Phi(\mathbf{x}), \Phi(\mathbf{x}^\prime)&gt;_H \in \mathbb{R}\)</span>, for <span class="math inline">\(\mathbf{x}, \mathbf{x}^\prime \in \mathbb{X}\)</span> that measures similarity between two inputs. Where <span class="math inline">\(\Phi\)</span> is maps into some inner product space <span class="math inline">\(H\)</span>, sometimes called the <strong>feature space</strong>.</p>
<h3 id="positive-definite-kernel">Positive Definite Kernel</h3>
<p>It can be shown that a kernel that corresponds to an inner product in some inner product space coincides with the class of positive definite kernels.</p>
<h4 id="definition-1-gram-matrix">Definition 1: Gram Matrix</h4>
<p>Given a kernel <span class="math inline">\(k\)</span> and inputs <span class="math inline">\(x_1, ...., x_n \in \mathbb{X}\)</span>, the <span class="math inline">\(n \times n\)</span> matrix:</p>
<p><span class="math display">\[K := (k(x_i, x_j))_{ij}\]</span></p>
<p>is called the Gram matrix or kernel matrix of <span class="math inline">\(k\)</span> w.r.t <span class="math inline">\(x_1, ...., x_n\)</span></p>
<p><br></p>
<h4 id="definition-2-positive-definite-kernel">Definition 2: Positive Definite Kernel</h4>
<p>The function <span class="math inline">\(k\)</span> is called a <strong>positive definite kernel</strong> if:</p>
<p><span class="math display">\[\sum^N_{n=1} \sum^N_{m=1} a_n a_m k(\mathbf{x}_n, \mathbf{x}_m) \geq 0\]</span></p>
<p>for any real numbers <span class="math inline">\(a_n, a_m\)</span> and points <span class="math inline">\(\mathbf{x}_n, \mathbf{x}_m \in \mathbb{X}\)</span> and any <span class="math inline">\(N \in \mathbb{N}\)</span>.</p>
<p><br></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/06/06/variational-inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/06/variational-inference/" class="post-title-link" itemprop="url">variational_inference</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-06-06 21:51:54 / Modified: 21:58:04" itemprop="dateCreated datePublished" datetime="2022-06-06T21:51:54+08:00">2022-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
    <span id="/2022/06/06/variational-inference/" class="post-meta-item leancloud_visitors" data-flag-title="variational_inference" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>2.7k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>2 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="variational-inference-a-review-for-statisticians">Variational Inference: A Review for Statisticians</h1>
<h2 id="general-problem-setting">General Problem Setting:</h2>
<p>Consider a joint density of latent variables <span class="math inline">\(\mathbf{z} = z_{1:m}\)</span> and observations <span class="math inline">\(\mathbf{x} = x_{1:n}\)</span>:</p>
<p><span class="math display">\[p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{x}|\mathbf{z})\]</span></p>
<p>The main idea behind variational inference is to use optimization to compute the conditional density of the latent variables given the observations:</p>
<p><span class="math display">\[p(\mathbf{z} | \mathbf{x}) = \frac{p(\mathbf{z}) p(\mathbf{x}|\mathbf{z})}{p(\mathbf{x})}\]</span></p>
<p>This conditional can be used to produce point or interval estimates of the latent variables, form predictive densities of new data <span class="math inline">\(p(x^* | \mathbf{x})\)</span> and more.</p>
<p>The quantity:</p>
<p><span class="math display">\[p(\mathbf{x}) = \int_\mathbf{z} p(\mathbf{z}, \mathbf{x}) d\mathbf{z}\]</span></p>
<p>is called the evidence, for many models, the evidence integral is unavailable in closed form or requires exponential time to compute.</p>
<h3 id="evidence-lower-bound">Evidence Lower Bound</h3>
<p>In variational inference, we specify a family <span class="math inline">\(\Theta\)</span> of densities over the latent variables. Each <span class="math inline">\(q(\mathbf{z})\)</span> is a candidate approximation to the exact conditional. Our goal is to find the best candidate, the one closest in KL divergence to the exact conditional. Inference now amounts to solving the following optimization problem:</p>
<p><span class="math display">\[q^*(\mathbf{z}) = \arg\min_{q(\mathbf{z}) \in \Theta} KL(q(\mathbf{z}) \;||\; p(\mathbf{z} | \mathbf{x})) = \int_{z} q(\mathbf{z})\log\frac{q(\mathbf{z})}{p(\mathbf{z}| \mathbf{x})} = E_{\mathbf{z} \sim q(\mathbf{z})}[\log q(\mathbf{z})] - E_{\mathbf{z} \sim q(\mathbf{z})}[\log p(\mathbf{z} | \mathbf{x})] = E_{\mathbf{z} \sim q(\mathbf{z})}[\log q(\mathbf{z})] - E_{\mathbf{z} \sim q(\mathbf{z})}[\log p(\mathbf{z}, \mathbf{x})] + \log p(\mathbf{x})\]</span></p>
<p>However, this objective is not computable because it requires computing the evidence <span class="math inline">\(\log p(\mathbf{x})\)</span>. Since we cannot compute KL, we optimize an alternative objective that is equivalent ot the KL up to an added constant:</p>
<p><span class="math display">\[ELBO(q) = E_{\mathbf{z} \sim q(\mathbf{z})} [\log p(\mathbf{z}, \mathbf{x})] - E_{\mathbf{z} \sim q(\mathbf{z})}[\log q(\mathbf{z})]\]</span></p>
<p>This function is called the evidence lower bound (ELBO), <strong>ELBO is the negative KL divergence plus a constant <span class="math inline">\(\log p(\mathbf{x})\)</span> w.r.t <span class="math inline">\(q(\mathbf{z})\)</span></strong>. Maximizing ELBO is equivalent to minimizing the KL divergence.</p>
<p><br></p>
<h4 id="property-1-elbo-is-the-balance-between-likelihood-and-prior">Property 1: ELBO is the Balance Between Likelihood and Prior</h4>
<p>Continue from above equation of <span class="math inline">\(ELBO(q)\)</span>, we can rewrite it as (<span class="math inline">\(E[\cdot] := E_{\mathbf{z} \sim q(\mathbf{z})}[\cdot]\)</span>):</p>
<p><span class="math display">\[ELBO(q) = E[\log p(\mathbf{z})] - E[\log q(\mathbf{z})] + E[\log p(\mathbf{x} | \mathbf{z})] = -KL(q(\mathbf{z}) | p(\mathbf{z})) + E[\log p(\mathbf{x} | \mathbf{z})]\]</span></p>
<p>In order to find a <span class="math inline">\(q(\mathbf{z})\)</span> that maximize ELBO, we have to maximize the expected log likelihood of the data given the hidden variables and minimize the distance to the prior (so the prior acts as a regularizer).</p>
<h4 id="property-2-elbo-is-the-lower-bound-of-the-log-evidence">Property 2: ELBO is the Lower Bound of the Log Evidence</h4>
<p>ELBO lower bounds the log evidence:</p>
<p><span class="math display">\[\log p(\mathbf{x}) = KL(q(\mathbf{z}) \;||\; p(\mathbf{z} | \mathbf{x})) \geq ELBO (q), \quad \quad \forall q \in \Theta\]</span></p>
<h2 id="ref">REF</h2>
<p>https://arxiv.org/pdf/2205.14415.pdf</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/05/28/time-series-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/28/time-series-3/" class="post-title-link" itemprop="url">time-series-3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-28 10:51:22" itemprop="dateCreated datePublished" datetime="2022-05-28T10:51:22+08:00">2022-05-28</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-06-17 20:32:43" itemprop="dateModified" datetime="2022-06-17T20:32:43+08:00">2022-06-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/05/28/time-series-3/" class="post-meta-item leancloud_visitors" data-flag-title="time-series-3" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>5.3k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>5 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="time-series-3">Time Series (3)</h1>
<h2 id="spectral-analysis-and-filtering">Spectral Analysis and Filtering</h2>
<p>We define a cycle as one complete period of a sine or cosine function defined over a unit time interval:</p>
<p><span class="math display">\[X_t = A\cos(2\pi\omega t + \phi) \quad \quad (4.1)\]</span></p>
<p>for <span class="math inline">\(t = 0, \pm 1, \pm 2, ...\)</span>, where:</p>
<ul>
<li><span class="math inline">\(\omega\)</span> is a <strong>frequency index</strong>, defined in cycles per unit time, so if <span class="math inline">\(\omega = 2\)</span>, for every 1 time unit, we have <span class="math inline">\(2\)</span> cycles, this is fixed.</li>
<li><span class="math inline">\(A\)</span> determining the height or <strong>amplitude</strong> of the function, this is <strong>random</strong>.</li>
<li><span class="math inline">\(\phi\)</span> determining the <strong>start point</strong> of the cosine function, this is <strong>random</strong>.</li>
</ul>
<p><br></p>
<p>Using the trigonometric identity, we can write above equation as:</p>
<p><span class="math display">\[X_t = U_1 \cos (2 \pi \omega t) + U_2 \sin (2 \pi \omega t) \quad \quad (4.2)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(U_1 = A \cos \phi\)</span> is often taken to be normally distributed random variable.</li>
<li><span class="math inline">\(U_2 = - A \sin \phi\)</span> is often taken to be normally distributed random variable.</li>
<li><span class="math inline">\(A = \sqrt{U_1^2 + U_2^2}\)</span></li>
<li><span class="math inline">\(\phi = \tan^{-1} (-\frac{U_2}{U_1})\)</span></li>
</ul>
<p><br></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/05/28/time-series-3/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/05/02/rigorous-probability-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/02/rigorous-probability-2/" class="post-title-link" itemprop="url">Rigorous Probability (2)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-02 11:32:04" itemprop="dateCreated datePublished" datetime="2022-05-02T11:32:04+08:00">2022-05-02</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-06-17 20:32:43" itemprop="dateModified" datetime="2022-06-17T20:32:43+08:00">2022-06-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/05/02/rigorous-probability-2/" class="post-meta-item leancloud_visitors" data-flag-title="Rigorous Probability (2)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>6.9k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>6 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="rigorous-probability-2">Rigorous Probability (2)</h1>
<h2 id="conditional-expectations">Conditional Expectations</h2>
<h3 id="elementary-conditional-probabilities">Elementary Conditional Probabilities</h3>
<h4 id="definition-8.2-conditional-probability">Definition 8.2 Conditional Probability</h4>
<p>Let <span class="math inline">\((\Omega, \mathbb{A}, P)\)</span> be a probability space adn <span class="math inline">\(B \in \mathbb{A}\)</span>. We define the <strong>conditional probability</strong> given <span class="math inline">\(B\)</span> for any <span class="math inline">\(A \in \mathbb{A}\)</span> by:</p>
<p><span class="math display">\[P(A | B) = \frac{P(A \cap B)}{P(B)}\]</span></p>
<p>with <span class="math inline">\(P(B) &gt; 0\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.4-pcdot-b-is-a-probability-measure">Theorem 8.4: <span class="math inline">\(P(\cdot | B)\)</span> is a Probability Measure</h4>
<p>If <span class="math inline">\(P(B) &gt; 0\)</span>, then <span class="math inline">\(P(\cdot | B)\)</span> is a probability measure on <span class="math inline">\((\Omega, \mathbb{A})\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.5-conditional-probability-of-independent-events">Theorem 8.5: Conditional Probability of Independent Events</h4>
<p>Let <span class="math inline">\(A, B \in \mathbb{A}\)</span> with <span class="math inline">\(P(A), P(B) &gt; 0\)</span>. Then, belows are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(A, B\)</span> are independent.</li>
<li><span class="math inline">\(P(A | B) = P(A)\)</span></li>
<li><span class="math inline">\(P(B | A) = P(B)\)</span></li>
</ol>
<p><br></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/05/02/rigorous-probability-2/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>
<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2021 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhu, Zhaoyang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">897k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">13:36</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.3" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{&quot;enable&quot;:true,&quot;app_id&quot;:&quot;gPOc95wWW2Hwp2pkVSAAz28m-MdYXbMMI&quot;,&quot;app_key&quot;:&quot;7Sf65xCHXfEEdBvu29UHSYdV&quot;,&quot;server_url&quot;:&quot;https:&#x2F;&#x2F;swag1ong.github.io&quot;,&quot;security&quot;:true}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{&quot;enable&quot;:true,&quot;repo&quot;:&quot;swag1ong&#x2F;swag1ong.github.io&quot;,&quot;issue_term&quot;:&quot;pathname&quot;,&quot;theme&quot;:&quot;github-light&quot;,&quot;pathname&quot;:&quot;pathname&quot;}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
