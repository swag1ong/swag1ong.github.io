<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="1xbHmVEsS5Fta14x1d1FXkHFr93LRr1pMxipdYVcNI4">
  <meta name="baidu-site-verification" content="code-Srzz2vTuzA">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;swag1ong.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;Searching...&quot;,&quot;empty&quot;:&quot;We didn&#39;t find any results for the search: ${query}&quot;,&quot;hits_time&quot;:&quot;${hits} results found in ${time} ms&quot;,&quot;hits&quot;:&quot;${hits} results found&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:3,&quot;unescape&quot;:false,&quot;preload&quot;:true}}</script>
<meta property="og:type" content="website">
<meta property="og:title" content="GoGoGogo!">
<meta property="og:url" content="https://swag1ong.github.io/index.html">
<meta property="og:site_name" content="GoGoGogo!">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhu, Zhaoyang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://swag1ong.github.io/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>GoGoGogo!</title><script src="/js/config.js"></script>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?852b005027c5efa81663f6f5c4c5b7fd"></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">GoGoGogo!</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-igloo fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">99</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">16</span></a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">25</span></a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-address-card fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhu, Zhaoyang"
      src="/images/others/favicon.jpeg">
  <p class="site-author-name" itemprop="name">Zhu, Zhaoyang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">99</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/swag1ong" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;swag1ong" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhaoyang.zhu@mail.utoronto.ca" title="E-Mail → mailto:zhaoyang.zhu@mail.utoronto.ca" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhuzhaoyangzzyu0616" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhuzhaoyangzzyu0616" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2030/05/30/aa_welcome/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2030/05/30/aa_welcome/" class="post-title-link" itemprop="url">Welcome</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2030-05-30 23:59:13" itemprop="dateCreated datePublished" datetime="2030-05-30T23:59:13+08:00">2030-05-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-27 13:09:10" itemprop="dateModified" datetime="2022-02-27T13:09:10+08:00">2022-02-27</time>
      </span>

  
    <span id="/2030/05/30/aa_welcome/" class="post-meta-item leancloud_visitors" data-flag-title="Welcome" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="welcome">Welcome</h1>
<p><img src="../about/mingren.gif"/></p>
<p><strong>Welcome to my website, hope you enjoy it, most of the notes are listed below</strong>:</p>
<p><br></p>
<p><strong>Some backgrounds</strong>:</p>
<ol type="1">
<li><a href="/2021/05/11/probability/" title="Probability (1)">Probability (1)</a></li>
<li><a href="/2021/05/11/probability-2/" title="Probability (2)">Probability (2)</a></li>
<li><a href="/2021/07/15/probability-3/" title="Probability (3)">Probability (3)</a></li>
<li><a href="/2021/05/14/calculus/" title="Calculus (1)">Calculus (1)</a></li>
<li><a href="/2021/07/06/cal-2/" title="Calculus (2)">Calculus (2)</a></li>
<li><a href="/2021/07/18/cnn/" title="Backpropagation in CNN">Backpropagation in CNN</a></li>
<li><a href="/2021/08/02/rnn/" title="RNN">RNN</a></li>
<li><a href="/2021/12/25/real-analysis-1/" title="Real Analysis (1)">Real Analysis (1)</a></li>
<li><a href="/2022/01/01/real-analysis-2/" title="Real Analysis (2)">Real Analysis (2)</a></li>
<li><a href="/2022/01/01/real-analysis-3/" title="Real Analysis (3)">Real Analysis (3)</a></li>
<li><a href="/2022/01/06/real-analysis-4/" title="Real Analysis (4)">Real Analysis (4)</a></li>
<li><a href="/2022/02/13/mira/" title="Measure Integral and Real Analysis (1)">Measure Integral and Real Analysis (1)</a></li>
<li><a href="/2022/02/27/mira-2/" title="Measure Integral and Real Analysis (2)">Measure Integral and Real Analysis (2)</a></li>
<li><a href="/2021/11/15/time-series-1/" title="Time Series (1)">Time Series (1)</a></li>
<li><a href="/2021/11/19/time-series-2/" title="Time Series (2)">Time Series (2)</a></li>
<li><a href="/2022/01/06/linear-algebra/" title="Linear Algebra (1)">Linear Algebra (1)</a></li>
<li><a href="/2022/01/09/linear-algebra-2/" title="Linear Algebra (2)">Linear Algebra (2)</a></li>
<li><a href="/2022/01/19/linear-algebra-3/" title="Linear Algebra (3)">Linear Algebra (3)</a></li>
<li><a href="/2022/01/25/linear-algebra-4/" title="Linear Algebra (4)">Linear Algebra (4)</a></li>
<li><a href="/2022/02/04/linear-algebra-5/" title="Linear Algebra (5)">Linear Algebra (5)</a></li>
</ol>
<p><strong>Some RL backgrounds</strong>:</p>
<ol type="1">
<li><a href="/2021/05/03/MDP/" title="MDP">MDP</a></li>
<li><a href="/2021/05/03/bellman-equations/" title="Bellman Equations">Bellman Equations</a></li>
<li><a href="/2021/05/03/bellman-optimality-equations/" title="Bellman Optimality Equations">Bellman Optimality Equations</a></li>
<li><a href="/2021/05/03/dp/" title="Dynamic Programming">Dynamic Programming</a></li>
<li><a href="/2021/05/03/value-iteration/" title="Value Iteration">Value Iteration</a></li>
<li><a href="/2021/05/03/policy-iteration/" title="Policy Iteration">Policy Iteration</a></li>
<li><a href="/2021/05/07/value-function-learning/" title="Learning From Stream of Data">Learning From Stream of Data</a></li>
<li><a href="/2021/05/15/mc/" title="Monte Carlo Methods">Monte Carlo Methods</a></li>
<li><a href="/2021/05/15/td/" title="Temporal Difference Learning">Temporal Difference Learning</a></li>
<li><a href="/2021/05/16/sarsa/" title="SARSA">SARSA</a></li>
<li><a href="/2021/05/16/q-learning/" title="Q Learning">Q Learning</a></li>
<li><a href="/2021/06/12/vfa-1/" title="Value Function Approximation (1)">Value Function Approximation (1)</a></li>
<li><a href="/2021/07/13/vfa-2/" title="Value Function Approximation (2)">Value Function Approximation (2)</a></li>
<li><a href="/2021/05/23/policy-gradient/" title="Policy Gradient (1)">Policy Gradient (1)</a></li>
<li><a href="/2021/05/30/policy-gradient-2/" title="Policy Gradient (2)">Policy Gradient (2)</a></li>
<li><a href="/2021/06/05/policy-gradient-3/" title="Policy Gradient (3)">Policy Gradient (3)</a></li>
<li><a href="/2021/05/30/average-reward-setting/" title="Average Reward Setting (Under Construction)">Average Reward Setting (Under Construction)</a></li>
<li><a href="/2021/06/28/semi-mdp/" title="Semi MDP (Under Construction)">Semi MDP (Under Construction)</a></li>
</ol>
<p><strong>Some interesting RL algorithms</strong>:</p>
<ol type="1">
<li><a href="/2021/05/06/DPG/" title="DPG">DPG</a></li>
<li><a href="/2021/06/09/DDPG/" title="DDPG">DDPG</a></li>
<li><a href="/2021/05/07/DDQN/" title="DDQN">DDQN</a></li>
<li><a href="/2021/06/23/td3/" title="TD3">TD3</a></li>
<li><a href="/2021/05/13/Dueling/" title="Dueling DQN">Dueling DQN</a></li>
<li><a href="/2021/06/11/TRPO/" title="TRPO">TRPO</a></li>
<li><a href="/2021/06/11/PPO/" title="PPO">PPO</a></li>
<li><a href="/2021/05/20/prior-exp-replay/" title="Prioritized Experience Replay">Prioritized Experience Replay</a></li>
<li><a href="/2021/06/25/instrinsic-motivation/" title="Intrinsic Motivation">Intrinsic Motivation</a></li>
<li><a href="/2021/06/25/go-explore/" title="Go Explore">Go Explore</a></li>
<li><a href="/2021/06/03/natural-actor-critic/" title="Natural Actor Critic (Under Construction)">Natural Actor Critic (Under Construction)</a></li>
<li><a href="/2021/06/03/off-policy-actor-critic/" title="Off Policy Actor Critic (Under Construction)">Off Policy Actor Critic (Under Construction)</a></li>
<li><a href="/2021/07/22/sac/" title="SAC (Under Construction)">SAC (Under Construction)</a></li>
</ol>
<p><strong>Some Deep Learning algorithms and models</strong>:</p>
<ol type="1">
<li><a href="/2021/05/25/drop-out/" title="Dropout">Dropout</a></li>
<li><a href="/2021/05/26/batch-norm/" title="Batch Normalization">Batch Normalization</a></li>
<li><a href="/2021/06/02/layer-norm/" title="Layer Normalization">Layer Normalization</a></li>
<li><a href="/2021/07/05/xavier/" title="Xavier Initialization">Xavier Initialization</a></li>
<li><a href="/2021/06/23/kaiming-init/" title="Kaiming Initialization">Kaiming Initialization</a></li>
<li><a href="/2021/07/05/LReLU/" title="LReLU">LReLU</a></li>
<li><a href="/2021/06/22/alex-net/" title="Alex Net">Alex Net</a></li>
<li><a href="/2021/06/25/overfeat/" title="Overfeat (Under Construction)">Overfeat (Under Construction)</a></li>
<li><a href="/2021/06/24/VGG/" title="VGG (Under Construction)">VGG (Under Construction)</a></li>
<li><a href="/2021/07/29/momentum/" title="Momentum">Momentum</a></li>
<li><a href="/2021/07/29/adaptive-lr/" title="Basic Adaptive LR Methods">Basic Adaptive LR Methods</a></li>
<li><a href="/2021/07/29/adam/" title="Adam">Adam</a></li>
<li><a href="/2021/08/06/attention/" title="Attention">Attention</a></li>
<li><a href="/2021/12/25/tcn/" title="TCN">TCN</a></li>
<li><a href="/2021/12/25/transformer/" title="Transformer">Transformer</a></li>
</ol>
<p><strong>Some old school ML algorithms</strong>:</p>
<ol type="1">
<li><a href="/2021/07/19/pca/" title="PCA">PCA</a></li>
<li><a href="/2021/07/19/logistic-regression/" title="Logistic Regression">Logistic Regression</a></li>
<li><a href="/2021/07/19/naive-bayes/" title="Naive Bayes">Naive Bayes</a></li>
<li><a href="/2021/07/19/decision-trees/" title="Decision Trees">Decision Trees</a></li>
<li><a href="/2021/07/19/random-forests/" title="Random Forest (Under Construction)">Random Forest (Under Construction)</a></li>
<li><a href="/2021/07/19/adaboost/" title="AdaBoost">AdaBoost</a></li>
<li><a href="/2021/07/19/gbdt/" title="GBDT">GBDT</a></li>
<li><a href="/2021/07/19/k-means/" title="K-means">K-means</a></li>
<li><a href="/2021/07/19/knn/" title="KNN (Under Construction)">KNN (Under Construction)</a></li>
<li><a href="/2021/07/19/svm/" title="SVM (Under Construction)">SVM (Under Construction)</a></li>
<li><a href="/2021/07/21/em/" title="EM Algorithm">EM Algorithm</a></li>
<li><a href="/2021/08/09/roc/" title="ROC">ROC</a></li>
<li><a href="/2021/09/06/lgb/" title="LGBM">LGBM</a></li>
<li><a href="/2021/09/09/graphical-models/" title="Graphical Models (Under Construction)">Graphical Models (Under Construction)</a></li>
<li><a href="/2021/09/16/hmm/" title="Sequential Data Modeling (Under Construction)">Sequential Data Modeling (Under Construction)</a></li>
</ol>
<p><strong>Some CS</strong>:</p>
<ol type="1">
<li><a href="/2021/05/18/leet-code-1/" title="LeetCode (1)">LeetCode (1)</a></li>
<li><a href="/2021/06/05/leet-code-2/" title="LeetCode (2)">LeetCode (2)</a></li>
<li><a href="/2021/06/16/leet-code-3/" title="LeetCode (3)">LeetCode (3)</a></li>
<li><a href="/2021/07/13/leet-code-4/" title="LeetCode (4)">LeetCode (4)</a></li>
<li><a href="/2021/07/19/heaps/" title="Heaps">Heaps</a></li>
<li><a href="/2021/06/06/sort/" title="Sorts">Sorts</a></li>
<li><a href="/2021/06/14/tree/" title="Trees">Trees</a></li>
</ol>
<p><br></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/02/27/mira-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/27/mira-2/" class="post-title-link" itemprop="url">Measure Integral and Real Analysis (2)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-02-27 13:06:47" itemprop="dateCreated datePublished" datetime="2022-02-27T13:06:47+08:00">2022-02-27</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-28 22:58:31" itemprop="dateModified" datetime="2022-02-28T22:58:31+08:00">2022-02-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/02/27/mira-2/" class="post-meta-item leancloud_visitors" data-flag-title="Measure Integral and Real Analysis (2)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>6.1k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>6 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="measure-integral-and-real-analysis-2">Measure Integral and Real Analysis (2)</h1>
<h2 id="integration">Integration</h2>
<h3 id="integration-w.r.t-a-measure">Integration w.r.t a Measure</h3>
<h4 id="definition-3.1-s-partition">Definition 3.1: <span class="math inline">\(S\)</span>-Partition</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on a set <span class="math inline">\(X\)</span>. An <strong><span class="math inline">\(S\)</span>-partition</strong> of <span class="math inline">\(X\)</span> is finite collection <span class="math inline">\(A_1, ..., A_m\)</span> of disjoint sets in <span class="math inline">\(S\)</span> s.t <span class="math inline">\(A_1 \cup ... \cup A_m = X\)</span>.</p>
<p><br></p>
<h4 id="definition-3.1-lower-lebesgue-sum">Definition 3.1: Lower Lebesgue Sum</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function, and <span class="math inline">\(P\)</span> is an <span class="math inline">\(S\)</span>-partition <span class="math inline">\(A_1, ..., A_m\)</span> of <span class="math inline">\(X\)</span>. The <strong>lower Lebesgue sum</strong> <span class="math inline">\(L(f, P)\)</span> is defined by:</p>
<p><span class="math display">\[L(f, P) = \sum^m_{j=1} \mu(A_j) \inf_{A_j} f\]</span></p>
<p><strong>The definition does not assume <span class="math inline">\(X\)</span> is a subset of <span class="math inline">\(\mathbb{R}\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-3.3-integral-of-a-nonnegative-function">Definition 3.3: Integral of a Nonnegative Function</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is an <span class="math inline">\(S\)</span>-measurable function. The <strong>integral</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(\mu\)</span>, denoted by <span class="math inline">\(\int f d\mu\)</span> is defined by:</p>
<p><span class="math display">\[\int f d\mu = \sup\{L(f, P): \text{ $P$ is an $S$-partition of $X$}\}\]</span></p>
<p><br></p>
<h4 id="theorem-3.4-integral-of-a-characteristic-function-chi_e">Theorem 3.4: Integral of a Characteristic Function <span class="math inline">\(\chi_E\)</span></h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E \in S\)</span>. Then:</p>
<p><span class="math display">\[\int \chi_E d\mu = \mu(E)\]</span></p>
<h5 id="proof-of-theorem-3.4">Proof of Theorem 3.4:</h5>
<p>If <span class="math inline">\(P\)</span> is the <span class="math inline">\(S\)</span>-partition of <span class="math inline">\(E, X / E\)</span>, then:</p>
<p><span class="math display">\[L(\chi_E, P) = \mu(E) * 1 + 0 * \mu(X / E) = \mu(E)\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[\int \chi_E d\mu \geq \mu(E)\]</span></p>
<p>Let <span class="math inline">\(P\)</span> be an <span class="math inline">\(S\)</span>-partition <span class="math inline">\(A_1, ..., A_m\)</span> of <span class="math inline">\(X\)</span>, then</p>
<p><span class="math display">\[
\mu(A_j) \inf_{A_j} \chi_ E=
\begin{cases}
\mu(A_j), \quad \text{if } A_j \subseteq E\\
0, \quad \text{ o. w }
\end{cases}
\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sum^{m}_{j=1} \mu(A_j) \inf_{A_j} \chi_E = \sum_{\{j: A_j \subseteq E\}} \mu(A_j) = \mu(\bigcup_{\{j: A_j \subseteq E\}} A_j) \leq \mu(E)\]</span></p>
<p><br></p>
<h4 id="theorem-3.7-integral-of-a-simple-function">Theorem 3.7: Integral of a Simple Function</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(E_1, E_2, .., E_n\)</span> are disjoint sets in <span class="math inline">\(S\)</span>, and <span class="math inline">\(c_1, ..., c_n \in [0, \infty]\)</span>. Then:</p>
<p><span class="math display">\[\int (\sum^n_{k=1} c_k \chi_{E_k}) d\mu = \sum^{n}_{k=1} c_k \mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-3.8-integration-is-order-preserving">Theorem 3.8: Integration is Order Preserving</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f, g: X \rightarrow [0, \infty]\)</span> are <span class="math inline">\(S\)</span>-measurable functions s.t <span class="math inline">\(f(x) \leq g(x)\)</span> for all <span class="math inline">\(x \in X\)</span>. Then:</p>
<p><span class="math display">\[\int f d\mu \leq \int g d\mu\]</span></p>
<h5 id="proof-of-theorem-3.8">Proof of Theorem 3.8:</h5>
<p>Suppose <span class="math inline">\(P\)</span> is a <span class="math inline">\(S\)</span>-partition <span class="math inline">\(A_1, ..., A_n\)</span> of <span class="math inline">\(X\)</span>. Then:</p>
<p><span class="math display">\[\inf_{A_i} f \leq \inf_{A_i} g \implies L(f, P) \leq L(g, P)\]</span></p>
<p>Then for any <span class="math inline">\(P\)</span>, we have:</p>
<p><span class="math display">\[\sup_P L(f, P) \leq \sup_P L(g, P)\]</span></p>
<p><br></p>
<h4 id="theorem-3.9-integral-via-simple-functions">Theorem 3.9: Integral Via Simple Functions</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable. Then:</p>
<p><span class="math display">\[\int f d\mu = \sup\{\sum^{m}_{j=1}c_j\mu(A_j): \text{ $A_1, ..., A_m$ are disjoint sets in $S$, $c_1, ...., c_m \in [0, \infty)$, $f(x)\geq \sum^m_{j=1}c_j \chi_{A_j}(x)$ for every $x \in X$}\}\]</span></p>
<p>Here, we have <span class="math inline">\(A_1, ..., A_m \in S\)</span> as arbitrary disjoint sets, they do not have to be <span class="math inline">\(S\)</span>-partition.</p>
<p><br></p>
<h4 id="theorem-3.11-monotone-convergence-theorem">Theorem 3.11: Monotone Convergence Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 \leq f_1 \leq f_2 \leq ...\)</span> is an increasing sequence of <span class="math inline">\(S\)</span>-measurable functions. Define <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> by:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} f_k (x)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu = \int f d\mu\]</span></p>
<h5 id="proof-of-theorem-3.11">Proof of Theorem 3.11:</h5>
<p>To show that the equality holds, we need to show that:</p>
<ol type="1">
<li><span class="math inline">\(\lim_{k\rightarrow \infty} \int f_k d\mu \leq \int f d\mu\)</span></li>
<li><span class="math inline">\(\lim_{k\rightarrow \infty} \int f_k d\mu \geq \int f d\mu\)</span></li>
</ol>
<p><strong>We first prove 1:</strong></p>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(0 \leq f_1 \leq f_2 \leq ...\)</span> is an increasing sequence of <span class="math inline">\(S\)</span>-measurable functions. Define <span class="math inline">\(f: X \rightarrow [0, \infty]\)</span> by:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} f_k (x)\]</span></p>
<p>Then by <code>theorem 2.53</code>, we have <span class="math inline">\(f\)</span> to be <span class="math inline">\(S\)</span>-measurable. Since <span class="math inline">\(f_k(x) \leq f(x), \;\; \forall x \in X, k \in \mathbb{Z}^+\)</span>, by <code>theorem 3.8</code>, we have:</p>
<p><span class="math display">\[\int f_k d \mu \leq \int f d\mu \implies \lim_{k \rightarrow \infty} \int f_k d \mu \leq \int f d\mu\]</span></p>
<p><strong>To prove 2, we need to use <code>theorem 3.9</code>:</strong></p>
<p>Suppose <span class="math inline">\(A_1, ..., A_m\)</span> are disjoint sets in <span class="math inline">\(S\)</span>, and <span class="math inline">\(c_1, ..., c_m \in [0, \infty)\)</span> are s.t:</p>
<p><span class="math display">\[f(x) \geq \sum^{m}_{j=1} c_j \chi_{A_j} (x)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\int f d\mu = \sup_{\text{all disjoint sets in $S$}}\{\sum^{m}_{j=1} c_j \mu(A_j)\}\]</span></p>
<p>Let <span class="math inline">\(t \in (0, 1)\)</span>. For <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, let:</p>
<p><span class="math display">\[E_k = \{x \in X: f_k (x) \geq t \sum^{m}_{j=1} c_j \chi_{A_j} (x)\}\]</span></p>
<p>Then <span class="math inline">\(E_1 \subseteq E_2 \subseteq , ...\)</span> is an increasing sequence of sets whose union is <span class="math inline">\(X\)</span> (because <span class="math inline">\(f(x) \geq \sum^{m}_{j=1} c_j \chi_{A_j} (x)\)</span>) and <span class="math inline">\((E_1 \cap A_j) \subseteq (E_2 \cap A_j) \subseteq .... \;\; \forall j \in \{1, ..., m\}\)</span> is also an increasing sequence of sets, this implies (by <code>theorem 2.59</code>) that:</p>
<p><span class="math display">\[\mu(\lim_{k\rightarrow \infty} (E_k \cap A_j)) = \mu(X \cap A_j) = \mu(A_j)\]</span></p>
<p>Then for all <span class="math inline">\(x \in X\)</span>:</p>
<p><span class="math display">\[f_k (x) \geq t \sum^{m}_{j=1} c_j \chi_{A_j \cap E_k} (x) \implies \int f_k d\mu \geq \int t \sum^{m}_{j=1} c_j \chi_{A_j \cap E_k} d \mu \implies \int f_k d\mu \geq t\sum^{m}_{j=1} c_j \mu(A_j \cap E_k)\]</span></p>
<p>Taking the limit to infinity:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu \geq  \lim_{k\rightarrow \infty} t\sum^{m}_{j=1} c_j \mu(A_j \cap E_k) = t \sum^{m}_{j=1} c_j \mu(A_j)\]</span></p>
<p>Taking the limit <span class="math inline">\(t \rightarrow 1\)</span>:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} \int f_k d\mu \geq  \sum^{m}_{j=1} c_j \mu(A_j)\]</span></p>
<p>Since right-hand side works for any <span class="math inline">\(c_1, ...., c_m \in [0, \infty)\)</span>, disjoint sets <span class="math inline">\(A_1, ..., A_m\)</span> that satisfies <span class="math inline">\(f(x) \geq \sum^{m}_{j=1} c_j \chi_{A_j} (x)\)</span>, we have:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} f_k(x) \geq  \sup_{\text{all disjoint sets in $S$}}\{\sum^{m}_{j=1} c_j \mu(A_j)\} = \int f d\mu\]</span></p>
<p><br></p>
<h4 id="theorem-3.13-integral-type-sums-for-simple-functions">Theorem 3.13: Integral-type Sums for Simple Functions</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measurable space. Suppose <span class="math inline">\(a_1, ..., a_m, b_1, ..., b_n \in [0, \infty]\)</span> and <span class="math inline">\(A_1, ..., A_m, B_1, ..., B_n \in S\)</span> s.t <span class="math inline">\(\sum^m_{j=1} a_j \chi_{A_j} = \sum^n_{k=1} b_k \chi_{B_k}\)</span>. Then:</p>
<p><span class="math display">\[\sum^{m}_{j=1} a_j \mu(A_j) = \sum^n_{k=1} b_k \mu(B_k)\]</span></p>
<p><br></p>
<h4 id="theorem-3.15-integral-of-a-linear-combination-of-characteristic-functions">Theorem 3.15: Integral of a Linear Combination of Characteristic Functions</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space, <span class="math inline">\(E_1, ..., E_n \in S\)</span>, and <span class="math inline">\(c_1, ..., c_n \in [0, \infty)\)</span>. Then:</p>
<p><span class="math display">\[\int (\sum^{n}_{k=1} c_k \chi_{E_k}) d\mu = \sum^{n}_{k=1} c_k \mu(E_k)\]</span></p>
<p><strong>The difference between this theorem and <code>theorem 3.7</code> is that, here we do not require <span class="math inline">\(E_1, ..., E_n\)</span> to be disjoint</strong></p>
<p><br></p>
<h4 id="theorem-3.16-additivity-of-integration">Theorem 3.16: Additivity of Integration</h4>
<p>Suppose <span class="math inline">\((X . S, \mu)\)</span> is a measure space and <span class="math inline">\(f, g: X \rightarrow [0, \infty]\)</span> are <span class="math inline">\(S\)</span>-measurable functions. Then:</p>
<p><span class="math display">\[\int (f+g) d\mu = \int f d\mu + \int g d\mu\]</span></p>
<h5 id="proof-of-theorem-3.16">Proof of Theorem 3.16:</h5>
<p>Suppose <span class="math inline">\(f, g\)</span> are simple functions, then:</p>
<p><span class="math display">\[\int (f + g) d\mu = \int (\sum_j c_j \chi_{E_j} + \sum_k c_k \chi_{E_k}) d\mu = \sum_j c_j \mu(E_j) + \sum_{k} c_k \mu(E_k) = \int f d\mu + \int g d\mu\]</span></p>
<p>So the integrals of simple functions are additive.</p>
<p>Let <span class="math inline">\(f_1, f_2, ...\)</span>, <span class="math inline">\(g_1, g_2, ....\)</span> be increasing sequence of simple functions s.t:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} f_k = f\]</span></p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} g_k = g\]</span></p>
<p>By <code>theorem 2.89</code>, these sequences exist.</p>
<p>Since <span class="math inline">\(f_k, g_k, f, g\)</span> are <span class="math inline">\(S\)</span>-measurable functions, <span class="math inline">\(f + g\)</span> is <span class="math inline">\(S\)</span>-measurable function. Then by <code>Monotone Convergence Theorem</code>, we have:</p>
<p><span class="math display">\[\int (f + g) d\mu = \lim_{k \rightarrow \infty} \int (f_k + g_k) d\mu = \lim_{k \rightarrow \infty} \int f_k \mu + \lim_{k \rightarrow \infty} \int g_k d\mu = \int f d\mu + \int g d\mu\]</span></p>
<p><br></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/02/13/mira/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/13/mira/" class="post-title-link" itemprop="url">Measure Integral and Real Analysis (1)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-02-13 12:16:16" itemprop="dateCreated datePublished" datetime="2022-02-13T12:16:16+08:00">2022-02-13</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-28 22:20:16" itemprop="dateModified" datetime="2022-02-28T22:20:16+08:00">2022-02-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/02/13/mira/" class="post-meta-item leancloud_visitors" data-flag-title="Measure Integral and Real Analysis (1)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>40k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>36 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="measure-integral-and-real-analysis-1">Measure Integral and Real Analysis (1)</h1>
<p><span class="math inline">\(X / A\)</span> means that the difference between set <span class="math inline">\(X\)</span> and <span class="math inline">\(A\)</span>.</p>
<h2 id="fields">Fields</h2>
<h3 id="complete-ordered-fields">Complete Ordered Fields</h3>
<h4 id="definition-0.1-field">Definition 0.1: Field</h4>
<p>A <strong>field</strong> is a set <span class="math inline">\(\mathbb{F}\)</span> along with <strong>closed</strong> operations of addition and multiplication on <span class="math inline">\(\mathbb{F}\)</span> that have the following properties:</p>
<ol type="1">
<li><strong>Commutativity</strong>: <span class="math display">\[a + b = b + a, \quad ab = ba \quad \forall a, b \in \mathbb{F}\]</span></li>
<li><strong>Associativity</strong>: <span class="math display">\[(a + b) + c  = a + (b + c) \quad (ab)c = a(bc) \quad \forall a,b,c \in \mathbb{F}\]</span></li>
<li><strong>Distributive Property</strong>: <span class="math display">\[a(b + c) = ab + ac \quad \forall a, b, c \in \mathbb{F}\]</span></li>
<li><strong>Additive Identity</strong>: There exists an element <span class="math inline">\(0 \in \mathbb{F}\)</span> s.t. <span class="math inline">\(a + 0 = a, \forall a \in \mathbb{F}\)</span></li>
<li><strong>Additive Inverse</strong>: For each <span class="math inline">\(a \in \mathbb{F}\)</span>, there exists an element <span class="math inline">\(-a \in \mathbb{F}\)</span> such that <span class="math inline">\(a + (-a) = 0\)</span>.</li>
<li><strong>Multiplicative Identity</strong>: There exists an element <span class="math inline">\(1 \in \mathbb{F}\)</span> s.t <span class="math inline">\(1 \neq 0\)</span> and <span class="math inline">\(a1 = a, \forall a \in \mathbb{F}\)</span>.</li>
<li><strong>Multiplicative Inverse</strong>: For each <span class="math inline">\(a \in \mathbb{F}\)</span> with <span class="math inline">\(a \neq 0\)</span>, there exists an element <span class="math inline">\(a^{-1} \in \mathbb{F}\)</span> s.t <span class="math inline">\(aa^{-1} = 1\)</span></li>
</ol>
<blockquote>
<p><span class="math inline">\(\mathbb{Q}, \mathbb{R}, \mathbb{C}, \{0, 1\}\)</span> with usual operation of addition and multiplication are fields.</p>
</blockquote>
<p><br></p>
<h4 id="definition-0.5-ordered-field-positive">Definition 0.5: Ordered Field, Positive</h4>
<p>An <strong>ordered field</strong> is a field <span class="math inline">\(\mathbb{F}\)</span> along with a subset <span class="math inline">\(P\)</span> of <span class="math inline">\(\mathbb{F}\)</span>, called the <strong>positive</strong> subset with the following properties:</p>
<ol type="1">
<li>If <span class="math inline">\(a \in \mathbb{F}\)</span>, then <span class="math inline">\(a \in P\)</span> or <span class="math inline">\(a = 0\)</span> or <span class="math inline">\(-a \in P\)</span>.</li>
<li>If <span class="math inline">\(a \in P\)</span>, then <span class="math inline">\(-a \notin P\)</span>.</li>
<li>If <span class="math inline">\(a, b \in P\)</span>, then <span class="math inline">\(a + b \in P\)</span> and <span class="math inline">\(ab \in P\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-0.6-the-positive-subset-is-closed-under-multiplicative-inverse">Theorem 0.6: The Positive Subset is Closed under Multiplicative Inverse</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field with positive subset <span class="math inline">\(P\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(1 \in P\)</span></li>
<li><span class="math inline">\(a^{-1} \in P, \forall a \in P\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-0.7-less-than-greater-than">Definition 0.7: Less Than, Greater Than</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field with positive subset <span class="math inline">\(P\)</span>. Suppose <span class="math inline">\(a, b \in \mathbb{F}\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(a &lt; b\)</span> is defined to mean <span class="math inline">\(b - a \in P\)</span>.</li>
<li><span class="math inline">\(a \leq b\)</span> is defined to mean <span class="math inline">\(a &lt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
<li><span class="math inline">\(a &gt; b\)</span> is defined to mean <span class="math inline">\(a - b \in P\)</span>.</li>
<li><span class="math inline">\(a \geq b\)</span> is defined to mean <span class="math inline">\(a &gt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
</ol>
<p>The statement <span class="math inline">\(0 &lt; b\)</span> is equivalent to the statement <span class="math inline">\(b \in P\)</span>.</p>
<p><br></p>
<h4 id="theorem-0.8-transitivity">Theorem 0.8: Transitivity</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field and <span class="math inline">\(a, b, c \in \mathbb{F}\)</span>. If <span class="math inline">\(a &lt; b\)</span> and <span class="math inline">\(b &lt; c\)</span>, then <span class="math inline">\(a &lt; c\)</span>.</p>
<p><br></p>
<h4 id="definition-0.9-absolute-value">Definition 0.9: Absolute Value</h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field and <span class="math inline">\(b \in \mathbb{F}\)</span>. The <strong>absolute value</strong> of <span class="math inline">\(b\)</span>, denoted <span class="math inline">\(|b|\)</span>, is defined by:</p>
<p><span class="math display">\[
|b| =
\begin{cases}
b, \quad \text{if} b \geq 0\\
-b, \quad \text{if} b &lt; 0
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="theorem-0.10-a-b-leq-a-b">Theorem 0.10: <span class="math inline">\(|a + b| \leq |a| + |b|\)</span></h4>
<p>Suppose <span class="math inline">\(\mathbb{F}\)</span> is an ordered field and <span class="math inline">\(a, b \in \mathbb{F}\)</span>. Then:</p>
<p><span class="math display">\[|a + b| \leq |a| + |b|\]</span></p>
<p><br></p>
<h3 id="completeness">Completeness</h3>
<h4 id="definition-0.19-complete-ordered-field">Definition 0.19: Complete Ordered Field</h4>
<p>An ordered field <span class="math inline">\(\mathbb{F}\)</span> is called <strong>complete</strong> if every nonempty subset of <span class="math inline">\(\mathbb{F}\)</span> that has an upper bound has a least upper bound.</p>
<p><br></p>
<h4 id="definition-0.20-mathbbr-the-field-of-real-numbers">Definition 0.20: <span class="math inline">\(\mathbb{R}\)</span>, The Field of Real Numbers</h4>
<p>The symbol <span class="math inline">\(\mathbb{R}\)</span> denotes a complete ordered field. This field is called real numbers.</p>
<p><br></p>
<h4 id="definition-0.35-supremum-and-infimum">Definition 0.35: Supremum and Infimum</h4>
<p>Suppose <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The <strong>supremum</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\sup A\)</span>, is defined as:</p>
<p><span class="math display">\[
\sup A =
\begin{cases}
\text{The Least Upper Bound}, \quad \text{if $A$ has an upper bound and $A \neq \emptyset$}\\
\infty, \quad \text{if $A$ does not have an upper bound}\\
-\infty, \quad \text{if $A = \emptyset$}
\end{cases}
\]</span></p>
<p>The <strong>Infimum</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\inf A\)</span>, is defined as:</p>
<p><span class="math display">\[
\inf A =
\begin{cases}
\text{The Greatest Lower Bound}, \quad \text{if $A$ has a lower bound and $A \neq \emptyset$}\\
-\infty, \quad \text{if $A$ does not have a lower bound}\\
\infty, \quad \text{if $A = \emptyset$}
\end{cases}
\]</span></p>
<h3 id="intervals">Intervals</h3>
<p>Sometimes it is useful to consider a set consisting of <span class="math inline">\(\mathbb{R}\)</span> and two additional elements called <span class="math inline">\(\infty\)</span> and <span class="math inline">\(-\infty\)</span>. We define it as <span class="math inline">\(\mathbb{R} \cup \{\infty, -\infty\}\)</span>.</p>
<h4 id="definition-0.40-ordering-on-mathbbr-cup-infty--infty">Definition 0.40: Ordering on <span class="math inline">\(\mathbb{R} \cup \{\infty, -\infty\}\)</span></h4>
<ul>
<li>The ordering <span class="math inline">\(&lt;\)</span> on <span class="math inline">\(\mathbb{R}\)</span> is extended to <span class="math inline">\(\mathbb{R} \cup \{\infty, -\infty\}\)</span> as follows:
<ul>
<li><span class="math inline">\(a &lt; \infty, \;\forall a \in \mathbb{R} \cup \{-\infty\}\)</span></li>
<li><span class="math inline">\(-\infty &lt; a, \;\forall a \in \mathbb{R} \cup \{\infty\}\)</span></li>
</ul></li>
<li>For <span class="math inline">\(a, b \in \mathbb{R}\cup \{\infty, -\infty\}\)</span>,
<ul>
<li>The notation <span class="math inline">\(a \leq b\)</span> means that <span class="math inline">\(a &lt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
<li>The notation <span class="math inline">\(a &gt; b\)</span> means that <span class="math inline">\(b &lt; a\)</span>.</li>
<li>The notation <span class="math inline">\(a \geq b\)</span> means that <span class="math inline">\(a &gt; b\)</span> or <span class="math inline">\(a = b\)</span>.</li>
</ul></li>
</ul>
<p><br></p>
<h4 id="definition-0.41-interval-notation">Definition 0.41: Interval Notation</h4>
<p>Suppose <span class="math inline">\(a, b \in \mathbb{R} \cup \{\infty, -\infty\}\)</span>. Then:</p>
<ul>
<li><span class="math inline">\((a, b) = \{t\in\mathbb{R}: a &lt; t &lt; b\}\)</span></li>
<li><span class="math inline">\([a, b] = \{t \in \mathbb{R} \cup \{\infty, -\infty\}: a \leq t \leq b\}\)</span></li>
<li><span class="math inline">\((a, b] = \{t \in \mathbb{R} \cup \{\infty\}: a &lt; t \leq b\}\)</span></li>
<li><span class="math inline">\([a, b) = \{t \in \mathbb{R} \cup \{-\infty\}: a \leq t &lt; b\}\)</span></li>
</ul>
<p>If <span class="math inline">\(a &gt; b\)</span> then all sets are empty ses. If <span class="math inline">\(a = b\)</span>, then <span class="math inline">\([a, b]\)</span> is the set of <span class="math inline">\(\{a\}\)</span>, all others are empty sets. The definition implies that:</p>
<ol type="1">
<li><span class="math inline">\((-\infty, \infty) = \mathbb{R}\)</span></li>
<li><span class="math inline">\([-\infty, \infty] = \mathbb{R} \cup \{\infty, \infty\}\)</span>, this is not a subset of <span class="math inline">\(\mathbb{R}\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-0.42-interval">Definition 0.42: Interval</h4>
<ul>
<li>A subset of <span class="math inline">\([-\infty, \infty]\)</span> is called an <strong>interval</strong> if it contains all numbers that are between pairs of its elements.</li>
<li>In other words, a set <span class="math inline">\(I \subset [-\infty, \infty]\)</span> is called an <strong>interval</strong> if <span class="math inline">\(c, d \in I\)</span> implies <span class="math inline">\((c, d) \in I\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-0.43-description-of-intervals">Theorem 0.43: Description of Intervals</h4>
<p>Suppose <span class="math inline">\(I \subset [-\infty, \infty]\)</span> is an interval. Then <span class="math inline">\(I\)</span> is one of the following sets for some <span class="math inline">\(a,b \in [-\infty, \infty]\)</span>:</p>
<p><span class="math display">\[(a, b), [a, b], (a, b], [a, b)\]</span></p>
<p><br></p>
<h3 id="open-and-closed-subsets-of-mathbbrn">Open and Closed Subsets of <span class="math inline">\(\mathbb{R}^n\)</span></h3>
<h4 id="definition-0.44-mathbbrn">Definition 0.44: <span class="math inline">\(\mathbb{R^n}\)</span></h4>
<p>^n is the set of all ordered <span class="math inline">\(n-tuples\)</span> of real numbers:</p>
<p><span class="math display">\[\mathbb{R}^n = \{(x_1, ..., x_n): x_1, ..., x_n \in \mathbb{R}\}\]</span></p>
<p><br></p>
<h4 id="definition-0.45-cdot-cdot_infty">Definition 0.45: <span class="math inline">\(\|\cdot\|, \|\cdot\|_{\infty}\)</span></h4>
<p>For <span class="math inline">\((x_1, ..., x_n) \in \mathbb{R}^n\)</span>, let:</p>
<p><span class="math display">\[\|(x_1, ..., x_n)\| = \sqrt{x_1^2 + ... + x_n^2}\]</span></p>
<p>and</p>
<p><span class="math display">\[\|(x_1, ..., x_n)\|_{\infty} = \max\{|x_1|, ..., |x_n|\}\]</span></p>
<p><br></p>
<h4 id="definition-0.46-limit">Definition 0.46: Limit</h4>
<p>Suppose <span class="math inline">\(a_1, a_2, ... \in\mathbb{R}^n\)</span> and <span class="math inline">\(L \in \mathbb{R}^n\)</span>. Then <span class="math inline">\(L\)</span> is called a limit of the sequence <span class="math inline">\(a_1, a_2, ...\)</span> and we write:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} a_k = L\]</span></p>
<p>If for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(m \in \mathbb{Z}^+\)</span> s.t:</p>
<p><span class="math display">\[\|a_k - L\|_\infty &lt; \epsilon\]</span></p>
<p>for all integers <span class="math inline">\(k \geq m\)</span>.</p>
<p><br></p>
<h4 id="definition-0.47-converge-convergent">Definition 0.47: Converge, Convergent</h4>
<p>A sequence in <span class="math inline">\(\mathbb{R}^n\)</span> is said to <strong>converge</strong> and to be a <strong>convergent sequence</strong> if it has a limit.</p>
<p><br></p>
<h4 id="theorem-0.48-coordinatewise-limits">Theorem 0.48: Coordinatewise Limits</h4>
<p>Suppose <span class="math inline">\(a_1, a_2, .... \in \mathbb{R}^n\)</span> and <span class="math inline">\(L \in \mathbb{R}^n\)</span>. For <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, let:</p>
<p><span class="math display">\[(a_{k, 1}, ...., a_{k, n}) = a_k\]</span></p>
<p>and let <span class="math inline">\((L_1, ..., L_n) = L\)</span>. Then, <span class="math inline">\(\lim_{k \rightarrow \infty} a_k = L\)</span> IFF:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} a_{k, j} = L_j\]</span></p>
<p>For each <span class="math inline">\(j \in \{1, ..., n\}\)</span></p>
<p><strong>Thus, questions about convergence of sequences in <span class="math inline">\(\mathbb{R}^n\)</span> can often be reduced to questions about convergence of sequences in <span class="math inline">\(\mathbb{R}\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-0.49-open-cube">Definition 0.49: Open Cube</h4>
<p>For <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(\delta &gt; 0\)</span>, the <strong>open cube</strong> <span class="math inline">\(B(x, \delta)\)</span> is defined by:</p>
<p><span class="math display">\[B(x, \delta) = \{y \in \mathbb{R}^n: \|y - x\|_{\infty} &lt; \delta\}\]</span></p>
<p><br></p>
<h4 id="definition-0.51-open-interval">Definition 0.51: Open Interval</h4>
<p>A subset of <span class="math inline">\(\mathbb{R}\)</span> of the form <span class="math inline">\((a, b)\)</span> for some <span class="math inline">\(a, b \in [-\infty, \infty]\)</span> is called an <strong>open interval</strong>.</p>
<p>If <span class="math inline">\(n = 1\)</span>, then <span class="math inline">\(B(x, \delta) = (x - \delta, x + \delta)\)</span></p>
<p><br></p>
<h4 id="definition-10.52-open-subset-of-mathbbrn">Definition 10.52: Open Subset of <span class="math inline">\(\mathbb{R}^n\)</span></h4>
<ul>
<li>A subset <span class="math inline">\(G\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>open</strong> if for every <span class="math inline">\(x \in G\)</span>, there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(B(x, \delta) \subseteq G\)</span>.</li>
<li>Equivalently, a subset <span class="math inline">\(G\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>open</strong> if every element of <span class="math inline">\(G\)</span> is contained in an open cube that is contained in <span class="math inline">\(G\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-0.55-union-and-intersection-of-open-sets">Theorem 0.55: Union and Intersection of Open Sets</h4>
<ol type="a">
<li>The union of every collection of open subsets of <span class="math inline">\(\mathbb{R}^n\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
<li>The intersection of every finite collection of open subset of <span class="math inline">\(\mathbb{R}^n\)</span> is an open subset of <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-0.56-countable-uncountable">Definition 0.56: Countable, Uncountable</h4>
<ul>
<li>A set <span class="math inline">\(C\)</span> is called <strong>countable</strong> if <span class="math inline">\(C = \emptyset\)</span> or if <span class="math inline">\(C = \{c_1 c_2, ...\}\)</span> for some sequence <span class="math inline">\(c_1, c_2, ...\)</span> of element of <span class="math inline">\(C\)</span>.</li>
<li>A set is called <strong>uncountable</strong> if it is not countable.</li>
</ul>
<p><br></p>
<h4 id="definition-0.58-disjoint">Definition 0.58: Disjoint</h4>
<p>A sequence <span class="math inline">\(E_1, E_2, ...\)</span> of sets is called disjoint if <span class="math inline">\(E_j \cap E_k = \emptyset\)</span> whenever <span class="math inline">\(j \neq k\)</span>.</p>
<p><br></p>
<h4 id="theorem-0.59-open-subset-of-mathbbr-is-countable-disjoint-union-of-open-intervals">Theorem 0.59: Open Subset of <span class="math inline">\(\mathbb{R}\)</span> is Countable Disjoint Union of Open Intervals</h4>
<p>A subset of <span class="math inline">\(\mathbb{R}\)</span> is open iFF it is the union of a disjoint sequence of open interval.</p>
<p><br></p>
<h4 id="definition-0.60-set-difference-complement">Definition 0.60: Set Difference, Complement</h4>
<ul>
<li>If <span class="math inline">\(S, A\)</span> are sets, then the <strong>set difference</strong> <span class="math inline">\(S \ A\)</span> is defined to be the set of elements of <span class="math inline">\(S\)</span> that are not in <span class="math inline">\(A\)</span>. In other words, <span class="math inline">\(S \ A = \{s \in S: s \neq A\}\)</span>.</li>
<li>If <span class="math inline">\(A \subseteq S\)</span>, then <span class="math inline">\(S \ A\)</span> is the <strong>complement</strong> of <span class="math inline">\(A\)</span> in <span class="math inline">\(S\)</span>.</li>
</ul>
<p><br></p>
<h4 id="definition-0.61-closed-subset-of-mathbbrn">Definition 0.61: Closed Subset of <span class="math inline">\(\mathbb{R}^n\)</span></h4>
<p>A subset of <span class="math inline">\(\mathbb{R}^n\)</span> is called <strong>closed</strong> if its complement in <span class="math inline">\(\mathbb{R}^n\)</span> is open.</p>
<p><strong>a subset of <span class="math inline">\(\mathbb{R}^n\)</span> need not be either open or closed. For example <span class="math inline">\((6, 16]\)</span> is neither open nor closed</strong></p>
<p><br></p>
<h4 id="theorem-0.62-characterization-of-closed-sets">Theorem 0.62: Characterization of Closed Sets</h4>
<p>A subset of <span class="math inline">\(\mathbb{R}^n\)</span> is closed IFF it contains the limit of every convergent sequence of elements of the set.</p>
<p><br></p>
<h4 id="theorem-0.63-de-morgans-laws">Theorem 0.63: De Morgan's Laws</h4>
<p>Suppose <span class="math inline">\(A\)</span> is a collection of subsets of some set <span class="math inline">\(X\)</span>. Then:</p>
<p><span class="math display">\[X /\ \bigcup_{E \in A} E = \bigcap_{E \in A} (X /\ E)\]</span></p>
<p>and</p>
<p><span class="math display">\[X /\ \bigcap_{E \in A} E = \bigcup_{E \in A} (X /\ E)\]</span></p>
<p><br></p>
<h4 id="theorem-0.65-sets-that-are-both-open-and-closed">Theorem 0.65: Sets that are Both Open and Closed</h4>
<p>The only subsets of <span class="math inline">\(\mathbb{R}^n\)</span> that are both open and closed are <span class="math inline">\(\emptyset\)</span> and <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<p><br></p>
<h2 id="riemann-integral">Riemann Integral</h2>
<h3 id="riemann-integral-review">Riemann Integral Review</h3>
<h4 id="definition-1.1-partition">Definition 1.1: Partition</h4>
<p>Suppose <span class="math inline">\(a, b \in \mathbb{R}\)</span> with <span class="math inline">\(a &lt; b\)</span>. A partition of <span class="math inline">\([a, b]\)</span> is a finite list of the form <span class="math inline">\(x_0, x_1, ...., x_n\)</span>, where:</p>
<p><span class="math display">\[a = x_0 &lt; x_1 &lt; .... &lt; x_n = b\]</span></p>
<p><br></p>
<h4 id="definition-1.2-notation-for-infimum-and-supremum-of-a-function">Definition 1.2: Notation for Infimum and Supremum of a Function</h4>
<p>If <span class="math inline">\(f\)</span> is a real-valued function and <span class="math inline">\(A\)</span> is a subset of the domain of <span class="math inline">\(f\)</span>, then:</p>
<p><span class="math display">\[\inf_A f = \inf\{f(x): x \in A\} \quad \quad \sup_A f = \sup\{f(x): x \in A\}\]</span></p>
<p><br></p>
<h4 id="definition-1.3-lower-and-upper-riemann-sums">Definition 1.3: Lower and Upper Riemann Sums</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function and <span class="math inline">\(P\)</span> is a partition <span class="math inline">\(x_0 ,...., x_n\)</span> of <span class="math inline">\([a, b]\)</span>. The <strong>lower Riemann sum</strong> <span class="math inline">\(L(f, P, [a, b])\)</span> and the <strong>upper Riemann sum</strong> <span class="math inline">\(U(f, P, [a, b])\)</span> are defined by:</p>
<p><span class="math display">\[L(f, P, [a, b]) = \sum^n_{j=1}(x_j - x_{j-1}) \inf_{[x_{j-1}, x_j]} f\]</span></p>
<p>and</p>
<p><span class="math display">\[U(f, P, [a, b]) = \sum^n_{j=1}(x_j - x_{j-1}) \sup_{[x_{j-1}, x_j]} f\]</span></p>
<p><br></p>
<h4 id="theorem-1.5-inequalities-with-riemann-sums">Theorem 1.5: Inequalities with Riemann Sums</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function and <span class="math inline">\(P, P^{\prime}\)</span> are partitions of <span class="math inline">\([a, b]\)</span>, such that the list defining <span class="math inline">\(P\)</span> is a sublist of the list defining <span class="math inline">\(P^{\prime}\)</span>. Then:</p>
<p><span class="math display">\[L(f, P, [a, b]) \leq L(f, P^{\prime}, [a, b]) \leq U(f, P^{\prime}, [a, b]) \leq U(f, P, [a, b])\]</span></p>
<h5 id="proof-of-theorem-1.5">Proof of Theorem 1.5:</h5>
<p>Let <span class="math inline">\(P\)</span> be the partition <span class="math inline">\(x_0, ..., x_n\)</span> and <span class="math inline">\(P^{\prime}\)</span> be the partition <span class="math inline">\(x^{\prime}_0, ..., x^{\prime}_N\)</span> of <span class="math inline">\([a, b]\)</span>. Then for each <span class="math inline">\(j = 1, ..., n\)</span>, there exists <span class="math inline">\(k \in \{0, ..., N-1\}\)</span> and a positive integer <span class="math inline">\(m\)</span> s.t <span class="math inline">\(x_{j-1} = x^{\prime}_k &lt; ... &lt; x^{\prime}_{k+m} = x_j\)</span>, in other words, the interval <span class="math inline">\([x_{j-1}, x_j]\)</span> contains several smaller intervals <span class="math inline">\([x^{\prime}_{k}, x^{\prime}_{k+1}], ...., [x^{\prime}_{k+m -1}, x^{\prime}_{k+m}]\)</span>. Then:</p>
<p><span class="math display">\[(x_j - x_{j-1}) \inf_{[x_{j-1}, x_j]} f = \sum^{m}_{i=1} (x^{\prime}_{k+i} - x^{\prime}_{k+i - 1})\inf_{[x_{j-1}, x_j]} f \leq \sum^{m}_{i=1} (x^{\prime}_{k+i} - x^{\prime}_{k+i - 1})\inf_{[x^{\prime}_{k+i - 1}, x^{\prime}_{k+i}]} f\]</span></p>
<p>Which implies the first inequality. The second and third are similar.</p>
<p><br></p>
<h4 id="theorem-1.6-lower-riemann-sums-leq-upper-riemann-sums">Theorem 1.6: Lower Riemann Sums <span class="math inline">\(\leq\)</span> Upper Riemann Sums</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function and <span class="math inline">\(P, P^{\prime}\)</span> are partitions of <span class="math inline">\([a, b]\)</span>. Then:</p>
<p><span class="math display">\[L(f, P, [a, b]) \leq U(f, P^{\prime}, [a, b])\]</span></p>
<h5 id="proof-of-theorem-1.6">Proof of Theorem 1.6:</h5>
<p>Let <span class="math inline">\(P^{\prime\prime}\)</span> be the partition of <span class="math inline">\([a, b]\)</span> obtained by merging the lists that define <span class="math inline">\(P, P^{\prime}\)</span>, then by <code>theorem 1.5</code>, we have:</p>
<p><span class="math display">\[L(f, P, [a, b]) \leq L(f, P^{\prime\prime}, [a, b]) \leq U(f, P^{\prime\prime}, [a, b]) \leq U(f, P^{\prime}, [a, b])\]</span></p>
<p>For any <span class="math inline">\(P, P^{\prime}\)</span>.</p>
<p><br></p>
<h4 id="definition-1.7-lower-and-upper-riemann-integrals">Definition 1.7: Lower and Upper Riemann Integrals</h4>
<p>Suppose <span class="math inline">\(f:[a, b] \rightarrow \mathbb{R}\)</span> is a bounded function. The <strong>lower</strong> Riemann integral <span class="math inline">\(L(f, [a, b])\)</span> and the <strong>upper</strong> Riemann integral <span class="math inline">\(U(f, [a, b])\)</span> of <span class="math inline">\(f\)</span> are defined by:</p>
<p><span class="math display">\[L(f, [a, b]) = \sup_{P} L(f, P, [a, b])\]</span></p>
<p>and</p>
<p><span class="math display">\[U(f, [a, b]) = \inf_P U(f, P, [a, b])\]</span></p>
<p>Where the supremum and infimum above are taken over all partitions <span class="math inline">\(P\)</span> of <span class="math inline">\([a, b]\)</span>.</p>
<p><br></p>
<h4 id="theorem-1.8-lower-riemann-integral-leq-upper-riemann-integral">Theorem 1.8: Lower Riemann Integral <span class="math inline">\(\leq\)</span> Upper Riemann Integral</h4>
<p>Suppose <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is a bounded function. Then:</p>
<p><span class="math display">\[L(f, [a, b]) \leq U(f, [a, b])\]</span></p>
<p><br></p>
<h4 id="definition-1.9-riemann-integrable-riemann-integral">Definition 1.9: Riemann Integrable; Riemann Integral</h4>
<ul>
<li>A <strong>bounded</strong> function on a <strong>closed bounded interval</strong> is called <strong>Riemann integrable</strong> if its lower Riemann integral equals its upper Riemann integral.</li>
<li>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is Riemann integrable, then the <strong>Riemann integral <span class="math inline">\(\int^a_b f\)</span></strong> is defined by: <span class="math display">\[\int^b_a f = L(f, [a, b]) = U(f, [a, b])\]</span></li>
</ul>
<p><br></p>
<h4 id="theorem-1.11-continuous-functions-are-riemann-integrable">Theorem 1.11: Continuous Functions are Riemann Integrable</h4>
<p>Every continuous real-valued function on each closed bounded interval is Riemann integrable.</p>
<p><br></p>
<h4 id="theorem-1.13-bounds-on-riemann-integral">Theorem 1.13: Bounds on Riemann Integral</h4>
<p>Suppose <span class="math inline">\(f:[a, b] \rightarrow \mathbb{R}\)</span> is Riemann integrable. Then:</p>
<p><span class="math display">\[(b - a) \inf_{[a, b]}f \leq \int^b_a f \leq (b - a) \sup_{[a, b]} f\]</span></p>
<p><br></p>
<h3 id="riemann-integral-is-not-good-enough">Riemann Integral Is not Good Enough</h3>
<p>The Riemann integral has several deficiencies:</p>
<ol type="1">
<li>Riemann integration does not handle functions with many discontinuities.</li>
<li>Riemann integration does not handle unbounded functions.</li>
<li>Riemann integration does not work well with limits.</li>
</ol>
<p><br></p>
<h2 id="measures">Measures</h2>
<h3 id="outer-measure-on-mathbbr">Outer Measure on <span class="math inline">\(\mathbb{R}\)</span></h3>
<h4 id="definition-2.1-length-of-open-interval-li">Definition 2.1: Length of Open Interval: <span class="math inline">\(l(I)\)</span></h4>
<p>The <strong>length</strong> <span class="math inline">\(l(I)\)</span> of an <strong>open</strong> interval <span class="math inline">\(I\)</span> is defined by:</p>
<p><span class="math display">\[
l(I) =
\begin{cases}
b - a, \quad \text{if $I = (a, b)$ for some $a, b \in \mathbb{R}$ with $a &lt; b$}\\
0, \quad \text{if $I = \emptyset$}\\
\infty, \quad \text{if $I = (-\infty, a)$ or $I = (a, \infty)$ for some $a \in \mathbb{R}$}\\
\infty, \quad \text{if $I = (-\infty, \infty)$}
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="definition-2.2-outer-measure-a">Definition 2.2: Outer Measure: <span class="math inline">\(|A|\)</span></h4>
<p>The <strong>outer measure</strong> <span class="math inline">\(|A|\)</span> of a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is defined by:</p>
<p><span class="math display">\[|A| = \inf\{\sum^{\infty}_{k=1} l(I_k): I_1, I_2, ... \text{ are open intervals such that $A \subseteq \bigcup_{k=1}^{\infty} I_k$}\}\]</span></p>
<blockquote>
<h4 id="example-2.3-finite-sets-have-outer-measure-0">Example 2.3: Finite sets have outer measure 0</h4>
<p>Suppose <span class="math inline">\(A = \{a_1, ..., a_n\}\)</span> is a finite set of real numbers. Suppose <span class="math inline">\(\epsilon &gt; 0\)</span>. Define a sequence <span class="math inline">\(I_1, I_2, ...\)</span> of open intervals by:</p>
<p><span class="math display">\[
I_k =
\begin{cases}
(a_k - \epsilon, a_k + \epsilon), \quad \text{if $k \leq n$}\\
\emptyset, \quad \text{if $k &gt; n$}\\
\end{cases}
\]</span></p>
<p>Then <span class="math inline">\(I_1, I_2, ...\)</span> is a sequence of open interval whose union contains <span class="math inline">\(A\)</span>. Clearly <span class="math inline">\(\sum^{\infty}_{k=1}l(I_k) = 2\epsilon n \implies |A| \leq 2\epsilon n\)</span>, since <span class="math inline">\(\epsilon &gt; 0\)</span> is an arbitrary positive number, this implies that <span class="math inline">\(|A| = 0\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.4-countable-sets-have-outer-measure-0">Theorem 2.4: Countable Sets Have Outer Measure <span class="math inline">\(0\)</span></h4>
<p>Every countable subset of <span class="math inline">\(\mathbb{R}\)</span> has outer measure <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.5-outer-measure-preserves-order">Theorem 2.5: Outer Measure Preserves Order</h4>
<p>Suppose <span class="math inline">\(A, B\)</span> are subsets of <span class="math inline">\(\mathbb{R}\)</span> with <span class="math inline">\(A \subseteq B\)</span>. Then <span class="math inline">\(|A| \leq |B|\)</span>.</p>
<p><br></p>
<h4 id="definition-2.6-translation-t-a">Definition 2.6: Translation, <span class="math inline">\(t + A\)</span></h4>
<p>If <span class="math inline">\(t \in \mathbb{R}\)</span> and <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, then the <strong>translation</strong> <span class="math inline">\(t + A\)</span> is defined by:</p>
<p><span class="math display">\[t + A = \{t + a: a \in A\}\]</span></p>
<p>If <span class="math inline">\(t \in \mathbb{R}, a, b \in [-\infty, \infty]\)</span>, then <span class="math inline">\(t + (a, b) = (t + a, t + b)\)</span> and <span class="math inline">\(t + \infty = \infty\)</span> and <span class="math inline">\(t + -\infty = -\infty\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.7-outer-measure-is-translation-invariant">Theorem 2.7: Outer Measure is Translation Invariant</h4>
<p>Suppose <span class="math inline">\(t \in \mathbb{R}\)</span> and <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then <span class="math inline">\(|t + A| = |A|\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.8-countable-subadditivity-of-outer-measure">Theorem 2.8: Countable Subadditivity of Outer Measure</h4>
<p>Suppose <span class="math inline">\(A_1, A_2, ...\)</span> is a sequence of subsets of <span class="math inline">\(\mathbb{R}\)</span>. Then:</p>
<p><span class="math display">\[|\bigcup_{k=1}^{\infty} A_k| \leq \sum^{\infty}_{k=1} |A_k|\]</span></p>
<p>In other words:</p>
<p><span class="math display">\[|A_1 \cup A_2 \cup ... | \leq |A_1| + |A_2| + ... \]</span></p>
<h5 id="proof-of-theorem-2.8">Proof of Theorem 2.8</h5>
<p>Assume <span class="math inline">\(|A_k| &lt; \infty\)</span> for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span>. Let <span class="math inline">\(\epsilon &gt; 0\)</span> and for each <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, let <span class="math inline">\(I_{1, k}, I_{2, k}, ...\)</span> be a sequence of open intervals whose union contains <span class="math inline">\(A_k\)</span> s.t:</p>
<p><span class="math display">\[\sum^{\infty}_{j=1} l(I_{j, k}) \leq \frac{\epsilon}{2^k} + |A_k|\]</span></p>
<p>This makes sense because <span class="math inline">\(|A| = \inf\{\sum^{\infty}_{j=1} l(I_{j, k})\}\)</span> and <span class="math inline">\(|A| + \epsilon \geq \inf\{\sum^{\infty}_{j=1} l(I_{j, k})\}\)</span>.</p>
<p>Sum both side over <span class="math inline">\(k\)</span>, we have:</p>
<p><span class="math display">\[\sum^{\infty}_{k=1}\sum^{\infty}_{j=1} l(I_{j, k}) \leq \epsilon + \sum^{\infty}_{k=1}|A_k|\]</span></p>
<p>The union of left hand side open intervals is the set $A_1 A_2 ... $, Thus, we have:</p>
<p><span class="math display">\[|A_1 \cup A_2 \cup ... | \leq \sum^{\infty}_{k=1}\sum^{\infty}_{j=1} l(I_{j, k}) \leq \epsilon + \sum^{\infty}_{k=1}|A_k|\]</span></p>
<p>Since <span class="math inline">\(\epsilon\)</span> is any positive real number, we have desired result.</p>
<p><br></p>
<h4 id="definition-2.10-open-cover-finite-subcover">Definition 2.10: Open Cover, Finite Subcover</h4>
<p>Suppose <span class="math inline">\(A \subseteq \mathbb{R}\)</span>:</p>
<ul>
<li>A collection <span class="math inline">\(C\)</span> of open subsets of <span class="math inline">\(\mathbb{R}\)</span> is called an <strong>open cover</strong> of <span class="math inline">\(A\)</span> if <span class="math inline">\(A\)</span> is contained in the union of all the sets in <span class="math inline">\(C\)</span>.</li>
<li>An open cover <span class="math inline">\(C\)</span> of <span class="math inline">\(A\)</span> is said to have a <strong>finite subcover</strong> if <span class="math inline">\(A\)</span> is contained in the union of some finite list of sets in <span class="math inline">\(C\)</span>.</li>
</ul>
<blockquote>
<h4 id="example-2.11">Example 2.11</h4>
<p>The collection <span class="math inline">\(\{(k, k+2): k \in \mathbb{Z}^+\}\)</span> is an open cover of <span class="math inline">\([2, 5]\)</span> because <span class="math inline">\([2, 5] \subseteq \bigcup^{\infty}_{k=1} (k, k+2)\)</span>. This open cover has finite subcover because <span class="math inline">\([2, 5] \subseteq (1, 3) \cup (2, 4) \cup (3, 5) \cup (4, 6)\)</span>.</p>
<p>The collection above is an open cover of <span class="math inline">\([2, \infty)\)</span> but does not have a finite subcover.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.12-heine-borel-theorem">Theorem 2.12: Heine-Borel Theorem</h4>
<p>Every open cover of a closed bounded subset of <span class="math inline">\(\mathbb{R}\)</span> has a finite subcover.</p>
<p><br></p>
<h4 id="theorem-2.14-outer-measure-of-a-closed-interval">Theorem 2.14: Outer Measure of a Closed Interval</h4>
<p>Suppose <span class="math inline">\(a, b \in \mathbb{R}\)</span> with <span class="math inline">\(a &lt; b\)</span>. Then <span class="math inline">\(|[a, b]| = b - a\)</span></p>
<p><br></p>
<h4 id="theorem-2.17-nontrivial-intervals-are-uncountable">Theorem 2.17: Nontrivial Intervals are Uncountable</h4>
<p>Every interval in <span class="math inline">\(\mathbb{R}\)</span> that contains at least two distinct elements is uncountable.</p>
<h5 id="proof-of-theorem-2.17">Proof of Theorem 2.17:</h5>
<p>Suppose <span class="math inline">\(I\)</span> is an interval that contains <span class="math inline">\(a, b \in \mathbb{R}\)</span> and <span class="math inline">\(b &gt; a\)</span>, then <span class="math inline">\([a, b] \subseteq I\)</span>, then by <code>theorem 2.5</code>, we have:</p>
<p><span class="math display">\[|I| \geq |[a, b]|\]</span></p>
<p>and</p>
<p><span class="math display">\[|[a, b]| = b - a &gt; 0\]</span></p>
<p><br></p>
<h4 id="theorem-2.18-nonadditivity-of-outer-measure">Theorem 2.18: Nonadditivity of Outer Measure</h4>
<p>There exist disjoint subsets <span class="math inline">\(A, B\)</span> of <span class="math inline">\(\mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[|A \cup B| \neq |A| + |B|\]</span></p>
<p><br></p>
<h3 id="measurable-spaces-and-functions">Measurable Spaces and Functions</h3>
<h4 id="theorem-2.22-nonexistence-of-extension-of-length-to-all-subsets-of-mathbbr">Theorem 2.22: Nonexistence of Extension of Length to All Subsets of <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>There does not exists a function <span class="math inline">\(\mu\)</span> with all the following properties:</p>
<ol type="a">
<li><span class="math inline">\(\mu\)</span> is a function from the set of subsets of <span class="math inline">\(\mathbb{R}\)</span> to <span class="math inline">\([0, \infty]\)</span>.</li>
<li><span class="math inline">\(\mu(I) = l(I)\)</span> for every open interval <span class="math inline">\(I\)</span> of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\mu (\sum^{\infty}_{k=1} A_k) = \sum^{\infty}_{k=1} \mu(A_k)\)</span> for every disjoint sequence <span class="math inline">\(A_1, A_2, ...\)</span> of subsets of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\mu(t + A) = \mu(A)\)</span> for every <span class="math inline">\(A \subseteq \mathbb{R}\)</span> and every <span class="math inline">\(t \in \mathbb{R}\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-2.23-sigma-algebra">Definition 2.23: <span class="math inline">\(\sigma\)</span>-algebra</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(S\)</span> is a set of subsets of <span class="math inline">\(X\)</span>. Then <span class="math inline">\(S\)</span> is called a <strong><span class="math inline">\(\sigma\)</span>-algebra</strong> on <span class="math inline">\(X\)</span> if the following three conditions are satisfied:</p>
<ul>
<li><span class="math inline">\(\emptyset \in S\)</span>.</li>
<li>If <span class="math inline">\(E \in S\)</span>, then <span class="math inline">\(X / E \in S\)</span>.</li>
<li>If <span class="math inline">\(E_1, E_2, ...\)</span> is a sequence of elements of <span class="math inline">\(S\)</span>, then <span class="math inline">\(\bigcup^{\infty}_{k=1} E_k \in S\)</span>.</li>
</ul>
<blockquote>
<p>{, X} is <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>. The set of all subsets of <span class="math inline">\(X\)</span> is <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.25-sigma-algebras-are-closed-under-countable-intersection">Theorem 2.25: <span class="math inline">\(\sigma\)</span>-algebras are Closed Under Countable Intersection</h4>
<p>Suppose <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on a set <span class="math inline">\(X\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(X \in S\)</span>.</li>
<li>If <span class="math inline">\(D, E \in S\)</span>, then <span class="math inline">\(D \cup E \in S\)</span> and <span class="math inline">\(D \cap E \in S\)</span> and <span class="math inline">\(D / E \in S\)</span>.</li>
<li>If <span class="math inline">\(E_1, E_2, ....\)</span> is a sequence of elemnts of <span class="math inline">\(S\)</span>, then <span class="math inline">\(\bigcap^{\infty}_{k=1} E_k \in S\)</span>.</li>
</ol>
<p><br></p>
<h4 id="definition-2.26-measurable-space-measurable-set">Definition 2.26: Measurable Space, Measurable Set</h4>
<ul>
<li>A <strong>measurable space</strong> is an ordered pair <span class="math inline">\((X, S)\)</span>, where <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra on <span class="math inline">\(X\)</span>.</li>
<li>An element of <span class="math inline">\(S\)</span> is called an <strong><span class="math inline">\(S\)</span>-measurable set</strong> or just a <strong>measurable set</strong> if <span class="math inline">\(S\)</span> is clear from the context.</li>
</ul>
<blockquote>
<p><span class="math inline">\(X = \mathbb{R}\)</span> and <span class="math inline">\(S\)</span> is the set of all subsets of <span class="math inline">\(\mathbb{R}\)</span> that are countable or have a countable complement, then the ordered pair <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(\mathbb{Q} \in S\)</span> is <span class="math inline">\(S\)</span>-measurable set.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.27-smallest-sigma-algebra-containing-a-collection-of-subsets">Theorem 2.27: Smallest <span class="math inline">\(\sigma\)</span>-algebra Containing a Collection of Subsets</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(A\)</span> is a set of subsets of <span class="math inline">\(X\)</span>. Then the intersection of all <span class="math inline">\(\sigma-\)</span>algebras on <span class="math inline">\(X\)</span> that contain <span class="math inline">\(A\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra on <span class="math inline">\(X\)</span>.</p>
<p>Using the <strong>smallest</strong> for the intersection of all <span class="math inline">\(\sigma\)</span>-algebras that contain as set <span class="math inline">\(A\)</span> of subset of <span class="math inline">\(X\)</span> makes sense, because the smallest <span class="math inline">\(\sigma\)</span>-algebra will be one of those <span class="math inline">\(\sigma\)</span>-algebra that contains <span class="math inline">\(A\)</span>. If <span class="math inline">\(A\)</span> is already <span class="math inline">\(\sigma\)</span>-algebra, then the interaction is just <span class="math inline">\(A\)</span>.</p>
<p><br></p>
<h4 id="definition-2.29-borel-set">Definition 2.29: Borel Set</h4>
<p>The smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> containing all open subsets of <span class="math inline">\(\mathbb{R}\)</span> is called <strong>the collection of Borel subsets</strong> of <span class="math inline">\(\mathbb{R}\)</span>. An element of this <span class="math inline">\(\sigma-algebra\)</span> is called a <strong>Borel set</strong>.</p>
<p>We can also define the collection of Borel subsets to be the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> containing all the <strong>open intervals</strong>. Because every open subset of <span class="math inline">\(\mathbb{R}\)</span> is the union of a sequence of open intervals.</p>
<p><strong>The set contains every open sets, closed sets, countable union, intersection of open, closed sets. There exists subsets of <span class="math inline">\(\mathbb{R}\)</span> that are not Borel sets, but any subset of <span class="math inline">\(\mathbb{R}\)</span> that you can write down in a concrete fashion is a Borel set.</strong></p>
<p><br></p>
<h4 id="definition-2.31-inverse-image-f-1-a">Definition 2.31: Inverse Image: <span class="math inline">\(f^{-1} (A)\)</span></h4>
<p>If <span class="math inline">\(f: X \rightarrow Y\)</span> is a function and <span class="math inline">\(A \subseteq Y\)</span>, then the set <span class="math inline">\(f^{-1} (A)\)</span> is defined by:</p>
<p><span class="math display">\[f^{-1} (A) = \{x \in X: f(x) \in A\}\]</span></p>
<p><br></p>
<h4 id="theorem-2.33-algebra-of-inverse-images">Theorem 2.33: Algebra of Inverse Images</h4>
<p>Suppose <span class="math inline">\(f: X \rightarrow Y\)</span> is a function. Then:</p>
<ol type="a">
<li><span class="math inline">\(f^{-1} (Y / A) = X / f^{-1}(A), \; \forall A \subseteq Y\)</span></li>
<li><span class="math inline">\(f^{-1} (\bigcap_{A \in \mathbf{A}} A) = \bigcap_{A \in \mathbb{A}} f^{-1}(A)\)</span>, for every set <span class="math inline">\(\mathbf{A}\)</span> of subsets of <span class="math inline">\(Y\)</span>.</li>
<li><span class="math inline">\(f^{-1} (\bigcup_{A \in \mathbf{A}} A) = \bigcup_{A \in \mathbb{A}} f^{-1}(A)\)</span>, for every set <span class="math inline">\(\mathbf{A}\)</span> of subsets of <span class="math inline">\(Y\)</span>.</li>
</ol>
<p>In other words, the inverse image of union or intersection of any subsets of <span class="math inline">\(Y\)</span>, is the same as the union or intersection of inverse image of these subsets of <span class="math inline">\(Y\)</span>.</p>
<h5 id="proof-of-theorem-2.33">Proof of Theorem 2.33:</h5>
<p>Suppose <span class="math inline">\(A \subseteq Y\)</span>. For <span class="math inline">\(x \in X\)</span>, we have:</p>
<p><span class="math display">\[x \in f^{-1} (Y / A) \Longleftrightarrow  f(x) \in Y / A \Longleftrightarrow f(x) \notin A \Longleftrightarrow x \notin f^{-1}(A) \implies x \in X / f^{-1}(A) \]</span></p>
<p>Let <span class="math inline">\(\mathbf{A}\)</span> be a set of subsets of <span class="math inline">\(Y\)</span>, then:</p>
<p><span class="math display">\[x \in f^{-1} (\bigcap_{A \in \mathbf{A}} A) \Longleftrightarrow f(x) \in \bigcap_{A \in \mathbf{A}} A\]</span></p>
<p>This implies that <span class="math inline">\(f(x)\)</span> is in every subset <span class="math inline">\(A \in \mathbf{A}\)</span>, thus, we have:</p>
<p><span class="math display">\[x \in f^{-1}(A) \; \forall A \in \mathbf{A} \implies x \in \bigcap_{A \in \mathbf{A}} f^{-1}(A)\]</span></p>
<p>The proof is similar for union.</p>
<p><br></p>
<h4 id="theorem-2.34-inverse-image-of-a-composition">Theorem 2.34: Inverse Image of a Composition</h4>
<p>Suppose <span class="math inline">\(f: X \rightarrow Y\)</span> and <span class="math inline">\(g: Y \rightarrow W\)</span> are functions. Then:</p>
<p><span class="math display">\[(g \circ f)^{-1} (A) = f^{-1} (g^{-1} (A))\]</span></p>
<p>for every <span class="math inline">\(A \subseteq W\)</span></p>
<h5 id="proof-of-theorem-2.34">Proof of Theorem 2.34:</h5>
<p>Suppose <span class="math inline">\(A \subseteq W\)</span>, <span class="math inline">\(x \in X\)</span>, then we have:</p>
<p><span class="math inline">\(x \in (g \circ f)^{-1} (A) \Longleftrightarrow g \circ f (x) \in A \Longleftrightarrow g(f(x)) \in A \Longleftrightarrow f(x) \in g^{-1} (A) \Longleftrightarrow x \in f^{-1}(g^{-1} (A))\)</span></p>
<p><br></p>
<h4 id="definition-2.35-measurable-function">Definition 2.35: Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space. A function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is called <strong><span class="math inline">\(S\)</span>-measurable</strong> (or just <strong>measurable</strong> if <span class="math inline">\(S\)</span> is clear from the context)</p>
<p>if:</p>
<p><span class="math display">\[f^{-1}(B) \in S\]</span></p>
<p>for every Borel set <span class="math inline">\(B \in \mathbb{R}\)</span>.</p>
<blockquote>
<h5 id="example-2.36-measurable-functions">Example 2.36: Measurable Functions</h5>
<p>If <span class="math inline">\(S = \{\emptyset, X\}\)</span>, then the only <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X\)</span> to <span class="math inline">\(\mathbb{R}\)</span> are the constant functions, because otherwise each <span class="math inline">\(x \in X\)</span> will have multiple <span class="math inline">\(f(x)\)</span>, which will violate the definition of function.</p>
<p>If <span class="math inline">\(S\)</span> is the set of all subsets of <span class="math inline">\(X\)</span>, then every function from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> is <span class="math inline">\(S\)</span>-measurable.</p>
<p>If <span class="math inline">\(S = \{\emptyset, (-\infty, 0), [0, \infty), \mathbb{R}\}\)</span>, then a function <span class="math inline">\(f:\mathbb{R} \rightarrow \mathbb{R}\)</span> is <span class="math inline">\(S\)</span>-measurable IFF <span class="math inline">\(f\)</span> is constant on <span class="math inline">\((-\infty, 0)\)</span> and <span class="math inline">\(f\)</span> is constant on <span class="math inline">\([0, \infty)\)</span>.</p>
</blockquote>
<p><br></p>
<h4 id="definition-2.37-characteristic-function-chi_e">Definition 2.37: Characteristic Function; <span class="math inline">\(\chi_E\)</span></h4>
<p>Suppose <span class="math inline">\(E\)</span> is a subset of a set <span class="math inline">\(X\)</span>. The <strong>characteristic function</strong> of <span class="math inline">\(E\)</span> is the function <span class="math inline">\(\chi_E: X \rightarrow \mathbb{R}\)</span> defined by:</p>
<p><span class="math display">\[
\chi_E (x) =
\begin{cases}
1, \quad \text{if} \; x \in E\\
0, \quad \text{if} \; x \notin E
\end{cases}
\]</span></p>
<p><br></p>
<h4 id="theorem-2.39-condition-for-measurable-function">Theorem 2.39: Condition for Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is a function such that:</p>
<p><span class="math display">\[f^{-1} ((a, \infty)) \in S\]</span></p>
<p>for all <span class="math inline">\(a \in \mathbb{R}\)</span>. Then <span class="math inline">\(f\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p>Where:</p>
<p><span class="math display">\[f^{-1}((a, \infty)) = \{x \in X: f(x) &gt; a\}\]</span></p>
<p><strong>We can replace the collection of sets <span class="math inline">\(\{(a, \infty): a\in \mathbb{R}\}\)</span> by any collection of subsets of <span class="math inline">\(\mathbb{R}\)</span> s.t the smallest <span class="math inline">\(\sigma\)</span>-algebra containing that collection contains the Borel subset of <span class="math inline">\(\mathbb{R}\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-2.40-borel-measurable-function">Definition 2.40: Borel Measurable Function</h4>
<p>Suppose <span class="math inline">\(X \subseteq \mathbb{R}\)</span>. A function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is called <strong>Borel Measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Borel set for every Borel set <span class="math inline">\(B \subseteq \mathbb{R}\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> is a Borel subset of <span class="math inline">\(\mathbb{R}\)</span>, then <span class="math inline">\(S\)</span> might be the set of Borel sets contained in <span class="math inline">\(X\)</span>, in which case the phrase Borel Measurable is the same as <span class="math inline">\(S\)</span>-measuable.</p>
<p><strong>If <span class="math inline">\(X \subseteq \mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> is Borel measurable implies that <span class="math inline">\(X\)</span> is a borel set.</strong></p>
<p><strong>If <span class="math inline">\(X \subseteq \mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> is Borel measurable IFF <span class="math inline">\(f^{-1}((a, \infty))\)</span> is a borel set for all <span class="math inline">\(a \in \mathbb{R}\)</span>. Most of the proofs of Borel measurable function involves this result.</strong></p>
<p><br></p>
<h4 id="definition-2.41-every-continuous-function-is-borel-measurable">Definition 2.41: Every Continuous Function is Borel Measurable</h4>
<p>Every continuous real-valued function defined on a Borel subset of <span class="math inline">\(\mathbb{R}\)</span> is a Borel measurable function.</p>
<p><br></p>
<h4 id="definition-2.42-increasing-function-strictly-increasing">Definition 2.42: Increasing Function; Strictly Increasing</h4>
<p>Suppose <span class="math inline">\(X \subseteq \mathbb{R}\)</span> and <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is a function:</p>
<ul>
<li><span class="math inline">\(f\)</span> is called <strong>increasing</strong> if <span class="math inline">\(f(x) \leq f(y)\)</span> for all <span class="math inline">\(x, y \in X\)</span> with <span class="math inline">\(x &lt; y\)</span>.</li>
<li><span class="math inline">\(f\)</span> is called <strong>strictly increasing</strong> if <span class="math inline">\(f(x) &lt; f(y)\)</span>, for all <span class="math inline">\(x, y \in X\)</span> with <span class="math inline">\(x &lt; y\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-2.43-every-increasing-function-is-borel-measurable">Theorem 2.43: Every Increasing Function is Borel Measurable</h4>
<p>Every increasing function defined on a Borel subset is Borel measurable.</p>
<p><strong>similar results for decreasing function</strong>.</p>
<h5 id="proof-of-theorem-2.43">Proof of Theorem 2.43:</h5>
<p>Let <span class="math inline">\(X \subseteq \mathbb{R}\)</span> be a borel set, let <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> be an increasing function. Then:</p>
<p>Let <span class="math inline">\(b = \inf f^{-1}((a, \infty))\)</span>. So we can write it as:</p>
<p><span class="math display">\[f^{-1}((a, \infty)) = [b, \infty) \cap X\]</span></p>
<p>Thus, we have <span class="math inline">\(f^{-1}((a, \infty))\)</span> is a borel set which implies that <span class="math inline">\(f\)</span> is borel measurable.</p>
<p><br></p>
<h4 id="theorem-2.44-composition-of-measurable-functions">Theorem 2.44: Composition of Measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> is an <span class="math inline">\(S\)</span>-measurable function. Suppose <span class="math inline">\(g\)</span> is a real-valued Borel measurable function defined on a subset of <span class="math inline">\(\mathbb{R}\)</span> that includes the range of <span class="math inline">\(f\)</span>. Then <span class="math inline">\(g \circ f: X \rightarrow \mathbb{R}\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<blockquote>
<h5 id="example-2.45">Example 2.45</h5>
<p>If <span class="math inline">\(f\)</span> is measurable, then so are <span class="math inline">\(-f, |f|, f^2\)</span>.</p>
<p>Since <span class="math inline">\(g(x) = -x\)</span>, <span class="math inline">\(g(x) = |x|\)</span>, <span class="math inline">\(g(x) = x^2\)</span> are all continuous functions defined on <span class="math inline">\(\mathbb{R}\)</span>, which is a borel subset of <span class="math inline">\(\mathbb{R}\)</span>, so <span class="math inline">\(g(f(x))\)</span> is measurable.</p>
</blockquote>
<h4 id="theorem-2.46-algebraic-operations-with-measurable-functions">Theorem 2.46: Algebraic Operations with Measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f, g: X \rightarrow \mathbb{R}\)</span> are <span class="math inline">\(S\)</span>-measurable. Then:</p>
<ol type="a">
<li><span class="math inline">\(f + g\)</span>, <span class="math inline">\(f - g\)</span>, and <span class="math inline">\(fg\)</span> are <span class="math inline">\(S-measurable\)</span> functions.</li>
<li>If <span class="math inline">\(g(x) \neq 0\)</span> for all <span class="math inline">\(x \in X\)</span>, then <span class="math inline">\(\frac{f}{g}\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</li>
</ol>
<p><br></p>
<h4 id="theorem-2.48-limit-of-s-measurable-functions">Theorem 2.48: Limit of <span class="math inline">\(S\)</span>-Measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>. Suppose <span class="math inline">\(\lim_{k \rightarrow \infty} f_k (x)\)</span> exists for each <span class="math inline">\(x \in X\)</span>. Define <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span> by:</p>
<p><span class="math display">\[f(x) = \lim_{k \rightarrow \infty} f_k (x)\]</span></p>
<p>Then, <span class="math inline">\(f\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p><br></p>
<h4 id="definition-2.50-borel-subsets-of--infty-infty-extended-definition-of-borel-subset-to-mathbbr-cup--infty-infty">Definition 2.50: Borel Subsets of <span class="math inline">\([-\infty, \infty]\)</span> (Extended definition of borel subset to <span class="math inline">\(\mathbb{R} \cup \{-\infty, \infty\}\)</span>)</h4>
<p>A subset of <span class="math inline">\([-\infty, \infty]\)</span> is called a <strong>Borel set</strong> if its intersection with <span class="math inline">\(\mathbb{R}\)</span> is a Borel Set.</p>
<blockquote>
<p><span class="math inline">\([-\infty, \infty]\)</span> is a borel set because <span class="math inline">\([-\infty, \infty] \cap \mathbb{R} = \mathbb{R}\)</span> is a borel set.</p>
</blockquote>
<p><br></p>
<h4 id="definition-2.51-measurable-function">Definition 2.51: Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space. A function <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is called <span class="math inline">\(S\)</span>-measurable if:</p>
<p><span class="math display">\[f^{-1}(B) \in S\]</span></p>
<p><br></p>
<h4 id="theorem-2.52-condition-for-measurable-function">Theorem 2.52: Condition for Measurable Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is a function s.t:</p>
<p><span class="math display">\[f^{-1} ((a, \infty]) \in S\]</span></p>
<p>for all <span class="math inline">\(a \in \mathbb{R}\)</span>. Then <span class="math inline">\(f\)</span> is an <span class="math inline">\(S\)</span>-measurable function.</p>
<p><br></p>
<h4 id="theorem-2.53-infimum-and-supremum-of-a-sequence-of-s-measurable-functions">Theorem 2.53: Infimum and Supremum of a Sequence of <span class="math inline">\(S\)</span>-measurable Functions</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X\)</span> to <span class="math inline">\([-\infty, \infty]\)</span>. Define <span class="math inline">\(g, h: X \rightarrow [-\infty, \infty]\)</span>. Define <span class="math inline">\(g, h: X \rightarrow [-\infty, \infty]\)</span> by:</p>
<p><span class="math display">\[g(x) = \inf\{f_k (x): k \in \mathbb{Z}^+\}\]</span></p>
<p>and</p>
<p><span class="math display">\[h(x) = \sup\{f_k (x): k \in \mathbb{Z}^+\}\]</span></p>
<p>Then <span class="math inline">\(g, h\)</span> are <span class="math inline">\(S\)</span>-measurable functions.</p>
<h5 id="proof-of-theorem-2.53">Proof of Theorem 2.53:</h5>
<p>Suppose <span class="math inline">\(a \in \mathbb{R}\)</span>, The definition of the supremum implies that:</p>
<p><span class="math display">\[h^{-1} ((a, \infty]) = \{x; h(x) &gt; a\}\]</span></p>
<p>Since,</p>
<p><span class="math display">\[\{x; h(x) &gt; a\} \subseteq \bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\}\]</span></p>
<p>On the other hand, for all <span class="math inline">\(x \in \bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\}\)</span>, we have <span class="math inline">\(\sup_k f_k (x) &gt; a\)</span>, thus:</p>
<p><span class="math display">\[\bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\}\subseteq \{x; h(x) &gt; a\} \]</span></p>
<p>This implies that:</p>
<p><span class="math display">\[h^{-1} ((a, \infty]) = \{x; h(x) &gt; a\} = \bigcup_{k=1}^{\infty} \{x; f_k(x) &gt; a\} = \bigcup_{k=1}^{\infty} f^{-1}_k ((a, \infty])\]</span></p>
<p>Since <span class="math inline">\(f^{-1}_k ((a, \infty]) \in S\)</span> by assumption, we have:</p>
<p><span class="math display">\[h^{-1} ((a, \infty]) \in S\]</span></p>
<p>Note that:</p>
<p><span class="math display">\[g(x) = - \sup\{-f_k (x): k \in \mathbb{Z}^+\}\]</span></p>
<p>for all <span class="math inline">\(x \in X\)</span>. The result about supremum implies that <span class="math inline">\(g\)</span> is <span class="math inline">\(S\)</span>-measurable.</p>
<p><br></p>
<h3 id="measures-and-their-properties">Measures and Their Properties</h3>
<p>The word <strong>measure</strong> allows us to use a single word instead of repeating theorems for length, area and volume.</p>
<h4 id="definition-2.54-measure">Definition 2.54: Measure</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set and <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>. A <strong>measure</strong> on <span class="math inline">\((X, S)\)</span> is a function <span class="math inline">\(\mu: S \rightarrow [0, \infty]\)</span> s.t <span class="math inline">\(\mu(\emptyset) = 0\)</span> and:</p>
<p><span class="math display">\[\mu(\bigcup_{k=1}^{\infty} E_k) = \sum^{\infty}_{k=1} \mu(E_k)\]</span></p>
<p>for every disjoint sequence <span class="math inline">\(E_1, E_2, ...\)</span> of sets in <span class="math inline">\(S\)</span>.</p>
<p>Notice that countable additivity implies finite additivity by constructing disjoint sequence <span class="math inline">\(E_1, E_2, ..., E_n, \emptyset, \emptyset, ...\)</span></p>
<p><br></p>
<h4 id="definition-2.56-measure-space">Definition 2.56: Measure Space</h4>
<p>A <strong>measure space</strong> is an ordered triple <span class="math inline">\((X, S, \mu)\)</span>, where <span class="math inline">\(X\)</span> is a set, <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(X\)</span>, and <span class="math inline">\(\mu\)</span> is a measure on <span class="math inline">\((X, S)\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.57-measure-preserves-order-measure-of-a-set-difference">Theorem 2.57: Measure Preserves Order; Measure of a Set Difference</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(D, E \in S\)</span> are such that <span class="math inline">\(D \subseteq E\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(\mu(D) \leq \mu(E)\)</span></li>
<li><span class="math inline">\(\mu(E / D) = \mu(E) - \mu(D)\)</span> provided that <span class="math inline">\(\mu(D) &lt; \infty\)</span></li>
</ol>
<h5 id="proof-of-theorem-2.57">Proof of Theorem 2.57:</h5>
<p>Suppose <span class="math inline">\(D \subseteq E\)</span>, then <span class="math inline">\(E = D \cup (E / D)\)</span> and these two sets are disjoint, that is:</p>
<p><span class="math display">\[\mu(E) = \mu(D \cup (E / D)) = \mu(D) + \mu(E / D) \geq \mu(D)\]</span></p>
<p>given that <span class="math inline">\(\mu(D) &lt; \infty\)</span> subtract both sides by <span class="math inline">\(\mu(D)\)</span>, we have b.</p>
<p><br></p>
<h4 id="theorem-2.58-countable-subadditivity">Theorem 2.58: Countable Subadditivity</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1, E_2, ... \in S\)</span>. Then:</p>
<p><span class="math display">\[\mu(\bigcup^{\infty}_{k=1} E_k) \leq \sum^{\infty}_{k=1}\mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-2.59-measure-of-an-increasing-union">Theorem 2.59: Measure of an Increasing Union</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1 \subseteq E_2 \subseteq ...\)</span> is an increasing sequence of sets in <span class="math inline">\(S\)</span>. Then:</p>
<p><span class="math display">\[\mu(\sum^\infty_{k=1} E_k) = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<h5 id="proof-theorem-2.59">Proof Theorem 2.59</h5>
<p>If <span class="math inline">\(\mu(E_k) = \infty\)</span> for some <span class="math inline">\(k \in \mathbb{Z}^+\)</span>, then the equation above holds because both sides equals <span class="math inline">\(\infty\)</span>:</p>
<p><span class="math display">\[\mu(\bigcup^{\infty}_{k=1} E_k) \geq \mu(E_k) = \infty = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<p>Thus, we consider only the case where <span class="math inline">\(\mu(E_k) &lt; \infty\)</span> for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span>.</p>
<p>Let <span class="math inline">\(E_0 = \emptyset\)</span>. Then:</p>
<p><span class="math display">\[\bigcup^{\infty}_{k=1} E_k = E_1 \cup (E_2 / E_1) \cup (E_3 / E_2) \cup ... = \bigcup^{\infty}_{j=1} E_{j} / E_{j-1}\]</span></p>
<p>And the union on the right hand side is disjoint, that is:</p>
<p><span class="math display">\[\mu(\bigcup^{\infty}_{j=1} E_{j} / E_{j-1}) = \sum^{\infty}_{j=1} \mu(E_{j} / E_{j-1}) = \lim_{k\rightarrow \infty} \sum^{k}_{j=1} \mu(E_{j} / E_{j-1})\]</span></p>
<p>Since <span class="math inline">\(E_{j-1} &lt; \infty\)</span>, we have:</p>
<p><span class="math display">\[\lim_{k\rightarrow \infty} \sum^{k}_{j=1} \mu(E_{j} / E_{j-1}) = \lim_{k\rightarrow \infty} \sum^{k}_{j=1} \mu(E_{j}) - \mu(E_{j-1}) = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-2.60-measure-of-a-decreasing-intersection">Theorem 2.60: Measure of a Decreasing Intersection</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(E_1 \supseteq E_2 \supseteq ...\)</span> is a decreasing sequence of sets in <span class="math inline">\(S\)</span>, with <span class="math inline">\(\mu(E_1) &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[\mu(\bigcap^{\infty}_{k=1}E_k) = \lim_{k\rightarrow \infty} \mu(E_k)\]</span></p>
<p><br></p>
<h4 id="theorem-2.61-measure-of-a-union">Theorem 2.61: Measure of a Union</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space and <span class="math inline">\(D, E \in S\)</span>, with <span class="math inline">\(\mu(D \cap E) &lt; \infty\)</span>. Then:</p>
<p><span class="math display">\[\mu(D \cup E) = \mu(D) + \mu(E) - \mu(D \cap E)\]</span></p>
<p><br></p>
<h3 id="lebesgue-measure">Lebesgue Measure</h3>
<p>The main goal of this section is to prove that outer measure when restrict to borel sets is a measure.</p>
<h4 id="theorem-2.62-additivity-of-outer-measure-if-one-of-the-sets-is-open">Theorem 2.62: Additivity of Outer Measure If One of the Sets is Open</h4>
<p>Suppose <span class="math inline">\(A, G\)</span> are disjoint subsets of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(G\)</span> is open. Then:</p>
<p><span class="math display">\[|A \cup G| = |A| + |G|\]</span></p>
<p><br></p>
<h4 id="theorem-2.63-additivity-of-outer-measure-iff-the-sets-is-closed">Theorem 2.63: Additivity of Outer Measure IFF the Sets is Closed</h4>
<p>Suppose <span class="math inline">\(A, F\)</span> are disjoint subsets of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(\mathbb{F}\)</span> is closed. Then:</p>
<p><span class="math display">\[|A \cup F| = |A| + |F|\]</span></p>
<p><br></p>
<h4 id="theorem-2.65-approximation-of-borel-sets-from-below-by-closed-sets">Theorem 2.65: Approximation of Borel Sets from Below by Closed Sets</h4>
<p>Suppose <span class="math inline">\(B \subseteq \mathbb{R}\)</span> is a Borel set. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq B\)</span> s.t <span class="math inline">\(|B / F| &lt; \epsilon\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.66-additivity-of-outer-measure-if-one-of-the-sets-is-a-borel-set">Theorem 2.66: Additivity of Outer Measure If One of the Sets is a Borel Set</h4>
<p>Suppose <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are disjoint subsets of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(B\)</span> is a Borel set. Then:</p>
<p><span class="math display">\[|A \cup B| = |A| + |B|\]</span></p>
<p><br></p>
<h4 id="theorem-2.67-existence-of-a-subset-of-mathbbr-that-is-not-a-borel-set">Theorem 2.67: Existence of a Subset of <span class="math inline">\(\mathbb{R}\)</span> that is not a Borel Set</h4>
<p>There exists a set <span class="math inline">\(B \subseteq \mathbb{R}\)</span> s.t <span class="math inline">\(|B| &lt; \infty\)</span> and <span class="math inline">\(B\)</span> is not a Borel set.</p>
<h5 id="proof-of-theorem-2.67">Proof of Theorem 2.67:</h5>
<p>From <code>Theorem 2.18</code>, we know that there exists disjoint set <span class="math inline">\(A, B \subseteq \mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[|A \cup B| \neq |A| + |B|\]</span></p>
<p>Then, according to <code>Theorem 2.66</code>, if all subsets of <span class="math inline">\(\mathbb{R}\)</span> are Borel sets, we would have violated <code>Theorem 2.18</code>.</p>
<p><br></p>
<h4 id="theorem-2.68-outer-measure-is-a-measure-on-borel-sets">Theorem 2.68: Outer Measure is a Measure on Borel Sets</h4>
<p>Outer measure is a measure on <span class="math inline">\((\mathbb{R}, \mathbb{B})\)</span>, where <span class="math inline">\(\mathbb{B}\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra of Borel subsets of <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p><br></p>
<h4 id="definition-2.69-lebesgue-measure-on-mathbbb">Definition 2.69: Lebesgue Measure (on <span class="math inline">\(\mathbb{B}\)</span>)</h4>
<p><strong>Lebesgue Measure</strong> is the measure on <span class="math inline">\((\mathbb{R}, \mathbb{B})\)</span>, where <span class="math inline">\(\mathbb{B}\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra of Borel subsets of <span class="math inline">\(\mathbb{R}\)</span>, that assigns to each Borel set its outer measure.</p>
<p>In other words, the <strong>Lebesgue measure</strong> of a set is the same as its outer measure except it should not be applied to arbitrary sets but only to Borel sets.</p>
<p><br></p>
<h3 id="lebesgue-measurable-sets">Lebesgue Measurable Sets</h3>
<h4 id="definition-2.70-lebesgue-meaurable-set">Definition 2.70: Lebesgue Meaurable Set</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is called <strong>Lebesgue measurable</strong> if there exists a Borel set <span class="math inline">\(B \subseteq A\)</span> s.t <span class="math inline">\(|A / B| = 0\)</span>.</p>
<p>This definition implies that all Borel set is Lebesgue measurable because if <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is a Borel set, then we can take <span class="math inline">\(B = A\)</span>. If <span class="math inline">\(A\)</span> is a set with outer measure <span class="math inline">\(0\)</span>, then <span class="math inline">\(A\)</span> is Lebesgue measurable because we can take <span class="math inline">\(B = \emptyset\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.71-equivalences-for-being-a-lebesgue-measurable-set">Theorem 2.71: Equivalences for Being a Lebesgue Measurable Set</h4>
<p>Suppose <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(A\)</span> is Lebesgue measurable.</li>
<li>For each <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq A\)</span> with <span class="math inline">\(|A / F| \leq \epsilon\)</span>.</li>
<li>There exists closed sets <span class="math inline">\(F_1, F_2, ...\)</span> contained in <span class="math inline">\(A\)</span> s.t <span class="math inline">\(|A / \bigcup^{\infty}_{k=1} F_k| = 0\)</span>.</li>
<li>There exists a Borel set <span class="math inline">\(B \subseteq A\)</span> s.t <span class="math inline">\(|A / B| = 0\)</span>.</li>
<li>For each <span class="math inline">\(\epsilon &gt; 0\)</span>. There exists an open set <span class="math inline">\(G \supseteq A\)</span> s.t <span class="math inline">\(|G / A| &lt; \epsilon\)</span>.</li>
<li>There exists open sets <span class="math inline">\(G_1, G_2, ...\)</span> containing <span class="math inline">\(A\)</span> s.t <span class="math inline">\(|(\bigcap^{\infty}_{k=1})G_k / A| = 0\)</span>.</li>
<li>There exists a Borel set <span class="math inline">\(B \subseteq A\)</span> s.t <span class="math inline">\(|B / A| = 0\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-2.72-outer-measure-is-a-measure-on-lebesgue-measurable-sets">Theorem 2.72: Outer Measure is a Measure on Lebesgue Measurable Sets</h4>
<ol type="a">
<li>The set <span class="math inline">\(L\)</span> of Lebesgue measurable subsets of <span class="math inline">\(\mathbb{R}\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>Outer measure is a measure on <span class="math inline">\((\mathbb{R}, L)\)</span>.</li>
</ol>
<p>b implies that there are sets in <span class="math inline">\(\mathbb{R}\)</span> that is not Lebesgue measurable.</p>
<h5 id="proof-of-theorem-2.72">Proof of Theorem 2.72:</h5>
<p>We know that from <code>theorem 2.71</code> that a and b are equivalent, that is, let <span class="math inline">\(L\)</span> be the set that contains all <span class="math inline">\(A\)</span> that satisfies b, we can show that <span class="math inline">\(L\)</span> is <span class="math inline">\(\sigma\)</span>-algebra.</p>
<p>To show b, let <span class="math inline">\(A_1, A_2, ... \in L\)</span> be a disjoint sequence of Lebesgue measurable sets, then by definition, we have Borel set <span class="math inline">\(B_k \subseteq A_k\)</span> s.t</p>
<p><span class="math display">\[|A_k / B_k| = 0\]</span></p>
<p>for all <span class="math inline">\(k\)</span>. Then, <span class="math inline">\(B_1, B_2, ..\)</span> is a sequence of disjoint Borel sets.</p>
<p>Then we have:</p>
<p><span class="math display">\[|\bigcup^{\infty}_{k=1} A_k| \geq |\bigcup^{\infty}_{k=1} B_k| = \sum^{\infty}_{k=1} |B_k|\]</span></p>
<p>Since <span class="math inline">\(|A_k| = |B_k \cup (A_k / B_k)| \leq |B_k| + |A_k / B_k| = |B_k|\)</span>, we have:</p>
<p><span class="math display">\[|\bigcup^{\infty}_{k=1} A_k| \geq \sum^{\infty}_{k=1} |B_k| \geq \sum^{\infty}_{k=1} |A_k|\]</span></p>
<p><br></p>
<h4 id="definition-2.73-lebesgue-measure-more-general-on-l">Definition 2.73: Lebesgue Measure (More general, on <span class="math inline">\(L\)</span>)</h4>
<p><strong>Lebesgue measure</strong> is the measure on <span class="math inline">\((\mathbb{R}, L)\)</span>, where <span class="math inline">\(L\)</span> is the <span class="math inline">\(\sigma\)</span>-algebra of Lebesgue measurable subsets of <span class="math inline">\(\mathbb{R}\)</span>, that assigns to each Lebesgue measurable set its outer measure.</p>
<p><strong>Every Lebesgue measurable set differs from a Borel set by a set with outer measure <span class="math inline">\(0\)</span>.</strong></p>
<p><strong>The two definitions differ only on the domain, which will be specified unless it is irrelevant.</strong></p>
<p><br></p>
<h4 id="definition-2.74-cantor-set">Definition 2.74: Cantor Set</h4>
<p>The <strong>Cantor set</strong> <span class="math inline">\(C\)</span> is <span class="math inline">\([0, 1] / (\bigcup^{\infty}_{n=1}) G_n\)</span>, where <span class="math inline">\(G_1 = (\frac{1}{3}, \frac{2}{3})\)</span> and <span class="math inline">\(G_n\)</span> for <span class="math inline">\(n &gt; 1\)</span> is the union of the middle-third open intervals in the intervals of <span class="math inline">\([0, 1] / \bigcup^{n-1}_{j=1}G_j\)</span>.</p>
<p>One way to envision the Cantor set <span class="math inline">\(C\)</span> is to start with the interval <span class="math inline">\([0, 1]\)</span> and then consdier the process that removes at each step the middle-third open intervals of all intervals left from the previous step.</p>
<p><br></p>
<h4 id="theorem-2.76-c-is-closed-has-measure-0-and-contains-no-nontrivial-intervals">Theorem 2.76: <span class="math inline">\(C\)</span> is Closed, has Measure <span class="math inline">\(0\)</span>, and Contains no nontrivial Intervals</h4>
<ol type="a">
<li>The Cantor set is a closed subset of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>The Cantor set has Lebesgue measure <span class="math inline">\(0\)</span>.</li>
<li>The Cantor set contains no interval with more than one element.</li>
</ol>
<p><br></p>
<h3 id="convergence-of-measurable-functions">Convergence of Measurable Functions</h3>
<h4 id="definition-2.82-pointwise-and-uniform-convergence">Definition 2.82: Pointwise and Uniform Convergence</h4>
<p>Suppose <span class="math inline">\(X\)</span> is a set, <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>, and <span class="math inline">\(f\)</span> is a function from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span>.</p>
<ul>
<li><p>The sequence <span class="math inline">\(f_1, f_2, ...\)</span> <strong>converges pointwise</strong> on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span>, if:</p>
<p><span class="math display">\[\lim_{k \rightarrow \infty} f_k (x) = f(x)\]</span></p>
<p>for each <span class="math inline">\(x \in X\)</span>. In other words, <span class="math inline">\(f_1, f_2, ...\)</span> converges pointwise on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span> if for each <span class="math inline">\(x \in X\)</span> and every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(n &gt; \mathbb{Z}^+\)</span> s.t <span class="math display">\[|f_k(x) - f(x)| &lt; \epsilon\]</span> for all integers <span class="math inline">\(k \geq n\)</span>.</p></li>
<li><p>The sequence <span class="math inline">\(f_1, f_2, ...\)</span> <strong>converges uniformly</strong> on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span> if for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(n \in \mathbb{Z}^+\)</span> s.t <span class="math inline">\(|f_k (x) - f(x)| &lt; \epsilon\)</span>, forall integers <span class="math inline">\(k \geq n\)</span> and for all <span class="math inline">\(x \in X\)</span>.</p></li>
</ul>
<p><br></p>
<h4 id="theorem-2.84-uniform-limit-of-continuous-function-is-continuous">Theorem 2.84: Uniform Limit of Continuous Function is Continuous</h4>
<p>Suppose <span class="math inline">\(B \subseteq \mathbb{R}\)</span> and <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of functions from <span class="math inline">\(B \rightarrow \mathbb{R}\)</span> that converges uniformly on <span class="math inline">\(B\)</span> to a function <span class="math inline">\(f: B \rightarrow \mathbb{R}\)</span>. Suppose <span class="math inline">\(b \in B\)</span> and <span class="math inline">\(f_k\)</span> is continuous at <span class="math inline">\(b\)</span> for each <span class="math inline">\(k \in \mathbb{Z}^+\)</span>. Then <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(b\)</span>.</p>
<p><br></p>
<h4 id="theorem-2.85-egorovs-theorem">Theorem 2.85: Egorov's Theorem</h4>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space with <span class="math inline">\(\mu(X) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> that converges pointwise on <span class="math inline">\(X\)</span> to a function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span>. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a set <span class="math inline">\(E \subseteq S\)</span> s.t <span class="math inline">\(\mu(X / E) &lt; \epsilon\)</span> and <span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(E\)</span>.</p>
<h5 id="proof-of-theorem-2.85">Proof of Theorem 2.85:</h5>
<p>Suppose <span class="math inline">\((X, S, \mu)\)</span> is a measure space with <span class="math inline">\(\mu(X) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_1, f_2, ...\)</span> is a sequence of <span class="math inline">\(S\)</span>-measurable functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> that converges pointwise on <span class="math inline">\(X\)</span> to a function <span class="math inline">\(f: X \rightarrow \mathbb{R}\)</span>.</p>
<p>We want to prove that:</p>
<ol type="1">
<li><span class="math inline">\(E = \bigcap^{\infty}_{n=1} A_{m_n, n} \in S\)</span>.</li>
<li><span class="math inline">\(\mu(X / E) &lt; \epsilon\)</span>.</li>
<li><span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(E\)</span>.</li>
</ol>
<p>Suppose <span class="math inline">\(\epsilon &gt; 0\)</span>, then for any <span class="math inline">\(n \in \mathbb{Z}^+\)</span>, the definition of pointwise convergence implies that for some <span class="math inline">\(k\)</span> for some <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[|f_k (x) - f(x)| &lt; \frac{1}{n}\]</span></p>
<p>then:</p>
<p><span class="math display">\[\bigcap^{\infty}_{k=1}\{x \in X: |f_k (x) - f(x)| &lt; \frac{1}{n}\} = X\]</span></p>
<p><span class="math display">\[\bigcup^{\infty}_{m=1}\bigcap^{\infty}_{k=m}\{x \in X: |f_k (x) - f(x)| &lt; \frac{1}{n}\} = X\]</span></p>
<p>For <span class="math inline">\(m \in \mathbb{Z}^+\)</span>, let:</p>
<p><span class="math display">\[A_{m, n} = \bigcap^{\infty}_{k=m}\{x \in X: |f_k (x) - f(x)| &lt; \frac{1}{n}\}\]</span></p>
<p>Since <span class="math inline">\(f_1, f_2, ...\)</span> is <span class="math inline">\(S\)</span>-measurable, by <code>theorem 2.48</code>, <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable, by <code>theorem 2.46</code> <span class="math inline">\(f_k - f\)</span> is <span class="math inline">\(S\)</span>-measurable, this implies that:</p>
<p><span class="math display">\[(f_k - f)^{-1} ((-\frac{1}{n}, \frac{1}{n})) \in S\]</span></p>
<p>So <span class="math inline">\(A_{m, n} \in S\)</span> <strong>which proves 1.</strong></p>
<p>We can clearly see that <span class="math inline">\(A_{1, n} \subseteq A_{2, n} \subseteq ...\)</span> is an increasing sequence of sets, and by <code>theorem 2.59</code>:</p>
<p><span class="math display">\[\lim_{m \rightarrow \infty} \mu(\bigcup^{\infty}_{m=1} A_{m, n}) = \mu(X)\]</span></p>
<p>Thus, by sequence convergence theorem, there exists <span class="math inline">\(m_n \in \mathbb{Z}^+\)</span> s.t:</p>
<p><span class="math display">\[\mu(X) - \mu(A_{m_n, n}) &lt; \frac{\epsilon}{2^n}\]</span></p>
<p>Let <span class="math inline">\(E = \bigcap^{\infty}_{n=1} A_{m_n, n}\)</span>, then:</p>
<p><span class="math display">\[\mu(X / E) = \mu(X /  \bigcap^{\infty}_{n=1} A_{m_n, n}) = \mu(\bigcup^{\infty}_{n=1}(X / A_{m_n, n})) \leq \sum^{\infty}_{n=1}\mu(X / A_{m_n, n}) = \sum^{\infty}_{n=1}\mu(X) - \mu(A_{m_n, n})\]</span></p>
<p>Since <span class="math inline">\(\sum^{\infty}_{n=1} \epsilon (\frac{1}{2})^n = (\sum^{\infty}_{n=0} \epsilon (\frac{1}{2})^n) - \epsilon = \epsilon\)</span>, we have:</p>
<p><span class="math display">\[\mu(X / E) &lt; \epsilon\]</span></p>
<p><strong>which proves 2.</strong></p>
<p>Now, suppose <span class="math inline">\(\epsilon^\prime &gt; 0\)</span> and let <span class="math inline">\(n\)</span> be such that <span class="math inline">\(\frac{1}{n} &lt; \epsilon^\prime\)</span>. Then <span class="math inline">\(E \subseteq A_{m_n, n}\)</span>, which implies that:</p>
<p><span class="math display">\[|f_k (x) - f(x)| &lt; \frac{1}{n} &lt; \epsilon^\prime\]</span></p>
<p>for all <span class="math inline">\(k \geq m_n\)</span> and <span class="math inline">\(x \in E\)</span>, thus, <strong>we have proved 3.</strong></p>
<p><br></p>
<h4 id="definition-2.88-simple-function">Definition 2.88: Simple Function</h4>
<p>A function is called <strong>simple</strong> if it takes only finite many values.</p>
<p>Let <span class="math inline">\(f = c_1\chi_{E_1} + .... + c_n \chi_{E_n}\)</span>, where <span class="math inline">\(E_k = f^{-1}(\{c_k\})\)</span>, then <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable IFF <span class="math inline">\(E_1, ..., E_n \in S\)</span></p>
<p>The representation of the simple function <span class="math inline">\(f\)</span> is not unique. By requiring <span class="math inline">\(c_1, ..., c_n\)</span> to be distinct and <span class="math inline">\(E_1, ...., E_n\)</span> to be nonempty and disjoint with <span class="math inline">\(E_1 \cup .... \cup E_n = X\)</span> produces what is called the <strong>standard representation</strong> of a simple function (taking <span class="math inline">\(E_k = f^{-1} (\{c_k\})\)</span> where <span class="math inline">\(c_1, c_2, ..., c_n\)</span> are distinct values of <span class="math inline">\(f\)</span>)</p>
<p><br></p>
<h4 id="theorem-2.89-approximation-by-simple-function">Theorem 2.89: Approximation by Simple Function</h4>
<p>Suppose <span class="math inline">\((X, S)\)</span> is a measurable space and <span class="math inline">\(f: X \rightarrow [-\infty, \infty]\)</span> is <span class="math inline">\(S\)</span>-measurable. Then there exists a sequence <span class="math inline">\(f_1, f_2, ...\)</span> of functions from <span class="math inline">\(X \rightarrow \mathbb{R}\)</span> s.t:</p>
<ol type="a">
<li>Each <span class="math inline">\(f_k\)</span> is simple <span class="math inline">\(S\)</span>-measurable function.</li>
<li><span class="math inline">\(|f_k(x)| \leq |f_{k+1}(x)| \leq |f(x)|\)</span> for all <span class="math inline">\(k \in \mathbb{Z}^+\)</span> and all <span class="math inline">\(x \in X\)</span>.</li>
<li><span class="math inline">\(\lim_{k \rightarrow \infty} f_k (x) = f(x)\)</span> for every <span class="math inline">\(x \in X\)</span>.</li>
<li><span class="math inline">\(f_1, f_2, ...\)</span> converges uniformly on <span class="math inline">\(X\)</span> to <span class="math inline">\(f\)</span> if <span class="math inline">\(f\)</span> is bounded.</li>
</ol>
<p><br></p>
<h4 id="theorem-2.91-luzins-theorem">Theorem 2.91: Luzin's Theorem</h4>
<p>Suppose <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> is a Borel measurable function. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq \mathbb{R}\)</span> s.t <span class="math inline">\(|\mathbb{R} / F| &lt; \epsilon\)</span> and <span class="math inline">\(g|_{F}\)</span> is a continuous function on <span class="math inline">\(F\)</span>.</p>
<p>In other words, if <span class="math inline">\(g\)</span> is Borel measurable function, then there exists a closed set <span class="math inline">\(F \subseteq \mathbb{R}\)</span>, s.t the outer measure of the complement of <span class="math inline">\(F\)</span> is arbitrarily large and <span class="math inline">\(g|_F\)</span> is continuous on this arbitrarily small open set. <strong><span class="math inline">\(g|_F\)</span> is continuous on <span class="math inline">\(F\)</span> is not the same as <span class="math inline">\(g\)</span> is continuous at every point of <span class="math inline">\(B\)</span>.</strong></p>
<blockquote>
<p><span class="math inline">\(\chi_\mathbb{Q}\)</span> is discontinuous as every point of <span class="math inline">\(\mathbb{R}\)</span>, however, <span class="math inline">\(\chi_{\mathbb{Q}} |_{\mathbb{R} / \mathbb{Q}}\)</span> is continuous everywhere on <span class="math inline">\(\mathbb{R} / \mathbb{Q}\)</span> because they are all 0.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-2.92-continuous-extensions-of-continuous-functions">Theorem 2.92: Continuous Extensions of Continuous Functions</h4>
<ul>
<li>Every continuous function on a closed subset of <span class="math inline">\(\mathbb{R}\)</span> can be extended to a continuous function on all of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>More precisely, if <span class="math inline">\(F \in \mathbb{R}\)</span> is closed and <span class="math inline">\(g: F \rightarrow \mathbb{R}\)</span> is continuous, then there exists a continuous function <span class="math inline">\(h: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t <span class="math inline">\(h|_F = g\)</span>.</li>
</ul>
<p><br></p>
<h4 id="theorem-2.93-luzins-theorem-second-version">Theorem 2.93: Luzin's Theorem, Second Version</h4>
<p>Suppose <span class="math inline">\(E \subseteq \mathbb{R}\)</span> and <span class="math inline">\(g: E \rightarrow \mathbb{R}\)</span> is a Borel measurable function. Then for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a closed set <span class="math inline">\(F \subseteq E\)</span> and a continuous function <span class="math inline">\(h: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t <span class="math inline">\(|E / F| &lt; \epsilon\)</span> and $h|_{F} = g |_F $.</p>
<p><br></p>
<h4 id="definition-2.94-lebesgue-measurable-function">Definition 2.94: Lebesgue Measurable Function</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, where <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, is called <strong>Lebesgue measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Lebesgue measurable set for every Borel set <span class="math inline">\(B \subseteq \mathbb{R}\)</span>.</p>
<p><strong>The definition implies that if <span class="math inline">\(A\)</span> is Lebesgue measurable then <span class="math inline">\(A\)</span> is a Lebesgue measurable subset of <span class="math inline">\(\mathbb{R}\)</span>. If <span class="math inline">\(A\)</span> is a Lebesgue measurable subset of <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(S\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra of all Lebesgue measurable subsets of <span class="math inline">\(A\)</span>, then <span class="math inline">\(f\)</span> is <span class="math inline">\(S\)</span>-measurable</strong>.</p>
<p><br></p>
<h4 id="theorem-2.95-every-lebesgue-measurable-function-is-almost-borel-measurable">Theorem 2.95 Every Lebesgue Measurable Function is Almost Borel Measurable:</h4>
<p>Suppose <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is a Lebesgue measurable function. Then there exists a Borel measurable function <span class="math inline">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t:</p>
<p><span class="math display">\[|\{x \in \mathbb{R}: g(x) \neq f(x)\}| = 0\]</span></p>
<p><br></p>
<h4 id="review-2.96">Review 2.96</h4>
<ul>
<li>A <strong>Borel set</strong> is an element of the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> that contains all the open subsets of <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li>A <strong>Lebesgue measurable set</strong> is an element of the smallest <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> that contains all the open subsets of <span class="math inline">\(\mathbb{R}\)</span> and all the subsets of <span class="math inline">\(\mathbb{R}\)</span> with outer measure <span class="math inline">\(0\)</span>.</li>
<li>Every Lebesgue measurable set differs from a Borel set by a set with outer measure <span class="math inline">\(0\)</span>.</li>
<li>Outer measure restricted to the <span class="math inline">\(\sigma\)</span>-algebra of Borel sets or Lebesgue measurable sets is called <strong>Lebesgue measure</strong>.</li>
<li>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is called <strong>Borel measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Borel set for every Borel set <span class="math inline">\(B \in \mathbb{B}\)</span>.</li>
<li>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is called <strong>Lebesgue measurable</strong> if <span class="math inline">\(f^{-1}(B)\)</span> is a Lebesgue measurable set for every Borel set <span class="math inline">\(B \in \mathbb{B}\)</span>.</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/02/04/linear-algebra-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/04/linear-algebra-5/" class="post-title-link" itemprop="url">Linear Algebra (5)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-02-04 10:53:18" itemprop="dateCreated datePublished" datetime="2022-02-04T10:53:18+08:00">2022-02-04</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-13 12:26:19" itemprop="dateModified" datetime="2022-02-13T12:26:19+08:00">2022-02-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/02/04/linear-algebra-5/" class="post-meta-item leancloud_visitors" data-flag-title="Linear Algebra (5)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>24k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>22 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="linear-algebra-5">Linear Algebra (5)</h1>
<h2 id="operators-on-complex-vector-spaces">Operators on Complex Vector Spaces</h2>
<h3 id="null-spaces-of-powers-of-an-operator">Null Spaces of Powers of an Operator</h3>
<h4 id="theorem-8.2-sequence-of-increasing-null-spaces">Theorem 8.2: Sequence of Increasing Null Spaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then</p>
<p><span class="math display">\[\{0\} = \text{null }T^0 \subseteq \text{null }T^1 \subseteq ... \subseteq \text{null }T^k \subseteq .... \]</span></p>
<p>where <span class="math inline">\(T^0 = I\)</span> is the identity mapping in <span class="math inline">\(V\)</span>.</p>
<h5 id="proof-of-theorem-8.2">Proof of Theorem 8.2:</h5>
<p>Suppose <span class="math inline">\(k\)</span> is non-negative integer and <span class="math inline">\(v \in \text{null }T^k\)</span>, then <span class="math inline">\(T^k(v) = 0 \implies T^{k+1}(v) = TT^k(v) = T(0) = 0\)</span>, thus, <span class="math inline">\(\forall v \in \text{null }T^k\)</span>, <span class="math inline">\(v \in \text{null }T^{k+1}\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.3-equality-in-the-sequence-of-null-spaces">Theorem 8.3: Equality in the Sequence of Null Spaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(m\)</span> is a non-negative integer such that <span class="math inline">\(\text{null }T^m = \text{null }T^{m+1}\)</span>. Then:</p>
<p><span class="math display">\[\text{null } T^m = \text{null }T^{m+1} = \text{null }T^{m+2} = ...\]</span></p>
<h5 id="proof-of-theorem-8.3">Proof of Theorem 8.3:</h5>
<p>Let <span class="math inline">\(k\)</span> be a positive integer, we want to prove:</p>
<p><span class="math display">\[\text{null } T^{m+k} = \text{null } T^{m+k+1}\]</span></p>
<p>Since we know by <code>theorem 8.2</code>, <span class="math inline">\(\text{null } T^{m+k} \subseteq \text{null } T^{m+k+1}\)</span>, we only need to prove:</p>
<p><span class="math display">\[\text{null } T^{m+k+1} \subseteq \text{null } T^{m+k}\]</span></p>
<p>Let <span class="math inline">\(v \in \text{null } T^{m+k+1}\)</span>, then:</p>
<p><span class="math display">\[T^{m + 1}(T^k (v)) = T^{m+k+1} (v) = 0\]</span></p>
<p>Thus, <span class="math inline">\(T^k(v) \in \text{null } T^{m+1}\)</span>, since <span class="math inline">\(\text{null } T^m = \text{null } T^{m+1}\)</span> by assumption, we have:</p>
<p><span class="math display">\[T^k(v) \in \text{null } T^m \implies T^m (T^k(v)) = T^{m+k} (v) = 0\]</span></p>
<p>Thus, <span class="math inline">\(\forall v \in \text{null } T^{m+k+1}\)</span>, we have <span class="math inline">\(v \in \text{null } T^{m+k}\)</span>.</p>
<h4 id="theorem-8.4-null-spaces-stop-growing">Theorem 8.4: Null Spaces Stop Growing</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then:</p>
<p><span class="math display">\[\text{null } T^n = \text{null } T^{n+1} = ....\]</span></p>
<p><br></p>
<h4 id="theorem-8.5-v-is-the-direct-sum-of-textnull-tdim-v-and-textrange-tdim-v">Theorem 8.5: <span class="math inline">\(V\)</span> is the Direct Sum of <span class="math inline">\(\text{null } T^{\dim V}\)</span> and <span class="math inline">\(\text{range } T^{\dim V}\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then:</p>
<p><span class="math display">\[V = \text{null } T^n \oplus \text{range } T^n\]</span></p>
<p><strong>In general, <span class="math inline">\(V \neq \text{null } T \oplus \text{range }T\)</span></strong>.</p>
<h4 id="proof-of-theorem-8.5">Proof of Theorem 8.5:</h4>
<p>We first show that:</p>
<p><span class="math display">\[(\text{null } T^n) \cap (\text{range }T^n) = \{0\}\]</span></p>
<p>Where <span class="math inline">\(n = \dim V\)</span>. Let <span class="math inline">\(v \in (\text{null } T^n) \cap (\text{range }T^n)\)</span>, then <span class="math inline">\(T^n(v) = 0\)</span> and <span class="math inline">\(\exists u \in V, T^n(u) = v\)</span>. Then we have:</p>
<p><span class="math display">\[T^n(T^n (u)) = T^n (v) = 0 \implies T^{2n} (u) = 0\]</span></p>
<p>By <code>theorem 8.4</code>, we have <span class="math inline">\(\text{null } T^{2n} = \text{null }T^n\)</span>, thus:</p>
<p><span class="math display">\[T^{n} (u) = v = 0\]</span></p>
<p>Thus, <span class="math inline">\(v = 0\)</span>.</p>
<p>Then by <code>theorem 1.45</code>, we have <span class="math inline">\((\text{null } T^n) \oplus (\text{range }T^n)\)</span>, then by <code>theorem 3.22</code>, we have:</p>
<p><span class="math display">\[\dim V = \dim\text{null } T^n + \dim\text{range }T^n = \dim \{(\text{null } T^n) \oplus (\text{range }T^n)\}\]</span></p>
<p><br></p>
<h4 id="definition-8.9-generalized-eigenvector">Definition 8.9: Generalized Eigenvector</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>. A vector <span class="math inline">\(v \in V\)</span> is called a <strong>generalized eigenvector</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(v \neq 0\)</span> and:</p>
<p><span class="math display">\[(T - \lambda I)^j (v) = 0\]</span></p>
<p>for some positive integer <span class="math inline">\(j\)</span>.</p>
<p><strong>Although <span class="math inline">\(j\)</span> is allowed to be an arbitrary integer in the equation, every generalized eigenvector satisfies this equation with <span class="math inline">\(j = \dim V\)</span>.</strong></p>
<p><br></p>
<h4 id="definition-8.10-generalized-eigenspace-glambda-t">Definition 8.10: Generalized Eigenspace, <span class="math inline">\(G(\lambda, T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. The <strong>generalized eigenspace</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span>, denoted <span class="math inline">\(G(\lambda, T)\)</span>, is defined to be the set of all generalized eigenvectors of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> along with the <span class="math inline">\(0\)</span> vector.</p>
<p>If <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>, then:</p>
<p><span class="math display">\[E(\lambda, T) \subseteq G(\lambda, T)\]</span></p>
<p><strong>Generalized eigenspace is a subspace of <span class="math inline">\(V\)</span> because null space is subspace of <span class="math inline">\(V\)</span>.</strong></p>
<p><br></p>
<h4 id="theorem-8.11-description-of-generalized-eigenspaces">Theorem 8.11: Description of Generalized Eigenspaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Then:</p>
<p><span class="math display">\[G(\lambda, T) = \text{null }(T - \lambda I)^{\dim V}\]</span></p>
<h5 id="proof-of-theorem-8.11">Proof of Theorem 8.11:</h5>
<p>Suppose <span class="math inline">\(v \in \text{null }(T - \lambda I)^{\dim V}\)</span>, then <span class="math inline">\(v \in G(\lambda, T)\)</span> by <code>definition 8.10</code>.</p>
<p>Suppose <span class="math inline">\(v \in G(\lambda, T)\)</span>, then there exists an integer <span class="math inline">\(j\)</span> s.t <span class="math inline">\((T - \lambda I)^j (v) = 0\)</span>. If we let <span class="math inline">\(j = \dim V\)</span>, then by <code>theorem 8.2, 8.4</code>, we have:</p>
<p><span class="math display">\[v \in \text{null } (T - \lambda I)^{i}, \forall i \in \mathbb{Z}\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[v \in G(\lambda, T)\]</span></p>
<p><br></p>
<h4 id="theorem-8.13-linearly-independent-generalized-eigenvectors">Theorem 8.13: Linearly Independent Generalized Eigenvectors</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are distinct eigenvalues of <span class="math inline">\(T\)</span> and <span class="math inline">\(v_1, ..., v_m\)</span> are corresponding generalized eigenvectors. Then <span class="math inline">\(v_1, ..., v_m\)</span> is linearly independent.</p>
<p><br></p>
<h4 id="definition-8.16-nilpotent">Definition 8.16: Nilpotent</h4>
<p>An operator is called <strong>nilpotent</strong> if some power of it equals <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.18-nilpotent-operator-raised-to-dimension-of-domain-is-0">Theorem 8.18: Nilpotent Operator Raised to Dimension of Domain is <span class="math inline">\(0\)</span></h4>
<p>Suppose <span class="math inline">\(N \in L(V)\)</span> is nilpotent. Then <span class="math inline">\(N^{\dim V} = 0\)</span>.</p>
<h5 id="proof-of-theorem-8.18">Proof of Theorem 8.18</h5>
<p>Since <span class="math inline">\(N\)</span> is nilpotent, we have <span class="math inline">\(G(0, N) = V\)</span>, since for some integer <span class="math inline">\(j\)</span>, we have <span class="math inline">\(N^j = 0 \implies N^j(v) = 0, \; \forall v \in V\)</span>. Thus, by <code>theorem 8.11</code>, we have:</p>
<p><span class="math display">\[\text{null }(N)^{\dim V} = V\]</span></p>
<p>Thus, <span class="math inline">\(N^{\dim V} = 0\)</span>.</p>
<h4 id="theorem-8.19-matrix-of-a-nilpotent-operator">Theorem 8.19: Matrix of a Nilpotent Operator</h4>
<p>Suppose <span class="math inline">\(N\)</span> is a nilpotent operator on <span class="math inline">\(V\)</span>. Then there is a basis of <span class="math inline">\(V\)</span> w.r.t which the matrix of <span class="math inline">\(N\)</span> has the form:</p>
<p><span class="math display">\[
A = 
\begin{bmatrix}
0 &amp; ... &amp; *\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; 0\\
\end{bmatrix}
\]</span></p>
<p>here all entries on and below the diagonal are <span class="math inline">\(0\)</span>.</p>
<p><br></p>
<h3 id="decomposition-of-an-operator">Decomposition of an Operator</h3>
<h4 id="theorem-8.20-the-null-space-and-range-of-pt-are-invariant-under-t">Theorem 8.20: The Null Space and Range of <span class="math inline">\(p(T)\)</span> are Invariant Under <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(p \in P(\mathbb{F})\)</span>. Then <span class="math inline">\(\text{null } p(T)\)</span> and <span class="math inline">\(\text{range } p(T)\)</span> are invariant under <span class="math inline">\(T\)</span>.</p>
<h5 id="proof-of-theorem-8.21">Proof of Theorem 8.21:</h5>
<ol type="1">
<li><p><span class="math inline">\(\text{null } p(T)\)</span> is invariant under <span class="math inline">\(T\)</span>:</p>
<p>Suppose <span class="math inline">\(v \in \text{null } p(T)\)</span>, we want to show that <span class="math inline">\(p(T)(T(v)) = 0\)</span>. Thus, <span class="math inline">\(p(T) (v) = 0 \implies T(p(T)(v)) = T(0) = 0 = p(T) (T(v)) = 0\)</span></p></li>
<li><p><span class="math inline">\(\text{range } p(T)\)</span> is invariant under <span class="math inline">\(T\)</span>:</p>
<p>Suppose <span class="math inline">\(v \in \text{range } p(T)\)</span>, we want to show that <span class="math inline">\(T(v) = p(T)(u)\)</span> for some <span class="math inline">\(u \in V\)</span>. Let <span class="math inline">\(v = p(T)(u)\)</span>, then <span class="math inline">\(T(v) = T(p(T)(u)) = p(T)(T(u))\)</span>, let <span class="math inline">\(u = T(u)\)</span>, we have the desired result.</p></li>
</ol>
<p><br></p>
<h4 id="theorem-8.21-description-of-operators-on-complex-vector-space">Theorem 8.21: Description of Operators on Complex Vector Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> be the distinct eigenvalues of <span class="math inline">\(T\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(V = G(\lambda_1, T) \oplus ... \oplus G(\lambda_m, T)\)</span>.</li>
<li>Each <span class="math inline">\(G(\lambda_j, T)\)</span> is invariant under <span class="math inline">\(T\)</span>.</li>
<li>Each <span class="math inline">\((T - \lambda_j I )|_{G(\lambda_j, T)}\)</span> is nilpotent.</li>
</ol>
<p><br></p>
<h4 id="theorem-8.23-a-basis-of-generalized-eigenvectors">Theorem 8.23: A Basis of Generalized Eigenvectors</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then there is a basis of <span class="math inline">\(V\)</span> consisting of generalized eigenvectors of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="definition-8.24-multiplicity">Definition 8.24: Multiplicity</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. The <strong>multiplicity</strong> of an eigenvalue <span class="math inline">\(\lambda\)</span> of <span class="math inline">\(T\)</span> is defined to be the dimension of the corresponding generalized eigenspace <span class="math inline">\(G(\lambda, T)\)</span>.</p>
<p>In other words, the multiplicity of an eigenvalue <span class="math inline">\(\lambda\)</span> of <span class="math inline">\(T\)</span> equals <span class="math inline">\(\dim \text{null }(T - \lambda I)^{\dim V}\)</span>.</p>
<p>The <strong>algebraic multiplicity of <span class="math inline">\(\lambda\)</span></strong> is defined above.</p>
<p>The <strong>geometric multiplicity of <span class="math inline">\(\lambda\)</span></strong> is defined to be the dimension of corresponding eigenspace:</p>
<p><span class="math display">\[\dim E(\lambda, T)\]</span></p>
<p><br></p>
<h4 id="theorem-8.26-sum-of-the-multiplicities-equals-dim-v">Theorem 8.26: Sum of the Multiplicities Equals <span class="math inline">\(\dim V\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the sum of the multiplicities of all eigenvalues of <span class="math inline">\(T\)</span> equals <span class="math inline">\(\dim V\)</span>.</p>
<p><br></p>
<h4 id="definition-8.27-block-diagonal-matrix">Definition 8.27: Block Diagonal Matrix</h4>
<p>A <strong>block diagonal matrix</strong> is a square matrix of the form:</p>
<p><span class="math display">\[
\begin{bmatrix}
A_1 &amp; ... &amp; 0\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; A_m\\
\end{bmatrix}
\]</span></p>
<p>Where <span class="math inline">\(A_1, ..., A_m\)</span> are square matrices lying along the diagonal and all the other entries of the matrix equal 0. If <span class="math inline">\(A_1, ..., A_m\)</span> are <span class="math inline">\(1 \times 1\)</span> matrix, we have diagonal matrix.</p>
<p><br></p>
<h4 id="theorem-8.29-block-diagonal-matrix-with-upper-triangular-blocks">Theorem 8.29: Block Diagonal Matrix with Upper-Triangular Blocks</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> be the distinct eigenvalues of <span class="math inline">\(T\)</span>, with multiplicities <span class="math inline">\(d_1, ..., d_m\)</span>. Then there is a basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has a <strong>block diagonal matrix</strong> of the form:</p>
<p><span class="math display">\[
\begin{bmatrix}
A_1 &amp; ... &amp; 0\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; A_m\\
\end{bmatrix}
\]</span></p>
<p>Where each <span class="math inline">\(A_j\)</span> is a <span class="math inline">\(d_j \times d_j\)</span> upper-triangular matrix of the form:</p>
<p><span class="math display">\[
A_i = 
\begin{bmatrix}
\lambda_j &amp; ... &amp; *\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; \lambda_j\\
\end{bmatrix}
\]</span></p>
<p><br></p>
<h4 id="theorem-8.31-identity-plus-nilpotent-has-a-square-root">Theorem 8.31: Identity Plus Nilpotent Has a Square Root</h4>
<p>Suppose <span class="math inline">\(N \in L(V)\)</span> is nilpotent. Then <span class="math inline">\(I + N\)</span> has a square root.</p>
<p><br></p>
<h4 id="theorem-8.33-over-mathbbc-invertible-operators-have-square-roots">Theorem 8.33: Over <span class="math inline">\(\mathbb{C}\)</span>, Invertible Operators Have Square Roots</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span> is invertible. Then <span class="math inline">\(T\)</span> has a square root.</p>
<p><br></p>
<h3 id="characteristic-and-minimal-polynomials">Characteristic and Minimal Polynomials</h3>
<h4 id="definition-8.34-characteristic-polynomial-complex-vector-space">Definition 8.34: Characteristic Polynomial (<strong>Complex Vector Space</strong>)</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space, and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> denote the distinct eigenvalues of <span class="math inline">\(T\)</span>, with multiplicities <span class="math inline">\(d_1, ..., d_m\)</span>. The polynomial <span class="math inline">\(q\)</span> defined as:</p>
<p><span class="math display">\[q(z) = (z - \lambda_1)^{d_1} ... (z - \lambda_m)^{d_m}\]</span></p>
<p>is called the <strong>characteristic polynomial</strong> of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.36-degree-and-zeros-of-characteristic-polynomial">Theorem 8.36: Degree and Zeros of Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then:</p>
<ol type="a">
<li>The characteristic polynomial of <span class="math inline">\(T\)</span> has degree <span class="math inline">\(\dim V\)</span>.</li>
<li>The zeros of the characteristic polynomial of <span class="math inline">\(T\)</span> are the eigenvalues of <span class="math inline">\(T\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-8.37-cayley-hamilton-theorem-this-also-works-for-real-vector-space-see-theorem-9.24">Theorem 8.37: Cayley-Hamilton Theorem (<strong>This also works for real vector space</strong>, see <code>theorem 9.24</code>)</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(q\)</span> denotes the characteristic polynomial of <span class="math inline">\(T\)</span>. Then <span class="math inline">\(q(T) = 0\)</span>.</p>
<h5 id="proof-of-theorem-8.37">Proof of Theorem 8.37:</h5>
<p>Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> be eigenvalues of <span class="math inline">\(T\)</span> and <span class="math inline">\(d_1, ..., d_m\)</span> be dimensions of the corresponding generalized eigenspace <span class="math inline">\(G(\lambda_1, T), ... ,G(\lambda_m, T)\)</span>. Then by <code>theorem 8.18</code>, we have:</p>
<p><span class="math display">\[(T - \lambda_j I)^{d_j}|_{G(\lambda_j, T)} = 0\]</span></p>
<p>Since <span class="math inline">\(V\)</span> is direct sum of the generalized eigenspaces, we can write every <span class="math inline">\(v \in V\)</span> as <span class="math inline">\(v = g_1, ...., g_m, \; g_1 \in G(\lambda_1, T), g_m \in G(\lambda_m, T)\)</span> and:</p>
<p><span class="math display">\[q(T) (v) = q(T) (g_1) + .... + q(T)(g_m)\]</span></p>
<p>Thus, to show that <span class="math inline">\(q(T) = 0\)</span>, we only need to show that</p>
<p><span class="math display">\[q(T)|_{G(\lambda_j, T)} = 0, \; \forall j=1, ..., m\]</span></p>
<p>We have:</p>
<p><span class="math display">\[q(T) = (T - \lambda_1 I)^{d_1} .... (T - \lambda_m I)^{d_m}\]</span></p>
<p>For every <span class="math inline">\(g_1 \in G(\lambda_1, T)\)</span>, we can write (by <code>theorem 5.20</code>):</p>
<p><span class="math display">\[q(T) (g_1) = (T - \lambda_m I)^{d_m} .... ((T - \lambda_1 I)^{d_1} (g_1)) = 0\]</span></p>
<p><br></p>
<h4 id="definition-8.38-monic-polynomial">Definition 8.38: Monic Polynomial</h4>
<p>A <strong>monic polynomial</strong> is a polynomial whose <strong>highest-degree coefficient</strong> equals <span class="math inline">\(1\)</span>.</p>
<blockquote>
<p><span class="math inline">\(z\)</span></p>
<p><span class="math inline">\(2 + 6z^2 + z^7\)</span></p>
</blockquote>
<p><br></p>
<h4 id="theorem-8.40-minimal-polynomial">Theorem 8.40: Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then there is a unique monic polynomial <span class="math inline">\(p\)</span> of the smallest degree such that <span class="math inline">\(p(T) = 0\)</span>.</p>
<p><br></p>
<h4 id="definition-8.43-minimal-polynomial">Definition 8.43: Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the <strong>minimal polynomial</strong> of <span class="math inline">\(T\)</span> is the unique monic polynomial <span class="math inline">\(p\)</span> of the smallest degree such that <span class="math inline">\(p(T) = 0\)</span></p>
<p>From <code>theorem 8.37, 8.36</code>, we know that if <span class="math inline">\(V\)</span> is a complex vector space, then <span class="math inline">\(p\)</span> has degree at most <span class="math inline">\(\dim V\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.46-qt-0-implies-q-is-a-multiple-of-the-minimal-polynomial">Theorem 8.46: <span class="math inline">\(q(T) = 0 \implies q\)</span> is a Multiple of the Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(q \in P(\mathbb{F})\)</span>. Then <span class="math inline">\(q(T) = 0\)</span> IFF <span class="math inline">\(q\)</span> is a polynomial multiple of the minimal polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.48-characteristic-polynomial-is-a-multiple-of-minimal-polynomial-complex-vector-space">Theorem 8.48: Characteristic Polynomial is a Multiple of Minimal Polynomial (<strong>Complex Vector Space</strong>)</h4>
<p>Suppose <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then the characteristic polynomial of <span class="math inline">\(T\)</span> is a polynomial multiple of the minimal polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-8.49-eigenvalues-are-the-zeros-of-the-minimal-polynomial">Theorem 8.49: Eigenvalues are the Zeros of the Minimal Polynomial</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Then the zeros of the minimal polynomial of <span class="math inline">\(T\)</span> are precisely the eigenvalues of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h3 id="jordan-form">Jordan Form</h3>
<h4 id="theorem-8.55-basis-corresponding-to-a-nilpotent-operator">Theorem 8.55: Basis Corresponding to a Nilpotent Operator</h4>
<p>Suppose <span class="math inline">\(N \in L(V)\)</span> is nilpotent. Then there exist vectors <span class="math inline">\(v_1, ..., v_n \in V\)</span> and non-negative integer <span class="math inline">\(m_1, ..., m_n\)</span> s.t:</p>
<ol type="a">
<li><span class="math inline">\(N^{m_1}(v_1), ...., N(v_1), v_1, ..., N^{m_n}(v_n), ..., N(v_n)\)</span> is a basis of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(N^{m_1 + 1} (v_1) = ... = N^{m_n + 1}(v_n) = 0\)</span></li>
</ol>
<p><br></p>
<h4 id="definition-8.59-jordan-basis">Definition 8.59: Jordan Basis</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. A basis of <span class="math inline">\(V\)</span> is called <strong>jordan basis</strong> for <span class="math inline">\(T\)</span> if with respect to this basis <span class="math inline">\(T\)</span> has a block diagonal matrix"</p>
<p><span class="math display">\[
\begin{bmatrix}
A_1 &amp; ... &amp; 0\\
. &amp; ... &amp; .\\
0 &amp; ... &amp; A_m\\
\end{bmatrix}
\]</span></p>
<p>where each <span class="math inline">\(A_j\)</span> is an upper-triangular matrix of the form:</p>
<p><span class="math display">\[
A_j = 
\begin{bmatrix}
\lambda_j &amp; 1 &amp;  &amp; 0\\
 &amp;  &amp; 1 &amp; \\
 &amp;  &amp;  &amp; 1\\
0 &amp;  &amp;  &amp; \lambda_j\\
\end{bmatrix}
\]</span></p>
<h4 id="theorem-8.60-jordan-form">Theorem 8.60: Jordan Form</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space. If <span class="math inline">\(T \in L(V)\)</span>, then there is a basis of <span class="math inline">\(V\)</span> that is a jordan basis for <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h2 id="operators-on-real-vector-spaces">Operators on Real Vector Spaces</h2>
<h3 id="complexification">Complexification</h3>
<h4 id="definition-9.2-complexification-of-v-v_c">Definition 9.2: Complexification of <span class="math inline">\(V, V_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space.</p>
<ul>
<li>The <strong>complexification</strong> of <span class="math inline">\(V\)</span>, denoted <span class="math inline">\(V_C\)</span>, equals <span class="math inline">\(V \times V\)</span>. An element of <span class="math inline">\(V_C\)</span> is an ordered pair <span class="math inline">\(u, v\)</span> where <span class="math inline">\(u, v \in V\)</span>, but we will write this as <span class="math inline">\(u + iv\)</span>.</li>
<li>Addition on <span class="math inline">\(V_C\)</span> is defined by: <span class="math display">\[(u_1 + iv_1) + (u_2 + iv_2) = (u_1 + u_2) + i(v_1 + v_2)\]</span> for <span class="math inline">\(u_1, v_1, u_2, v_2 \in V\)</span></li>
<li>Complex scalar multiplication on <span class="math inline">\(V_C\)</span> is defined by: <span class="math display">\[(a + bi)(u + iv) = (au - bv) + i(av + bu)\]</span></li>
</ul>
<p>We can think of <span class="math inline">\(V\)</span> as a subset of <span class="math inline">\(V_C\)</span> by identifying <span class="math inline">\(u \in V\)</span> with <span class="math inline">\(u + i0\)</span></p>
<p><br></p>
<h4 id="theorem-9.3-v_c-is-a-complex-vector-space">Theorem 9.3: <span class="math inline">\(V_C\)</span> is a complex vector space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space. Then with the definition of addition and scalar multiplication above, <span class="math inline">\(V_C\)</span> is a complex vector space.</p>
<p><br></p>
<h4 id="theorem-9.4-basis-of-v-is-a-basis-of-v_c">Theorem 9.4: Basis of <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space.</p>
<ol type="1">
<li>If <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, then <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V_C\)</span>.</li>
<li>The dimension of <span class="math inline">\(V_C\)</span> equals the dimension of <span class="math inline">\(V\)</span> (<span class="math inline">\(\dim(V \times V) = \dim V + \dim V\)</span> over same <span class="math inline">\(\mathbb{F}\)</span>, in this case, we extend from <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span> to <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span>).</li>
</ol>
<p><br></p>
<h4 id="definition-9.5-complexification-of-t-t_c">Definition 9.5: Complexification of <span class="math inline">\(T, T_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. The <strong>complexification</strong> of <span class="math inline">\(T\)</span>, denoted <span class="math inline">\(T_C\)</span>, is the operator <span class="math inline">\(T_C \in L(V_C)\)</span> defined by:</p>
<p><span class="math display">\[T_C(u + iv) = T(u) + iT(v)\]</span></p>
<p>for <span class="math inline">\(u, v \in V\)</span></p>
<blockquote>
<p>Suppose <span class="math inline">\(A\)</span> is a <span class="math inline">\(n \times n\)</span> matrix of real numbers. Define <span class="math inline">\(T \in L(\mathbb{R}^n)\)</span> by <span class="math inline">\(T(x) = Ax\)</span> where the element in <span class="math inline">\(\mathbb{R}^n\)</span> are though of as <span class="math inline">\(n \times 1\)</span> column vectors. Then, we have <span class="math inline">\(T_C(z) = Az\)</span>, where <span class="math inline">\(z \in \mathbb{C}^n\)</span>. <strong>Thus, we can think of <span class="math inline">\(T_C\)</span> as matrix multiplication by the same <span class="math inline">\(A\)</span> of <span class="math inline">\(T\)</span> on <span class="math inline">\(\mathbb{R}^n\)</span> that acts on larger domain <span class="math inline">\(\mathbb{C}^n\)</span>.</strong></p>
</blockquote>
<p><br></p>
<h4 id="theorem-9.7-matrix-of-t_c-equals-matrix-of-t">Theorem 9.7: Matrix of <span class="math inline">\(T_C\)</span> equals Matrix of <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space with basis <span class="math inline">\(v_1, .., v_n\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(M(T) = M(T_C)\)</span>, where both matrices are w.r.t the basis <span class="math inline">\(v_1, ..., v_n\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.8-every-operator-has-an-invariant-subspace-of-dimension-1-or-2">Theorem 9.8: Every Operator Has an Invariant Subspace of Dimension 1 or 2</h4>
<p>Every operator on a nonzero finite-dimensional vector space has an invariant subspace of dimension 1 or 2.</p>
<p><br></p>
<h4 id="theorem-9.10-minimal-polynomial-of-t_c-equals-minimal-polynomial-of-t">Theorem 9.10: Minimal Polynomial of <span class="math inline">\(T_C\)</span> Equals Minimal Polynomial of <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the minimal polynomial of <span class="math inline">\(T_C\)</span> equals the minimal polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.11-real-eigenvalues-of-t_c">Theorem 9.11: Real Eigenvalues of <span class="math inline">\(T_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, and <span class="math inline">\(\lambda \in \mathbb{R}\)</span>. Then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span> if and only if <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>.</p>
<h5 id="proof-of-theorem-9.11">Proof of Theorem 9.11:</h5>
<p>The real eigenvalues of <span class="math inline">\(T\)</span> are the real zeros of the minimal polynomial of <span class="math inline">\(T\)</span>. The real eigenvalues of <span class="math inline">\(T_C\)</span> are the real zeros of minimal polynomial of <span class="math inline">\(T_C\)</span>. Since their polynomials are the same, we can conclude that the real eigenvalues of <span class="math inline">\(T, T_C\)</span> are the same.</p>
<p><br></p>
<h4 id="theorem-9.12-t_c---lambda-i-t_c---barlambda-i">Theorem 9.12 <span class="math inline">\(T_C - \lambda I, T_C - \bar{\lambda} I\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, <span class="math inline">\(\lambda \in \mathbb{C}\)</span>, <span class="math inline">\(j\)</span> is a non-negative integer, and <span class="math inline">\(u, v \in V\)</span>. Then:</p>
<p><span class="math display">\[(T_C - \lambda I)^j (u + iv) = 0 \quad \text{ IFF } \quad (T_C - \bar{\lambda} I)^j (u - iv) = 0\]</span></p>
<p><br></p>
<h4 id="theorem-9.16-non-real-eigenvalues-of-t_c-come-in-pairs">Theorem 9.16: Non-real Eigenvalues of <span class="math inline">\(T_C\)</span> Come in Pairs</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, and <span class="math inline">\(\lambda \in \mathbb{C}\)</span>. Then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span> IFF <span class="math inline">\(\bar{\lambda}\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.17-multiplicity-of-lambda-equals-multiplicity-of-barlambda">Theorem 9.17: Multiplicity of <span class="math inline">\(\lambda\)</span> Equals Multiplicity of <span class="math inline">\(\bar{\lambda}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, <span class="math inline">\(T \in L(V)\)</span>, <span class="math inline">\(\lambda \in \mathbb{C}\)</span> is an eigenvalue of <span class="math inline">\(T_C\)</span>. Then the multiplicity of <span class="math inline">\(\lambda\)</span> as an eigenvalue of <span class="math inline">\(T_C\)</span> equals the multiplicity of <span class="math inline">\(\bar{\lambda}\)</span> as an eigenvalue of <span class="math inline">\(T_C\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.19-operator-on-odd-dimensional-vector-space-has-eigenvalue">Theorem 9.19: Operator on Odd-dimensional Vector Space Has Eigenvalue</h4>
<p>Every operator on an odd-dimensional real vector space has an eigenvalue.</p>
<h5 id="proof-of-theorem-9.19">Proof of Theorem 9.19:</h5>
<p>Since all complex eigenvalues of <span class="math inline">\(T_C\)</span> comes in conjugate pairs and the dimensions of generalized eigenspaces add up to the dimension of <span class="math inline">\(V_C\)</span>, we have that at least 1 real eigenvalue exists.</p>
<p><br></p>
<h4 id="theorem-9.20-characteristic-polynomial-of-t_c">Theorem 9.20 Characteristic Polynomial of <span class="math inline">\(T_C\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the coefficients of the characteristic polynomial of <span class="math inline">\(T_C\)</span> are all real.</p>
<p><br></p>
<h4 id="definition-9.21-characteristic-polynomial">Definition 9.21: Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then the <strong>characteristic polynomial</strong> of <span class="math inline">\(T\)</span> is defined to be the characteristic polynomial of <span class="math inline">\(T_C\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.23-degree-and-zeros-of-characteristic-polynomials">Theorem 9.23: Degree and Zeros of Characteristic Polynomials</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space and <span class="math inline">\(T \in L(V)\)</span>. Then:</p>
<ol type="1">
<li>The coefficients of the characteristic polynomial of <span class="math inline">\(T\)</span> are all real.</li>
<li>The characteristic polynomial of <span class="math inline">\(T\)</span> has degree <span class="math inline">\(\dim V\)</span>.</li>
<li>The eigenvalues of <span class="math inline">\(T\)</span> are precisely the real zeros of the characteristic polynomial of <span class="math inline">\(T\)</span>.</li>
</ol>
<p><br></p>
<h4 id="theorem-9.24-cayley-hamilton-theorem">Theorem 9.24: Cayley-Hamilton Theorem</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(q\)</span> denotes the characteristic polynomial of <span class="math inline">\(T\)</span>, then <span class="math inline">\(q(T) = 0\)</span>.</p>
<p><br></p>
<h4 id="theorem-9.26-characteristic-polynomial-is-a-multiple-of-minimal-polynomial">Theorem 9.26: Characteristic Polynomial is a Multiple of Minimal Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then:</p>
<ol type="1">
<li>The degree of minimal polynomial of <span class="math inline">\(T\)</span> is at most <span class="math inline">\(\dim V\)</span>.</li>
<li>The characteristic polynomial of <span class="math inline">\(T\)</span> is a polynomial multiple of the minimal polynomial of <span class="math inline">\(T\)</span>.</li>
</ol>
<p><br></p>
<h3 id="operators-on-real-inner-product-spaces">Operators on Real Inner Product Spaces</h3>
<h4 id="theorem-9.27-normal-but-not-self-ajoint-operators">Theorem 9.27: Normal But Not Self-Ajoint Operators</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a 2-dimensional real inner product space and <span class="math inline">\(T \in L(V)\)</span>.</p>
<p>Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is normal but not self-adjoint.</li>
<li>The matrix of <span class="math inline">\(T\)</span> w.r.t every orthonormal basis of <span class="math inline">\(V\)</span> has the form: <span class="math display">\[
 \begin{bmatrix}
 a &amp; -b\\
 b &amp; a\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(b \neq 0\)</span></li>
<li>The matrix of <span class="math inline">\(T\)</span> w.r.t some orthonormal basis of <span class="math inline">\(V\)</span> has the form: <span class="math display">\[
 \begin{bmatrix}
 a &amp; -b\\
 b &amp; a\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(b &gt; 0\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-9.30-normal-operators-and-invariant-subspaces">Theorem 9.30: Normal Operators and Invariant Subspaces</h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner-product space, <span class="math inline">\(T \in L(V)\)</span> is normal, and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> that is invariant under <span class="math inline">\(T\)</span>. Then:</p>
<ol type="a">
<li><span class="math inline">\(U^{\perp}\)</span> is invariant under <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(U\)</span> is invariant under <span class="math inline">\(T^*\)</span>.</li>
<li><span class="math inline">\((T|_U)^* = (T^*)|_U\)</span></li>
<li><span class="math inline">\(T|_U \in L(U)\)</span> and <span class="math inline">\(T|_{U^{\perp}} \in L(U^{\perp})\)</span> are normal operators.</li>
</ol>
<p><br></p>
<h4 id="theorem-9.34-characterization-of-normal-operators-when-mathbbf-mathbbr">Theorem 9.34 Characterization of Normal Operators When <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real inner product space and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is normal.</li>
<li>There is an orthonormal basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has a block diagonal matrix s.t each block is a <span class="math inline">\(1 \times 1\)</span> matrix or a <span class="math inline">\(2 \times 2\)</span> matrix of the form: <span class="math display">\[
 \begin{bmatrix}
 a &amp; -b\\
 b &amp; a\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(b &gt; 0\)</span></li>
</ol>
<p><br></p>
<h4 id="theorem-9.36-description-of-isometries-when-mathbbf-mathbbr">Theorem 9.36: Description of Isometries When <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a real inner product space and <span class="math inline">\(S \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(S\)</span> is an isometry.</li>
<li>There is an orthonormal basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(S\)</span> has a block diagonal matrix such that each block on the diagonal is a <span class="math inline">\(1 \times 1\)</span> matrix containing <span class="math inline">\(1\)</span> or <span class="math inline">\(-1\)</span> or is a <span class="math inline">\(2 \times 2\)</span> matrix of the form: <span class="math display">\[
 \begin{bmatrix}
 \cos \theta &amp; -\sin \theta\\
 \sin \theta &amp; \cos \theta\\
 \end{bmatrix}
 \]</span> with <span class="math inline">\(\theta \in (0, \pi)\)</span></li>
</ol>
<p><br></p>
<h2 id="trace-and-determinant">Trace and Determinant</h2>
<h3 id="trace">Trace</h3>
<h4 id="definition-10.2-identity-matrix-i">Definition 10.2: Identity Matrix, <span class="math inline">\(I\)</span></h4>
<p>Suppose <span class="math inline">\(n\)</span> is a positive integer. The <span class="math inline">\(n \times n\)</span> diagonal matrix:</p>
<p><span class="math display">\[
\begin{bmatrix}
1 \theta &amp; 0\\
0 &amp; \cos 1\\
\end{bmatrix}
\]</span></p>
<p>is called the <strong>identity matrix</strong> and is denoted <span class="math inline">\(I\)</span>. With respect to every basis of <span class="math inline">\(V\)</span>, the matrix of identity operator <span class="math inline">\(I \in L(V)\)</span> is the identity matrix.</p>
<p><br></p>
<h4 id="definition-10.3-invertible-inverse-a-1-non-singular">Definition 10.3, Invertible, inverse, <span class="math inline">\(A^{-1}\)</span> (<strong>non-singular</strong>)</h4>
<p>A square matrix <span class="math inline">\(A\)</span> is called <strong>invertible</strong> if there is a unique matrix <span class="math inline">\(B\)</span> of the same size such that <span class="math inline">\(AB = BA = I\)</span>. We call <span class="math inline">\(B\)</span> the <strong>inverse</strong> of <span class="math inline">\(A\)</span> and denotes it by <span class="math inline">\(A^{-1}\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.4-the-matrix-of-the-product-of-linear-maps">Theorem 10.4: The Matrix of the Product of Linear Maps</h4>
<p>Suppose <span class="math inline">\(u_1, ..., u_n\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> and <span class="math inline">\(w_1, ..., w_n\)</span> are all bases of <span class="math inline">\(V\)</span>. Suppose <span class="math inline">\(S, T \in L(V)\)</span>. Then:</p>
<p><span class="math display">\[M(ST, (u_1, ..., u_n), (w_1, ..., w_n)) = M(S, (v_1,....,v_n), (w_1, ..., w_n))M(T, (u_1, ..., u_n), (v_1, ..., v_n)\]</span></p>
<p><br></p>
<h4 id="theorem-10.5-matrix-of-the-identity-w.r.t-two-bases">Theorem 10.5: Matrix of the Identity w.r.t Two Bases</h4>
<p>Suppose <span class="math inline">\(u_1, ..., u_n\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> are bases of <span class="math inline">\(V\)</span>. Then the matrices <span class="math inline">\(M(I, (u_1, ..., u_n), (v_1, ..., v_n)))\)</span> and <span class="math inline">\(M(I, (v_1, .., v_n), (u_1, ..., u_n))\)</span> are invertible, and each is the inverse of the other.</p>
<h5 id="proof-of-theorem-10.5">Proof of Theorem 10.5:</h5>
<p>Let <span class="math inline">\(u_j = w_j\)</span> in <code>theorem 10.4</code>, then we have:</p>
<p><span class="math display">\[M(II, (u_j), (u_j)) = M(I, (v_j), (u_j))M(I, (u_j)(v_j)) = I\]</span></p>
<p>interchange the role of <span class="math inline">\(v_j, u_j\)</span> we have</p>
<p><span class="math display">\[M(II, (v_j), (v_j)) = M(I, (u_j), (v_j))M(I, (v_j)(u_j)) = I\]</span></p>
<p><br></p>
<h4 id="theorem-10.7-change-of-basis-formula">Theorem 10.7: Change of Basis Formula</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(u_1, ..., u_n\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> be bases of <span class="math inline">\(V\)</span>. Let <span class="math inline">\(A = M(I, (u_1, ..., u_n), (v_1, ..., v_n))\)</span>. Then:</p>
<p><span class="math display">\[M(T, (u_1, ..., u_n)) = A^{-1} M(T, (v_1, ..., v_n)) A\]</span></p>
<h5 id="proof-of-theorem-10.7">Proof of Theorem 10.7</h5>
<p>By <code>theorem 10.4</code>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(u_j\)</span>, we have:</p>
<p><span class="math display">\[M(IT, (u_j), (v_j))) = M(I, (v_j), (u_j)) M(T, (u_j), (v_j)) = A^{-1} M(T, (u_j), (v_j))\]</span></p>
<p>By <code>theorem 10.4</code>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(v_j\)</span>, we have:</p>
<p><span class="math display">\[M(IT, (u_j), (v_j))) = A^{-1} M(T, (u_j), (v_j)) M(T, (v_j), (v_j)) M(I, (u_j), (v_j)) = A^{-1} M(T, (v_j)) A\]</span></p>
<p><br></p>
<h4 id="definition-10.9-trace-of-an-operator">Definition 10.9: Trace of an Operator</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>:</p>
<ul>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span>, then the <strong>trace</strong> of <span class="math inline">\(T\)</span> is the sum of eigenvalues of <span class="math inline">\(T\)</span>, with each eigenvalue repeated according to its multiplicity.</li>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the <strong>trace</strong> of <span class="math inline">\(T\)</span> is the sum of the eigenvalues of <span class="math inline">\(T_C\)</span>, with each eigenvalue repeated according to its multiplicity.</li>
</ul>
<p><span class="math display">\[tr(T) = d_1 \lambda_1 + ... + d_m \lambda_m\]</span></p>
<p>Where <span class="math inline">\(\lambda_i\)</span> are eigenvalues of <span class="math inline">\(T_C\)</span> or <span class="math inline">\(T\)</span> depends on <span class="math inline">\(\mathbb{F}\)</span>, and <span class="math inline">\(d_i\)</span> are multiplicities of eigenvalues.</p>
<p><br></p>
<h4 id="theorem-10.12-trace-and-characteristic-polynomial">Theorem 10.12: Trace and Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then <span class="math inline">\(tr(T)\)</span> equals the negative of the coefficient of <span class="math inline">\(z^{n-1}\)</span> in the characteristic polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="definition-10.13-trace-of-a-matrix">Definition 10.13: Trace of a Matrix</h4>
<p>The <strong>trace</strong> of a square matrix <span class="math inline">\(A\)</span>, denoted trace <span class="math inline">\(A\)</span>, is defined to be the sum of the diagonal entries of <span class="math inline">\(A\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.14-trab-trba">Theorem 10.14: <span class="math inline">\(tr(AB) = tr(BA)\)</span></h4>
<p>If <span class="math inline">\(A, B\)</span> are square matrices of the same size, then:</p>
<p><span class="math display">\[tr(AB) = tr(BA)\]</span></p>
<p><br></p>
<h4 id="theorem-10.15-trace-of-matrix-of-operator-does-not-depend-on-basis">Theorem 10.15: Trace of Matrix of Operator Does Not Depend on Basis</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(v_1, ..., v_n\)</span> and <span class="math inline">\(u_1, ..., u_n\)</span> are bases of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[tr(M(T, (u_1, ..., u_n))) = tr(M(T, (v_1, ..., v_n)))\]</span></p>
<p><br></p>
<h4 id="theorem-10.16-trace-of-an-operator-equals-trace-of-its-matrix">Theorem 10.16: Trace of an Operator Equals Trace of Its Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(tr(T) = tr(M(T))\)</span>.</p>
<p>This implies that the sum of eigenvalues of <span class="math inline">\(T\)</span> or <span class="math inline">\(T_C\)</span> is equal to the sum of diagonal of matrix of <span class="math inline">\(T\)</span> regardless of the basis.</p>
<p><br></p>
<h4 id="theorem-10.18-trace-is-additive">Theorem 10.18: Trace is Additive</h4>
<p>Suppose <span class="math inline">\(S, T \in L(V)\)</span>. Then <span class="math inline">\(tr(S + T) = tr(S) + tr(T)\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.19-the-identity-is-not-the-difference-of-st-and-ts">Theorem 10.19: The Identity is not the Difference of <span class="math inline">\(ST\)</span> and <span class="math inline">\(TS\)</span></h4>
<p>There do not exist operators <span class="math inline">\(S, T \in L(V)\)</span> s.t <span class="math inline">\(ST - TS = I\)</span></p>
<p><br></p>
<h3 id="determinant">Determinant</h3>
<h4 id="determinant-of-an-operator-det-t">Determinant of an Operator, <span class="math inline">\(\det T\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span></p>
<ul>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span>, then the <strong>determinant</strong> of <span class="math inline">\(T\)</span> is the product of the eigenvalues of <span class="math inline">\(T\)</span> with each eigenvalue repeated according to its multiplicity.</li>
<li>If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the <strong>determinant</strong> of <span class="math inline">\(T\)</span> is the product of the eigenvalues of <span class="math inline">\(T_C\)</span> with each eigenvalue repeated according to its multiplicity.</li>
</ul>
<p>The determinant of <span class="math inline">\(T\)</span> is denoted by <span class="math inline">\(\det T\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.22-determinant-and-characteristic-polynomial">Theorem 10.22: Determinant and Characteristic Polynomial</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(n = \dim V\)</span>. Then <span class="math inline">\(\det T\)</span> equals <span class="math inline">\((-1)^n\)</span> times the constant term of the characteristic polynomial of <span class="math inline">\(T\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.23-characteristic-polynomial-trace-and-determinant">Theorem 10.23: Characteristic Polynomial, Trace and Determinant</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the characteristic polynomial of <span class="math inline">\(T\)</span> can be written as:</p>
<p><span class="math display">\[z^n - (tr(T)) z^{n-1} + ... + (-1)^n \det T\]</span></p>
<p><br></p>
<h4 id="theorem-10.24-invertible-is-equivalent-to-nonzero-determinant">Theorem 10.24: Invertible is Equivalent to Nonzero Determinant</h4>
<p>An operator on <span class="math inline">\(V\)</span> is invertible IFF its determinant is nonzero.</p>
<h5 id="proof-of-theorem-10.24">Proof of Theorem 10.24:</h5>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space and <span class="math inline">\(T \in L(V)\)</span>, then by <code>theorem 5.30</code>, <span class="math inline">\(T\)</span> is invertible IFF all its eigenvalues are nonzero. Clearly this happens IFF the product of the eigenvalues of <span class="math inline">\(T\)</span> is not 0.</p>
<p>Suppose <span class="math inline">\(V\)</span> is a real vector space, then if 0 is not an eigenvalue of <span class="math inline">\(T\)</span>, then the eigenvalues of <span class="math inline">\(T_C\)</span> do not contain 0, thus the product of eigenvalues does not equal 0.</p>
<p><br></p>
<h4 id="theorem-10.25-characteristic-polynomial-of-t-equals-det-zi---t">Theorem 10.25: Characteristic Polynomial of <span class="math inline">\(T\)</span> Equals <span class="math inline">\(\det (zI - T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the characteristic polynomial of <span class="math inline">\(T\)</span> equals <span class="math inline">\(\det (zI - T)\)</span>.</p>
<h5 id="proof-of-theorem-10.25">Proof of Theorem 10.25:</h5>
<p>Suppose <span class="math inline">\(V\)</span> is a complex vector space, if <span class="math inline">\(\lambda, z \in \mathbb{C}\)</span>, then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span> IFF <span class="math inline">\(z - \lambda\)</span> is an eigenvalue of <span class="math inline">\((zI - T)\)</span> because:</p>
<p><span class="math display">\[-(T - \lambda I) = (\underbrace{(zI - T)}_{\text{operator}} - \underbrace{(z - \lambda)}_{\text{eigenvalue}} I)\]</span></p>
<p>Then we have:</p>
<p><span class="math display">\[\dim (\text{null }(-(T - \lambda I))^{\dim V}) = \dim (\text{null }((zI - T) - (z - \lambda))^{\dim V})\]</span></p>
<p>Suppose <span class="math inline">\(T\)</span> has eigenvalues <span class="math inline">\(\lambda_1, ..., \lambda_n\)</span> repeated to its multiplicity, then we have <span class="math inline">\((z - \lambda_1), ...., (z - \lambda_n)\)</span> as eigenvalues of <span class="math inline">\(zI - T\)</span> repeated to its multiplicity. Thus, we have:</p>
<p><span class="math display">\[\det(zI - T) = (z - \lambda_1) .... (z - \lambda_n)\]</span></p>
<p>Which is the same as the characteristic polynomial of <span class="math inline">\(T\)</span> with eigenvalues <span class="math inline">\(\lambda_1, ..., \lambda_n\)</span> repeated to its multiplicity.</p>
<p>The proof of real vector space is the same as complex vector space.</p>
<p><br></p>
<h4 id="definition-10.27-permutation-textperm-n">Definition 10.27: Permutation, <span class="math inline">\(\text{perm } n\)</span></h4>
<ul>
<li>A <strong>permutation</strong> of <span class="math inline">\((1 ,..., n)\)</span> is a list <span class="math inline">\((m_1, ..., m_n)\)</span> that contains each of the numbers <span class="math inline">\(1, ..., n\)</span> exactly once.</li>
<li>The set of all permutations of <span class="math inline">\((1, ..., n)\)</span> is denoted <span class="math inline">\(\text{perm } n.\)</span></li>
</ul>
<p>We should think of an element of <span class="math inline">\(\text{perm } n\)</span> as a rearrangement of the first <span class="math inline">\(n\)</span> items of the list.</p>
<p><br></p>
<h4 id="definition-10.30-sign-of-a-permutation">Definition 10.30: Sign of a Permutation</h4>
<ul>
<li>The <strong>sign</strong> of a permutation <span class="math inline">\((m_1, ..., m_n)\)</span> is defined to be <span class="math inline">\(1\)</span> if the number of paris of integers <span class="math inline">\((j, k)\)</span> with <span class="math inline">\(1 \leq j &lt; k \leq n\)</span> s.t <span class="math inline">\(j\)</span> appears after <span class="math inline">\(k\)</span> in the list <span class="math inline">\((m_1, ..., m_n)\)</span> is even and <span class="math inline">\(-1\)</span> if the number of such pairs is odd.</li>
<li>In other words, the sign of a permutation equals <span class="math inline">\(1\)</span> if the natural order has been changed an even number of times and equals <span class="math inline">\(-1\)</span> if the natural order has been changed an odd number times.</li>
</ul>
<blockquote>
<p>The only par of integers <span class="math inline">\((j, k)\)</span> with <span class="math inline">\(j &lt; k\)</span> s.t <span class="math inline">\(j\)</span> appears after <span class="math inline">\(k\)</span> in the permutation <span class="math inline">\(2, 1, 3, 4\)</span> is (1, 2), thus, the permutation has sign 1.</p>
</blockquote>
<p><br></p>
<h4 id="theorem-10.32-interchanging-two-entries-in-a-permutation">Theorem 10.32: Interchanging Two Entries in a Permutation</h4>
<p>Interchanging two entries in a permutation multiplies the sign of the permutation by <span class="math inline">\(-1\)</span>.</p>
<p><br></p>
<h4 id="definition-10.33-determinant-of-a-matrix-det-a">Definition 10.33: Determinant of a Matrix, <span class="math inline">\(\det A\)</span></h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times n\)</span> matrix:</p>
<p><span class="math display">\[
A = 
\begin{bmatrix}
A_{1,1} &amp; ... &amp; A_{1,n}\\
. &amp; ... &amp; .\\
A_{n,1} &amp; ... &amp; A_{n,n}\\
\end{bmatrix}
\]</span></p>
<p>The <strong>determinant</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\det A\)</span>, is defined by:</p>
<p><span class="math display">\[\det A = \sum_{(m_1, ..., m_n) \in \text{perm n}} (sign(m_1, ..., m_n)) A_{m_1, 1} .... A_{m_n, n}\]</span></p>
<p><br></p>
<h4 id="theorem-10.36-interchanging-two-columns-in-a-matrix">Theorem 10.36: Interchanging Two Columns in a Matrix</h4>
<p>Suppose <span class="math inline">\(A\)</span> is a square matrix and <span class="math inline">\(B\)</span> is the matrix obtained from <span class="math inline">\(A\)</span> by interchanging two columns. Then:</p>
<p><span class="math display">\[\det A = -\det B\]</span></p>
<p><br></p>
<h4 id="theorem-10.37-matrix-with-two-equal-columns">Theorem 10.37: Matrix with Two Equal Columns</h4>
<p>If <span class="math inline">\(A\)</span> is a square matrix that has two equal columns, then <span class="math inline">\(\det A = 0\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.38-permuting-the-columns-of-a-matrix">Theorem 10.38: Permuting the Columns of a Matrix</h4>
<p>Suppose <span class="math inline">\(A = [A_{\cdot, 1} .... A_{\cdot, n}]\)</span> is an <span class="math inline">\(n \times n\)</span> matrix and <span class="math inline">\((m_1, ..., m_n)\)</span> is a permutation. Then:</p>
<p><span class="math display">\[\det (A_{\cdot, m_1} .... A_{\cdot, m_n}) = sign(m_1, ..., m_n) \det A\]</span></p>
<p><br></p>
<h4 id="theorem-10.39-determinant-is-a-linear-function-of-each-column">Theorem 10.39: Determinant is a Linear Function of Each Column</h4>
<p>Suppose <span class="math inline">\(k, n\)</span> are positive integers with <span class="math inline">\(1 \leq k \leq n\)</span>. Fix <span class="math inline">\(n \times 1\)</span> matrices <span class="math inline">\(A_{\cdot, 1}, ..., A_{\cdot, k}\)</span>. Then the function that takes an <span class="math inline">\(n \times 1\)</span> column vector <span class="math inline">\(A_{\cdot, k}\)</span> to:</p>
<p><span class="math display">\[\det(A_{\cdot, 1} ... A_{\cdot, k} .... A_{\cdot, n})\]</span></p>
<p>is a linear map from the vector space of <span class="math inline">\(n \times 1\)</span> matrices with entries in <span class="math inline">\(\mathbb{F}\)</span> to <span class="math inline">\(\mathbb{F}\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.40-determinant-is-multiplicative">Theorem 10.40: Determinant is Multiplicative</h4>
<p>Suppose <span class="math inline">\(A, B\)</span> are square matrices of the same size. Then:</p>
<p><span class="math display">\[\det(AB) = \det(BA) = \det(A)\det(B)\]</span></p>
<p><br></p>
<h4 id="theorem-10.41-determinant-of-matrix-of-operator-does-not-depend-on-basis">Theorem 10.41: Determinant of Matrix of Operator Does not Depend on Basis</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(u_1, ..., u_j\)</span> and <span class="math inline">\(v_1, ...., v_n\)</span> are bases of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\det M(T, (u_1, ..., u_n)) = \det M(T, (v_1, ..., v_n))\]</span></p>
<p><br></p>
<h4 id="theorem-10.42-determinant-of-an-operator-equals-determinant-of-its-matrix">Theorem 10.42: Determinant of an Operator Equals Determinant of Its Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(\det T = \det M(T)\)</span>.</p>
<p><br></p>
<h4 id="theorem-10.43-isometries-have-determinant-with-absolute-value-1">Theorem 10.43: Isometries Have Determinant with Absolute Value <span class="math inline">\(1\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is an inner product space and <span class="math inline">\(S \in L(V)\)</span> is an isometry. Then <span class="math inline">\(|\det S| = 1\)</span>.</p>
<p><br></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/01/25/linear-algebra-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/25/linear-algebra-4/" class="post-title-link" itemprop="url">Linear Algebra (4)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-25 20:54:30" itemprop="dateCreated datePublished" datetime="2022-01-25T20:54:30+08:00">2022-01-25</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-04 10:53:38" itemprop="dateModified" datetime="2022-02-04T10:53:38+08:00">2022-02-04</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/01/25/linear-algebra-4/" class="post-meta-item leancloud_visitors" data-flag-title="Linear Algebra (4)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>20k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>18 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="linear-algebra-4">Linear Algebra (4)</h1>
<h2 id="inner-product-spaces">Inner Product Spaces</h2>
<p><strong>If <span class="math inline">\(\lambda\)</span> is a complex number, then we define <span class="math inline">\(\lambda \geq 0\)</span> to be real number and nonnegative.</strong></p>
<h3 id="inner-products-and-norms">Inner Products and Norms</h3>
<p>For <span class="math inline">\(z \in \mathbb{F}^n\)</span>, we define the norm of <span class="math inline">\(z\)</span> w.r.t Euclidian inner product by:</p>
<p><span class="math display">\[\|z\| = \sqrt{|z_1|^2 + ... + |z_n|^2}\]</span></p>
<p>Where <span class="math inline">\(|z_1|^2 = z\bar{z} = a^2 + b^2\)</span></p>
<h4 id="definition-6.2-dot-product">Definition 6.2: Dot Product</h4>
<p>For <span class="math inline">\(x, y \in \mathbb{R}^n\)</span>, the <strong>dot product</strong> of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, denoted <span class="math inline">\(x \cdot y\)</span>, is defined by:</p>
<p><span class="math display">\[x \cdot y = x_1y_1 + ... + x_ny_n\]</span></p>
<p>where <span class="math inline">\(x=(x_1, ..., x_n), y=(y_1, ..., y_n)\)</span></p>
<p>It has the following properties:</p>
<ol type="1">
<li><span class="math inline">\(x \cdot x \geq 0, \; \forall x \in \mathbb{R}^n\)</span></li>
<li><span class="math inline">\(x \cdot x = 0\)</span> IFF <span class="math inline">\(x = 0\)</span></li>
<li>For <span class="math inline">\(y \in \mathbb{R}^n\)</span> fixed, the map from <span class="math inline">\(\mathbb{R}^n \rightarrow \mathbb{R}\)</span> that sends <span class="math inline">\(x \in \mathbb{R}^n\)</span> to <span class="math inline">\(x \cdot y\)</span> is linear.</li>
<li><span class="math inline">\(x \cdot y = y \cdot x, \; \forall x, y \in \mathbb{R}^n\)</span></li>
</ol>
<h4 id="definition-6.3-inner-product">Definition 6.3: Inner Product</h4>
<p>An <strong>inner product</strong> on <span class="math inline">\(V\)</span> is a <strong>function</strong> that takes each ordered pair <span class="math inline">\((u, v)\)</span> of elements of <span class="math inline">\(V\)</span> to a number <span class="math inline">\(&lt;u, v&gt; \in \mathbb{F}\)</span> and has the following properties:</p>
<ol type="1">
<li><strong>Positive</strong>: <span class="math display">\[&lt;v, v&gt; \geq 0 , \; \forall v \in V\]</span></li>
<li><strong>Definiteness</strong>: <span class="math display">\[&lt;v, v&gt; = 0 \;\; \text{ IFF } \;\; v = 0\]</span></li>
<li><strong>Additivity in first slot</strong>: <span class="math display">\[&lt;u + v, w&gt; = &lt;u, w&gt; + &lt;v, w&gt;, \; \forall u, v, w \in V\]</span></li>
<li><strong>Homogeneity in first slot</strong>: <span class="math display">\[&lt;\lambda u, v&gt; = \lambda &lt;u, v&gt;, \; \forall \lambda \in \mathbb{F}, u,v \in V\]</span></li>
<li><strong>Conjugate Symmetry</strong>: <span class="math display">\[&lt;u, v&gt; = \overline{&lt;v, u&gt;}, \; \forall u, v \in V\]</span></li>
</ol>
<blockquote>
<p>The <strong>Euclidean inner product on <span class="math inline">\(\mathbb{F}^n\)</span></strong> is defined by: <span class="math display">\[&lt;(w_1, ..., w_n), (z_1, ..., z_n)&gt; = w_1 \bar{z}_1 + .... + w_n \bar{z}_n\]</span></p>
<p>If <span class="math inline">\(c_1, ..., c_n\)</span> are positive numbers, then an inner product can be defined on <span class="math inline">\(\mathbb{F}^n\)</span> by: <span class="math display">\[&lt;(w_1,  ...., w_n), (z_1, ..., z_n)&gt; = c_1w_1 \bar{z}_1 + .... + c_nw_n \bar{z}_n\]</span></p>
<p>An inner product can be defined on the vector space of continuous real-valued functions on the interval <span class="math inline">\([-1, 1]\)</span> by: <span class="math display">\[&lt;f, g&gt; = \int^1_{-1} f(x)g(x) dx\]</span></p>
<p>An inner product can be defined on <span class="math inline">\(P(\mathbb{R})\)</span> by: <span class="math display">\[&lt;p, q&gt; = \int^{\infty}_{0} p(x) q(x) e^{-x} dx\]</span></p>
</blockquote>
<h4 id="definition-6.5-inner-product-space">Definition 6.5: Inner Product Space</h4>
<p>An <strong>inner product space</strong> is a vector space <span class="math inline">\(V\)</span> along with an inner product on <span class="math inline">\(V\)</span>.</p>
<p><br></p>
<p><span style="color:red"><strong>For the rest of the Inner product space chapter, <span class="math inline">\(V\)</span> denotes inner product space over <span class="math inline">\(\mathbb{F}\)</span>. If the inner product on <span class="math inline">\(V\)</span> is missing from the context, we assume it to be Euclidean inner product if the vector space is <span class="math inline">\(\mathbb{F}^n\)</span></strong></span>.</p>
<p><br></p>
<h4 id="theorem-6.7-basic-properties-of-an-inner-product">Theorem 6.7: Basic Properties of an Inner Product</h4>
<ol type="1">
<li>For each fixed <span class="math inline">\(u \in V\)</span>, the function that takes <span class="math inline">\(v\)</span> to <span class="math inline">\(&lt;v, u&gt;\)</span> is a linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(\mathbb{F}\)</span>.</li>
<li><span class="math inline">\(&lt;0, u&gt; = 0\)</span> for every <span class="math inline">\(u \in V\)</span>.</li>
<li><span class="math inline">\(&lt;u, 0&gt; = 0\)</span> for every <span class="math inline">\(u \in V\)</span>.</li>
<li><span class="math inline">\(&lt;u, v + w&gt; = &lt;u, v&gt; + &lt;u, w&gt;\)</span> for all <span class="math inline">\(u, v, w \in V\)</span>.</li>
<li><span class="math inline">\(&lt;u, \lambda v&gt; = \bar{\lambda} &lt;u, v&gt; \; \forall \lambda \in \mathbb{F}, u, v \in V\)</span>.</li>
</ol>
<h4 id="definition-6.8-norm-v">Definition 6.8: Norm, <span class="math inline">\(\| v \|\)</span></h4>
<p>For <span class="math inline">\(v \in V\)</span>, the <strong>norm</strong> of <span class="math inline">\(v\)</span>, denoted <span class="math inline">\(\|v\|\)</span>, is defined by:</p>
<p><span class="math display">\[\|v\| = \sqrt{&lt;v, v&gt;}\]</span></p>
<h4 id="theorem-6.10-basic-properties-of-the-norm">Theorem 6.10: Basic Properties of the Norm</h4>
<p>Suppose <span class="math inline">\(v \in V\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\|v\| = 0\)</span>, if and only if <span class="math inline">\(v = 0\)</span>.</li>
<li><span class="math inline">\(\|\lambda v\| = |\lambda| \|v\|, \; \forall \lambda \in \mathbb{F}\)</span>.</li>
</ol>
<h4 id="definition-6.11-orthogonal">Definition 6.11: Orthogonal</h4>
<p>Two vectors <span class="math inline">\(u, v \in V\)</span> are called <strong>orthogonal</strong> if <span class="math inline">\(&lt;u, v&gt; = 0\)</span>.</p>
<h4 id="theorem-6.12-orthogonality-and-0">Theorem 6.12: Orthogonality and <span class="math inline">\(0\)</span></h4>
<ol type="1">
<li><span class="math inline">\(0\)</span> is orthogonal to every vector in <span class="math inline">\(V\)</span>.</li>
<li>0 is the only vector in <span class="math inline">\(V\)</span> that is orthogonal to itself.</li>
</ol>
<h4 id="theorem-6.13-pythagorean-theorem">Theorem 6.13 Pythagorean Theorem</h4>
<p>Suppose <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are <strong>orthogonal</strong> vectors in <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\|u + v\|^2 = \|u\|^2 + \|v\|^2\]</span></p>
<h4 id="theorem-6.14-an-orthogonal-decomposition">Theorem 6.14: An Orthogonal Decomposition</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>, with <span class="math inline">\(v \neq 0\)</span>. Set <span class="math inline">\(c = \frac{&lt;u, v&gt;}{\|v\|^2}\)</span> and <span class="math inline">\(w = u - \frac{&lt;u, v&gt;}{\|v\|^2} v\)</span>. Then:</p>
<p><span class="math display">\[&lt;w, v&gt; = 0\]</span></p>
<p>and</p>
<p><span class="math display">\[u = cv + w\]</span></p>
<h4 id="theorem-6.15-cauchy-schwarz-inequality">Theorem 6.15: Cauchy-Schwarz Inequality</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>. Then:</p>
<p><span class="math display">\[|&lt;u, v&gt;| \leq \|u\|\|v\|\]</span></p>
<p>This inequality is an equality if and only if one of <span class="math inline">\(u, v\)</span> is a scalar multiple of the other.</p>
<h5 id="proof-of-theorem-6.15">Proof of theorem 6.15:</h5>
<p>If <span class="math inline">\(v = 0\)</span>, we have <span class="math inline">\(0 = 0\)</span>, thus, we can assume <span class="math inline">\(v \neq 0\)</span>. Then, by <code>theorem 6.14</code>, we have:</p>
<p><span class="math display">\[u = \frac{&lt;u, v&gt; v}{\|v\|^2} + w\]</span></p>
<p>Since <span class="math inline">\(v, w\)</span> are orthogonal, by taking the norm square on both side we have:</p>
<p><span class="math display">\[\|u\|^2 = \|\frac{&lt;u, v&gt; v}{\|v\|^2}\|^2 + \|w\|^2\]</span></p>
<p>Since <span class="math inline">\(\frac{&lt;u, v&gt;}{\|v\|^2} \in \mathbb{F}\)</span>, we can take them out:</p>
<p><span class="math display">\[\|u\|^2 = \frac{|&lt;u, v&gt;|^2}{\|v\|^4}\|v\|^2 + \|w\|^2 \geq \frac{|&lt;u, v&gt;|}{\|v\|^2}\]</span></p>
<p>Multiply both sides by <span class="math inline">\(\|v\|^2\)</span>, we have:</p>
<p><span class="math display">\[\|w\|^2\|v\|^2 \geq |&lt;u, v&gt;|\]</span></p>
<p>Notice that, the equality only happens when <span class="math inline">\(\|w\|^2 = 0\)</span>, in other words, <span class="math inline">\(w = u - \frac{&lt;u, v&gt;}{\|v\|^2} v = 0 \implies u = \frac{&lt;u, v&gt;}{\|v\|^2} v\)</span>, thus, if <span class="math inline">\(u\)</span> is scalar multiple of <span class="math inline">\(v\)</span>.</p>
<h4 id="theorem-6.18-triangle-inequality">Theorem 6.18: Triangle Inequality</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>. Then</p>
<p><span class="math display">\[\|u + v\| \leq \|u\| + \|v\|\]</span></p>
<p>This inequality is an equality if and only if one of <span class="math inline">\(u, v\)</span> is a nonnegative multiple of the other.</p>
<h4 id="theorem-6.22-parallelogram-equality">Theorem 6.22 Parallelogram Equality</h4>
<p>Suppose <span class="math inline">\(u, v \in V\)</span>. Then:</p>
<p><span class="math display">\[\|u + v\|^2 + \|u - v\|^2 = 2 (\|u\|^2 + \|v\|^2)\]</span></p>
<h4 id="theorem-the-polarization-identities">Theorem: The Polarization Identities</h4>
<p><a target="_blank" rel="noopener" href="https://unapologetic.wordpress.com/2009/04/23/the-polarization-identities/">Polarization Identities</a></p>
<h3 id="orthonormal-bases">Orthonormal Bases</h3>
<h4 id="definition-6.23-orthonormal">Definition 6.23: Orthonormal</h4>
<p>A list of vectors is called <strong>orthonormal</strong> if each vector in the list has norm <span class="math inline">\(1\)</span> and is orthogonal to all the other vectors in the list. In other words, a list <span class="math inline">\(e_1, ..., e_m\)</span> of vectors in <span class="math inline">\(V\)</span> is orthonormal if</p>
<p><span class="math display">\[
&lt;e_j, e_j&gt; =
\begin{cases}
1, \quad \text{if} \;\; k = j\\
0, \quad \text{if} \;\; k \neq j
\end{cases}
\]</span></p>
<blockquote>
<p>The standard basis in <span class="math inline">\(\mathbb{F}^n\)</span> w.r.t Euclidean inner product is an orthonormal list.</p>
</blockquote>
<h4 id="theorem-6.25-the-norm-of-an-orthonormal-linear-combination">Theorem 6.25: The Norm of an Orthonormal Linear Combination</h4>
<p>If <span class="math inline">\(e_1, ..., e_m\)</span> is an orthonormal list of vectors in <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[\|a_1e_1 + ... + a_m e_m\|^2 = |a_1|^2 + ... + |a_m|^2\]</span></p>
<p>for all <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span></p>
<h4 id="theorem-6.26-an-orthonormal-list-is-linearly-independent">Theorem 6.26: An Orthonormal List is linearly Independent</h4>
<p>Every orthonormal list of vectors is linearly independent.</p>
<h4 id="definition-6.27-orthonormal-basis">Definition 6.27: Orthonormal Basis</h4>
<p>An <strong>orthonormal basis</strong> of <span class="math inline">\(V\)</span> is an orthonormal list of vectors in <span class="math inline">\(V\)</span> that is also a basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.28-an-orthonormal-list-of-the-right-length-is-an-orthonormal-basis">Theorem 6.28: An Orthonormal List of the Right Length is an Orthonormal Basis</h4>
<p>Every orthonormal list of vectors in <span class="math inline">\(V\)</span> with length <span class="math inline">\(\dim V\)</span> is an orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.30-writing-a-vector-as-linear-combination-of-orthonormal-basis">Theorem 6.30: Writing a Vector as Linear Combination of Orthonormal Basis</h4>
<p>Suppose <span class="math inline">\(e_1, ..., e_n\)</span> is an orthonormal basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(v \in V\)</span>. Then:</p>
<p><span class="math display">\[v = &lt;v, e_1&gt; e_1 + ... + &lt;v, e_n&gt;e_n\]</span></p>
<p>and</p>
<p><span class="math display">\[\|v\|^2 = |&lt;v, e_1&gt;|^2 + ... + |&lt;v, e_n&gt;|^2\]</span></p>
<h5 id="proof-of-theorem-6.30">Proof of Theorem 6.30</h5>
<p>Since <span class="math inline">\(e_1, ...., e_n\)</span> is an orthonormal basis, there exists a list of scalars <span class="math inline">\(a_1, ..., a_n\)</span> s.t:</p>
<p><span class="math display">\[v = a_1e_1 + ... + a_ne_n\]</span></p>
<p>Take the inner product of <span class="math inline">\(e_j\)</span> on both sides, we have:</p>
<p><span class="math display">\[&lt;v, e_j&gt; = a_j\]</span></p>
<h4 id="theorem-6.31-gram-schmidt-procedure">Theorem 6.31: Gram-Schmidt Procedure</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_m\)</span> is a linearly independent list of vectors in <span class="math inline">\(V\)</span>. Let <span class="math inline">\(e_1 = \frac{v_1}{\|v_1\|}\)</span>. For <span class="math inline">\(j=2, ..., m\)</span>, define <span class="math inline">\(e_j\)</span> inductively by:</p>
<p><span class="math display">\[e_j = \frac{v_j - &lt;v_j, e_1&gt; e_1 - ... - &lt;v_j, e_{j-1}&gt;e_{j-1}}{\|v_j - &lt;v_j, e_1&gt; e_1 - ... - &lt;v_j, e_{j-1}&gt;e_{j-1}\|}\]</span></p>
<p>Then <span class="math inline">\(e_j, ..., e_m\)</span> is an orthonormal list of vectors in <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[span(v_1, ..., v_j) = span(e_1, ..., e_j)\]</span></p>
<p>for <span class="math inline">\(j = 1, ..., m\)</span></p>
<h4 id="theorem-6.34-existence-of-orthonormal-basis">Theorem 6.34: Existence of Orthonormal Basis</h4>
<p>Every finite-dimensional inner product space has an orthonormal basis.</p>
<h4 id="theorem-6.35-orthonormal-list-extends-to-orthonormal-basis">Theorem 6.35: Orthonormal List Extends to Orthonormal Basis</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then every orthonormal list of vectors in <span class="math inline">\(V\)</span> can be extended to an orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.37-upper-triangular-matrix-w.r.t-orthonormal-basis">Theorem 6.37: Upper-Triangular Matrix w.r.t Orthonormal Basis</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. If <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>, then <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h5 id="proof-theorem-6.37">Proof Theorem 6.37:</h5>
<p>Assume <span class="math inline">\(v_1, ..., v_n\)</span> is a basis s.t <span class="math inline">\(T\)</span> has an upper triangular matrix, then by <code>theorem 5.26</code>, we have <span class="math inline">\(span(v_1, .., v_j)\)</span> is invariant under <span class="math inline">\(T\)</span> for each <span class="math inline">\(j=1\)</span>. Then by Gram-Schmidt Procedure, we can construct <span class="math inline">\(e_1, ..., e_n\)</span> from <span class="math inline">\(v_1, ..., v_n\)</span> s.t</p>
<p><span class="math display">\[span(e_1, ..., e_j) = span(v_1, ..., v_j)\]</span></p>
<p>Then, by <code>theorem 5.26</code>, we can conclude the <span class="math inline">\(e_1, ..., e_n\)</span> is a basis s.t <span class="math inline">\(T\)</span> has an upper triangular matrix.</p>
<h4 id="theorem-6.38-schurs-theorem">Theorem 6.38: Schur's Theorem</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a finite-dimensional complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some orthonormal basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="theorem-6.42-riesz-representation-theorem">Theorem 6.42: Riesz Representation Theorem</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(\psi\)</span> is a linear functional on <span class="math inline">\(V\)</span>. Then there is a <strong>unique</strong> vector <span class="math inline">\(u \in V\)</span> that does not depend on the choice of basis s.t</p>
<p><span class="math display">\[\psi (v) = &lt;v, u&gt;\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span>.</p>
<p>In other words, any linear functional on <span class="math inline">\(V\)</span> can be written as the map that sends <span class="math inline">\(v \in V\)</span> to inner product.</p>
<h5 id="proof-theorem-6.42">Proof Theorem 6.42</h5>
<p>Let <span class="math inline">\(e_1, ..., e_n\)</span> be an orthonormal basis of <span class="math inline">\(V\)</span>. Then:</p>
<span class="math display">\[\begin{aligned}
\psi (v) &amp;= \psi (&lt;v, e_1&gt; e_1 + ... + &lt;v, e_n&gt; e_n) \\
&amp;= &lt;v, e_1&gt; \psi(e_1) + ... + &lt;v, e_n&gt;\psi(e_n)\\
&amp;= &lt;v, \overline{\psi(e_1)} e_1 + .... + \overline{\psi(e_n)} e_n&gt;
\end{aligned}\]</span>
<p>Let <span class="math inline">\(u = \overline{\psi(e_1)} e_1 + .... + \overline{\psi(e_n)} e_n\)</span>, then we have:</p>
<p><span class="math display">\[\psi(v) = &lt;v, u&gt;\]</span></p>
<p>We now show that <span class="math inline">\(u\)</span> is unique. Suppose <span class="math inline">\(\psi (v) = &lt;v, u_1 &gt; = &lt;v, u_2&gt;\)</span>, then:</p>
<p><span class="math display">\[&lt;v, u_1&gt; - &lt;v, u_2&gt; = 0\]</span></p>
<p>Thus, we have <span class="math inline">\(\forall v \in V\)</span>:</p>
<p><span class="math display">\[&lt;v, u_1 - u_2&gt; = 0\]</span></p>
<p>This shows that <span class="math inline">\(u_1 = u_2\)</span>.</p>
<h3 id="orthogonal-complements-and-minimization-problems">Orthogonal Complements and Minimization Problems</h3>
<h4 id="definition-6.45-orthogonal-complement-uperp">Definition 6.45: Orthogonal Complement, <span class="math inline">\(U^{\perp}\)</span></h4>
<p>If <span class="math inline">\(U\)</span> is a subset of <span class="math inline">\(V\)</span>, then the <strong>orthogonal complement</strong> of <span class="math inline">\(U\)</span>, denoted <span class="math inline">\(U^{\perp}\)</span> is the set of all vectors in <span class="math inline">\(V\)</span>, that are orthogonal to every vector in <span class="math inline">\(U\)</span>:</p>
<p><span class="math display">\[U^{\perp} = \{v \in V: &lt;v, u&gt; = 0; \forall u \in U\}\]</span></p>
<h4 id="theorem-6.46-basic-properties-of-orthogonal-complement">Theorem 6.46 Basic Properties of Orthogonal Complement</h4>
<ol type="1">
<li>If <span class="math inline">\(U\)</span> is a subset of <span class="math inline">\(V\)</span>, then <span class="math inline">\(U^{\perp}\)</span> is a subspace of <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(\{0\}^{\perp} = V\)</span>.</li>
<li><span class="math inline">\(V^{\perp} = \{0\}\)</span>.</li>
<li>If <span class="math inline">\(U\)</span> is a subset of <span class="math inline">\(V\)</span>, then <span class="math inline">\(U \cap U^{\perp} \subseteq \{0\}\)</span>. (<strong>empty set is subset of every set</strong>)</li>
<li>If <span class="math inline">\(U\)</span> and <span class="math inline">\(W\)</span> are subsets of <span class="math inline">\(V\)</span> and <span class="math inline">\(U \subseteq W\)</span>, then <span class="math inline">\(W^{\perp} \subseteq U^{\perp}\)</span>.</li>
</ol>
<h5 id="proof-of-theorem-6.46">Proof of Theorem 6.46:</h5>
<p>1 to 4 are trivial.</p>
<ol start="5" type="1">
<li>Suppose <span class="math inline">\(U, W\)</span> are subsets of <span class="math inline">\(V\)</span> and <span class="math inline">\(U \subseteq W\)</span>. Suppose <span class="math inline">\(v \in W^{\perp}\)</span>, then <span class="math inline">\(\forall u \in W\)</span>, we have <span class="math inline">\(&lt;u, v&gt; = 0\)</span>. Thus, we have <span class="math inline">\(\forall u \in U\)</span>, <span class="math inline">\(&lt;v, u&gt; = 0\)</span>, so <span class="math inline">\(v \in U^{\perp}, \forall v\in W^{\perp}\)</span>. Hence, <span class="math inline">\(W^{\perp} \subseteq U^{\perp}\)</span>.</li>
</ol>
<h4 id="theorem-6.47-direct-sum-of-a-subspace-and-its-orthogonal-complement">Theorem 6.47: Direct Sum of a Subspace and Its Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(U\)</span> is finite-dimensional subspace of <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[V = U \oplus U^{\perp}\]</span></p>
<h5 id="proof-of-theorem-6.47">Proof of Theorem 6.47:</h5>
<p>We first show that:</p>
<p><span class="math display">\[V = U + W\]</span></p>
<p>Let <span class="math inline">\(U, W\)</span> be a subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(e_1, ..., e_m\)</span> be orthonormal basis of <span class="math inline">\(U\)</span>. Then, <span class="math inline">\(\forall v \in V\)</span> by <code>theorem 6.30</code>:</p>
<p><span class="math display">\[v = \underbrace{(v - &lt;v, e_1&gt;e_1 + ... + &lt;v, e_m&gt;e_m)}_{w} + \underbrace{(&lt;v, e_1&gt;e_1 + ... + &lt;v, e_m&gt;e_m)}_{u}\]</span></p>
<p>Let <span class="math inline">\(u, w\)</span> be defined as above, we clearly have <span class="math inline">\(u \in U\)</span>. Thus:</p>
<p><span class="math display">\[&lt;w, e_j&gt; = &lt;v - &lt;v, e_1&gt;e_1 + ... + &lt;v, e_m&gt;e_m, e_j&gt; = &lt;v, e_j&gt; - &lt;v, e_j&gt; = 0\]</span></p>
<p>So, we have <span class="math inline">\(\forall u \in U\)</span>, <span class="math inline">\(&lt;w, u&gt; = 0\)</span>, so <span class="math inline">\(w \in U^{\perp} = W\)</span>. Thus, <span class="math inline">\(\forall v \in V\)</span> we have:</p>
<p><span class="math display">\[v = u + w\]</span></p>
<p>and <span class="math inline">\(U, W\)</span> are subspaces of <span class="math inline">\(V\)</span>.</p>
<p>Since <span class="math inline">\(U \cap U^{\perp} \subseteq \{0\}\)</span> and <span class="math inline">\(U\)</span> is a subspace so we have <span class="math inline">\(U \cap U^{\perp} = \{0\}\)</span>, by <code>theorem 1.45</code>, we have:</p>
<p><span class="math display">\[V = U \oplus W = U \oplus U^{\perp}\]</span></p>
<h4 id="theorem-6.50-dimension-of-the-orthogonal-complement">Theorem 6.50 Dimension of the Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\dim U^{\perp} = \dim V - \dim U\]</span></p>
<h4 id="theorem-6.51-the-orthogonal-complement-of-the-orthogonal-complement">Theorem 6.51: The Orthogonal Complement of the Orthogonal Complement</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span>, then:</p>
<p><span class="math display">\[U = (U^{\perp})^{\perp}\]</span></p>
<h4 id="definition-6.53-orthogonal-projection-p_u">Definition 6.53: Orthogonal Projection, <span class="math inline">\(P_U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span>. For <span class="math inline">\(v \in V\)</span>, write <span class="math inline">\(v = u + w\)</span>, where <span class="math inline">\(u \in U, w \in U^{\perp}\)</span>, the <strong>orthogonal projection</strong> of <span class="math inline">\(V\)</span> onto <span class="math inline">\(U\)</span> is the operator <span class="math inline">\(P_U \in L(V)\)</span> defined as:</p>
<p><span class="math display">\[P_{U} (v) = u\]</span></p>
<blockquote>
<p>Suppose <span class="math inline">\(v \in V\)</span>. Let <span class="math inline">\(x \in V, x \neq 0\)</span> and <span class="math inline">\(U = span(x)\)</span>, then:</p>
<p><span class="math display">\[v = (\frac{&lt;v, x&gt;}{\|x\|^2} x) + (v - \frac{&lt;v, x&gt;}{\|x\|^2} x)\]</span></p>
<p>The first term is in <span class="math inline">\(U\)</span> and the second therm is in <span class="math inline">\(U^{\perp}\)</span>, thus</p>
<p><span class="math display">\[P_U(v) = \frac{&lt;v, x&gt;}{\|x\|^2} x\]</span></p>
</blockquote>
<h4 id="theorem-6.55-properties-of-the-orthogonal-projection-p_u">Theorem 6.55: Properties of the Orthogonal Projection <span class="math inline">\(P_{U}\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(v \in V\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(P_U \in L(V)\)</span>.</li>
<li><span class="math inline">\(P_U (u) = u, \; \forall u \in U\)</span>.</li>
<li><span class="math inline">\(P_u (w) = 0, \; \forall w \in U^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{range } P_{U} = U\)</span>.</li>
<li><span class="math inline">\(\text{null } P_U = U^{\perp}\)</span>.</li>
<li><span class="math inline">\(v - P_U(v) \in U^{\perp}\)</span></li>
<li><span class="math inline">\(P^2_U = P_U\)</span>.</li>
<li><span class="math inline">\(\|P_U (v)\| \leq \|v\|\)</span>.</li>
<li>For every orthonormal basis <span class="math inline">\(e_1, ..., e_m\)</span> of <span class="math inline">\(U\)</span>, <span class="math display">\[P_U (v) = &lt;v, e_1&gt;e_1 + .... + &lt;v, e_m&gt;e_m\]</span></li>
</ol>
<h4 id="theorem-6.56-minimizing-the-distance-to-a-subspace">Theorem 6.56 Minimizing the Distance to a Subspace</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a finite-dimensional subspace of <span class="math inline">\(V\)</span>, <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(u \in U\)</span>. Then:</p>
<p><span class="math display">\[\|v - P_U (v)\| \leq \|v - u\|\]</span></p>
<p>Furthermore, the inequality above is an equality iFF <span class="math inline">\(u = P_U(v)\)</span>.</p>
<p><strong>Notice there, <span class="math inline">\(u\)</span> and <span class="math inline">\(P_U (v)\)</span> might be different.</strong></p>
<h2 id="operators-on-inner-product-spaces">Operators on Inner Product Spaces</h2>
<h3 id="self-adjoint-and-normal-operators">Self-Adjoint and Normal Operators</h3>
<h4 id="definition-7.2-adjoint-t">Definition 7.2: Adjoint, <span class="math inline">\(T^*\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. The <strong>adjoint</strong> of <span class="math inline">\(T\)</span> is the function <span class="math inline">\(T^*: W \rightarrow V\)</span> s.t:</p>
<p><span class="math display">\[&lt;T(v), w&gt; = &lt;v, T^*(w)&gt;\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span> and every <span class="math inline">\(w \in W\)</span>.</p>
<p><strong>To see why this definition makes sense</strong>, let <span class="math inline">\(T: V \rightarrow \mathbb{F}\)</span> be a linear functional on <span class="math inline">\(V\)</span> defined as:</p>
<p><span class="math display">\[T(v) = &lt;T(v), w&gt;\]</span></p>
<p>for some <span class="math inline">\(w \in W\)</span>. By <code>theorem 6.42</code>, there exists a unique element <span class="math inline">\(v_2\)</span> in <span class="math inline">\(V\)</span> s.t for every element <span class="math inline">\(v \in V\)</span>:</p>
<p><span class="math display">\[T(v) = &lt;T(v), w&gt; = &lt;v, v_2&gt;\]</span></p>
<p>We call this unique vector <span class="math inline">\(T^* (w)\)</span>.</p>
<blockquote>
<p>Define <span class="math inline">\(T: \mathbb{R}^3 \rightarrow \mathbb{R}^2\)</span> by: <span class="math display">\[T(x_1, x_2, x_3) = (x_2 + 3x_3, 2x_1)\]</span></p>
<p>Here <span class="math inline">\(T^*: \mathbb{R}^2 \rightarrow \mathbb{R}^3\)</span> can be found by:</p>
<p><span class="math display">\[&lt;(x_1, x_2, x_3), T^*(y_1, y_2)&gt; = &lt;T(x_1, x_2, x_3), (y_1, y_2)&gt; = &lt;(x_1, x_2, x_3), (2y_2, y_1, 3y_1)&gt;\]</span></p>
<p>Where <span class="math inline">\((y_1, y_2) \in \mathbb{R}^2, (x_1, x_2, x_3) \in \mathbb{R}^3\)</span>.</p>
</blockquote>
<h4 id="theorem-7.5-the-adjoint-is-a-linear-map">Theorem 7.5: The Adjoint is a Linear Map</h4>
<p>If <span class="math inline">\(T \in L(V, W)\)</span>, then <span class="math inline">\(T^* \in L(W, V)\)</span>.</p>
<h4 id="theorem-7.6-properties-of-the-adjoint">Theorem 7.6: Properties of the Adjoint</h4>
<ol type="a">
<li><span class="math inline">\((S + T)^* = S^* + T^*, \; \forall S, T \in L(V, W)\)</span></li>
<li><span class="math inline">\((\lambda T)^* = \bar{\lambda} T^*, \; \forall \lambda \in \mathbb{F}, T \in L(V, W)\)</span></li>
<li><span class="math inline">\((T^*)^* = T\)</span></li>
<li><span class="math inline">\(I^* = I\)</span>, where <span class="math inline">\(I\)</span> is the identity operator on <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\((ST)^* = T^* S^*, \; \forall T \in L(V, W), S \in L(W, U)\)</span></li>
</ol>
<h4 id="theorem-7.7-null-space-and-range-of-t">Theorem 7.7: Null Space and Range of <span class="math inline">\(T^*\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(\text{null } T^* = (\text{range }T)^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{range }T^* = (\text{null } T)^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{null }T = (\text{range }T^*)^{\perp}\)</span>.</li>
<li><span class="math inline">\(\text{range }T = (\text{null }T^*)^{\perp}\)</span>.</li>
</ol>
<h4 id="definition-7.8-conjugate-transpose">Definition 7.8: Conjugate Transpose</h4>
<p>The <strong>conjugate transpose</strong> of an <span class="math inline">\(m \times n\)</span> matrix is the <span class="math inline">\(n \times m\)</span> matrix obtained by interchanging the rows and columns and then taking the complex conjugate of each entry. If <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span>, then the conjugate transpose of a matrix is the same as its <strong>transpose</strong>.</p>
<h4 id="theorem-7.10-the-matrix-of-t">Theorem 7.10: The Matrix of <span class="math inline">\(T^*\)</span></h4>
<p>Let <span class="math inline">\(T \in L(V, W)\)</span>. Suppose <span class="math inline">\(e_1, ..., e_n\)</span> is an <strong>orthonormal basis</strong> of <span class="math inline">\(V\)</span> and <span class="math inline">\(f_1, ..., f_m\)</span> is an orthonormal basis of <span class="math inline">\(W\)</span>. Then:</p>
<p><span class="math display">\[M(T^*, (f_1, ..., f_m), (e_1, ..., e_n))\]</span></p>
<p>is the conjugate transpose of:</p>
<p><strong>Notice that, the result above only applies when we have orthonormal bases, for non-orthonormal bases, the matrix <span class="math inline">\(T^*\)</span> does not necessarily equal the conjugate transpose of the matrix of <span class="math inline">\(T\)</span>.</strong></p>
<h4 id="definition-7.11-self-adjoint-hermitian">Definition 7.11: Self-Adjoint (Hermitian)</h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is called <strong>self-adjoint</strong> if <span class="math inline">\(T = T^*\)</span>. In other words, <span class="math inline">\(T \in L(V)\)</span> is self-adjoint if and only if:</p>
<p><span class="math display">\[&lt;T(v), w&gt; = &lt;v, T(w)&gt;\]</span></p>
<p>for all <span class="math inline">\(v, w \in V\)</span>.</p>
<p><strong>Adjoint on <span class="math inline">\(L(V)\)</span> plays a role similar to complex conjugation on <span class="math inline">\(\mathbb{C}\)</span> and self-adjoint operator is analogous to a real number. Sometimes, people use symmetric for the matrix of self-adjoint operator with real entries.</strong></p>
<h4 id="theorem-7.13-eigenvalues-of-self-adjoint-operators-are-real">Theorem 7.13: Eigenvalues of Self-Adjoint Operators are Real</h4>
<p>Every eigenvalue of a self-adjoint operator is real.</p>
<h4 id="theorem-7.14">Theorem 7.14:</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a <strong>complex inner product space</strong> and <span class="math inline">\(T \in L(V)\)</span>. Suppose:</p>
<p><span class="math display">\[&lt;T(v), v&gt; = 0\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>. Then <span class="math inline">\(T = 0\)</span>.</p>
<p><strong>This result is not true for real value space.</strong></p>
<h4 id="theorem-7.15-over-mathbbc-tv-v-is-real-for-all-v-only-for-self-adjoint-operators">Theorem 7.15: Over <span class="math inline">\(\mathbb{C}\)</span>, <span class="math inline">\(&lt;T(v), v&gt;\)</span> is real for all <span class="math inline">\(v\)</span> only for self-adjoint operators</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex inner product space and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(T\)</span> is self-adjoint if and only if:</p>
<p><span class="math display">\[&lt;T(v), v&gt; \in \mathbb{R}\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span></p>
<h4 id="theorem-7.16-if-t-t-and-tv-v-0-forall-v-then-t-0">Theorem 7.16: If <span class="math inline">\(T = T^*\)</span> and <span class="math inline">\(&lt;T(v), v&gt; = 0; \forall v\)</span>, Then <span class="math inline">\(T = 0\)</span></h4>
<p>Suppose <span class="math inline">\(T\)</span> is self-adjoint operator on <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[&lt;Tv, v&gt; = 0\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>. Then <span class="math inline">\(T = 0\)</span>.</p>
<h4 id="definition-7.18-normal">Definition 7.18: Normal</h4>
<p>An operator on an inner product space is called <strong>normal</strong> if it commutes with its adjoint. In other words, <span class="math inline">\(T \in L(V)\)</span> is normal if <span class="math display">\[TT^* = T^*T\]</span></p>
<p><strong>Every self-adjoint operator is normal</strong></p>
<h4 id="theorem-7.20-t-is-normal-iff-tv-tv-forall-v">Theorem 7.20: <span class="math inline">\(T\)</span> is Normal IFF <span class="math inline">\(\|T(v)\| = \|T^*(v)\| \; \forall v\)</span></h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is normal if and only if:</p>
<p><span class="math display">\[\|T(v)\| = \|T^*(v)\|\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="theorem-7.21-for-t-normal-t-t-have-the-same-eigenvectors">Theorem 7.21: For <span class="math inline">\(T\)</span> normal, <span class="math inline">\(T, T^*\)</span> Have the Same Eigenvectors</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is normal and <span class="math inline">\(v \in V\)</span> is an eigenvector of <span class="math inline">\(T\)</span> with eigenvalue <span class="math inline">\(\lambda\)</span>. Then <span class="math inline">\(v\)</span> is also an eigenvector of <span class="math inline">\(T^*\)</span> with eigenvalue <span class="math inline">\(\bar{\lambda}\)</span>.</p>
<h4 id="theorem-7.22-orthogonal-eigenvectors-for-normal-operators">Theorem 7.22: Orthogonal Eigenvectors for Normal Operators</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is normal. Then eigenvectors of <span class="math inline">\(T\)</span> corresponding to distinct eigenvalues are orthogonal.</p>
<h3 id="the-spectral-theorem">The Spectral Theorem</h3>
<h4 id="theorem-7.24-complex-spectral-theorem">Theorem 7.24: Complex Spectral Theorem</h4>
<p>Suppose <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(T\)</span> is normal.</li>
<li><span class="math inline">\(V\)</span> has an orthonormal basis consisting of eigenvectors of <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T\)</span> has a diagonal matrix with respect to some orthonormal basis of <span class="math inline">\(V\)</span>.</li>
</ol>
<h5 id="proof-theorem-7.24">Proof Theorem 7.24</h5>
<p>Suppose 2 holds, then <span class="math inline">\(T\)</span> has a diagonal matrix, then <span class="math inline">\(T^*\)</span> has a diagonal matrix, since diagonal matrices commute, we have 1.</p>
<p>Suppose 3 holds, similarly 1 holds.</p>
<p>Suppose 1 holds, so <span class="math inline">\(T\)</span> is normal. by <code>theorem 6.38</code>, there is an orthonormal basis <span class="math inline">\(e_1, ..., e_n\)</span> of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has an upper-triangular matrix. Thus, have:</p>
<p><span class="math display">\[\|T(e_1)\|^2 = |a_{1, 1}|^2\]</span></p>
<p><span class="math display">\[\|T^*(e_1)\|^2 = |\overline{a_{1, 1}}|^2 + .... + |\overline{a_{1, n}}|^2 = |a_{1, 1}|^2 + .... + |a_{1, n}|^2\]</span></p>
<p>Since <span class="math inline">\(\|T^*(e_1)\|^2 = \|T(e_1)\|^2\)</span>, we have all entries equal 0 except possibly <span class="math inline">\(a_{1, 1}\)</span>. Repeat this procedure for second column, we have 3.</p>
<h4 id="theorem-7.26-invertible-quadratic-expressions">Theorem 7.26: Invertible Quadratic Expressions</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is self-adjoint and <span class="math inline">\(b, c \in \mathbb{R}\)</span> are such that <span class="math inline">\(b^2 &lt; 4c\)</span>. Then:</p>
<p><span class="math display">\[T^2 + bT + cI\]</span></p>
<p>is invertible.</p>
<h4 id="theorem-7.27-self-adjoint-operators-have-eigenvalues">Theorem 7.27: Self-Adjoint Operators Have Eigenvalues</h4>
<p>Suppose <span class="math inline">\(V \neq \{0\}\)</span> and <span class="math inline">\(T \in L(V)\)</span> is a self-adjoint operator. Then <span class="math inline">\(T\)</span> has an eigenvalue.</p>
<h4 id="theorem-7.28-self-adjoint-operators-and-invariant-subspaces">Theorem 7.28: Self-Adjoint Operators and Invariant Subspaces</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is self-adjoint and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> that is invariant under <span class="math inline">\(T\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(U^{\perp}\)</span> is invariant under <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T|_{U} \in L(U)\)</span> is self-adjoint.</li>
<li><span class="math inline">\(T|_{U^{\perp}} \in L(U^{\perp})\)</span> is self-adjoint.</li>
</ol>
<h4 id="theorem-7.29-real-spectral-theorem">Theorem 7.29: Real Spectral Theorem</h4>
<p>Suppose <span class="math inline">\(\mathbb{F} = \mathbb{R}\)</span> and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(T\)</span> is self-adjoint (Symmetric).</li>
<li><span class="math inline">\(V\)</span> has an orthonormal basis consisting of eigenvectors of <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T\)</span> has a diagonal matrix w.r.t to some orthonormal basis of <span class="math inline">\(V\)</span>.</li>
</ol>
<h3 id="positive-operators-and-isometries">Positive Operators and Isometries</h3>
<h4 id="definition-7.31-positive-operator-positive-semi-definite">Definition 7.31: Positive Operator (Positive Semi-definite)</h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is called <strong>positive</strong> if <span class="math inline">\(T\)</span> is self-adjoint and</p>
<p><span class="math display">\[&lt;T(v), v&gt; \geq 0\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span>.</p>
<p><strong>If <span class="math inline">\(V\)</span> is a complex vector space, then the requirement that <span class="math inline">\(T\)</span> is self-joint can be dropped because we require <span class="math inline">\(&lt;T(v), v&gt; \in \mathbb{R}\)</span></strong>.</p>
<blockquote>
<p>If U is a subspace of <span class="math inline">\(V\)</span>, then the orthogonal projection <span class="math inline">\(P_U\)</span> is a positive operator because: <span class="math display">\[&lt;P_U (v), v&gt; = &lt;u, u + w&gt; = \|u\|^2 \geq 0\]</span></p>
<p>At the same time, <span class="math inline">\(P_U\)</span> is a self-adjoint operator because the matrix of <span class="math inline">\(P_U\)</span> is identity matrix w.r.t orthonormal basis <span class="math inline">\(e_1, ..., e_m\)</span>.</p>
</blockquote>
<h4 id="definition-7.33-square-root">Definition 7.33: Square Root</h4>
<p>An operator <span class="math inline">\(R\)</span> is called a <strong>square root</strong> of an operator <span class="math inline">\(T\)</span> if <span class="math inline">\(R^2 = T\)</span>.</p>
<blockquote>
<p>If <span class="math inline">\(T \in L(\mathbb{F}^3)\)</span> is defined by <span class="math inline">\(T(z_1, z_2, z_3) = (z_3, 0, 0)\)</span>, then the operator <span class="math inline">\(R \in L(\mathbb{F}^3)\)</span> defined by <span class="math inline">\(R(z_1, z_2, z_3) = (z_2, z_3, 0)\)</span> is a square root of <span class="math inline">\(T\)</span>.</p>
</blockquote>
<h4 id="theorem-7.35-characterization-of-positive-operators">Theorem 7.35: Characterization of Positive Operators</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(T\)</span> is positive.</li>
<li><span class="math inline">\(T\)</span> is self-adjoint and all the eigenvalues of <span class="math inline">\(T\)</span> are non-negative.</li>
<li><span class="math inline">\(T\)</span> has a positive square root.</li>
<li><span class="math inline">\(T\)</span> has a self-adjoint square root.</li>
<li>There exists an operator <span class="math inline">\(R \in L(V)\)</span> s.t <span class="math inline">\(T = R^*R\)</span>.</li>
</ol>
<h4 id="theorem-7.36-every-positive-operator-has-only-one-positive-square-root">Theorem 7.36: Every Positive Operator Has Only One Positive Square Root</h4>
<p>Every positive operator on <span class="math inline">\(V\)</span> has a unique positive square root.</p>
<p><strong>A positive operator can have infinitely many square roots, although only one of them can be positive.</strong></p>
<h4 id="definition-7.37-isometry">Definition 7.37: Isometry</h4>
<p>An operator <span class="math inline">\(S \in L(V)\)</span> is called an <strong>isometry</strong> if:</p>
<p><span class="math display">\[\|S(v)\| = \|v\|\]</span></p>
<p>for all <span class="math inline">\(v \in V\)</span></p>
<p>In other words, an operator is an isometry if it preserves norms</p>
<h4 id="theorem-7.42-characterization-of-isometries">Theorem 7.42: Characterization of Isometries</h4>
<p>Suppose <span class="math inline">\(S \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(S\)</span> is an isometry.</li>
<li><span class="math inline">\(&lt;S(u), S(v)&gt; = &lt;u, v&gt;, \; \forall u, v \in V\)</span>.</li>
<li><span class="math inline">\(S(e_1) , ...., S(e_n)\)</span> is orthonormal for every orthonormal list of vectors <span class="math inline">\(e_1, ..., e_n \in V\)</span>.</li>
<li>There exists an orthonormal basis <span class="math inline">\(e_1, ..., e_n\)</span> of <span class="math inline">\(V\)</span> s.t <span class="math inline">\(S(e_1), ..., S(e_n)\)</span> is orthonormal.</li>
<li><span class="math inline">\(S^*S = I\)</span></li>
<li><span class="math inline">\(SS^* = I\)</span></li>
<li><span class="math inline">\(S^*\)</span> is an isometry.</li>
<li><span class="math inline">\(S\)</span> is invertible and <span class="math inline">\(S^{-1} = S^*\)</span>.</li>
<li><span class="math inline">\(S\)</span> is normal.</li>
</ol>
<h4 id="theorem-7.43-description-of-isometries-when-mathbbf-mathbbc">Theorem 7.43: Description of Isometries When <span class="math inline">\(\mathbb{F} = \mathbb{C}\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is a complex inner product space and <span class="math inline">\(S \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="a">
<li><span class="math inline">\(S\)</span> is an isometry.</li>
<li>There is an orthonormal basis of <span class="math inline">\(V\)</span> consisting of eigenvectors of <span class="math inline">\(S\)</span> whose corresponding eigenvalues all have absolute value <span class="math inline">\(1\)</span>.</li>
</ol>
<h3 id="polar-decomposition-and-singular-value-decomposition">Polar Decomposition and Singular Value Decomposition</h3>
<h4 id="definition-7.44-sqrtt">Definition 7.44: <span class="math inline">\(\sqrt{T}\)</span></h4>
<p>If <span class="math inline">\(T\)</span> is a positive operator, then <span class="math inline">\(\sqrt{T}\)</span> denotes the unique positive square root of <span class="math inline">\(T\)</span>.</p>
<h4 id="theorem-7.45-polar-decomposition">Theorem 7.45: Polar Decomposition</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then there exists an isometry <span class="math inline">\(S \in L(V)\)</span> s.t:</p>
<p><span class="math display">\[T = S\sqrt{T^*T}\]</span></p>
<h4 id="definition-7.49-singular-value-decomposition">Definition 7.49: Singular Value Decomposition</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. The <strong>singular values</strong> of <span class="math inline">\(T\)</span> are the eigenvalues of <span class="math inline">\(\sqrt{T^* T}\)</span>, with each eigenvalue <span class="math inline">\(\lambda\)</span> repeated <span class="math inline">\(\dim E(\lambda, \sqrt{T^*T})\)</span> times.</p>
<p><strong>The singular values of <span class="math inline">\(T\)</span> are all non-negative, because they are the eigenvalues of the positive operator <span class="math inline">\(\sqrt{T^*T}\)</span></strong></p>
<blockquote>
<p>Define <span class="math inline">\(T \in L(\mathbb{F}^4)\)</span>: <span class="math display">\[T(z_1, z_2, z_3, z_4) = (0, 3z_1, 2z_2, -3z_4)\]</span></p>
<p>a bit calculation, we have:</p>
<p><span class="math display">\[T^* (x_1, x_2, x_3, x_4) = (3x_2, 2x_3, 0, -3x_4)\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[T^*T(z_1, z_2, z_3, z_4) = (9z_1, 4z_2, 0, 9z_4)\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sqrt{T^* T} (z_1, z_2, z_3, z_4) = (3z_1, 2z_2, 0, 3z_4)\]</span></p>
<p>The eigenvalues are <span class="math inline">\(3, 2, 0\)</span> and: <span class="math display">\[\dim E(3, \sqrt{T^*T}) = 2, \dim E(2, \sqrt{T^*T}) = 1, \dim E(0, \sqrt{T^*T}) = 1\]</span></p>
<p>Hence, the singular values of <span class="math inline">\(T\)</span> are <span class="math inline">\(3, 3, 2, 0\)</span></p>
</blockquote>
<h4 id="theorem-7.51-singular-value-decomposition">Theorem 7.51: Singular Value Decomposition</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> has singular values <span class="math inline">\(s_1, ..., s_n\)</span>. Then there exist orthonormal bases <span class="math inline">\(e_1, ..., e_n\)</span> and <span class="math inline">\(f_1, ..., f_n\)</span> of <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[T(v) = s_1 &lt;v, e_1&gt;f_1 + .... + s_n&lt;v, e_n&gt;f_n\]</span></p>
<p>for every <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="theorem-7.52-singular-values-without-taking-square-root-of-an-operator">Theorem 7.52: Singular Values Without Taking Square Root of an Operator</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. Then the singular values of <span class="math inline">\(T\)</span> are the non-negative square roots of the eigenvalues of <span class="math inline">\(T^*T\)</span>, with each eigenvalue <span class="math inline">\(\lambda\)</span> repeated <span class="math inline">\(\dim E(\lambda, T^*T) times\)</span>.</p>
<h5 id="proof-of-theorem-7.52">Proof of Theorem 7.52:</h5>
<p>Let <span class="math inline">\(e_1, ..., e_n\)</span> be orthonormal basis of <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[\sqrt{T^*T} (e_j) = s_j e_j\]</span></p>
<p>Then:</p>
<p><span class="math display">\[\sqrt{T^*T}\sqrt{T^*T} (e_j) = \sqrt{T^*T}(s_j e_j) = s^2_j e_j = T^*T(e_j)\]</span></p>
<p>Thus, <span class="math inline">\(s^2_j = \lambda_j\)</span> which is the eigenvalue of <span class="math inline">\(T^*T(e_j)\)</span>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/01/19/linear-algebra-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/19/linear-algebra-3/" class="post-title-link" itemprop="url">Linear Algebra (3)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-19 22:25:07" itemprop="dateCreated datePublished" datetime="2022-01-19T22:25:07+08:00">2022-01-19</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-01-25 20:53:51" itemprop="dateModified" datetime="2022-01-25T20:53:51+08:00">2022-01-25</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/01/19/linear-algebra-3/" class="post-meta-item leancloud_visitors" data-flag-title="Linear Algebra (3)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>14 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="linear-algebra-3">Linear Algebra (3)</h1>
<h2 id="polynomials">Polynomials</h2>
<h3 id="complex-conjugate-and-absolute-value">Complex Conjugate and Absolute Value</h3>
<h4 id="definition-4.2-rez-imz">Definition 4.2: <span class="math inline">\(Re(z)\)</span>, <span class="math inline">\(Im(z)\)</span></h4>
<p>Suppose <span class="math inline">\(z = a + b_i\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are real numbers.</p>
<ul>
<li>The <strong>real part</strong> of <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(Re(z)\)</span>, is defined by <span class="math inline">\(Re(z) = a\)</span>.</li>
<li>The <strong>imaginary part</strong> of <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(Im(z)\)</span>, is defined by <span class="math inline">\(Im(z) = b\)</span>.</li>
</ul>
<p>Thus for every complex number <span class="math inline">\(z\)</span>, we have:</p>
<p><span class="math display">\[z = Re(z) + Im(z) i\]</span></p>
<h4 id="definition-4.3-complex-conjugate-barz-absolute-value-z.">Definition 4.3: Complex Conjugate, <span class="math inline">\(\bar{z}\)</span>, absolute value, |z|.</h4>
<p>Suppose <span class="math inline">\(z \in \mathbb{C}\)</span>:</p>
<ul>
<li>The <strong>complex conjugate</strong> of <span class="math inline">\(z \in \mathbb{C}\)</span>, denoted <span class="math inline">\(\bar{z}\)</span>, is defined by: <span class="math display">\[\bar{z} = Re(z) - Im(z)i\]</span></li>
<li>The <strong>absolute value</strong> of a complex number <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(|z|\)</span>, is defined by: <span class="math display">\[|z| = \sqrt{(Re (z))^2 + (Im (z))^2}\]</span></li>
</ul>
<h4 id="theorem-4.5-properties-of-complex-numbers">Theorem 4.5: Properties of Complex Numbers</h4>
<p>Suppose <span class="math inline">\(w, z \in \mathbb{C}\)</span>. Then:</p>
<ul>
<li><strong>Sum of <span class="math inline">\(z\)</span> and <span class="math inline">\(\bar{z}\)</span></strong>: <span class="math display">\[z + \bar{z} = 2 Re(z)\]</span></li>
<li><strong>Difference of <span class="math inline">\(z\)</span> and <span class="math inline">\(\bar{z}\)</span></strong>: <span class="math display">\[z - \bar{z} = 2(Im (z)) i\]</span></li>
<li><strong>Product of <span class="math inline">\(z\)</span> and <span class="math inline">\(\bar{z}\)</span></strong>: <span class="math display">\[z \bar{z} = |z|^2\]</span></li>
<li><strong>Additive and Multiplicative of Complex Conjugate</strong>: <span class="math display">\[\overline{w + z} = \bar{w} + \bar{z}, \quad \overline{wz} = \bar{w}\bar{z}\]</span></li>
<li><strong>Conjugate of Conjugate</strong>: <span class="math display">\[\bar{\bar{z}} = z\]</span></li>
<li><strong>Real and Imaginary Parts are Bounded by <span class="math inline">\(|z|\)</span></strong>: <span class="math display">\[|Re (z)| \leq |z|, \quad |Im(z)| \leq |z|\]</span></li>
<li><strong>Absolute Value of the Complex Conjugate</strong>: <span class="math display">\[|\bar{z}| = |z|\]</span></li>
<li><strong>Multiplicative of Absolute Value</strong> <span class="math display">\[|wz| = |w||z|\]</span></li>
<li><strong>Triangle Inequality</strong>: <span class="math display">\[|w + z| \leq |w| + |z|\]</span></li>
</ul>
<h3 id="uniqueness-of-coefficients-for-polynomials">Uniqueness of Coefficients for Polynomials</h3>
<p>A function <span class="math inline">\(p: \mathbb{F} \rightarrow \mathbb{F}\)</span> is called a polynomial with coefficients in <span class="math inline">\(\mathbb{F}\)</span> if there exists <span class="math inline">\(a_0 , ..., a_m \in \mathbb{F}\)</span> s.t:</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + .... + a_mz^m\]</span></p>
<p>for all <span class="math inline">\(z \in \mathbb{F}\)</span></p>
<h4 id="theorem-4.7-if-a-polynomial-is-the-zero-function-then-all-coefficients-are-0">Theorem 4.7: If a Polynomial is the Zero Function, Then All Coefficients are <span class="math inline">\(0\)</span></h4>
<p>Suppose <span class="math inline">\(a_0, ..., a_m \in \mathbb{F}\)</span>. If</p>
<p><span class="math display">\[a_0 + a_1 z + ... + a_m z^m = 0\]</span></p>
<p>for every <span class="math inline">\(z \in \mathbb{F}\)</span>, then <span class="math inline">\(a_0 = ... = a_m = 0\)</span></p>
<p><strong>This results show that the coefficients of a polynomial are uniquely determined</strong>.</p>
<p>Recall that if a polynomial <span class="math inline">\(p\)</span> with <span class="math inline">\(a_m \neq 0\)</span>, then we say that <span class="math inline">\(p\)</span> has degree <span class="math inline">\(m\)</span>, and we write <span class="math inline">\(\deg p = m\)</span>. The degree of <span class="math inline">\(0\)</span> polynomial is defined to be <span class="math inline">\(-\infty\)</span>.</p>
<h4 id="theorem-4.8-division-algorithm-for-polynomials">Theorem 4.8: Division Algorithm for Polynomials</h4>
<p>Suppose that <span class="math inline">\(p, s \in P(\mathbb{F})\)</span>, with <span class="math inline">\(s \neq 0\)</span>. Then there exist unique polynomials, <span class="math inline">\(q, r \in P(\mathbb{F})\)</span> s.t:</p>
<p><span class="math display">\[p = sq + r\]</span></p>
<p>and <span class="math inline">\(\text{deg } r &lt; \text{deg } s\)</span></p>
<h4 id="definition-4.9-zero-of-a-polynomial">Definition 4.9: Zero of a Polynomial</h4>
<p>A number <span class="math inline">\(\lambda \in \mathbb{F}\)</span> is called a <strong>zero or root</strong> of a polynomial <span class="math inline">\(p \in P(\mathbb{F})\)</span> if:</p>
<p><span class="math display">\[p(\lambda) = 0\]</span></p>
<h4 id="definition-4.10-factor">Definition 4.10: Factor</h4>
<p>A polynomial <span class="math inline">\(s \in P(\mathbb{F})\)</span> is called a <strong>factor</strong> of <span class="math inline">\(p \in P(\mathbb{F})\)</span> if there exists a polynoimal <span class="math inline">\(q \in P(\mathbb{F})\)</span> s.t <span class="math inline">\(p = sq\)</span>.</p>
<h4 id="theorem-4.11-each-zero-of-a-polynomial-corresponds-to-a-degree-1-factor">Theorem 4.11: Each Zero of a Polynomial Corresponds to a Degree-1 Factor</h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{F})\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Then <span class="math inline">\(p(\lambda) = 0\)</span> if and only if there is a polynomial <span class="math inline">\(q \in P(\mathbb{F})\)</span> s.t:</p>
<p><span class="math display">\[p(z) = (z - \lambda) q(z)\]</span></p>
<p>for every <span class="math inline">\(z \in \mathbb{F}\)</span></p>
<h4 id="theorem-4.12-a-polynomial-has-at-most-as-many-zeros-as-its-degree">Theorem 4.12: A Polynomial has at most as many Zeros as Its Degree</h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{F})\)</span> is a polynomial with degree <span class="math inline">\(m \geq 0\)</span>. Then <span class="math inline">\(p\)</span> has at most <span class="math inline">\(m\)</span> distinct zeros in <span class="math inline">\(\mathbb{F}\)</span>.</p>
<h4 id="theorem-4.13-fundamental-theorem-of-algebra">Theorem 4.13: Fundamental Theorem of Algebra</h4>
<p>Every nonconstant polynomial with complex coefficients has a zero.</p>
<h4 id="theorem-4.14-factorization-of-a-polynomial-over-mathbbc">Theorem 4.14: Factorization of a Polynomial over <span class="math inline">\(\mathbb{C}\)</span></h4>
<p>If <span class="math inline">\(p \in P(\mathbb{C})\)</span> is a nonconstant polynomial, then <span class="math inline">\(p\)</span> has a unique factorization except for the order of the factors of the form:</p>
<p><span class="math display">\[p(z) = c(z - \lambda_1) ... (z - \lambda_m)\]</span></p>
<p>where <span class="math inline">\(c, \lambda_1, ..., \lambda_m \in \mathbb{C}\)</span>, <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are the zeros of <span class="math inline">\(p\)</span>.</p>
<p><strong>The failure of the fundamental theorem of algebra for <span class="math inline">\(\mathbb{R}\)</span> accounts for the differences between operators on real and complex vector spaces.</strong></p>
<h4 id="theorem-4.15-polynomials-with-real-coefficients-have-zeros-in-pairs">Theorem 4.15: Polynomials with Real Coefficients Have Zeros in Pairs</h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{C})\)</span> is a polynomial with real coefficients. If <span class="math inline">\(\lambda \in \mathbb{C}\)</span> is a zero of <span class="math inline">\(p\)</span>, then so is <span class="math inline">\(\bar{\lambda}\)</span>.</p>
<h5 id="proof-of-theorem-4.15">Proof of Theorem 4.15</h5>
<p>Let:</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + .... + a_m z^m\]</span></p>
<p>If <span class="math inline">\(\lambda\)</span> is a root of <span class="math inline">\(p\)</span>, we have:</p>
<p><span class="math display">\[p(\lambda) = a_0 + a_1 \lambda_m + .... + a_m \lambda^m = 0\]</span></p>
<p>By taking the conjugate:</p>
<p><span class="math display">\[\overline{a_0 + a_1 \lambda_m + .... + a_m \lambda^m} = a_0 + a_1 \bar{\lambda} + ... + a_m \bar{\lambda}^m = 0\]</span></p>
<h4 id="theorem-4.16-factorization-of-a-quadratic-polynomial">Theorem 4.16: Factorization of a Quadratic Polynomial</h4>
<p>Suppose <span class="math inline">\(b, c \in \mathbb{R}\)</span>. Then there is a polynomial factorization of the form:</p>
<p><span class="math display">\[x^2 + bx + c = (x  - \lambda_1) (x - \lambda_2)\]</span></p>
<p>with <span class="math inline">\(\lambda_1, \lambda_2 \in \mathbb{R}\)</span> if and only if <span class="math inline">\(b^2 \geq 4c\)</span></p>
<h4 id="theorem-4.17-factorization-of-a-polynomial-over-mathbbr">Theorem 4.17: Factorization of a Polynomial over <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>Suppose <span class="math inline">\(p \in P(\mathbb{R})\)</span> is a nonconstant polynomial. Then <span class="math inline">\(p\)</span> has a unique factorization of the form:</p>
<p><span class="math display">\[p(x) = c(x - \lambda_1) ... (x - \lambda_m) (x^2 + b_1 x + c_1 ) ... (x^2 + b_M x + c_M)\]</span></p>
<p>where <span class="math inline">\(c, \lambda_1, ..., \lambda_m, b_1, ..., b_M, c_1, ..., c_M \in \mathbb{R}\)</span>, with <span class="math inline">\(b_j^2 &lt; 4c_j\)</span> for each <span class="math inline">\(j\)</span>.</p>
<p><br></p>
<h2 id="eigenvalues-eigenvectors-and-invariant-subspaces">Eigenvalues, Eigenvectors, and Invariant Subspaces</h2>
<h3 id="invariant-subspaces">Invariant Subspaces</h3>
<p>Let <span class="math inline">\(T \in L(V)\)</span>, <span class="math inline">\(U \subseteq V\)</span> be a proper subspace, then <span class="math inline">\(T|_U\)</span> denotes the domain of <span class="math inline">\(T\)</span> restrict to the set <span class="math inline">\(U\)</span>.</p>
<h4 id="definition-5.2-invariant-subspace">Definition 5.2: Invariant Subspace</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> is an operator on <span class="math inline">\(V\)</span>. A subspace <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> is called <strong>invariant</strong> under <span class="math inline">\(T\)</span> if <span class="math inline">\(u \in U \implies T(u) \in U\)</span>.</p>
<p>In other words, <span class="math inline">\(U\)</span> is invariant under <span class="math inline">\(T\)</span> if <span class="math inline">\(T|_U\)</span> is an operator on <span class="math inline">\(U\)</span>.</p>
<blockquote>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>, then the following subspaces are invariant under <span class="math inline">\(T\)</span>:</p>
<p><span class="math inline">\(\{0\}\)</span></p>
<p><span class="math inline">\(V\)</span></p>
<p><span class="math inline">\(\text{null } T\)</span></p>
<p><span class="math inline">\(\text{range } T\)</span></p>
</blockquote>
<h3 id="eigenvalues-and-eigenvectors">EigenValues and Eigenvectors</h3>
<p>Take any <span class="math inline">\(v \in V\)</span> with <span class="math inline">\(v \neq 0\)</span> and let <span class="math inline">\(U\)</span> equal the set of all scalar multiples of <span class="math inline">\(v\)</span>:</p>
<p><span class="math display">\[U = \{\lambda v : \lambda \in \mathbb{F}\} = span (v)\]</span></p>
<p>Then <span class="math inline">\(U\)</span> is a 1-dimensional subspace of <span class="math inline">\(V\)</span>. If <span class="math inline">\(T\)</span> is a linear operator s.t <span class="math inline">\(T(v) \in U\)</span>, then:</p>
<p><span class="math display">\[T(v) = \lambda v\]</span></p>
<p>For some <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Conversely, if <span class="math inline">\(T(v) = \lambda v\)</span> for some <span class="math inline">\(\lambda \in \mathbb{F}\)</span>, then <span class="math inline">\(U = span(v)\)</span> is a 1-dimensional invariant subspace of <span class="math inline">\(V\)</span> under <span class="math inline">\(T\)</span>.</p>
<h4 id="definition-5.5-eigenvalue">Definition 5.5: Eigenvalue</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span>. A number <span class="math inline">\(\lambda \in \mathbb{F}\)</span> is called an <strong>eigenvalue</strong> of <span class="math inline">\(T\)</span> if there exists <span class="math inline">\(v \in V\)</span> s.t <span class="math inline">\(v \neq 0\)</span> and <span class="math inline">\(T(v) = \lambda v\)</span>.</p>
<p>In other words, <span class="math inline">\(T\)</span> has a 1-dimensional subspace IFF <span class="math inline">\(T\)</span> has an eigenvalue.</p>
<h4 id="theorem-5.6-equivalent-conditions-to-be-an-eigenvalue">Theorem 5.6 Equivalent Conditions to be an Eigenvalue</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional, <span class="math inline">\(T \in L(V)\)</span>, and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>.</li>
<li><span class="math inline">\(T - \lambda I\)</span> is not injective.</li>
<li><span class="math inline">\(T - \lambda I\)</span> is not surjective.</li>
<li><span class="math inline">\(T - \lambda I\)</span> is not invertible.</li>
</ol>
<p>where <span class="math inline">\(I \in L(V)\)</span> is the identity operator defined by <span class="math inline">\(I(v) = v, \; \forall v \in V\)</span>.</p>
<h4 id="definition-5.7-eigenvector">Definition 5.7: Eigenvector</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span> is an eigenvalue of <span class="math inline">\(T\)</span>. A vector <span class="math inline">\(v \in V\)</span> is called an <strong>eigenvector</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(v \neq 0\)</span> and <span class="math inline">\(T(v) = \lambda v\)</span>.</p>
<p>In other words, a vector <span class="math inline">\(v \in V\)</span> is an eigenvector of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span> IFF <span class="math inline">\(v \in \text{null } (T - \lambda I)\)</span></p>
<h4 id="theorem-5.10-linearly-independent-eigenvectors">Theorem 5.10: Linearly Independent Eigenvectors</h4>
<p>Let <span class="math inline">\(T \in L(V)\)</span>. Suppose <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are distinct eigenvalues of <span class="math inline">\(T\)</span> and <span class="math inline">\(v_1, ..., v_m\)</span> are corresponding eigenvectors. Then <span class="math inline">\(v_1, ..., v_m\)</span> is linearly independent.</p>
<h4 id="theorem-5.13-number-of-eigenvalues">Theorem 5.13: Number of Eigenvalues</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then each operator on <span class="math inline">\(V\)</span> has at most <span class="math inline">\(\dim V\)</span> distinct eigenvalues.</p>
<h4 id="definition-5.14-t_u-and-t-u">Definition 5.14: <span class="math inline">\(T|_U\)</span> and <span class="math inline">\(T / U\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> invariant under <span class="math inline">\(T\)</span>.</p>
<ul>
<li><p>The <strong>restriction operator</strong> <span class="math inline">\(T|_U \in L(U)\)</span> is defined by: <span class="math display">\[T|_U (u) = T(u)\]</span></p>
<p>for <span class="math inline">\(u \in U\)</span>.</p></li>
<li><p>The <strong>quotient operator</strong> <span class="math inline">\(T / U \in L(V / U)\)</span> is defined by: <span class="math display">\[(T / U) (v + U) = T(v) + U\]</span></p>
<p>for <span class="math inline">\(v \in V\)</span></p></li>
</ul>
<h3 id="eigenvectors-and-upper-triangular-matrices">Eigenvectors and Upper-Triangular Matrices</h3>
<p><strong>The main reason that a richer theory exists for operators (which map a vector space into itself) than for more general linear maps is that operators can be raised to powers.</strong></p>
<h4 id="definition-5.16-tm">Definition 5.16 <span class="math inline">\(T^m\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(m\)</span> is a positive integer.</p>
<ul>
<li><p><span class="math inline">\(T^m\)</span> is defined by: <span class="math display">\[T^m = T \underbrace{...}_{m \text{ times}} T\]</span></p></li>
<li><p><span class="math inline">\(T^0\)</span> is defined to be the identity operator <span class="math inline">\(I\)</span> on <span class="math inline">\(V\)</span>.</p></li>
<li><p>If <span class="math inline">\(T\)</span> is invertible with inverse <span class="math inline">\(T^{-1}\)</span>, then <span class="math inline">\(T^{-m}\)</span> is defined by: <span class="math display">\[T^{-m} = (T^{-1})^m\]</span></p></li>
<li><p><span class="math inline">\(T^m T^n = T^{m + n}\)</span>, <span class="math inline">\((T^{m})^n = T^{mn}\)</span></p></li>
</ul>
<h4 id="definition-5.17-pt">Definition 5.17: <span class="math inline">\(p(T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(p \in P(\mathbb{F})\)</span> is a polynomial given by:</p>
<p><span class="math display">\[p(z) = a_0 + a_1 z + a_2 z^2 + ... + a_m z^m\]</span></p>
<p>for <span class="math inline">\(z \in \mathbb{F}\)</span>. Then, <span class="math inline">\(p(T)\)</span> is the operator defined by:</p>
<p><span class="math display">\[p(T) = a_1 I + a_1 T + .... + a_m T^m\]</span></p>
<blockquote>
<p>Suppose <span class="math inline">\(D \in L(P(\mathbb{R}))\)</span> is the differentiation operator defined by <span class="math inline">\(D(q) = q^{\prime}\)</span> and <span class="math inline">\(p(x) = 16 - 3 x + 5x^3\)</span>. Then:</p>
<p><span class="math display">\[p(D) = 16I - 3 D + 5D^3\]</span></p>
<p>and</p>
<p><span class="math display">\[(p(D))(q) = 16 I - 3 q^{\prime} + 5 q^{\prime \prime \prime}\]</span></p>
</blockquote>
<p><strong>If we fix an operator <span class="math inline">\(T \in L(V)\)</span>, then the function <span class="math inline">\(M: P(\mathbb{F}) \rightarrow L(V)\)</span> defined by <span class="math inline">\(M(p) = p(T)\)</span> is linear.</strong></p>
<h4 id="definition-5.19-product-of-polynomials">Definition 5.19: Product of Polynomials</h4>
<p>If <span class="math inline">\(p, q \in P(\mathbb{F})\)</span>, then <span class="math inline">\(pq \in P(\mathbb{F})\)</span> is the polynomial defined by:</p>
<p><span class="math display">\[(pq)(z) = p(z) q(z)\]</span></p>
<p>for <span class="math inline">\(z \in \mathbb{F}\)</span></p>
<h4 id="theorem-5.20-multiplicative-properties-of-polynomials">Theorem 5.20: Multiplicative Properties of Polynomials</h4>
<p>Suppose <span class="math inline">\(p, q \in P(\mathbb{F})\)</span> and <span class="math inline">\(T \in L(V)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\((pq)(T) = p(T) q(T)\)</span></li>
<li><span class="math inline">\(p(T)q(T) = q(T)p(T)\)</span></li>
</ol>
<p><strong>When expanding a product of polynomials using the distributive property, it does not matter whether the symbol is <span class="math inline">\(z\)</span> or <span class="math inline">\(T\)</span></strong></p>
<h4 id="theorem-5.21-operators-on-complex-vector-spaces-have-an-eigenvalue">Theorem 5.21: Operators on Complex Vector Spaces Have an Eigenvalue</h4>
<p>Every operator on a finite-dimensional, nonzero, complex vector space has an eigenvalue.</p>
<h4 id="definition-5.22-matrix-of-an-operator-mt">Definition 5.22 Matrix of an Operator, <span class="math inline">\(M(T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>. The <strong>matrix of <span class="math inline">\(T\)</span></strong> w.r.t this basis is the <span class="math inline">\(n \times n\)</span> matrix:</p>
<p><span class="math display">\[
M(T) = 
\begin{bmatrix}
A_{1, 1} &amp; ... &amp; A_{1, n}\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
A_{n, 1} &amp; ... &amp; A_{n, n}
\end{bmatrix}
\]</span></p>
<p>whose entries <span class="math inline">\(A_{j, k}\)</span> are defined by:</p>
<p><span class="math display">\[T(v_k) = A_{1, k} v_1 + .... + A_{n, k} v_n\]</span></p>
<p>The <span class="math inline">\(k\)</span>th column of the matrix is formed from the coefficients used to write <span class="math inline">\(T(v_k)\)</span> as a linear combination of <span class="math inline">\(v_1, ..., v_n\)</span>. If the basis is not clear from the context, then the notation <span class="math inline">\(M(T, (v_1, ..., v_n))\)</span> is used or standard bases are assumed.</p>
<blockquote>
<p>Define <span class="math inline">\(T \in L(\mathbb{R}^3)\)</span> by <span class="math inline">\(T(x, y, z) = (2x + y, 5y + 3x, 8z)\)</span>, then <span class="math display">\[
M(T) = 
\begin{bmatrix}
2 &amp; 1 &amp; 0\\
0 &amp; 5 &amp; 3\\
0 &amp; 0 &amp; 8\\
\end{bmatrix}
\]</span></p>
</blockquote>
<h4 id="definition-5.24-diagonal-of-a-matrix">Definition 5.24: Diagonal of a Matrix</h4>
<p>THe <strong>diagonal</strong> of a square matrix consists of the entries along the line from the upper left corner to the bottom right corner.</p>
<h4 id="definition-5.25-upper-triangular-matrix">Definition 5.25 Upper-Triangular Matrix</h4>
<p>A matrix is called <strong>upper triangular</strong> if all the entries below the diagonal equal <span class="math inline">\(0\)</span>.</p>
<h4 id="theorem-5.26-conditions-for-upper-triangular-matrix">Theorem 5.26: Conditions for Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li>The matrix of <span class="math inline">\(T\)</span> w.r.t <span class="math inline">\(v_1, ..., v_n\)</span> is upper triangular.</li>
<li><span class="math inline">\(T(v_j) \in span(v_1, ..., v_j)\)</span> for each <span class="math inline">\(j = 1, ...., n\)</span>.</li>
<li><span class="math inline">\(span(v_1, ..., v_j)\)</span> is invariant under <span class="math inline">\(T\)</span> for each <span class="math inline">\(j = 1 , ..., n\)</span>.</li>
</ol>
<h5 id="proof-of-theorem-5.26">Proof of Theorem 5.26:</h5>
<p><span class="math inline">\(1 \Longleftrightarrow 2, 3 \rightarrow 2\)</span> is trivial, so we only need to prove <span class="math inline">\(2 \rightarrow 3\)</span>.</p>
<p>Suppose <span class="math inline">\(2\)</span> holds and fix <span class="math inline">\(j \in \{1, ..., n\}\)</span> then we have:</p>
<p><span class="math display">\[T(v_1) = span(v_1) \subseteq span(v_1, ..., v_j)\]</span> <span class="math display">\[T(v_2) = span(v_1, v_2) \subseteq span(v_1, ..., v_j)\]</span> <span class="math display">\[.\]</span> <span class="math display">\[.\]</span> <span class="math display">\[.\]</span> <span class="math display">\[T(v_j) = span(v_1, ..., v_j)\]</span></p>
<p>Let <span class="math inline">\(v \in span(v_1, ..., v_j)\)</span>, then <span class="math inline">\(v = a_1v_1 + ... + a_j v_j\)</span>:</p>
<p><span class="math display">\[T(v) = a_1 T(v_1) + ... + a_j T(v_j) \in span(v_1, ..., v_j)\]</span></p>
<p>Thus, we can conclude that <span class="math inline">\(span (v_1, ..., v_j)\)</span> is invariant under <span class="math inline">\(T\)</span>.</p>
<h4 id="theorem-5.27-over-mathbbc-every-operator-has-an-upper-triangular-matrix">Theorem 5.27: Over <span class="math inline">\(\mathbb{C}\)</span>, Every Operator has an Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(V\)</span> is a finite-dimensional complex vector space and <span class="math inline">\(T \in L(V)\)</span>. Then <span class="math inline">\(T\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>.</p>
<p><strong>This result does not hold for real number space, because we are not guaranteed to have an eigenvalue for every operator in the real number vector space.</strong></p>
<h4 id="theorem-5.30-determination-of-invertibility-from-upper-triangular-matrix">Theorem 5.30: Determination of Invertibility from Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(T\)</span> is invertible if and only if all the entries on the diagonal of that upper-triangular matrix are nonzero.</p>
<h4 id="theorem-5.32-determination-of-eigenvalues-from-upper-triangular-matrix">Theorem 5.32: Determination of Eigenvalues from Upper-Triangular Matrix</h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> has an upper-triangular matrix w.r.t some basis of <span class="math inline">\(V\)</span>. Then the eigenvalues of <span class="math inline">\(T\)</span> are precisely the entries on the diagonal of that upper-triangular matrix.</p>
<h5 id="proof-of-theorem-5.32">Proof of Theorem 5.32:</h5>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> w.r.t which <span class="math inline">\(T\)</span> has an upper-triangular matrix:</p>
<p><span class="math display">\[
M(T) = 
\begin{bmatrix}
\lambda_1 &amp; ... &amp; *\\
. &amp; \lambda_2 &amp; .\\
. &amp; ... &amp; .\\
\end{bmatrix}
\]</span></p>
<p>Let <span class="math inline">\(\lambda \in \mathbb{F}\)</span>, then:</p>
<p><span class="math display">\[
M(T - \lambda I) = M(T) - \lambda M(I) = 
\begin{bmatrix}
\lambda_1 - \lambda &amp; ... &amp; *\\
. &amp; \lambda_2 - \lambda &amp; .\\
. &amp; ... &amp; .\\
\end{bmatrix}
\]</span></p>
<p><span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span> IFF <span class="math inline">\(T - \lambda I\)</span> is not invertible, which means that by <code>theorem 5.30</code>, at least one of the diagonal entries of <span class="math inline">\(M(T - \lambda I)\)</span> has to be zero. So the eigenvalue is one of the diagonal entries.</p>
<h3 id="eigenspaces-and-diagonal-matrices">Eigenspaces and Diagonal Matrices</h3>
<h4 id="definition-5.34-diagonal-matrix">Definition 5.34: Diagonal Matrix</h4>
<p>A <strong>diagonal matrix</strong> is a square matrix that is <span class="math inline">\(0\)</span> everywhere except possibly along the diagonal.</p>
<p>If an operator has a diagonal matrix with respect to some basis, then the entries along the diagonal are precisely the eigenvalues of the operator.</p>
<h4 id="definition-5.36-eigenspace-elambda-t">Definition 5.36: Eigenspace, <span class="math inline">\(E(\lambda, T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. The <strong>eigenspace</strong> of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span>, denoted <span class="math inline">\(E(\lambda, T)\)</span>, is defined by:</p>
<p><span class="math display">\[E(\lambda, T) = \text{null}(T - \lambda I)\]</span></p>
<p>In other words, <span class="math inline">\(E(\lambda, T)\)</span> is the set of span of all eigenvectors of <span class="math inline">\(T\)</span> corresponding to <span class="math inline">\(\lambda\)</span>, along with the <span class="math inline">\(0\)</span> vector and <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(T\)</span> IFF <span class="math inline">\(E(\lambda, T) \neq \{0\}\)</span>.</p>
<h4 id="theorem-5.38-sum-of-eigenspaces-is-a-direct-sum">Theorem 5.38: Sum of Eigenspaces is a Direct Sum</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V)\)</span>. Suppose also that <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> are distinct eigenvalues of <span class="math inline">\(T\)</span>. Then:</p>
<p><span class="math display">\[E(\lambda_1, T) + ... + E(\lambda_m, T)\]</span></p>
<p>is a direct sum. Furthermore,</p>
<p><span class="math display">\[\dim E(\lambda_1, T) + ... + \dim E(\lambda_m, T) \leq \dim V\]</span></p>
<h4 id="definition-5.39-diagonalizable">Definition 5.39: Diagonalizable</h4>
<p>An operator <span class="math inline">\(T \in L(V)\)</span> is called diagonalizable if the operator has a diagonal matrix with respect ot some basis of <span class="math inline">\(V\)</span>.</p>
<blockquote>
<p>Define <span class="math inline">\(T \in L(\mathbb{R}^2)\)</span> by: <span class="math display">\[T(x, y) = (41x + 7y, -20x + 74y)\]</span></p>
<p><span class="math inline">\(T\)</span> is diagonalizable w.r.t the basis <span class="math inline">\((1, 4), (7, 5)\)</span></p>
</blockquote>
<h4 id="theorem-5.41-conditions-equivalent-to-diagonalizability">Theorem 5.41: Conditions Equivalent to Diagonalizability</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V)\)</span>. Let <span class="math inline">\(\lambda_1, ..., \lambda_m\)</span> denote the distinct eigenvalues of <span class="math inline">\(T\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(T\)</span> is diagonalizable.</li>
<li><span class="math inline">\(V\)</span> has a basis consisting of eigenvectors of <span class="math inline">\(T\)</span>.</li>
<li>There exists <span class="math inline">\(1\)</span>-dimensional subspaces <span class="math inline">\(U_1, ..., U_n\)</span> of <span class="math inline">\(V\)</span>, each invariant under <span class="math inline">\(T\)</span>, such that: <span class="math display">\[V = U_1 \oplus .... \oplus U_n\]</span></li>
<li><span class="math inline">\(V = E(\lambda_1, T) \oplus ... \oplus E(\lambda_m, T)\)</span></li>
<li><span class="math inline">\(\dim V = \dim E(\lambda_1, T) + ... + \dim E(\lambda_m, T)\)</span></li>
</ol>
<h5 id="proof-of-theorem-5.41">Proof of Theorem 5.41</h5>
<p><span class="math inline">\(1 \Longleftrightarrow 2\)</span> is trivial. Let <span class="math inline">\(v_1, .., v_n\)</span> be a basis s.t <span class="math inline">\(T\)</span> is diagonalizable, then we have <span class="math inline">\(T(v_j) = \lambda_j v_j\)</span>, so <span class="math inline">\(\{v_j\}\)</span> are eigenvectors of <span class="math inline">\(T\)</span> and basis of <span class="math inline">\(V\)</span>.</p>
<p>Suppose <span class="math inline">\(2\)</span> holds, then <span class="math inline">\(v_1, ..., v_n\)</span> is an eigenvector basis of <span class="math inline">\(V\)</span>. Let <span class="math inline">\(U_1 = span(v_1), ...., U_n = span(v_n)\)</span>, since <span class="math inline">\(v_1, ..., v_n\)</span> are eigenvectors of <span class="math inline">\(T\)</span>, then <span class="math inline">\(U_1, ..., U_n\)</span> are <span class="math inline">\(1\)</span>-dimensional invariant subspaces. Since <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, we have each vector <span class="math inline">\(v \in V\)</span> can be uniquely write as linear combination of <span class="math inline">\(u_j \in U_j\)</span>:</p>
<p><span class="math display">\[v = a_1v_1 + ... + a_n v_n = u_1 + ... + u_n\]</span></p>
<p>Thus, we have <span class="math inline">\(V = U_1 \oplus ... \oplus U_n\)</span>, <span class="math inline">\(2 \rightarrow 3\)</span>.</p>
<p>Suppose <span class="math inline">\(3\)</span> holds, then <span class="math inline">\(U_1 = span(v_1), ..., U_n = span(v_n)\)</span>, where <span class="math inline">\(u_1, ..., u_n\)</span> are eigenvector of <span class="math inline">\(T\)</span>, since <span class="math inline">\(V = U_1 \oplus ... \oplus U_n\)</span>, we have:</p>
<p><span class="math display">\[v = u_1 + ... + u_n = a_1 v_1 + ... + a_n v_n, \; \forall v \in V\]</span></p>
<p>Thus, we have <span class="math inline">\(v_1, ..., v_n\)</span> being eigenvector basis of <span class="math inline">\(V\)</span>, which implies <span class="math inline">\(2\)</span>.</p>
<p>Suppose <span class="math inline">\(2\)</span> holds, we have a basis consisting of eigenvectors of <span class="math inline">\(T\)</span>. Hence, every vector of <span class="math inline">\(V\)</span> can be written as:</p>
<p><span class="math display">\[v = a_1 v_1 + ... + a_n v_n = u_1 + ... + u_n\]</span></p>
<p>Where <span class="math inline">\(u_i \in \text{null} (T - \lambda_j I), \; i \in \{1, ..., n\}, j \in \{1, ..., m\}\)</span>. Thus, we have:</p>
<p><span class="math display">\[V = E(\lambda_1, T) + ... + E(\lambda_m, T)\]</span></p>
<p>By <code>theorem 5.38</code>, we have:</p>
<p><span class="math display">\[V = E(\lambda_1, T) \oplus ... \oplus E(\lambda_m, T)\]</span></p>
<p>Thus, <span class="math inline">\(2 \rightarrow 4\)</span>.</p>
<p>By <code>theorem 5.38</code>, we can easily see that <span class="math inline">\(4 \rightarrow 5\)</span></p>
<p>Finally, suppose <span class="math inline">\(5\)</span> holds, we have:</p>
<p><span class="math display">\[\dim V = \dim E(\lambda_1, T) + ... +  \dim E(\lambda_m, T)\]</span></p>
<p>Choose a basis of each <span class="math inline">\(E(\lambda_j, T)\)</span> and put all these bases together to form a list <span class="math inline">\((v_1, ..., v_n)\)</span> of eigenvectors of <span class="math inline">\(T\)</span>, where <span class="math inline">\(n = \dim V\)</span>. To show that they are linearly independent, suppose that:</p>
<p><span class="math display">\[a_1 v_1 + ... a_n v_n = 0\]</span></p>
<p>For each <span class="math inline">\(j = 1, ..., m\)</span>, let <span class="math inline">\(u_j\)</span> denote the sum of all the terms <span class="math inline">\(a_kv_k\)</span> s.t <span class="math inline">\(v_k \in E(\lambda_j, T)\)</span>. Thus, each <span class="math inline">\(u_j\)</span> is in <span class="math inline">\(E(\lambda_j, T)\)</span>, and:</p>
<p><span class="math display">\[u_1 + ... + u_m = 0\]</span></p>
<p>Since eigenvectors corresponding to different eigenvalues are independent and <span class="math inline">\(u_i\)</span> is sum of basis in <span class="math inline">\(E(\lambda_j, T)\)</span>, we have <span class="math inline">\(u_1, ..., u_m\)</span> independent and all <span class="math inline">\(a_k = 0\)</span>. Thus, <span class="math inline">\(5 \rightarrow 2\)</span>.</p>
<h4 id="theorem-5.44-enough-eigenvalues-implies-diagonalizability">Theorem 5.44: Enough Eigenvalues Implies Diagonalizability</h4>
<p>If <span class="math inline">\(T \in L(V)\)</span> has <span class="math inline">\(\dim V\)</span> distinct eigenvalues, then <span class="math inline">\(T\)</span> is diagonalizable.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/01/09/linear-algebra-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/09/linear-algebra-2/" class="post-title-link" itemprop="url">Linear Algebra (2)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-09 21:32:35" itemprop="dateCreated datePublished" datetime="2022-01-09T21:32:35+08:00">2022-01-09</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-09 23:11:37" itemprop="dateModified" datetime="2022-02-09T23:11:37+08:00">2022-02-09</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/01/09/linear-algebra-2/" class="post-meta-item leancloud_visitors" data-flag-title="Linear Algebra (2)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>27k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>24 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="linear-algebra-2">Linear Algebra (2)</h1>
<h2 id="finite-dimensional-vector-space">Finite Dimensional Vector Space</h2>
<h3 id="span-and-linear-independence">Span and Linear Independence</h3>
<p><strong>List of vectors are written without surrounding parentheses. For example <span class="math inline">\((4, 1, 6), (9, 5, 7)\)</span> is a list of length 2 of vectors in <span class="math inline">\(\mathbb{R}^3\)</span></strong>.</p>
<h4 id="definition-2.3-linear-combination">Definition 2.3: Linear Combination</h4>
<p>A <strong>linear combination</strong> of a list <span class="math inline">\(v_1, ..., v_m\)</span> of vectors in <span class="math inline">\(V\)</span> is a vector of the form:</p>
<p><span class="math display">\[a_1v_1 + ... + a_m v_m\]</span></p>
<p>where <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span></p>
<blockquote>
<p><span class="math inline">\((17, -4, 2)\)</span> is a linear combination of list of vectosr <span class="math inline">\((2, 1, -3), (1, -2, 4)\)</span> with <span class="math inline">\(a_1 = 6, a_2=5\)</span>.</p>
</blockquote>
<h4 id="definition-2.5-span-linear-span">Definition 2.5: Span (Linear Span)</h4>
<p>The set of all linear combinations of a list of vectors <span class="math inline">\(v_1, ..., v_m\)</span> in <span class="math inline">\(V\)</span> is called the <strong>span</strong> of <span class="math inline">\(v_1, ..., v_m\)</span>, denoted <span class="math inline">\(span(v_1, ..., v_m)\)</span>. In other words,</p>
<p><span class="math display">\[span(v_1, ..., v_m) = \{a_1v_1 + .... + a_m v_m; a_1, ..., a_m \in \mathbb{F}\}\]</span></p>
<p><strong>The span of a list of vectors in <span class="math inline">\(V\)</span> is the smallest subspace of <span class="math inline">\(V\)</span> containing all the vectors in the list.</strong></p>
<h4 id="definition-2.8-spans">Definition 2.8: Spans</h4>
<p>If <span class="math inline">\(span(v_1, .., v_m) = V\)</span>, we say that <span class="math inline">\(v_1, ..., v_m\)</span> <strong>spans</strong> <span class="math inline">\(V\)</span>.</p>
<h4 id="definition-2.10-finite-dimensional-vector-space">Definition 2.10: Finite-dimensional Vector Space</h4>
<p>A vector space is called <strong>finite-dimensional</strong> if some list of vectors in it spans the space. (every list has finite length)</p>
<h4 id="definition-2.11-polynomial-pmathbbf">Definition 2.11: Polynomial, <span class="math inline">\(P(\mathbb{F})\)</span></h4>
<p>A function <span class="math inline">\(p: \mathbb{F} \rightarrow \mathbb{F}\)</span> is called a <strong>polynomial</strong> with coefficients in <span class="math inline">\(\mathbb{F}\)</span> if there exist <span class="math inline">\(a_0, ..., a_m \in \mathbb{F}\)</span> s.t:</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + a_2z^2 + .... + a_m z^m\]</span></p>
<p>for all <span class="math inline">\(z \in \mathbb{F}\)</span>.</p>
<p><span class="math inline">\(P(\mathbb{F})\)</span> is the set of all polynomials with coefficients in <span class="math inline">\(\mathbb{F}\)</span>. (so it is the set of functions) With the usual operations of addition and scalar multiplication, <span class="math inline">\(P(\mathbb{F})\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span> or it is a subspace of <span class="math inline">\(\mathbb{F}^{\mathbb{F}}\)</span>.</p>
<h4 id="definition-2.12-degree-of-a-polynomial">Definition 2.12: Degree of a Polynomial</h4>
<p>A polynomial <span class="math inline">\(p \in P(\mathbb{F})\)</span> is said to have <strong>degree</strong> <span class="math inline">\(m\)</span> if there exist scalars <span class="math inline">\(a_0 ,..., a_m \in \mathbb{F}\)</span> with <span class="math inline">\(a_m \neq 0\)</span> s.t</p>
<p><span class="math display">\[p(z) = a_0 + a_1z + ... + a_m z^m\]</span></p>
<p>for all <span class="math inline">\(z \in \mathbb{F}\)</span> . If <span class="math inline">\(p\)</span> has degree <span class="math inline">\(m\)</span>, we write <span class="math inline">\(\text{deg} \;p = m\)</span>.</p>
<p>The polynomial that is identically <span class="math inline">\(0\)</span> is said to have degree <span class="math inline">\(-\infty\)</span>.</p>
<h4 id="definition-2.13-p_mmathbbf">Definition 2.13: <span class="math inline">\(P_m(\mathbb{F})\)</span></h4>
<p>For <span class="math inline">\(m\)</span> a nonnegative integer, <span class="math inline">\(P_m (\mathbb{F})\)</span> denotes the set of all polynomials with coefficients in <span class="math inline">\(\mathbb{F}\)</span> and degree at most <span class="math inline">\(m\)</span>. Then <span class="math inline">\(P_m (\mathbb{F})\)</span> is a finite-dimensional vector space for each nonnegative integer <span class="math inline">\(m\)</span>.</p>
<h4 id="definition-2.15-infinite-dimensional-vector-space">Definition 2.15: Infinite-Dimensional Vector Space</h4>
<p>A vector space is called <strong>infinite-dimensional</strong> if it is not finite-dimensional.</p>
<h4 id="definition-2.17-linearly-independent">Definition 2.17: Linearly Independent</h4>
<p>A list <span class="math inline">\(v_1, ..., v_m\)</span> of vectors in <span class="math inline">\(V\)</span> is called <strong>linearly independent</strong> if the only choice of <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span> that makes <span class="math inline">\(a_1v_1 + ... + a_mv_m = 0\)</span> is <span class="math inline">\(a_1 = ... = a_m = 0\)</span>.</p>
<p>The empty list <span class="math inline">\(()\)</span> is also declared to be linearly independent.</p>
<h4 id="definition-2.19-linearly-dependent">Definition 2.19: Linearly Dependent</h4>
<p>A list of vector in <span class="math inline">\(V\)</span> is called <strong>linearly dependent</strong> if it is not linearly independent.</p>
<p>In other words, a list <span class="math inline">\(v_1, ..., v_m\)</span> of vectors in <span class="math inline">\(V\)</span> is linearly dependent if there exist <span class="math inline">\(a_1, ..., a_m \in \mathbb{F}\)</span>, not all <span class="math inline">\(0\)</span>, such that:</p>
<p><span class="math display">\[a_1v_1 + ... + a_mv_m = 0\]</span></p>
<h4 id="lemma-2.21-linear-dependence-lemma">Lemma 2.21: Linear Dependence Lemma</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_m\)</span> is a linearly dependent list in <span class="math inline">\(V\)</span>. Then there exists <span class="math inline">\(j \in \{1, 2, ...., m\}\)</span> such that the following hold:</p>
<ol type="1">
<li><span class="math inline">\(v_j \in span(v_1, ..., v_{j-1})\)</span></li>
<li>If the <span class="math inline">\(j\)</span>th term is removed from <span class="math inline">\(v_1, ...., v_m\)</span>, the span of the remaining list equals <span class="math inline">\(span(v_1, ..., v_m)\)</span>.</li>
</ol>
<h4 id="definition-2.23-length-of-linearly-independent-list-leq-length-of-spanning-list">Definition: 2.23: Length of Linearly Independent List <span class="math inline">\(\leq\)</span> Length of Spanning List</h4>
<p>In a finite-dimensional vector space, the length of every linearly independent list of vectors is less than or equal to the length of every spanning list of vectors (i.e every list of vectors that spans <span class="math inline">\(V\)</span>).</p>
<h4 id="definition-2.26-finite-dimensional-subspaces">Definition 2.26: Finite-dimensional Subspaces</h4>
<p>Every subspace of a finite-dimensional vector space is finite-dimensional.</p>
<h3 id="bases">Bases</h3>
<h4 id="definition-2.27-basis">Definition 2.27: Basis</h4>
<p>A <strong>basis</strong> of <span class="math inline">\(V\)</span> is a list of vectors in <span class="math inline">\(V\)</span> that is linearly independent and spans <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.31-spanning-list-contains-a-basis">Corollary 2.31: Spanning List Contains a Basis</h4>
<p>Every spanning list in a vector space can be reduced to a basis of the vector space.</p>
<h4 id="corollary-2.32-basis-of-finite-dimensional-vector-space">Corollary 2.32: Basis of Finite-Dimensional Vector Space</h4>
<p>Every finite-dimensional vector space has a basis.</p>
<h4 id="corollary-2.33-linearly-independent-list-extands-to-a-basis">Corollary 2.33: Linearly Independent List Extands to a Basis</h4>
<p>Every linearly independent list of vectors in a finite-dimensional vector space can be extended to a basis of the vector space.</p>
<h4 id="corollary-2.34-every-subspace-of-v-is-part-of-a-direct-sum-equal-to-v">Corollary 2.34: Every Subspace of <span class="math inline">\(V\)</span> is part of a Direct Sum Equal to <span class="math inline">\(V\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then there is a subspace <span class="math inline">\(W\)</span> of <span class="math inline">\(V\)</span> s.t <span class="math inline">\(V = U \oplus W\)</span>.</p>
<h3 id="dimension">Dimension</h3>
<h4 id="corollary-2.35-basis-length-does-not-depend-on-basis">Corollary 2.35: Basis Length Does Not Depend on Basis</h4>
<p>Any two bases of a finite-dimensional vector space have the same length.</p>
<h4 id="definition-2.36-dimension-dim-v">Definition 2.36: Dimension, dim <span class="math inline">\(V\)</span></h4>
<p>The <strong>dimension</strong> of a finite-dimensional vector space is the length of any basis of the vector space.</p>
<p>The dimension of <span class="math inline">\(V\)</span> (if <span class="math inline">\(V\)</span> is finite-dimensional) is denoted by dim <span class="math inline">\(V\)</span></p>
<h4 id="corollary-2.38-dimension-of-a-subspace">Corollary 2.38: Dimension of a Subspace</h4>
<p>If <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>, then dim <span class="math inline">\(U\)</span> dim <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.39-linearly-independent-list-of-the-right-length-is-a-basis">Corollary 2.39: Linearly Independent List of the Right Length is a Basis</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then every linearly independent list of vectors in <span class="math inline">\(V\)</span> with length dim <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.42-spanning-list-of-the-right-length-is-a-basis">Corollary 2.42: Spanning List of the Right Length is a Basis</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then, every spanning list of vectors in <span class="math inline">\(V\)</span> with length dim <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V\)</span>.</p>
<h4 id="corollary-2.43-dimension-of-a-sum">Corollary 2.43: Dimension of a Sum</h4>
<p>If <span class="math inline">\(U_1\)</span> amd <span class="math inline">\(U_2\)</span> are subspaces of a finite-dimensional vector space, then</p>
<p><span class="math display">\[\text{dim}(U_1 + U_2) = \text{dim } U_1 + \text{dim } U_2 - \dim(U_1 \cap U_2)\]</span></p>
<h2 id="linear-maps">Linear Maps</h2>
<h3 id="the-vector-space-of-linear-map">The Vector Space of Linear Map</h3>
<p>Assume <span class="math inline">\(V, U, W\)</span> are vector spaces.</p>
<h4 id="definition-3.2-linear-map-linear-transformation">Definition 3.2: Linear Map (Linear Transformation)</h4>
<p>A <strong>linear map</strong> from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is a function <span class="math inline">\(T: V \rightarrow W\)</span> with the following properties:</p>
<ol type="1">
<li><strong>Additivity</strong>: <span class="math display">\[T(v + w) = T(v) + T(w)\]</span></li>
<li><strong>Homogeneity</strong>: <span class="math display">\[T(\lambda v) = \lambda (Tv), \; \forall \lambda \in \mathbb{F}, \; \forall v \in V\]</span></li>
</ol>
<p><span class="math inline">\(Tv = T(v)\)</span></p>
<h4 id="notation-3.3-lv-w">Notation 3.3: <span class="math inline">\(L(V, W)\)</span></h4>
<p>The set of all linear maps from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is denoted <span class="math inline">\(L(V, W)\)</span>.</p>
<h4 id="corollary-3.5-linear-maps-and-basis-of-domain">Corollary 3.5: Linear Maps and Basis of Domain</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_n\)</span> is a basis of <span class="math inline">\(W\)</span>. Then there exists a unique linear map <span class="math inline">\(T: V \rightarrow W\)</span> s.t</p>
<p><span class="math display">\[Tv_j = w_j\]</span></p>
<p>for each <span class="math inline">\(j=1, ..., n\)</span></p>
<h4 id="definition-3.6-addition-and-scalar-multiplication-on-lv-w">Definition 3.6: Addition and Scalar Multiplication on <span class="math inline">\(L(V, W)\)</span></h4>
<p>Suppose <span class="math inline">\(S,T \in L(V, W)\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>. The <strong>sum</strong> <span class="math inline">\(S+T\)</span> and the <strong>product</strong> <span class="math inline">\(\lambda T\)</span> are the linear maps from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> defined by:</p>
<p><span class="math display">\[(S + T) (v) = Sv + Tv\]</span></p>
<p><span class="math display">\[\lambda (T)(v) = \lambda (Tv)\]</span></p>
<h4 id="corollary-3.7-lw-v-is-a-vector-space">Corollary 3.7: <span class="math inline">\(L(W, V)\)</span> is a Vector Space</h4>
<p>With the operations of addition and scalar multiplication as defined in <code>Definition 3.6</code>, <span class="math inline">\(L(V, W)\)</span> is a vector space.</p>
<h4 id="definition-3.8-product-of-linear-maps">Definition 3.8: Product of Linear Maps</h4>
<p>If <span class="math inline">\(T \in L(U, V)\)</span> and <span class="math inline">\(S \in L(V, W)\)</span>, then the <strong>product</strong> <span class="math inline">\(ST \in L(U, W)\)</span> is defined by</p>
<p><span class="math display">\[(ST)(u) = S(T(u))\]</span></p>
<p>for <span class="math inline">\(u \in U\)</span>. In other words, we can write this as composition:</p>
<p><span class="math display">\[(S \circ T) (u)\]</span></p>
<h4 id="corollary-3.9-algebraic-properties-of-products-of-linear-maps">Corollary 3.9: Algebraic Properties of Products of Linear Maps</h4>
<p>Assume all products make sense.</p>
<ol type="1">
<li><p><strong>Associativity</strong>: <span class="math display">\[(T_1T_2)T_3 = T_1(T_2T_3)\]</span></p></li>
<li><p><strong>Identity</strong>: <span class="math display">\[TI = IT = T\]</span> Whenever <span class="math inline">\(T \in L(V, W)\)</span>, the first <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(V\)</span>, the second <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(W\)</span>.</p></li>
<li><p><strong>Distributive</strong>: <span class="math display">\[(S_1 + S_2) T = S_1T + S_2T\]</span> <span class="math display">\[S(T_1 + T_2) = ST_1 + ST_2\]</span></p>
<p>Whenever <span class="math inline">\(T, T_1, T_2 \in L(U, V)\)</span>, <span class="math inline">\(S, S_1, S_2 \in L(V, W)\)</span></p></li>
</ol>
<h4 id="corollary-3.11-linear-maps-take-0-to-0">Corollary 3.11: Linear Maps Take <span class="math inline">\(0\)</span> to <span class="math inline">\(0\)</span></h4>
<p>Suppose <span class="math inline">\(T\)</span> is a linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span>. Then <span class="math inline">\(T(0) = 0\)</span>. In other words, the linear map, maps additive identity in <span class="math inline">\(V\)</span> to additive identity in <span class="math inline">\(W\)</span>.</p>
<p><br></p>
<h3 id="null-spaces-and-ranges">Null Spaces and Ranges</h3>
<h4 id="definition-3.12-null-space-null-t">Definition 3.12: Null Space, null <span class="math inline">\(T\)</span></h4>
<p>For <span class="math inline">\(T \in L(V, W)\)</span>, the <strong>null space</strong> of <span class="math inline">\(T\)</span>, denoted null <span class="math inline">\(T\)</span>, is the subset of <span class="math inline">\(V\)</span> consisting of those vectors that <span class="math inline">\(T\)</span> maps to <span class="math inline">\(0\)</span>:</p>
<p><span class="math display">\[\text{null } T = \{v \in V: T(v) = 0\}\]</span></p>
<h4 id="corollary-3.14-the-null-space-is-a-subspace">Corollary 3.14: The Null Space is a Subspace</h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Then null <span class="math inline">\(T\)</span> is a subspace of <span class="math inline">\(V\)</span>.</p>
<h4 id="definition-3.15-injective-one-to-one">Definition 3.15: Injective (One to One)</h4>
<p>A fuinction <span class="math inline">\(T: V \rightarrow W\)</span> is called <strong>injective</strong> if <span class="math inline">\(T(u) = T(v) \implies u = v\)</span>.</p>
<h4 id="corollary-3.16-injectivity-is-equivalent-to-null-space-equals-0">Corollary 3.16: Injectivity is Equivalent to Null Space Equals <span class="math inline">\(\{0\}\)</span></h4>
<p>Let <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(T\)</span> is injective if and only if null <span class="math inline">\(T = \{0\}\)</span>.</p>
<h4 id="definition-3.17-range-image">Definition 3.17: Range (Image)</h4>
<p>For <span class="math inline">\(T: V \rightarrow W\)</span>, the <strong>range</strong> of <span class="math inline">\(T\)</span> is the subset of <span class="math inline">\(W\)</span> consisting of those vectors that are of the form <span class="math inline">\(T(v)\)</span> for some <span class="math inline">\(v \in V\)</span>:</p>
<p><span class="math display">\[\text{range } T = \{T(v): v \in V\}\]</span></p>
<h4 id="corollary-3.19-the-range-is-a-subspace">Corollary 3.19: The Range is a Subspace</h4>
<p>If <span class="math inline">\(T \in L(V, W)\)</span>, then range <span class="math inline">\(T\)</span> is a subspace of <span class="math inline">\(W\)</span>.</p>
<h4 id="definition-3.20-surjective-on-to">Definition 3.20: Surjective (On to)</h4>
<p>A function <span class="math inline">\(T: V \rightarrow W\)</span> is called <strong>surjective</strong> if its range equals <span class="math inline">\(W\)</span>:</p>
<p><span class="math display">\[\text{range } T = W\]</span></p>
<h4 id="theorem-3.22-fundamental-theorem-of-linear-maps">Theorem 3.22: Fundamental Theorem of Linear Maps</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. The range <span class="math inline">\(T\)</span> is finite-dimensional and</p>
<p><span class="math display">\[\dim V = \dim \text{null } T + \dim \text{range } T\]</span></p>
<h4 id="corollary-3.23-a-map-to-a-smaller-dimensional-space-is-not-injective">Corollary 3.23: A Map to a Smaller Dimensional Space is not Injective</h4>
<p>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces such that <span class="math inline">\(\dim V &gt; \dim W\)</span>. Then no linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is injective.</p>
<h4 id="corollary-3.24-a-map-to-a-larger-dimensional-space-is-not-surjective">Corollary 3.24: A Map to a Larger Dimensional Space is not Surjective</h4>
<p>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces such that <span class="math inline">\(\dim V &lt; \dim W\)</span>. Then no linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is surjective.</p>
<h4 id="corollary-3.26-homogeneous-system-of-linear-equations-ax-0">Corollary 3.26: Homogeneous System of Linear Equations (<span class="math inline">\(Ax = 0\)</span>)</h4>
<p>A homogeneous system of linear equations with more variables than equations has nonzero solutions. (followed by Corollary 3.23)</p>
<h4 id="corollary-3.29-inhomogeneous-system-of-linear-equations-ax-c">Corollary 3.29: Inhomogeneous System of Linear Equations (<span class="math inline">\(Ax = c\)</span>)</h4>
<p>An inhomogeneous system of linear equations with more equations than variables has no solution for <strong>some choice</strong> of the constant terms. (followed by Corollary 3.24)</p>
<h3 id="matrices">Matrices</h3>
<p><strong>If <span class="math inline">\(T\)</span> is a linear map from <span class="math inline">\(\mathbb{F}^n\)</span> to <span class="math inline">\(\mathbb{F^m}\)</span>, then unless stated, assume the bases in question are the standard ones where the <span class="math inline">\(k\)</span>th basis vector is <span class="math inline">\(1\)</span> in the <span class="math inline">\(k\)</span>th slot and <span class="math inline">\(0\)</span> o.w.</strong></p>
<h4 id="definition-3.30-matrix-a_jk">Definition 3.30: Matrix <span class="math inline">\(A_{j,k}\)</span></h4>
<p>Let <span class="math inline">\(m, n\)</span> denote positive integers. An <span class="math inline">\(m \times n\)</span> <strong>matrix</strong> <span class="math inline">\(A\)</span> is a rectangular array of elements of <span class="math inline">\(\mathbb{F}\)</span> with <span class="math inline">\(m\)</span> rows and <span class="math inline">\(n\)</span> columns:</p>
<p><span class="math display">\[
A = 
\begin{bmatrix}
A_{1, 1} &amp; ... &amp; A_{1, n}\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
. &amp; ... &amp; .\\
A_{m, 1} &amp; ... &amp; A_{m, n}
\end{bmatrix}
\]</span> The notation <span class="math inline">\(A_{j, k}\)</span> denotes the entry in row <span class="math inline">\(j\)</span>, column <span class="math inline">\(k\)</span> of <span class="math inline">\(A\)</span>.</p>
<h4 id="definition-3.32-matrix-of-a-linear-map-m-t">Definition 3.32: Matrix of a Linear Map, <span class="math inline">\(M (T)\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. The <strong>matrix</strong> of <span class="math inline">\(T\)</span> with respect to these bases is the <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix <span class="math inline">\(M(T)\)</span> whose entries <span class="math inline">\(A_{j, k}\)</span> are defined by:</p>
<p><span class="math display">\[T(v_k) = A_{1, k} w_1 + .... + A_{m, k} w_m\]</span></p>
<p>If the bases are not clear from the context, then the notation <span class="math inline">\(M(T, (v_1, ...., v_n), (w_1, ...., w_m))\)</span> are used.</p>
<p><strong>We can think of the <span class="math inline">\(k\)</span>th column of <span class="math inline">\(M(T)\)</span> as <span class="math inline">\(T\)</span> applied to the <span class="math inline">\(k\)</span>th standard basis vector and formed by standard basis in <span class="math inline">\(W\)</span>.</strong></p>
<blockquote>
<p>Suppose <span class="math inline">\(T \in L(\mathbb{F}^2, \mathbb{F}^3)\)</span> is defined as <span class="math display">\[T(x, y) = (x + 3y, 2x+5y, 7x + 9y)\]</span> then, the matrix of <span class="math inline">\(T\)</span> w.r.t the standard bases of <span class="math inline">\(\mathbb{F}^2\)</span> and <span class="math inline">\(\mathbb{F}^3\)</span> is: <span class="math display">\[T(1, 0) = A_1 = (1, 2, 7)\]</span> <span class="math display">\[T(0, 1) = A_2 = (3, 5, 9)\]</span> <span class="math display">\[M(T)  = [A_1, A_2]\]</span></p>
</blockquote>
<h4 id="definition-3.35-matrix-addition">Definition 3.35: Matrix Addition</h4>
<p>The <strong>sum of two matrices <span class="math inline">\(A, C\)</span> of the same size</strong> is the matrix obtained by adding corresponding entries in the matrices:</p>
<p><span class="math display">\[(A + C)_{j, k} = A_{j, k} + C_{j, k}\]</span></p>
<h4 id="corollary-3.36-the-matrix-of-the-sum-of-linear-maps">Corollary 3.36: The Matrix of the Sum of Linear Maps</h4>
<p>Suppose <span class="math inline">\(S, T \in L(V, W)\)</span>. Then <span class="math inline">\(M(S + T) = M(S) + M(T)\)</span></p>
<h4 id="definition-3.37-scalar-multiplication-of-a-matrix">Definition 3.37: Scalar Multiplication of a Matrix</h4>
<p>The product of a scalar <span class="math inline">\(\lambda\)</span> and a matrix <span class="math inline">\(A\)</span> is the matrix obtained by multiplying each entry in the matrix by the scalar:</p>
<p><span class="math display">\[(\lambda A)_{j, k} = \lambda A_{j, k}\]</span></p>
<h4 id="corollary-3.38-the-matrix-of-a-scalar-times-a-linear-map">Corollary 3.38: The Matrix of a Scalar Times a Linear Map</h4>
<p>Suppose <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(M(\lambda T) = \lambda M(T)\)</span>.</p>
<h4 id="notation-3.39-mathbbfm-times-n">Notation 3.39: <span class="math inline">\(\mathbb{F}^{m \times n}\)</span></h4>
<p>For <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> positive integers, the <strong>set</strong> of all <span class="math inline">\(m\)</span>-by-<span class="math inline">\(n\)</span> matrices with entries in <span class="math inline">\(\mathbb{F}\)</span> is denoted by <span class="math inline">\(\mathbb{F}^{m, n}\)</span>.</p>
<h4 id="corollary-3.40-dim-mathbbfm-n-mn">Corollary 3.40: <span class="math inline">\(\dim \mathbb{F}^{m, n} = mn\)</span></h4>
<p>Suppose <span class="math inline">\(m, n\)</span> are positive integers. With addition and scalar multiplication defined in <code>3.35, 3.35</code>, <span class="math inline">\(\mathbb{F}^{m, n}\)</span> is a vector space with dimension <span class="math inline">\(mn\)</span>.</p>
<h4 id="definition-3.41-matrix-multiplication">Definition 3.41: Matrix Multiplication</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix. Then <span class="math inline">\(AC\)</span> is defined to be the <span class="math inline">\(m\)</span> by <span class="math inline">\(p\)</span> matrix whose entry in row <span class="math inline">\(j\)</span>, column <span class="math inline">\(k\)</span>, is given by the following equation:</p>
<p><span class="math display">\[(AC)_{j,k} = \sum^{n}_{r=1} A_{j, r}C_{r, k}\]</span></p>
<p>In other words, the entry in row <span class="math inline">\(j\)</span>, column <span class="math inline">\(k\)</span>, of <span class="math inline">\(AC\)</span> is computed by taking row <span class="math inline">\(j\)</span> of <span class="math inline">\(A\)</span> and column <span class="math inline">\(k\)</span> of <span class="math inline">\(C\)</span>, multiplying together corresponding entries and then summing.</p>
<h4 id="corollary-3.43-the-matrix-of-the-product-of-linear-maps">Corollary 3.43: The Matrix of the Product of Linear Maps</h4>
<p>If <span class="math inline">\(T \in L(U, V)\)</span> and <span class="math inline">\(S \in L(V, W)\)</span>, then <span class="math inline">\(M(ST) = M(S) M(T)\)</span></p>
<h4 id="notation-3.44-a_j-cdot-a_cdot-k">Notation 3.44: <span class="math inline">\(A_{j, \cdot}, A_{\cdot, k}\)</span></h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix:</p>
<ul>
<li>If <span class="math inline">\(1 \leq j \leq m\)</span>, then <span class="math inline">\(A_{j, \cdot}\)</span>, donotes the <span class="math inline">\(1\)</span> by <span class="math inline">\(n\)</span> matrix consisting of row <span class="math inline">\(j\)</span> of <span class="math inline">\(A\)</span>.</li>
<li>If <span class="math inline">\(1 \leq k \leq n\)</span>, then <span class="math inline">\(A_{\cdot, k}\)</span> denotes the <span class="math inline">\(n\)</span> by <span class="math inline">\(1\)</span> matrix consisting of column <span class="math inline">\(k\)</span> of <span class="math inline">\(A\)</span>.</li>
</ul>
<p>Thus, we can think of matrix multiplication as row times column.</p>
<h4 id="corollary-3.49-column-of-matrix-product-equals-matrix-times-column">Corollary 3.49: Column of Matrix Product Equals Matrix Times Column</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix. Then</p>
<p><span class="math display">\[(AC)_{\cdot, k} = A C_{\cdot, k}\]</span></p>
<p>for <span class="math inline">\(1 \leq k \leq p\)</span>.</p>
<h4 id="corollary-3.52-linear-combination-of-columns">Corollary 3.52: Linear Combination of Columns</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(c = [c_1 .... c_n]^T\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(1\)</span> matrix, then:</p>
<p><span class="math display">\[Ac = c_1 A_{\cdot, 1} + ... + c_n A_{\cdot, n}\]</span></p>
<p>In other words, <span class="math inline">\(Ac\)</span> is a linear combination of the columns of <span class="math inline">\(A\)</span>, with the scalars that multiply the columns coming from <span class="math inline">\(c\)</span>.</p>
<h4 id="corollary-3.53-row-of-matrix-product-equals-row-times-matrix">Corollary 3.53: Row of Matrix Product Equals Row Times Matrix</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix, then:</p>
<p><span class="math display">\[(AC)_{j, \cdot} = A_{j, \cdot} C\]</span></p>
<p>for <span class="math inline">\(1 \leq j \leq m\)</span>.</p>
<h4 id="corollary-3.54-linear-combination-of-rows">Corollary 3.54: Linear Combination of Rows</h4>
<p>Suppose <span class="math inline">\(a = [a_1 ... a_n]\)</span> is a <span class="math inline">\(1 \times n\)</span> matrix and <span class="math inline">\(C\)</span> is a <span class="math inline">\(n \times p\)</span> matrix:</p>
<p><span class="math display">\[aC = a_1 C_{1, \cdot} + ... + a_n C_{n, \cdot}\]</span></p>
<p><br></p>
<h3 id="invertibility-and-isomorphic-vector-spaces">Invertibility and Isomorphic Vector Spaces</h3>
<h4 id="definition-3.53-invertible-inverse">Definition 3.53: Invertible, Inverse</h4>
<ul>
<li>A linear map <span class="math inline">\(T \in L(V, W)\)</span> is called <strong>invertible</strong> if there exists a linear map <span class="math inline">\(S \in L(W, V)\)</span> s.t <span class="math inline">\(ST\)</span> equals the identity map on <span class="math inline">\(V\)</span> and <span class="math inline">\(TS\)</span> equals the identity map on <span class="math inline">\(W\)</span>.</li>
<li>A linear map <span class="math inline">\(S \in L(W, V)\)</span> satisfying <span class="math inline">\(ST = I\)</span> and <span class="math inline">\(TS = I\)</span> is called an <strong>inverse</strong> of <span class="math inline">\(T\)</span> (note that the first <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(V\)</span> and the second <span class="math inline">\(I\)</span> is the identity map on <span class="math inline">\(W\)</span>).</li>
</ul>
<h4 id="definition-3.54-inverse-is-unique">Definition 3.54: Inverse is Unique</h4>
<p>An invertible linear map has a unique inverse.</p>
<h4 id="notation-3.55-t-1">Notation 3.55: <span class="math inline">\(T^{-1}\)</span></h4>
<p>If <span class="math inline">\(T\)</span> is invertible, then its inverse is denoted by <span class="math inline">\(T^{-1}\)</span>. In other words, if <span class="math inline">\(T \in L(V, W)\)</span> is invertible, then <span class="math inline">\(T^{-1}\)</span> is the unique element of <span class="math inline">\(L(W, V)\)</span> s.t <span class="math inline">\(T^{-1}T = I\)</span> and <span class="math inline">\(TT^{-1} = I\)</span>.</p>
<h4 id="corollary-3.56-invertibility-is-equivalent-to-injectivity-and-surjectivity">Corollary 3.56: Invertibility is Equivalent to Injectivity and Surjectivity</h4>
<p>A linear map is invertible if and only if it is injective and surjective.</p>
<h4 id="definition-3.58-isomorphism-isomorphic-equal-shape">Definition 3.58: Isomorphism, Isomorphic (Equal Shape)</h4>
<ul>
<li>An <strong>isomorphism</strong> is an invertible linear map.</li>
<li>Two vector space are called <strong>isomorphic</strong> if there is an isomorphism from one vector space onto the other one.</li>
</ul>
<p>One way to think of <strong>isomorphic</strong> is that we can always label <span class="math inline">\(v \in V\)</span> by <span class="math inline">\(T(v) \in W\)</span>, because there is always a linear map that maps <span class="math inline">\(T(v) \in W\)</span> back to <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="corollary-3.59-dimension-shows-whether-vector-spaces-are-isomorphic">Corollary 3.59: Dimension Shows Whether Vector Spaces are Isomorphic</h4>
<p>Two finite-dimensional vector spaces over <span class="math inline">\(\mathbb{F}\)</span> are isomorphic if and only if they have the same dimension.</p>
<h4 id="corollary-3.60-m-is-a-linear-mapping">Corollary 3.60: <span class="math inline">\(M\)</span> is a Linear Mapping</h4>
<p>Given bases of <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, <span class="math inline">\(M\)</span> is a linear mapping following <code>3.36, 3.38</code>.</p>
<h4 id="corollary-3.60-lv-w-and-mathbbfmn-are-isomorphic">Corollary 3.60: <span class="math inline">\(L(V, W)\)</span> and <span class="math inline">\(\mathbb{F}^{m,n}\)</span> are Isomorphic</h4>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. Then <span class="math inline">\(M\)</span> is an isomorphism between <span class="math inline">\(L(V, W)\)</span> and <span class="math inline">\(\mathbb{F}^{m, n}\)</span>.</p>
<h4 id="corollary-3.61-dim-lv-w-dim-v-dim-w">Corollary 3.61: <span class="math inline">\(\dim L(V, W) = (\dim V) (\dim W)\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional. Then <span class="math inline">\(L(V, W)\)</span> is finite dimensional and:</p>
<p><span class="math display">\[\dim L(V, W) = (\dim V) (\dim W)\]</span></p>
<h4 id="definition-3.62-matrix-of-a-vector-mv">Definition 3.62: Matrix of a Vector, <span class="math inline">\(M(v)\)</span></h4>
<p>Suppose <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(v_1, ...., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>. The <strong>matrix of <span class="math inline">\(v\)</span></strong> w.r.t this basis is the <span class="math inline">\(n\)</span> by <span class="math inline">\(1\)</span> matrix:</p>
<p><span class="math display">\[
M(v) = 
\begin{bmatrix}
c_1\\
.\\
.\\
.\\
c_n
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(c_1, ..., c_n\)</span> are the scalars such that:</p>
<p><span class="math display">\[v = c_1 v_1 + ... + c_n v_n\]</span></p>
<p><span class="math inline">\(M(v)\)</span> depends on the bases, so they should be clear from the context and thus it is not included in the notation. <strong>M</strong> is an isomorphism of <span class="math inline">\(V\)</span> onto <span class="math inline">\(\mathbb{F}^{n, 1}\)</span>.</p>
<h4 id="definition-3.64-mt_cdot-k-mtv_k">Definition 3.64: <span class="math inline">\(M(T)_{\cdot, k} = M(T(v_k))\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span> and <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. Let <span class="math inline">\(1 \leq k \leq n\)</span>. Then the <span class="math inline">\(k\)</span>th column of <span class="math inline">\(M(T)\)</span>, which is denoted by <span class="math inline">\(M(T)_{\cdot, k}\)</span>, equals <span class="math inline">\(M(T(v_k))\)</span>.</p>
<h4 id="theorem-3.65-linear-maps-act-like-matrix-multiplication">Theorem 3.65: Linear Maps Act Like Matrix Multiplication</h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span> and <span class="math inline">\(v \in V\)</span>. Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(w_1, ..., w_m\)</span> is a basis of <span class="math inline">\(W\)</span>. Then:</p>
<p><span class="math display">\[M(T(v)) = M(T) M(v)\]</span></p>
<p><br></p>
<p>We can think of every linear map as Matrix because, we can identify any <span class="math inline">\(T(v) \in W\)</span> by:</p>
<p><span class="math display">\[M(T(v)) = M(T) M(v)\]</span></p>
<p><span class="math inline">\(M(T(v))\)</span> can be used to recover any <span class="math inline">\(T(v)\)</span>.</p>
<h4 id="definition-3.67-operator-lv">Definition 3.67: Operator, <span class="math inline">\(L(V)\)</span></h4>
<ul>
<li>A linear map from a vector space to itself is called an <strong>operator</strong>.</li>
<li>The notation <span class="math inline">\(L(V)\)</span> denotes the set of all operators on <span class="math inline">\(V\)</span>: <span class="math display">\[L(V) = L(V, V)\]</span></li>
</ul>
<h4 id="theorem-3.69-injectivity-is-equivalent-ot-surjectivity-in-finite-dimensions">Theorem 3.69: Injectivity is Equivalent ot Surjectivity in Finite Dimensions</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T \in L(V)\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li>T is invertible.</li>
<li>T is injective.</li>
<li>T is surjective.</li>
</ol>
<p><strong>In infinite-dimensional vector space, neither injectivity nor surjectivity implies invertibility.</strong></p>
<h3 id="products-and-quotients-of-vector-spaces">Products and Quotients of Vector Spaces</h3>
<p>As usual when dealing with more than oen vector space, all the vector spaces in use should be over the same field.</p>
<h4 id="definition-3.71-product-of-vector-spaces">Definition 3.71: Product of Vector Spaces</h4>
<p>Suppose <span class="math inline">\(V_1, ..., V_m\)</span> are vector spaces over <span class="math inline">\(\mathbb{F}\)</span>.</p>
<ul>
<li>The <strong>product</strong> <span class="math inline">\(V_1 \times V_2 \times .... \times V_m\)</span> is defined by: <span class="math display">\[V_1 \times ... \times V_2 = \{(v_1, ..., v_m): v_1 \in V_1 , ..., v_m \in V_m\}\]</span></li>
<li>Addition on <span class="math inline">\(V_1 \times V_2 \times ... \times V_m\)</span> is defined by: <span class="math display">\[(u_1, ...., u_m) + (v_1, ...., v_m) = (u_1 + v_1 , ...., u_m + v_m)\]</span></li>
<li>Scalar multiplication on <span class="math inline">\(V_1 \times .... \times V_m\)</span> is defined by: <span class="math display">\[\lambda (v_1, ..., v_m) = (\lambda v_1 , ..., \lambda v_m)\]</span></li>
</ul>
<blockquote>
<p>Elements of <span class="math inline">\(P_2(\mathbb{R}) \times \mathbb{R}^3\)</span> are lists of length 2:</p>
<p><span class="math display">\[(5 - 6x + 16x^2, (1, 2, 3)) \in P_2(\mathbb{R}) \times \mathbb{R}^3\]</span></p>
</blockquote>
<h4 id="theorem-3.73-product-of-vector-space-is-a-vector-space">Theorem 3.73: Product of Vector Space is a Vector Space</h4>
<p>Suppose <span class="math inline">\(V_1, ..., V_m\)</span> are vector spaces over <span class="math inline">\(\mathbb{F}\)</span>. Then <span class="math inline">\(V_1 \times ... \times V_m\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span>.</p>
<p><strong>Elements in <span class="math inline">\(\mathbb{R}^2 \times \mathbb{R}^3\)</span> has length 2 and elements in <span class="math inline">\(\mathbb{R}^5\)</span> has length 5, so they are not identical. But the linear map that takes a vector from first space to second space is clearly an isomorphism, thus these two vector spaces are isomorphic.</strong></p>
<h4 id="theorem-3.76-dimension-of-a-product-is-the-sum-of-dimensions">Theorem 3.76: Dimension of a Product is the Sum of Dimensions</h4>
<p>Suppose <span class="math inline">\(V_1, ..., V_m\)</span> are finite-dimensional vector spaces. Then <span class="math inline">\(V_1 \times ... \times V_m\)</span> is finite-dimensional and:</p>
<p><span class="math display">\[\dim(V_1 \times ... \times V_m) = \dim V_1 + ... + \dim V_m\]</span></p>
<h4 id="proof-of-theorem-3.76">Proof of Theorem 3.76</h4>
<p>Choose a basis of each <span class="math inline">\(V_j\)</span>. For each basis vector of each <span class="math inline">\(V_j\)</span>, consider the element of <span class="math inline">\(V_1 \times ... \times V_m\)</span> that equals the basis vector in the <span class="math inline">\(j\)</span>th slot and 0 in other slots. The list of all such vectors is linearly independent and spans the product space. Thus, it is a basis of <span class="math inline">\(V_1 \times ... \times V_m\)</span>. The length is <span class="math inline">\(\dim V_1 + ... + \dim V_m\)</span>.</p>
<h4 id="theorem-3.77-products-and-direct-sums">Theorem 3.77: Products and Direct Sums</h4>
<p>Suppose that <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Define a linear map <span class="math inline">\(\Gamma: U_1 \times .... \times U_m \rightarrow U_1 + ... + U_m\)</span> by:</p>
<p><span class="math display">\[\gamma (u_1, ...., u_m) = u_1 + ... + u_m\]</span></p>
<p>Then <span class="math inline">\(U_1 + ... + U_m\)</span> is a direct sum if and only if <span class="math inline">\(\Gamma\)</span> is injective (By definition of sum of subspace, we have <span class="math inline">\(\Gamma\)</span> surjective, so we can replace the <strong>injective</strong> by <strong>invertible</strong>).</p>
<h5 id="proof-of-theorem-3.77">Proof of Theorem 3.77:</h5>
<ol type="1">
<li><span class="math inline">\(\leftarrow\)</span>: The linear map <span class="math inline">\(\Gamma\)</span> is injective iff the only way to write <span class="math inline">\(0\)</span> as a sum <span class="math inline">\(u_1 + ... + u_m\)</span> is by taking every <span class="math inline">\(u_j = 0\)</span>, this leads to the <code>Def 1.44</code>.</li>
<li><span class="math inline">\(\rightarrow\)</span>: by <code>Def 1.44</code>, the only way for <span class="math inline">\(U_1 + ... + U_m\)</span> to be direct sum is to have <span class="math inline">\(\text{null } \Gamma = \{0\}\)</span>, which implies injectivity.</li>
</ol>
<h4 id="theorem-3.78-a-sum-is-a-direct-sum-iff-dimensions-add-up">Theorem 3.78: A Sum is a Direct Sum IFF Dimensions Add Up</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U_1 + ... + U_m\)</span> is a direct sum IFF:</p>
<p><span class="math display">\[\dim (U_1 + ... + U_m) = \dim (U_1) + ... + \dim (U_m)\]</span></p>
<h5 id="proof-of-theorem-3.78">Proof of Theorem 3.78:</h5>
<p>Suppose that <span class="math inline">\(\Gamma\)</span> is invertible, then by <code>3.22</code>:</p>
<p><span class="math display">\[\dim (U_1 \times ... \times U_m) = \dim \text{null } (\Gamma) + \dim \text{range } \Gamma\]</span></p>
<p>Since <span class="math inline">\(\Gamma\)</span> is injective, we have:</p>
<p><span class="math display">\[\dim (U_1 \times ... \times U_m) =  \dim \text{range } \Gamma\]</span></p>
<p>Since <span class="math inline">\(\Gamma\)</span> is surjective, we have:</p>
<p><span class="math display">\[\dim \text{range } \Gamma = \dim (U_1 + ... + U_m)\]</span> <span class="math display">\[\implies \dim (U_1 \times ... \times U_m) = \dim (U_1 + ... + U_m)\]</span></p>
<p>By <code>3.76</code> and <code>3.77</code>, we have <span class="math inline">\(\dim (U_1 + ... + U_m)\)</span> is a direct sum and:</p>
<p><span class="math display">\[\dim (U_1) + ... + \dim(U_m) = \dim (U_1 + ... + U_m)\]</span></p>
<h4 id="definition-3.79-v-u">Definition 3.79: <span class="math inline">\(v + U\)</span></h4>
<p>Suppose <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(v + U\)</span> is the subset of <span class="math inline">\(V\)</span> defined by:</p>
<p><span class="math display">\[v + U = \{v + u: u \in U\}\]</span></p>
<h4 id="definition-3.81-affine-subset-parallel">Definition 3.81: Affine subset, Parallel</h4>
<ul>
<li>An <strong>affine subset</strong> of <span class="math inline">\(V\)</span> is a subset of <span class="math inline">\(V\)</span> of the form <span class="math inline">\(v + U\)</span> for some <span class="math inline">\(v \in V\)</span> and some subspace <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span>.</li>
<li>For <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(U\)</span> a subspace of <span class="math inline">\(V\)</span>, the affine subset <span class="math inline">\(v + U\)</span> is said to be <strong>parallel</strong> to <span class="math inline">\(U\)</span>.</li>
</ul>
<blockquote>
<p>If <span class="math inline">\(U = \{(x, y, 0) \in \mathbb{R}^3: x, y \in \mathbb{R}\}\)</span>, then the affine subsets of <span class="math inline">\(\mathbb{R}^3\)</span> parallel to <span class="math inline">\(U\)</span> are the planes in <span class="math inline">\(\mathbb{R}^3\)</span> that are parallel to the <span class="math inline">\(xy\)</span>-plane <span class="math inline">\(U\)</span> in the usual sense.</p>
</blockquote>
<h4 id="definition-3.83-quotient-space-v-u">Definition 3.83: Quotient Space, <span class="math inline">\(V / U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then the <strong>quotient space</strong> <span class="math inline">\(V / U\)</span> is the set of all affine subsets of <span class="math inline">\(V\)</span> parallel to <span class="math inline">\(U\)</span>. In other words:</p>
<p><span class="math display">\[V / U = \{v + U: v \in V\}\]</span></p>
<blockquote>
<p>If <span class="math inline">\(U = \{(x, 2x) \in \mathbb{R}^2: x \in \mathbb{R}\}\)</span>, then <span class="math inline">\(\mathbb{R}^2 / U\)</span> is the subset of all lines with slope of <span class="math inline">\(2\)</span>. If <span class="math inline">\(U\)</span> is a line in <span class="math inline">\(\mathbb{R}^3\)</span> containing the origin, then <span class="math inline">\(\mathbb{R}^3 / U\)</span> is the set of all lines in <span class="math inline">\(\mathbb{R}^3\)</span> parallel to <span class="math inline">\(U\)</span>.</p>
</blockquote>
<h4 id="theorem-3.85-two-affine-subsets-parallel-to-u-are-equal-or-disjoint">Theorem 3.85: Two Affine Subsets Parallel to <span class="math inline">\(U\)</span> are Equal or Disjoint</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(v, w \in V\)</span>. Then the following are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(v - w \in U\)</span></li>
<li><span class="math inline">\(v + U = w + U\)</span></li>
<li><span class="math inline">\((v + U) \cap (w + U) = \emptyset\)</span></li>
</ol>
<h5 id="proof-of-theorem-3.85">Proof of Theorem 3.85</h5>
<p>Assume <span class="math inline">\((1)\)</span> holds, then we have for some <span class="math inline">\(u \in U\)</span>:</p>
<p><span class="math display">\[v + u = w + \underbrace{(v - w + u)}{\in U} \in w + U\]</span></p>
<p>Since the additive inverse <span class="math inline">\(w - v\)</span>, is also in <span class="math inline">\(U\)</span>,</p>
<p><span class="math display">\[w + u = v + \underbrace{(w - v + u)}{\in U} \in v + U\]</span></p>
<p>Then we have:</p>
<p><span class="math display">\[v + U \subseteq w + U\]</span></p>
<p>and</p>
<p><span class="math display">\[w + U \subseteq v + U\]</span></p>
<p>Thus, <span class="math inline">\(v + U = w + U\)</span>, this implies <span class="math inline">\((3)\)</span> holds.</p>
<p>Assume <span class="math inline">\((3)\)</span> holds, then <span class="math inline">\(\exists \; u_1, u_2 \in U\)</span>, then we have:</p>
<p><span class="math display">\[v + u_1 = w + u_2 \implies v - w = u_2 - u_1 \in U\]</span></p>
<p>Since <span class="math inline">\((1) \implies (2)\)</span>, we have <span class="math inline">\((3) \implies (2)\)</span>.</p>
<h4 id="definition-3.86-addition-and-scalar-multiplication-on-v-u">Definition 3.86: Addition and Scalar Multiplication on <span class="math inline">\(V / U\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then <strong>addition</strong> and <strong>scalar multiplication</strong> are defined on <span class="math inline">\(V / U\)</span> by:</p>
<p><span class="math display">\[(v + U) + (w + U) = (v + w) + U\]</span> <span class="math display">\[\lambda (v + U) = (\lambda v) + U\]</span></p>
<p>for <span class="math inline">\(v, w \in V\)</span> and <span class="math inline">\(\lambda \in \mathbb{F}\)</span>.</p>
<h4 id="theorem-3.87-quotient-space-is-a-vector-space">Theorem 3.87 Quotient Space is a Vector Space</h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(V / U\)</span>, with the operations of addition and scalar multiplication as defined above, is a vector space.</p>
<p>Notice the additive inverse of <span class="math inline">\(v + U\)</span> is <span class="math inline">\((-v) + U\)</span>, and additive identity is <span class="math inline">\(0 + U\)</span>.</p>
<h4 id="definition-3.88-quotient-map-pi">Definition 3.88: Quotient Map, <span class="math inline">\(\pi\)</span></h4>
<p>Suppose <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. The <strong>quotient map <span class="math inline">\(\pi\)</span></strong> is the linear map <span class="math inline">\(\pi : V \rightarrow V / U\)</span> defined by:</p>
<p><span class="math display">\[\pi(v) = v + U\]</span></p>
<p>for <span class="math inline">\(v \in V\)</span>.</p>
<h4 id="theorem-3.89-dimension-of-a-quotient-space">Theorem 3.89: Dimension of a Quotient Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\dim V / U = \dim V - \dim U\]</span></p>
<h5 id="proof-of-theorem-3.89">Proof of Theorem 3.89</h5>
<p>Since <span class="math inline">\(0 + U\)</span> is the additive identity in <span class="math inline">\(V / U\)</span>, so it is the set of <span class="math inline">\(U\)</span>, and we can clearly see that the range <span class="math inline">\(\pi = V / U\)</span>. Thus:</p>
<p><span class="math display">\[\dim V = \dim U + \dim V / U \implies \dim V / U = \dim V - \dim U\]</span></p>
<h4 id="definition-3.90-tildet">Definition 3.90: <span class="math inline">\(\tilde{T}\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Define <span class="math inline">\(\tilde{T}: V / (\text{null } T) \rightarrow W\)</span> by:</p>
<p><span class="math display">\[\tilde{T} (v + \text{null } T) = T(v)\]</span></p>
<h4 id="theorem-3.91-null-space-and-range-of-tildet">Theorem 3.91: Null Space and Range of <span class="math inline">\(\tilde{T}\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(\tilde{T}\)</span> is a linear map from <span class="math inline">\(V / \text{null } T\)</span> to <span class="math inline">\(W\)</span>.</li>
<li><span class="math inline">\(\tilde{T}\)</span> is injective.</li>
<li><span class="math inline">\(\text{range } \tilde{T} = \text{range }T\)</span>.</li>
<li><span class="math inline">\(V / (\text{null } T)\)</span> is isomorphic to <span class="math inline">\(\text{range }T\)</span>.</li>
</ol>
<h3 id="duality">Duality</h3>
<h4 id="definition-3.92-linear-functional">Definition 3.92: Linear Functional</h4>
<p>A <strong>linear functional</strong> on <span class="math inline">\(V\)</span> is a linear map from <span class="math inline">\(V\)</span> to the scalar field <span class="math inline">\(\mathbb{F}\)</span>. In other words, a linear functional is an element of <span class="math inline">\(L(V, \mathbb{F})\)</span>.</p>
<blockquote>
<p>Define <span class="math inline">\(\phi: \mathbb{R}^3 \rightarrow \mathbb{R}\)</span> by <span class="math inline">\(\phi(x, y, z) = 4x - 5y + 2z\)</span>. Then <span class="math inline">\(\phi\)</span> is a linear functional on <span class="math inline">\(\mathbb{R}^3\)</span></p>
</blockquote>
<h4 id="definition-3.94-dual-space-vprime">Definition 3.94: Dual Space, <span class="math inline">\(V^{\prime}\)</span></h4>
<p>The <strong>dual space</strong> of <span class="math inline">\(V\)</span>, denoted <span class="math inline">\(V^{\prime}\)</span>, is the vector space of all linear functionals on <span class="math inline">\(V\)</span>. In other words:</p>
<p><span class="math display">\[T^{\prime} = L(V, \mathbb{F})\]</span></p>
<h4 id="theorem-3.95-dim-vprime-dim-v">Theorem 3.95: <span class="math inline">\(\dim V^{\prime} = \dim V\)</span></h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then <span class="math inline">\(V^{\prime}\)</span> is also finite-dimensional and <span class="math inline">\(\dim V^{\prime} = \dim V\)</span>.</p>
<h5 id="proof-of-theorem-3.95">Proof of Theorem 3.95:</h5>
<p>By <code>Corollary 3.6.1</code>, we have <span class="math inline">\(\dim L(V, \mathbb{F}) = \dim (V) \dim (\mathbb{F}) = \dim V\)</span></p>
<h4 id="definition-3.96-dual-basis">Definition 3.96: Dual Basis</h4>
<p>If <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, then the <strong>dual basis</strong> of <span class="math inline">\(v_1, ..., v_n\)</span> is the list <span class="math inline">\(\psi_1 , ..., \psi_n\)</span> of elements of <span class="math inline">\(V^{\prime}\)</span>, where each <span class="math inline">\(\psi_j\)</span> is a linear functional on <span class="math inline">\(V\)</span> s.t:</p>
<p><span class="math display">\[
\psi_j(v_k)=
\begin{cases}
1, \quad \text{if} \;\; k = j\\
0, \quad \text{if} \;\; k \neq j
\end{cases}
\]</span></p>
<blockquote>
<p>What is the dual basis of the standard basis <span class="math inline">\(e_1, ..., e_n\)</span> of <span class="math inline">\(\mathbb{F}^n\)</span>?</p>
<p>For <span class="math inline">\(1 \leq j \leq n\)</span>, define <span class="math inline">\(\psi_j\)</span> to be the linear functional on <span class="math inline">\(\mathbb{F}^n\)</span> that:</p>
<p><span class="math display">\[\psi_j(x_1, ..., x_n) = x_j, \quad \quad (x_1, ..., x_n) \in \mathbb{F}^n\]</span> Clearly: <span class="math display">\[
\psi_j(e_k)=
\begin{cases}
1, \quad \text{if} \;\; k = j\\
0, \quad \text{if} \;\; k \neq j
\end{cases}
\]</span></p>
</blockquote>
<h4 id="theorem-3.98-dual-basis-is-a-basis-of-the-dual-space">Theorem 3.98: Dual Basis is a Basis of the Dual Space</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional. Then the dual basis of a basis of <span class="math inline">\(V\)</span> is a basis of <span class="math inline">\(V^{\prime}\)</span>.</p>
<h5 id="proof-of-theorem-3.98">Proof of Theorem 3.98</h5>
<p>Suppose <span class="math inline">\(v_1, ..., v_n\)</span> is a basis of <span class="math inline">\(V\)</span>, let <span class="math inline">\(\psi_1, ..., \psi_n\)</span> be dual basis. Then, for all <span class="math inline">\(v_j \in (v_1, ..., v_n)\)</span>:</p>
<p><span class="math display">\[a_1 \psi_n + ... + a_n \psi_n = 0 \implies (a_1 \psi_n + ... + a_n \psi_n) (v_j) = a_j = 0\]</span></p>
<p>Thus, all <span class="math inline">\(a_j = 0\)</span>, the dual basis is independent.</p>
<p>Since <span class="math inline">\(\psi_1, ..., \psi_n\)</span> is independent, by <code>theorem 3.95, 2.39</code>, it is a basis of the dual space.</p>
<h4 id="definition-3.99-dual-map-tprime">Definition 3.99: Dual Map, <span class="math inline">\(T^{\prime}\)</span></h4>
<p>If <span class="math inline">\(T \in L(V, W)\)</span>, then the <strong>dual map</strong> of <span class="math inline">\(T\)</span> is the linear map <span class="math inline">\(T^{\prime} \in L(W^{\prime}, V^{\prime})\)</span> defined by <span class="math inline">\(T^{\prime} (\psi) = \psi \circ T\)</span> for <span class="math inline">\(\psi \in W^{\prime}\)</span>. so:</p>
<p><span class="math display">\[T^{\prime} (\psi): V \rightarrow \mathbb{F}\]</span></p>
<h4 id="theorem-3.101-algebraic-properties-of-dual-maps">Theorem 3.101: Algebraic Properties of Dual Maps</h4>
<ol type="1">
<li><span class="math inline">\((S+T)^{\prime} = S^{\prime} + T^{\prime}\)</span></li>
<li><span class="math inline">\((\lambda T)^{\prime} = \lambda T^{\prime}\)</span> for all <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and all <span class="math inline">\(T \in L(V, W)\)</span></li>
<li><span class="math inline">\((ST)^{\prime} = T^{\prime}S^{\prime}\)</span> for all <span class="math inline">\(T \in L(U, V)\)</span> and all <span class="math inline">\(S \in L(V, W)\)</span></li>
</ol>
<h5 id="proof-of-theorem-3.101">Proof of Theorem 3.101</h5>
<ol type="1">
<li><span class="math inline">\((S + T)^{\prime} (\psi) = \psi \circ (S + T) = \psi \circ S + \psi \circ T = S^{\prime} + T^{\prime}\)</span></li>
<li><span class="math inline">\((\lambda T)^{\prime} (\psi)= \lambda \psi \circ T = \lambda T^{\prime}\)</span></li>
<li><span class="math inline">\((ST)^\prime (\psi) = \psi \circ (ST) = (\psi \circ S) \circ T = T^{\prime} (\psi \circ S) = T^{\prime} (S^{\prime} (\psi)) = T^{\prime} S^{\prime}\)</span> by <code>definition 3.8</code></li>
</ol>
<h4 id="definition-3.102-annihilator-u0">Definition 3.102: Annihilator, <span class="math inline">\(U^0\)</span></h4>
<p>For <span class="math inline">\(U \subseteq V\)</span>, the <strong>annihilator</strong> of <span class="math inline">\(U\)</span>, denoted <span class="math inline">\(U^0\)</span> is defined by:</p>
<p><span class="math display">\[U^0 = \{\psi \in V^{\prime}: \psi (u) = 0, \; \forall u \in U\}\]</span></p>
<h4 id="theorem-3.105-the-annihilator-is-a-subspace">Theorem 3.105: The Annihilator is a Subspace</h4>
<p>Suppose <span class="math inline">\(U \subseteq V\)</span>. Then <span class="math inline">\(U^0\)</span> is a subspace of <span class="math inline">\(V^\prime\)</span>. Where <span class="math inline">\(0 \in U^0\)</span> the is <span class="math inline">\(0\)</span> linear functional that maps every <span class="math inline">\(v \in V\)</span> to <span class="math inline">\(0 \in \mathbb{F}\)</span>.</p>
<h4 id="theorem-3.106-dimension-of-the-annihilator">Theorem 3.106: Dimension of the Annihilator</h4>
<p>Suppose <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span>. Then:</p>
<p><span class="math display">\[\dim U + \dim U^0 = \dim V\]</span></p>
<h4 id="theorem-3.107-the-null-space-of-tprime">Theorem 3.107: The Null Space of <span class="math inline">\(T^{\prime}\)</span></h4>
<ol type="1">
<li>null <span class="math inline">\(T^\prime\)</span> = <span class="math inline">\((\text{range } T)^0\)</span></li>
<li><span class="math inline">\(\dim \text{null }T^{\prime} = \dim \text{null }T + \dim W - \dim V\)</span></li>
</ol>
<h4 id="theorem-3.108-t-surjective-is-equivalent-to-tprime-injective">Theorem 3.108: <span class="math inline">\(T\)</span> Surjective is Equivalent to <span class="math inline">\(T^{\prime}\)</span> Injective</h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(T\)</span> is surjective iff <span class="math inline">\(T^{\prime}\)</span> is injective.</p>
<h4 id="theorem-3.109-the-range-of-tprime">Theorem 3.109: The Range of <span class="math inline">\(T^{\prime}\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then:</p>
<ol type="1">
<li><span class="math inline">\(\dim \text{range }T^{\prime} = \dim \text{range } T\)</span></li>
<li><span class="math inline">\(\text{range }T^{\prime} = (\text{null } T)^0\)</span></li>
</ol>
<h4 id="theorem-3.110-t-injective-is-equivalent-to-tprime-surjective">Theorem 3.110: <span class="math inline">\(T\)</span> injective is equivalent to <span class="math inline">\(T^{\prime}\)</span> Surjective</h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(T\)</span> is injective if and only if <span class="math inline">\(T^{\prime}\)</span> is surjective.</p>
<h3 id="matrix-of-the-dual-of-a-linear-map">Matrix of the Dual of a Linear Map</h3>
<h4 id="definition-3.111-transpose-at">Definition 3.111: Transpose, <span class="math inline">\(A^T\)</span></h4>
<p>The <strong>transpose</strong> of a matrix <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(A^T\)</span>, is the matrix obtained from <span class="math inline">\(A\)</span> by interchanging the rows and columns. More specifically, if <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix, then <span class="math inline">\(A^T\)</span> is a <span class="math inline">\(n \times m\)</span> matrix whose entries are given by:</p>
<p><span class="math display">\[(A^T)_{k, j} = A_{j, k}\]</span></p>
<h4 id="theorem-3.113">Theorem 3.113:</h4>
<p>If <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix and <span class="math inline">\(C\)</span> is an <span class="math inline">\(n \times p\)</span> matrix:</p>
<p><span class="math display">\[(AC)^T = C^TA^T\]</span> <span class="math display">\[(A + C)^T = A^T + C^T\]</span> <span class="math display">\[(\lambda A)^T = \lambda A^T\]</span></p>
<h4 id="theorem-3.114-the-matrix-of-tprime-is-the-transpose-of-the-matrix-of-t">Theorem 3.114: The Matrix of <span class="math inline">\(T^{\prime}\)</span> is the Transpose of the Matrix of <span class="math inline">\(T\)</span></h4>
<p>Suppose <span class="math inline">\(T \in L(V, W)\)</span>, then <span class="math inline">\(M(T^{\prime}) = (M(T))^T\)</span></p>
<h4 id="definition-3.115-row-rank-column-rank">Definition 3.115: Row Rank, Column Rank</h4>
<p>Suppose <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix with entries in <span class="math inline">\(\mathbb{F}\)</span>.</p>
<ul>
<li>The <strong>row rank</strong> of <span class="math inline">\(A\)</span> is the dimension of the span of the rows of <span class="math inline">\(A\)</span> in <span class="math inline">\(\mathbb{F}^{1, n}\)</span>.</li>
<li>The <strong>column rank</strong> of <span class="math inline">\(A\)</span> is the dimension of the span of the columns of <span class="math inline">\(A\)</span> in <span class="math inline">\(\mathbb{F}^{m , 1}\)</span></li>
</ul>
<h4 id="theorem-3.117-dimension-of-range-t-equals-column-rank-of-mt">Theorem 3.117: Dimension of range <span class="math inline">\(T\)</span> Equals Column Rank of <span class="math inline">\(M(T)\)</span></h4>
<p>Suppose <span class="math inline">\(V, W\)</span> are finite-dimensional and <span class="math inline">\(T \in L(V, W)\)</span>. Then <span class="math inline">\(\dim \text{range } T\)</span> equals the column rank of <span class="math inline">\(M(T)\)</span>.</p>
<h5 id="proof-of-theorem-3.117">Proof of Theorem 3.117:</h5>
<p>Assume <span class="math inline">\(v_1, ..., v_n, w_1, ..., w_m\)</span> are basis of <span class="math inline">\(V, W\)</span> respectively. Since <span class="math inline">\(M\)</span> is an isomorphism from <span class="math inline">\(W \rightarrow \mathbb{F}^{m \times 1}\)</span> (<code>def 3.62</code>), we have <span class="math inline">\(M: \text{span }(Tv_1, ..., Tv_n) \rightarrow \text{range } M\)</span> isomorphic. Then:</p>
<p><span class="math display">\[M(a_1 Tv_1 + ... + a_n Tv_n) = a_1 M (Tv_1) + .... + a_n M(Tv_n) \implies \text{span }(M(Tv_1), ..., M(Tv_n)) = \text{range } M\]</span></p>
<p>Thus, <span class="math inline">\(M: \text{span }(Tv_1, ..., Tv_n) \rightarrow \text{span }(M(Tv_1), ..., M(Tv_n))\)</span> isomorphic and by <code>corollary 3.59</code>, we have:</p>
<p><span class="math display">\[\dim \text{span }(Tv_1, ..., Tv_n) = \dim \text{span }(M(Tv_1), ..., M(Tv_n))\]</span></p>
<p>in other words, we have:</p>
<p><span class="math display">\[\dim \text{range } T  = \text{span } (\text{columns of $A$}) = \text{The column rank of $M(T)$}\]</span></p>
<h4 id="theorem-3.118-row-rank-equals-column-rank">Theorem 3.118: Row Rank Equals Column Rank</h4>
<p>Suppose <span class="math inline">\(A \in \mathbb{F^{m, n}}\)</span>. Then the row rank of <span class="math inline">\(A\)</span> equals the column rank of <span class="math inline">\(A\)</span>.</p>
<h5 id="definition-3.119-rank">Definition 3.119: Rank</h5>
<p>The <strong>rank</strong> of a matrix <span class="math inline">\(A \in \mathbb{F}^{m, n}\)</span> is the column rank of <span class="math inline">\(A\)</span>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/01/06/real-analysis-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/06/real-analysis-4/" class="post-title-link" itemprop="url">real-analysis-4</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-06 21:01:03" itemprop="dateCreated datePublished" datetime="2022-01-06T21:01:03+08:00">2022-01-06</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-01-17 21:28:20" itemprop="dateModified" datetime="2022-01-17T21:28:20+08:00">2022-01-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/01/06/real-analysis-4/" class="post-meta-item leancloud_visitors" data-flag-title="real-analysis-4" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>20k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>18 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="real-analysis-4">Real Analysis (4)</h1>
<h2 id="sequences-and-series-of-functions-1">Sequences and Series of Functions [1]</h2>
<h3 id="uniform-convergence-of-a-seuqence-of-functions">Uniform Convergence of a Seuqence of Functions</h3>
<h4 id="definition-6.2.1-pointwise-convergence">Definition 6.2.1: Pointwise Convergence</h4>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, let <span class="math inline">\(f_n\)</span> be a function defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The sequence <span class="math inline">\((f_n)\)</span> of functions <strong>converges pointwise</strong> on <span class="math inline">\(A\)</span> to a function <span class="math inline">\(f\)</span> if, for all <span class="math inline">\(x \in A\)</span>, the sequence of real numbers <span class="math inline">\(f_{n} (x)\)</span> converges to <span class="math inline">\(f(x)\)</span>.</p>
<p>In this case, we write <span class="math inline">\(f_n \rightarrow f\)</span>, <span class="math inline">\(\lim_{n \rightarrow \infty} f_n = f\)</span> or <span class="math inline">\(\lim_{n \rightarrow \infty} f_n(x) = f(x)\)</span>.</p>
<h4 id="definition-6.2.1b-pointwise-convergence">Definition 6.2.1B: Pointwise Convergence</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then, <span class="math inline">\((f_n)\)</span> <strong>convergence pointwise</strong> on <span class="math inline">\(A\)</span> to a limit function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(A\)</span> if, for every <span class="math inline">\(\epsilon &gt; 0\)</span> and <span class="math inline">\(x \in A\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> (<strong>perhaps depends on <span class="math inline">\(x\)</span></strong>) such that <span class="math inline">\(|f_{n} (x) - f(x) | &lt; \epsilon\)</span> whenever <span class="math inline">\(n \geq N\)</span>.</p>
<h4 id="definition-6.2.3-uniform-convergence-stronger-than-pointwise">Definition 6.2.3: Uniform Convergence (Stronger than Pointwise)</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. Then, <span class="math inline">\((f_n)\)</span> <strong>convergence uniformly</strong> on <span class="math inline">\(A\)</span> to a limit function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(A\)</span> if, for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that <span class="math inline">\(|f_{n} (x) - f(x) | &lt; \epsilon\)</span> whenever <span class="math inline">\(n \geq N\)</span> and <span class="math inline">\(x \in A\)</span>.</p>
<p><strong>Similar to uniform continuous, this is a stronger, which involves finding <span class="math inline">\(N \in \mathbb{N}\)</span> for a given <span class="math inline">\(\epsilon &gt; 0\)</span> for all <span class="math inline">\(x \in A\)</span></strong>.</p>
<p>Graphically speaking, the uniform convergence of <span class="math inline">\(f_n\)</span> to a limit <span class="math inline">\(f\)</span> on a set <span class="math inline">\(A\)</span> can be seen as there exists a point in the sequence after which each <span class="math inline">\(f_n\)</span> is <strong>completely</strong> contained in the <span class="math inline">\(\epsilon\)</span>-strip.</p>
<p><img src="/images/RL/background/ra_6_2_3.png" width="600"></p>
<h4 id="theorem-6.2.5-cauchy-criterion-for-uniform-convergence">Theorem 6.2.5: Cauchy Criterion for Uniform Convergence</h4>
<p>A sequence of functions <span class="math inline">\((f_n)\)</span> defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> converges uniformly on <span class="math inline">\(A\)</span> if and only if for every <span class="math inline">\(\epsilon &gt; 0\)</span> there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> such that <span class="math inline">\(|f_n(x) - f_m(x)| &lt; \epsilon\)</span> whenever <span class="math inline">\(m, n \geq N\)</span> for all <span class="math inline">\(x \in A\)</span>.</p>
<h4 id="theorem-6.2.6-continuous-limit-theorem">Theorem 6.2.6: Continuous Limit Theorem</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions defined on <span class="math inline">\(A \subseteq \mathbb{R}\)</span> that converges uniformly on <span class="math inline">\(A\)</span> to a function <span class="math inline">\(f\)</span>. If each <span class="math inline">\(f_n\)</span> is continuous at <span class="math inline">\(c \in A\)</span>, then <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c\)</span>.</p>
<h3 id="uniform-convergence-and-differentiation">Uniform Convergence and Differentiation</h3>
<h4 id="theorem-6.3.1-differentiable-limit-theorem">Theorem 6.3.1: Differentiable Limit Theorem</h4>
<p>Let <span class="math inline">\(f_n \rightarrow f\)</span> pointwise on the closed interval <span class="math inline">\([a, b]\)</span>, and assume that each <span class="math inline">\(f_n\)</span> is differentiable. If <span class="math inline">\((f^{\prime}(c))\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span> to a function <span class="math inline">\(g\)</span>, then the function <span class="math inline">\(f\)</span> is differentiable and <span class="math inline">\(f^{\prime} = g\)</span>.</p>
<h4 id="theorem-6.3.2">Theorem 6.3.2</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of differentiable functions defined on the closed interval <span class="math inline">\([a, b]\)</span>, and assume <span class="math inline">\((f^{\prime}_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span>. If there exists a point <span class="math inline">\(x_0 \in [a, b]\)</span>, where <span class="math inline">\(f_{n} (x_0)\)</span> is convergent, then <span class="math inline">\((f_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span>.</p>
<h4 id="theorem-6.3.3-combine-theorem-6.3.1-and-6.3.2">Theorem 6.3.3: Combine Theorem 6.3.1 and 6.3.2</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of differentiable functions defined on the closed interval <span class="math inline">\([a, b]\)</span>, and assume <span class="math inline">\((f^{\prime}_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span> to a function <span class="math inline">\(g\)</span> on <span class="math inline">\([a, b]\)</span>. If there exists a point <span class="math inline">\(x_0 \in [a, b]\)</span>, where <span class="math inline">\(f_{n} (x_0)\)</span> is convergent, then <span class="math inline">\((f_n)\)</span> converges uniformly on <span class="math inline">\([a, b]\)</span>. Moreover, the limit function <span class="math inline">\(f = \lim_{n\rightarrow \infty} f_n\)</span> is differentiable and satisfies <span class="math inline">\(f^{\prime} = g\)</span>.</p>
<h3 id="series-of-functions">Series of Functions</h3>
<h4 id="definition-6.4.1-pointwise-convergence-and-uniform-convergence-of-series-of-functions">Definition 6.4.1: Pointwise Convergence and Uniform Convergence of Series of Functions</h4>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, let <span class="math inline">\(f_n\)</span> and <span class="math inline">\(f\)</span> be functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The infinite series:</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} f_n  = f_1 + f_2 + .... \]</span></p>
<p><strong>converges pointwise</strong> on <span class="math inline">\(A\)</span> to <span class="math inline">\(f\)</span> if the sequence <span class="math inline">\(s_k\)</span> of partial sums defined by:</p>
<p><span class="math display">\[s_k = f_1  + f_2  + ... + f_k\]</span></p>
<p>converges pointwise to <span class="math inline">\(f\)</span>. The series <strong>converges uniformly</strong> on <span class="math inline">\(A\)</span> to <span class="math inline">\(f\)</span> if the sequence <span class="math inline">\(s_k\)</span> converges uniformly on <span class="math inline">\(A\)</span> to <span class="math inline">\(f\)</span>. In either case, we can write:</p>
<p><span class="math display">\[f = \sum^{\infty}_{n=1} f_n\]</span></p>
<p>or</p>
<p><span class="math display">\[f(x) = \sum^{\infty}_{n=1} f_n(x)\]</span></p>
<h4 id="theorem-6.4.2-term-by-term-continuity-theorem">Theorem 6.4.2: Term-by-Term Continuity Theorem</h4>
<p>Let <span class="math inline">\(f_n\)</span> be continuous functions defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, and assume <span class="math inline">\(\sum^{\infty}_{m=1} f_n\)</span> converges uniformly on <span class="math inline">\(A\)</span> to a function <span class="math inline">\(f\)</span>. Then <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-6.4.3-term-by-term-differentiability-theorem">Theorem 6.4.3: Term-by-Term Differentiability Theorem</h4>
<p>Let <span class="math inline">\(f_n\)</span> be differentiable functions defined on an interval <span class="math inline">\(A\)</span>, and assume <span class="math inline">\(\sum^{\infty}_{n=1} f^{\prime}_n\)</span> converges uniformly to a limit function <span class="math inline">\(g\)</span> on <span class="math inline">\(A\)</span>. If there exists a point <span class="math inline">\(x_0 \in [a, b]\)</span> where <span class="math inline">\(\sum^{\infty}_{n=1} f_n (x_0)\)</span> converges, then the series <span class="math inline">\(\sum^{\infty}_{n=1} f_n\)</span> converges uniformly to a differentiable function <span class="math inline">\(f\)</span> satisfying <span class="math inline">\(f^{\prime} = g\)</span> on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-6.4.4-cauchy-criterion-for-uniform-convergence-of-series">Theorem 6.4.4: Cauchy Criterion for Uniform Convergence of Series</h4>
<p>A series <span class="math inline">\(\sum^{\infty}_{n=1} f_n\)</span> converges uniformly on <span class="math inline">\(A \subseteq \mathbb{R}\)</span> if and only if for every <span class="math inline">\(\epsilon &gt; 0\)</span> there exists an <span class="math inline">\(N \in \mathbb{N}\)</span> s.t</p>
<p><span class="math display">\[|f_{m+1} (x) + f_{m+2} (x) + ... + f_{n} (x) | &lt; \epsilon\]</span></p>
<p>whenever <span class="math inline">\(n &gt; m \geq N\)</span> and <span class="math inline">\(x \in A\)</span></p>
<h4 id="corollary-6.4.5-weierstrass-m-test">Corollary 6.4.5: Weierstrass M-Test</h4>
<p>For each <span class="math inline">\(n \in \mathbb{N}\)</span>, let <span class="math inline">\(f_n\)</span> be a function defined on a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, and let <span class="math inline">\(M_n &gt; 0\)</span> be a real number satisfying:</p>
<p><span class="math display">\[|f_n(x)| \leq M_n\]</span></p>
<p>for all <span class="math inline">\(x \in A\)</span>. If <span class="math inline">\(\sum^{\infty}_{n=1} M_n\)</span> converges, then <span class="math inline">\(\sum^{\infty}_{n=1} f_n\)</span> converges uniformly on <span class="math inline">\(A\)</span>.</p>
<h3 id="power-series">Power Series</h3>
<p><span class="math display">\[f(x) = \sum^{\infty}_{n=0} a_n x^n = a_0 + a_1x + a_2x^2 + a_3 x^3 + ...\]</span></p>
<h4 id="theorem-6.5.1">Theorem 6.5.1</h4>
<p>If a power series <span class="math inline">\(\sum^{\infty}_{n=0} a_n x^n\)</span> converges at some point <span class="math inline">\(x_0 \in \mathbb{R}\)</span>, then it converges absolutely for any <span class="math inline">\(x\)</span> satisfying <span class="math inline">\(|x| &lt; |x_0|\)</span>.</p>
<h4 id="theorem-6.5.2">Theorem 6.5.2</h4>
<p>If a power series <span class="math inline">\(\sum^{\infty}_{n=0} a_n x^n\)</span> converges absolutely at a point <span class="math inline">\(x_0\)</span>, then it converges uniformly on the closed interval <span class="math inline">\([-c, c]\)</span>, where <span class="math inline">\(c=|x_0|\)</span>.</p>
<h4 id="lemma-6.5.3-abels-lemma">Lemma 6.5.3: Abel's Lemma</h4>
<p>Let <span class="math inline">\(b_n\)</span> satisfy <span class="math inline">\(b_1 \geq b_2 \geq b_3 \geq .... \geq 0\)</span>, and let <span class="math inline">\(\sum^{\infty}_{n=1} a_n\)</span> be a series for which the partial sums are bounded. In other words, assume there exists <span class="math inline">\(A &gt; 0\)</span> s.t</p>
<p><span class="math display">\[|a_1 + a_2 + ... + a_n| \leq A\]</span></p>
<p>for all <span class="math inline">\(n \in \mathbb{N}\)</span>. Then for all <span class="math inline">\(n \in \mathbb{N}\)</span>,</p>
<p>$$|a_1b_1 + a_2b_2 + .... + a_nb_n| </p>
<h4 id="theorem-6.5.4-abels-theorem">Theorem 6.5.4: Abel's Theorem</h4>
<p>Let <span class="math inline">\(g(x) = \sum^{\infty}_{n=0} a_nx^n\)</span> be a power series that converges at the point <span class="math inline">\(x = R &gt; 0\)</span>. Then the series converges uniformly on the interval <span class="math inline">\([0, R]\)</span>. A similar result holds if the series converges at <span class="math inline">\(x = -R\)</span>.</p>
<h4 id="theorem-6.5.5">Theorem 6.5.5</h4>
<p>If a power series converges pointwise on the set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, then it converges uniformly on any compact set <span class="math inline">\(K \subseteq A\)</span>.</p>
<h4 id="theorem-6.5.6">Theorem 6.5.6</h4>
<p>If <span class="math inline">\(\sum^{\infty}_{n=0}a_n x^n\)</span> converges for all <span class="math inline">\(x \in (-R, R)\)</span>, then the differentiated series <span class="math inline">\(\sum^{\infty}_{n=1} na_n x^{n-1}\)</span> converges at each <span class="math inline">\(x\in (-R, R)\)</span> as well. Consequently, the convergence is unifrom on compact sets contained in <span class="math inline">\((-R, R)\)</span>.</p>
<h4 id="theorem-6.5.7">Theorem 6.5.7</h4>
<p>Assume</p>
<p><span class="math display">\[f(x) = \sum^{\infty}_{n=0} a_n x^n\]</span></p>
<p>converges on an interval <span class="math inline">\(A \subseteq \mathbb{R}\)</span>. The function <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\(A\)</span> and differentiable on any open interval <span class="math inline">\((-R, R) \subseteq A\)</span>. The derivative is given by:</p>
<p><span class="math display">\[f^{\prime} (x) = \sum^{\infty}_{n=1} na_nx^{n-1}\]</span></p>
<p>Moreover, <span class="math inline">\(f\)</span> is infinitely differentiable on <span class="math inline">\((-R, R)\)</span>, and the successive derivatives can be obtained via term-by-term differentiation of the appropriate series.</p>
<h3 id="taylor-series">Taylor Series</h3>
<p>Given an infinitely differentiable function <span class="math inline">\(f\)</span> defined on some interval centered at zero, the idea is to assume that <span class="math inline">\(f\)</span> has a power series expansion and deduce what the coefficients must be. (<strong>Not every infinitely differentiable function can be represented by its taylor series</strong>)</p>
<h4 id="theorem-6.6.2-taylors-formula-centered-at-zero-maclaurin-series">Theorem 6.6.2: Taylor's Formula Centered at Zero (Maclaurin Series)</h4>
<p>Let</p>
<p><span class="math display">\[f(x) = a_0 + a_1x + a_2x^2 + ...\]</span></p>
<p>be defined on some nontrivial interval centered at zero. Then:</p>
<p><span class="math display">\[a_n = \frac{f^{(n)}(0)}{n!}\]</span></p>
<p>Where <span class="math inline">\(f^{(n)}(0)\)</span> is the <span class="math inline">\(n\)</span>th derivative of <span class="math inline">\(f\)</span> evaluate at <span class="math inline">\(0\)</span>.</p>
<p><strong>This formula assumes that the function <span class="math inline">\(f\)</span> has a power series representation.</strong></p>
<h4 id="theorem-6.6.3-lagranges-remainder-theorem">Theorem 6.6.3: Lagrange's Remainder Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> be differentiable <span class="math inline">\(N + 1\)</span> times on <span class="math inline">\((-R, R)\)</span>, define <span class="math inline">\(a_n = \frac{f^{n} (0)}{n!}\)</span> for <span class="math inline">\(n=0, 1, ... , N\)</span>, and let:</p>
<p><span class="math display">\[S_N(x) = a_0 + a_1 x + a_2 x^2 + ... + a_N x^N\]</span></p>
<p>Given <span class="math inline">\(x \neq 0\)</span> in <span class="math inline">\((-R, R)\)</span>, there exists a point <span class="math inline">\(c\)</span> satisfying <span class="math inline">\(|c| &lt; |x|\)</span> where the error function <span class="math inline">\(E_N(x) = f(x) - S_N (x)\)</span> satisfies:</p>
<p><span class="math display">\[E_N(x) = \frac{f^{(N+1)} (c)}{(N+1)!} x^{N+1}\]</span></p>
<h4 id="definition-6.6.7-taylor-series-centered-at-a-neq-0">Definition 6.6.7: Taylor Series Centered at <span class="math inline">\(a \neq 0\)</span></h4>
<p>If <span class="math inline">\(f\)</span> is defined in some neighborhood of <span class="math inline">\(a \in \mathbb{R}\)</span> and infinitely differentiable at <span class="math inline">\(a\)</span>, then the Taylor series expansion around <span class="math inline">\(a\)</span> takes the form:</p>
<p><span class="math display">\[\sum^{\infty}_{n=0}c_n (x - a)^n\]</span></p>
<p>where <span class="math inline">\(c_n = \frac{f^{(n)} (a)}{n!}\)</span></p>
<h3 id="the-weierstrass-approximation-theorem">The Weierstrass Approximation Theorem</h3>
<h4 id="theorem-6.7.1-weierstrass-approximation-theorem">Theorem 6.7.1: Weierstrass Approximation Theorem</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous. Given <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a polynomial <span class="math inline">\(p(x)\)</span> satisfying:</p>
<p><span class="math display">\[|f(x) - p(x) | &lt; \epsilon\]</span></p>
<p>for all <span class="math inline">\(x \in [a, b]\)</span>.</p>
<p>In other words, every continuous function on a closed interval can be uniformly approximated by a polynomial.</p>
<h4 id="definition-6.7.2-polygonal">Definition 6.7.2: Polygonal</h4>
<p>A continuous function <span class="math inline">\(\phi: [a, b] \rightarrow \mathbb{R}\)</span> is <strong>polygonal</strong> if there is a partition:</p>
<p><span class="math display">\[a = x_0 &lt; x_1 &lt; x_2 &lt; .... &lt; x_n = b\]</span></p>
<p>of <span class="math inline">\([a, b]\)</span> such that <span class="math inline">\(\phi\)</span> is linear on each subinterval <span class="math inline">\([x_{i-1}, x_i]]\)</span> where <span class="math inline">\(i=1, ..., n\)</span></p>
<h4 id="theorem-6.7.3">Theorem 6.7.3</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous. Given <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a polygonal function <span class="math inline">\(\phi\)</span> satisfying:</p>
<p><span class="math display">\[|f(x) - \phi(x) | &lt; \epsilon\]</span></p>
<h2 id="the-riemann-integral">The Riemann Integral</h2>
<h3 id="the-definition-of-the-riemann-integral">The Definition of the Riemann Integral</h3>
<p><strong>Throughout this section, it is assumed that we are working with a bounded function <span class="math inline">\(f\)</span> on a closed interval <span class="math inline">\([a, b]\)</span>, meaning that there exists an <span class="math inline">\(M &gt; 0\)</span> s.t <span class="math inline">\(|f(x)| \leq M, \; \forall x \in [a, b]\)</span></strong></p>
<h4 id="definition-7.2.1-partition-lower-sum-upper-sum">Definition 7.2.1: Partition, Lower Sum, Upper Sum</h4>
<p>A <strong>partition</strong> <span class="math inline">\(P\)</span> of <span class="math inline">\([a, b]\)</span> is a finite set of points from <span class="math inline">\([a, b]\)</span> that includes both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. A partition <span class="math inline">\(P = \{x_0, ...., x_n\}\)</span> is listed in increasing order:</p>
<p><span class="math display">\[a=x_0 &lt; x_1 &lt; x_2 &lt; ... &lt; x_n = b\]</span></p>
<p>For each subinterval <span class="math inline">\([x_{k-1}, x_k]\)</span> of <span class="math inline">\(P\)</span>, let:</p>
<p><span class="math display">\[m_k = \inf\{f(x): x \in [x_{k-1}, x_k]\}\]</span></p>
<p>and</p>
<p><span class="math display">\[M_k = \sup\{f(x): x\in[x_{k-1}, x_k]\}\]</span></p>
<p>Since the function is bounded, the supreme and infimum always exists.</p>
<p>The <strong>lower sum</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(P\)</span> is given by:</p>
<p><span class="math display">\[L(f, P) = \sum^{n}_{k=1} m_k (x_k - x_{k-1})\]</span></p>
<p>The <strong>upper sum</strong> of <span class="math inline">\(f\)</span> w.r.t <span class="math inline">\(P\)</span> is given by:</p>
<p><span class="math display">\[U(f, P) = \sum^{n}_{k=1} M_k (x_k - x_{k-1})\]</span></p>
<p>For a particular partition <span class="math inline">\(P\)</span>, it is clear that:</p>
<p><span class="math display">\[U(f, P) \geq L(f, P)\]</span></p>
<h4 id="definition-7.2.2-refinement">Definition 7.2.2: Refinement</h4>
<p>A partition <span class="math inline">\(Q\)</span> is a <strong>refinement</strong> of a partition <span class="math inline">\(P\)</span> if <span class="math inline">\(Q\)</span> contains all of the points of <span class="math inline">\(P\)</span> if <span class="math inline">\(Q\)</span> contains all of the points of <span class="math inline">\(P\)</span>; that is, if <span class="math inline">\(P \in Q\)</span>.</p>
<h4 id="lemma-7.2.3">Lemma 7.2.3</h4>
<p>If <span class="math inline">\(P \subseteq Q\)</span>, then <span class="math inline">\(L(f, P) \leq L(f, Q)\)</span>, and <span class="math inline">\(U(f, P) \geq U(f, Q)\)</span>.</p>
<h4 id="lemma-7.2.4">Lemma 7.2.4</h4>
<p>If <span class="math inline">\(P_1, P_2\)</span> are any two partitions of <span class="math inline">\([a, b]\)</span>, then <span class="math inline">\(L(f, P_1) \leq U(f, P_2)\)</span>.</p>
<p><strong>We can think of upper sum as an overestimate for the value of the integral and a lower sum as an underestimate. As the partitions get more refined, the upper sums get potentially smaller while the lower sums get potentially larger.</strong></p>
<h4 id="definition-7.2.5-upper-integral-lower-integral">Definition 7.2.5: Upper Integral, Lower Integral</h4>
<p>Let <span class="math inline">\(\mathbf{P}\)</span> be the collection of all possible partitions of the interval <span class="math inline">\([a, b]\)</span>. The <strong>upper integral</strong> of <span class="math inline">\(f\)</span> is defined to be:</p>
<p><span class="math display">\[U(f) = \inf\{U(f, P): P \in \mathbf{P}\}\]</span></p>
<p>In a similar way, define the <strong>lower integral</strong> of <span class="math inline">\(f\)</span> by:</p>
<p><span class="math display">\[L(f) = \sup\{L(f, P): P\in\mathbf{P}\}\]</span></p>
<h4 id="lemma-7.2.6">Lemma 7.2.6</h4>
<p>For any bounded function <span class="math inline">\(f\)</span> on <span class="math inline">\([a, b]\)</span>, it is always the case that <span class="math inline">\(U(f) \geq L(f)\)</span>.</p>
<h4 id="definition-7.2.7-riemann-integrability">Definition 7.2.7: Riemann Integrability</h4>
<p>A bounded function <span class="math inline">\(f\)</span> defined on the interval <span class="math inline">\([a, b]\)</span> is <strong>Riemann-integrable</strong> if <span class="math inline">\(U(f) = L(f)\)</span>. In this case, we define <span class="math inline">\(\int^{b}_{a} f\)</span> or <span class="math inline">\(\int^{a}_{b} f(x) dx\)</span> to be this common value, namely:</p>
<p><span class="math display">\[\int^b_{a} f = U(f) = L(f)\]</span></p>
<h3 id="criteria-for-integrability">Criteria for Integrability</h3>
<h4 id="theorem-7.2.8-integrability-criterion">Theorem 7.2.8: Integrability Criterion</h4>
<p>A bounded function <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, b]\)</span> if and only if, for every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a partition <span class="math inline">\(P_{\epsilon}\)</span> of <span class="math inline">\([a, b]\)</span> s.t</p>
<p><span class="math display">\[U(f, P_\epsilon) - L(f, P_{\epsilon}) &lt; \epsilon\]</span></p>
<h4 id="theorem-7.2.9">Theorem 7.2.9</h4>
<p>If <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\([a, b]\)</span>, then it is integrable.</p>
<h4 id="theorem-7.3.2">Theorem 7.3.2</h4>
<p>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is bounded, and <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([c, b]\)</span> for all <span class="math inline">\(c \in (a, b)\)</span>, then <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, b]\)</span>. An analogous result holds at the other end point.</p>
<h3 id="properties-of-the-integral">Properties of the Integral</h3>
<h4 id="theorem-7.4.1">Theorem 7.4.1</h4>
<p>Assume <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is bounded, and let <span class="math inline">\(c \in (a, b)\)</span>. Then, <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, b]\)</span> if and only if <span class="math inline">\(f\)</span> is integrable on <span class="math inline">\([a, c]\)</span> and <span class="math inline">\([c, b]\)</span>. In this case, we have:</p>
<p><span class="math display">\[\int^{b}_{a} f = \int^{c}_{a} f + \int^{b}_{c} f\]</span></p>
<h4 id="theorem-7.4.2">Theorem 7.4.2</h4>
<p>Assume <span class="math inline">\(f, g\)</span> are integrable functions on the interval <span class="math inline">\([a, b]\)</span>.</p>
<ol type="1">
<li>The function <span class="math inline">\(f + g\)</span> is integrable on <span class="math inline">\([a, b]\)</span> with <span class="math inline">\(\int^{b}_{a} (f + g) = \int^{b}_{a} f + \int^{b}_{a} g\)</span>.</li>
<li>For <span class="math inline">\(k \in \mathbb{R}\)</span>, the function <span class="math inline">\(kf\)</span> is integrable with <span class="math inline">\(\int^{b}_{a} kf = k \int^{b}_{a} f\)</span>.</li>
<li>If <span class="math inline">\(m \leq f(x) \leq M\)</span> on <span class="math inline">\([a, b]\)</span>, then <span class="math inline">\(m(b - a) \leq \int^{b}_{a} f \leq M (b - a)\)</span>.</li>
<li>If <span class="math inline">\(f(x) \leq g(x)\)</span> on <span class="math inline">\([a, b]\)</span>, then <span class="math inline">\(\int^{b}_{a} f \leq \int^b_a g\)</span></li>
<li>The function <span class="math inline">\(|f|\)</span> is integrable and <span class="math inline">\(|\int^{b}_{a} f| \leq \int^{b}_{a} |f|\)</span></li>
</ol>
<h4 id="definition-7.4.3">Definition 7.4.3</h4>
<p>If <span class="math inline">\(f\)</span> is integrable on the interval <span class="math inline">\([a, b]\)</span>, define:</p>
<p><span class="math display">\[\int^a_{b} f = - \int^b_a f\]</span></p>
<p>Also, for <span class="math inline">\(c \in [a, b]\)</span>, definte:</p>
<p><span class="math display">\[\int^c_c f = 0\]</span></p>
<h4 id="theorem-7.4.4-integrable-limit-theorem">Theorem 7.4.4: Integrable Limit Theorem</h4>
<p>Assume that <span class="math inline">\(f_n \rightarrow f\)</span> uniformly on <span class="math inline">\([a, b]\)</span> and that each <span class="math inline">\(f_n\)</span> is integrable. Then <span class="math inline">\(f\)</span> is integrable and:</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} f_n = \int^b_{a} f\]</span></p>
<h3 id="the-fundamental-theorem-of-calculus">The Fundamental Theorem of Calculus</h3>
<h4 id="theorem-7.5.1-fundamental-theorem-of-calculus">Theorem 7.5.1: Fundamental Theorem of Calculus</h4>
<ol type="1">
<li><p>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is integrable, and <span class="math inline">\(\mathbb{F}: [a, b] \rightarrow \mathbb{R}\)</span> satisfies <span class="math inline">\(F^{\prime} (x) = f(x) \;\; \forall x \in [a, b]\)</span> satisfies <span class="math inline">\(F^{\prime} (x) = f(x), \; \forall x \in [a, b]\)</span>, then:</p>
<p><span class="math display">\[\int^b_a f = F(b) - F(a)\]</span></p></li>
<li><p>Let <span class="math inline">\(g: [a, b] \rightarrow \mathbb{R}\)</span> be integrable, and for <span class="math inline">\(x \in [a, b]\)</span>, define:</p>
<p><span class="math display">\[G(x) = \int^x_a g\]</span></p>
<p>Then <span class="math inline">\(G\)</span> is continuous on <span class="math inline">\([a, b]\)</span>. If <span class="math inline">\(g\)</span> is continuous at some point <span class="math inline">\(c \in [a, b]\)</span>, then <span class="math inline">\(G\)</span> is differentiable at <span class="math inline">\(c\)</span> and <span class="math inline">\(G^{\prime}(c) = g(c)\)</span></p>
<p><span class="math display">\[G^{\prime}(x) = \frac{d}{dx} \int^x_a g = g(x)\]</span></p></li>
</ol>
<h4 id="definition-7.6.1-measure-zero">Definition 7.6.1: Measure Zero</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> has <strong>measure zero</strong> if, for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a countable collection of open intervals <span class="math inline">\(O_n\)</span> with the property that <span class="math inline">\(A\)</span> is contained in the union of all of the intervals <span class="math inline">\(O_n\)</span> and the sum of the lengths of all of the intervals is less than or equal to <span class="math inline">\(\epsilon\)</span>. More precisely, if <span class="math inline">\(|O_n|\)</span> refers to the length of the interval <span class="math inline">\(O_n\)</span>, then we have:</p>
<p><span class="math display">\[A \subseteq \bigcup^{\infty}_{n=1} O_n\]</span></p>
<p>and</p>
<p><span class="math display">\[\sum^{\infty}_{n=1} | O_n | \leq \epsilon\]</span></p>
<blockquote>
<p>Consider a finite set <span class="math inline">\(A = \{a_1, ..., a_n\}\)</span>. To show that <span class="math inline">\(A\)</span> has measure zero, let <span class="math inline">\(\epsilon &gt; 0\)</span> be arbitrary. For each <span class="math inline">\(1 \leq n &lt; N\)</span>, construct the interval: <span class="math display">\[G_n = (a_n - \frac{\epsilon}{2N}, a_n + \frac{\epsilon}{2N})\]</span></p>
<p>Clearly, <span class="math inline">\(A\)</span> is contained in the union of these intervals, and <span class="math display">\[\sum^N_{n=1} | G_n | = \sum^N_{n=1}\frac{\epsilon}{N} = \epsilon\]</span></p>
</blockquote>
<h4 id="definition-7.6.3-alpha-continuity">Definition 7.6.3: <span class="math inline">\(\alpha\)</span>-Continuity</h4>
<p>Let <span class="math inline">\(f\)</span> be defined on <span class="math inline">\([a, b]\)</span>, and let <span class="math inline">\(\alpha &gt; 0\)</span>. The function <span class="math inline">\(f\)</span> is <span class="math inline">\(\alpha\)</span>-continuous at <span class="math inline">\(x \in [a, b]\)</span> if there exists <span class="math inline">\(\delta &gt; 0\)</span> s.t for all <span class="math inline">\(y, z \in (x - \delta, x + \delta)\)</span>, it follows that <span class="math inline">\(|f(y) - f(z)| &lt; \alpha\)</span>.</p>
<p>Let <span class="math inline">\(f\)</span> be a bounded function on <span class="math inline">\([a, b]\)</span>, for each <span class="math inline">\(\alpha &gt; 0\)</span>, defined <span class="math inline">\(D^{\alpha}\)</span> to be the set of points in <span class="math inline">\([a, b]\)</span>, where the function <span class="math inline">\(f\)</span> fails to be <span class="math inline">\(\alpha\)</span>-continuous;</p>
<h4 id="definition-7.6.4-uniformly-alpha-continuous">Definition 7.6.4: Uniformly <span class="math inline">\(\alpha\)</span>-continuous</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is uniformly <span class="math inline">\(\alpha\)</span>-continuous on <span class="math inline">\(A\)</span>, if there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t whenever <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are points in <span class="math inline">\(A\)</span> satisfying <span class="math inline">\(|x - y| &lt; \delta\)</span>, it follows that <span class="math inline">\(|f(x) - f(y)| &lt; \alpha\)</span>..</p>
<h4 id="theorem-7.6.5-lebesgues-theorem">Theorem 7.6.5 Lebesgue's Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> be a bounded function defined on the interval <span class="math inline">\([a, b]\)</span>. Then, <span class="math inline">\(f\)</span> is Riemann-integrable if and only if the set of points where <span class="math inline">\(f\)</span> is not continuous has measure zero.</p>
<h4 id="definition-8.4.3-improper-riemann-integrals">Definition 8.4.3: Improper Riemann Integrals</h4>
<p>Assume <span class="math inline">\(f\)</span> is defined on <span class="math inline">\([a, \infty)\)</span> and integrable on every interval of the form <span class="math inline">\([a, b]\)</span>. Then define <span class="math inline">\(\int^{\infty}_{a} f\)</span> to be:</p>
<p><span class="math display">\[\lim_{b \rightarrow \infty} \int^{b}_{a} f\]</span></p>
<p>provided the limit exists, in this case we say that the <strong>improper integral</strong> <span class="math inline">\(\int^{\infty}_a f\)</span> converges.</p>
<h3 id="interchange-of-limits-2">Interchange of Limits [2]</h3>
<h4 id="theorem-8.2.4">Theorem 8.2.4</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence of functions be defined on <span class="math inline">\([a, b] \in \mathbb{R}\)</span> and suppose that <span class="math inline">\((f_n)\)</span> converges <strong>uniformly</strong> on <span class="math inline">\([a, b]\)</span> to <span class="math inline">\(f\)</span>. Then <span class="math inline">\(f \in \mathbb{R}\)</span> and:</p>
<p><span class="math display">\[\int^{a}_{b} f = \lim_{n \rightarrow \infty} \int^b_a f_n\]</span></p>
<p>We can switch the integral and the limit.</p>
<h4 id="theorem-8.2.5-bounded-convergence-theorem">Theorem 8.2.5: Bounded Convergence Theorem</h4>
<p>Let <span class="math inline">\((f_n)\)</span> be a sequence defined on <span class="math inline">\(\mathbb{R}[a, b]\)</span> that converges on <span class="math inline">\([a, b]\)</span> to a function <span class="math inline">\(f \in \mathbb{R} [a, b]\)</span>. Suppose also that there exists a <span class="math inline">\(B &gt; 0\)</span> s.t <span class="math inline">\(|f_n(x)| \leq B, \; \forall x \in [a, b]\)</span>, <span class="math inline">\(n \in \mathbb{N}\)</span>. Then:</p>
<p><span class="math display">\[\int^{a}_{b} f = \lim_{n \rightarrow \infty} \int^b_a f_n\]</span></p>
<h4 id="theorem-8.2.6-dinis-theorem">Theorem 8.2.6: Dini's Theorem</h4>
<p>Suppose that <span class="math inline">\((f_n)\)</span> is a monotone sequence of continuous functions on <span class="math inline">\(I:=[a, b]\)</span> that converges on <span class="math inline">\(I\)</span> to a continuous function <span class="math inline">\(f\)</span>. Then the convergence of the sequence is uniform.</p>
<h3 id="the-exponential-function">The Exponential Function</h3>
<h4 id="theorem-8.3.1">Theorem 8.3.1:</h4>
<p>There exists a function <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span> s.t:</p>
<ol type="1">
<li><span class="math inline">\(E^{\prime} (x) = E(x)\)</span></li>
<li><span class="math inline">\(E(0) = 1\)</span></li>
</ol>
<h5 id="partial-proof-of-theorem-8.3.1">Partial Proof of Theorem 8.3.1</h5>
<p>We define a sequence <span class="math inline">\((E_n)\)</span> of continuous functions as follows:</p>
<ol type="1">
<li><span class="math inline">\(E_{1} (x) := 1 + x\)</span></li>
<li><span class="math inline">\(E_{n + 1} (x) := 1 + \int^x_0 E_n(t) dt\)</span></li>
</ol>
<p>for all <span class="math inline">\(n \in \mathbb{N}, x \in \mathbb{R}\)</span>, we can also show that:</p>
<p><span class="math display">\[E_{n} (x) = 1 + \frac{x}{1!} + \frac{x^2}{2!} + ... + \frac{x^n}{n!}\]</span></p>
<p>We can show that the limiting function <span class="math inline">\(E = \lim_{n\rightarrow \infty}\)</span> exists and satisfies all two points of <code>theorem 8.3.1</code>.</p>
<h4 id="corollary-8.3.2">Corollary 8.3.2</h4>
<p>The function <span class="math inline">\(E\)</span> has a derivative of every order and <span class="math inline">\(E^(n) (x) = E(x), \; \forall n \in \mathbb{N}, x \in \mathbb{R}\)</span>.</p>
<h4 id="corollary-8.3.3">Corollary 8.3.3</h4>
<p>If <span class="math inline">\(x &gt; 0\)</span>, then <span class="math inline">\(1 + x &lt; E(x)\)</span></p>
<h4 id="theorem-8.3.4">Theorem 8.3.4</h4>
<p>The function <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span> that satisfies <code>theorem 8.3.1 (i) and (ii)</code> is unique.</p>
<h4 id="definition-8.3.5">Definition 8.3.5</h4>
<p>The unique function <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span>, such that <span class="math inline">\(E^{\prime} (x) = E(x)\)</span> for all <span class="math inline">\(x \in \mathbb{R}\)</span> and <span class="math inline">\(E(0) = 1\)</span> is called the <strong>exponential function</strong>. The number <span class="math inline">\(e := E(1)\)</span> is called <strong>Euler's number</strong>:</p>
<p><span class="math display">\[\exp(x) := E(x)\]</span></p>
<p>or</p>
<p><span class="math display">\[e^x := E(x)\]</span></p>
<p>for <span class="math inline">\(x \in \mathbb{R}\)</span></p>
<h4 id="theorem-8.3.6">Theorem 8.3.6</h4>
<p>The exponential function satisfies the following properties:</p>
<ol type="1">
<li><span class="math inline">\(E(x) \neq 0, \; \forall x \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(E(x + y) = E(x)E(y), \; \forall x, y \in \mathbb{R}\)</span></li>
<li><span class="math inline">\(E(r) = e^r, \;\forall r \in \mathbb{Q}\)</span></li>
</ol>
<h4 id="theorem-8.3.7">Theorem 8.3.7</h4>
<p>The exponential function <span class="math inline">\(E\)</span> is <strong>strictly increasing</strong> on <span class="math inline">\(\mathbb{R}\)</span> and has range equal to <span class="math inline">\(y \in \mathbb{R}: y &gt; 0\)</span>. Further, we have:</p>
<ol type="1">
<li><span class="math inline">\(\lim_{x \rightarrow \infty} E(x) = 0\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow \infty} E(x) = \infty\)</span></li>
</ol>
<h3 id="the-logarithm-function">The Logarithm Function</h3>
<h4 id="definition-8.3.8-logarithm-function">Definition 8.3.8: Logarithm Function</h4>
<p>The function inverse to <span class="math inline">\(E: \mathbb{R} \rightarrow \mathbb{R}\)</span> is called the <strong>logarithm (natural logarithm)</strong> denoted by <span class="math inline">\(L\)</span> or by <span class="math inline">\(\ln\)</span>.</p>
<p>Since they are inverse, we have:</p>
<p><span class="math display">\[(L \circ E) (x) = x, \; \forall x \in \mathbb{R}\]</span></p>
<p>and</p>
<p><span class="math display">\[(E \circ L) (y) = y, \; \forall y \in \mathbb{R}, y &gt; 0\]</span></p>
<h4 id="theorem-8.3.9">Theorem 8.3.9</h4>
<p>The logarithm is a strictly increasing function <span class="math inline">\(L\)</span> with doman <span class="math inline">\(x \in \mathbb{R}: x &gt; 0\)</span> and range <span class="math inline">\(\mathbb{R}\)</span>. The derivative of <span class="math inline">\(L\)</span> is given by:</p>
<ol type="1">
<li><span class="math inline">\(L^{\prime} (x) = \frac{1}{x}\)</span></li>
<li><span class="math inline">\(L(xy) = L(x) L(y)\)</span></li>
<li><span class="math inline">\(L(1) = 0, L(e) = 1\)</span></li>
<li><span class="math inline">\(L(x^r) = rL(x), \; \forall r \in \mathbb{Q}\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow 0^+} L(x) = -\infty\)</span> and <span class="math inline">\(\lim_{x \rightarrow \infty} L(x) = \infty\)</span></li>
</ol>
<h3 id="power-function">Power Function</h3>
<h4 id="definition-8.3.10-power-function">Definition 8.3.10: Power Function</h4>
<p>If <span class="math inline">\(\alpha \in \mathbb{R}\)</span> and <span class="math inline">\(x &gt; 0\)</span>, the number <span class="math inline">\(x^\alpha\)</span> is defined to be</p>
<p><span class="math display">\[x^\alpha := e^{\alpha \ln x} = E(\alpha L(x))\]</span></p>
<p>The function <span class="math inline">\(x \rightarrow x^\alpha\)</span> for <span class="math inline">\(x &gt; 0\)</span> is called the <strong>power function</strong> with exponent <span class="math inline">\(\alpha\)</span>.</p>
<h4 id="theorem-8.3.11">Theorem 8.3.11</h4>
<p>If <span class="math inline">\(\alpha \in \mathbb{R}\)</span> and <span class="math inline">\(x, y\)</span> belong to <span class="math inline">\((0, \infty)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(1^\alpha = 1\)</span></li>
<li><span class="math inline">\(x^\alpha &gt; 0\)</span></li>
<li><span class="math inline">\((xy)^\alpha = x^\alpha y^\alpha\)</span></li>
<li><span class="math inline">\((\frac{x}{y})^{\alpha} = \frac{x^\alpha}{y^\alpha}\)</span></li>
</ol>
<h4 id="theorem-8.3.12">Theorem 8.3.12</h4>
<p>If <span class="math inline">\(\alpha, \beta \in \mathbb{R}\)</span> and <span class="math inline">\(x \in (0, \infty)\)</span>, then:</p>
<ol type="1">
<li><span class="math inline">\(x^{\alpha + \beta} = x^{\alpha} + x^{\beta}\)</span></li>
<li><span class="math inline">\((x^\alpha)^\beta = x^{\alpha\beta} = (x^{\beta})^\alpha\)</span></li>
<li><span class="math inline">\(x^{-\alpha} = \frac{1}{x^\alpha}\)</span></li>
<li>If <span class="math inline">\(\alpha &lt; \beta\)</span>, then <span class="math inline">\(x^\alpha &lt; x^\beta\)</span> for <span class="math inline">\(x &gt; 1\)</span></li>
</ol>
<h4 id="theorem-8.3.13">Theorem 8.3.13</h4>
<p>Let <span class="math inline">\(\alpha \in \mathbb{R}\)</span>. Then the function <span class="math inline">\(x \rightarrow x^\alpha\)</span> on <span class="math inline">\((0, \infty)\)</span> to <span class="math inline">\(\mathbb{R}\)</span> is continuous and differentiable, and</p>
<p><span class="math display">\[D x^\alpha = \alpha x^{\alpha - 1}\]</span></p>
<p>If <span class="math inline">\(\alpha &gt; 0\)</span> the power function is strictly increasing, if <span class="math inline">\(\alpha &lt; 0\)</span>, the power function is strictly decreasing.</p>
<h3 id="function-log_a">Function <span class="math inline">\(\log_a\)</span></h3>
<p>if <span class="math inline">\(a &gt; 0\)</span>, <span class="math inline">\(a \neq 1\)</span>, it is sometimes useful to define the function <span class="math inline">\(\log_a\)</span></p>
<h4 id="definition-8.3.14">Definition 8.3.14</h4>
<p>Let <span class="math inline">\(a &gt; 0, a \neq 1\)</span>. We define:</p>
<p><span class="math display">\[\log_a (x) := \frac{\ln x}{\ln a}\]</span></p>
<p>for <span class="math inline">\(x \in (0, \infty)\)</span></p>
<p>This is called <strong>logarithm of <span class="math inline">\(x\)</span> to the base <span class="math inline">\(a\)</span>.</strong></p>
<h3 id="the-trigonometric-function">The Trigonometric Function</h3>
<h4 id="theorem-8.4.1">Theorem 8.4.1</h4>
<p>There exist functions <span class="math inline">\(C: \mathbb{R} \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(S: \mathbb{R} \rightarrow \mathbb{R}\)</span> such that:</p>
<ol type="1">
<li><span class="math inline">\(C^{\prime\prime} (x) = - C(x)\)</span> and <span class="math inline">\(S^{\prime\prime} (x) = - S(x)\)</span> for all <span class="math inline">\(S: \mathbb{R} \rightarrow \mathbb{R}\)</span>.</li>
<li><span class="math inline">\(C(0) = 1, C^{\prime} (0)\)</span>, and <span class="math inline">\(S(0) = 0, S^{\prime} (0) = 1\)</span></li>
</ol>
<h5 id="partial-proof-of-theorem-8.4.1">Partial Proof of Theorem 8.4.1</h5>
<p>Define the sequences <span class="math inline">\((C_n), (S_n)\)</span> of continuous functions inductively as:</p>
<ol type="1">
<li><span class="math inline">\(C_1 (x) := 1, \; S_1 (x) := x\)</span></li>
<li><span class="math inline">\(S_n(x) := \int^x_0 C_n(t) dt\)</span></li>
<li><span class="math inline">\(C_{n+1} (x) := 1 - \int^x_0 S_n(t) dt\)</span></li>
</ol>
<p>for all <span class="math inline">\(n \in \mathbb{N}, x \in \mathbb{R}\)</span>. By induction, we have:</p>
<p><span class="math display">\[C_{n+1} (x) = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - ... + (-1)^n \frac{x^{2n}}{(2n)!}\]</span> <span class="math display">\[S_{n+1} (x) = x - \frac{x^3}{3!} + \frac{x^5}{t!} - .... + (-1)^n \frac{x^{2n+1}}{(2n+1)!}\]</span></p>
<p>Then the sequences converges uniformly to some function <span class="math inline">\(C, S\)</span> that satisfies all the properties of <code>theorem 8.4.1</code>.</p>
<h4 id="corollary-8.4.2">Corollary 8.4.2</h4>
<p>If <span class="math inline">\(C, S\)</span> are the functions in <code>theorem 8.4.1</code>, then:</p>
<ol type="1">
<li><span class="math inline">\(C^{\prime} (x) = -S(x)\)</span> and <span class="math inline">\(S^{\prime} (x) = C(x)\)</span> for all <span class="math inline">\(x \in \mathbb{R}\)</span>.</li>
</ol>
<p>Moreover, these functions have derivatives of all orders.</p>
<h4 id="corollary-8.4.3">Corollary 8.4.3</h4>
<p>The functions <span class="math inline">\(C, S\)</span> satisfy the pythagorean identity:</p>
<ol type="1">
<li><span class="math inline">\((C(x))^2 + (S(x))^2 = 1\)</span></li>
</ol>
<h4 id="theorem-8.4.4">Theorem 8.4.4</h4>
<p>The function <span class="math inline">\(C, S\)</span> satisfying properties of <code>theorem 8.4.1</code> are unique.</p>
<h4 id="definition-8.4.5">Definition 8.4.5</h4>
<p>The unique functions <span class="math inline">\(C: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math inline">\(S: \mathbb{R} \rightarrow \mathbb{R}\)</span> satisfying properties in <code>theorem 8.4.1</code> are called <strong>cosine function</strong> and <strong>sine function</strong>:</p>
<p><span class="math display">\[\cos x := C(x)\]</span> <span class="math display">\[\sin x := S(x)\]</span></p>
<h4 id="theorem-8.4.6">Theorem 8.4.6</h4>
<p>If <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is such that</p>
<p><span class="math display">\[f^{\prime\prime} (x) = -f(x), \;\; \forall x \in \mathbb{R}\]</span></p>
<p>then there exist real numbers <span class="math inline">\(\alpha, \beta\)</span> s.t</p>
<p><span class="math display">\[f(x) = \alpha C(x) + \beta S(x)\]</span></p>
<h4 id="theorem-8.4.7">Theorem 8.4.7:</h4>
<p>The function <span class="math inline">\(C\)</span> is even and <span class="math inline">\(S\)</span> is odd in the sense that:</p>
<ol type="1">
<li><span class="math inline">\(C(-x) = C(x)\)</span> and <span class="math inline">\(S(-x) = - S(x)\)</span></li>
</ol>
<p>If <span class="math inline">\(x, y \in \mathbb{R}\)</span>, then we have the <strong>addition formula</strong>:</p>
<p><span class="math display">\[C(x + y) = C(x) C(y) - S(x)S(y)\]</span> <span class="math display">\[S(x + y) = S(x)C(y) + C(x)S(y)\]</span></p>
<h2 id="ref">Ref</h2>
<p>[1] Understanding Analysis by Stephen Abbott</p>
<p>[2] Introduction to Real Analysis by G.Bartle, R.Sherbert</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/01/06/linear-algebra/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/06/linear-algebra/" class="post-title-link" itemprop="url">linear-algebra</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-06 08:29:19" itemprop="dateCreated datePublished" datetime="2022-01-06T08:29:19+08:00">2022-01-06</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-02-04 14:03:43" itemprop="dateModified" datetime="2022-02-04T14:03:43+08:00">2022-02-04</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/01/06/linear-algebra/" class="post-meta-item leancloud_visitors" data-flag-title="linear-algebra" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>9.4k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>9 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="linear-algebra-1">Linear Algebra (1)</h1>
<p>All the notes precisely follows <strong>Linear Algebra Done Right by Sheldon Axler</strong></p>
<h2 id="vector-spaces">Vector Spaces</h2>
<h3 id="complex-numbers">Complex Numbers</h3>
<h4 id="definition-1.1-complex-numbers">Definition 1.1: Complex Numbers</h4>
<ol type="1">
<li>A <strong>Complex Number</strong> is an order pair <span class="math inline">\((a, b)\)</span>, where <span class="math inline">\(a, b \in \mathbb{R}\)</span>.</li>
<li><strong>Addition and multiplication</strong> is defined as: <span class="math display">\[x + y = (a + b) + (c + d) = (a + c, b + d)\]</span> <span class="math display">\[xy = (a + b) (c + d) = (ac - bd, ad + bc)\]</span></li>
<li><span class="math inline">\(i = (0, 1)\)</span> and <span class="math inline">\(i^2 = (0, 1) (0, 1) = -1\)</span></li>
<li>Every complex number can be written as <span class="math display">\[x = (a, b) = (a, 0) + (0, b) = (a, 0) + (b, 0)(0, 1) = a + bi\]</span></li>
<li>The set of all complex numbers is denoted by <span class="math inline">\(\mathbb{C}\)</span>: <span class="math display">\[\mathbb{C} = \{a + bi: a, b \in \mathbb{R}\}\]</span></li>
<li><strong>Addition and multiplication</strong> on <span class="math inline">\(\mathbb{C}\)</span> are defined by <span class="math display">\[(a + bi) + (c + di) = (a + c) + (b + d)i\]</span> <span class="math display">\[(a + bi) (c + di) = (ac - bd) + (ad + bc)i\]</span></li>
</ol>
<p><span class="math inline">\(a, c, b, d \in \mathbb{R}\)</span></p>
<p>If <span class="math inline">\(a \in \mathbb{R}\)</span>, we identify <span class="math inline">\(a + 0i\)</span> with the real number <span class="math inline">\(a\)</span>. Thus we can think of <span class="math inline">\(\mathbb{R}\)</span> as a subset of <span class="math inline">\(\mathbb{C}\)</span>.</p>
<h4 id="definition-1.2-conjugate">Definition 1.2: Conjugate</h4>
<p>If <span class="math inline">\(a, b\)</span> are real and <span class="math inline">\(z = a + bi\)</span>, then the complex number <span class="math inline">\(\bar{z} = a - bi\)</span> is called the <strong>conjugate</strong> of <span class="math inline">\(z\)</span>. The numbers <span class="math inline">\(a, b\)</span> are the real part and the imaginary part of <span class="math inline">\(z\)</span> respectively:</p>
<p><span class="math display">\[a = Re(z), \quad \quad b = Im(z)\]</span></p>
<h4 id="theorem-1.3a">Theorem 1.3A</h4>
<p>If <span class="math inline">\(z\)</span> and <span class="math inline">\(w\)</span> are complex, then</p>
<ol type="1">
<li><span class="math inline">\(\overline{z + w} = \bar{z} + \bar{w}\)</span></li>
<li><span class="math inline">\(\overline{zw} = \bar{z}\bar{w}\)</span></li>
<li><span class="math inline">\(z + \bar{z} = 2Re(z),\quad z - \bar{z} = 2i Im(z)\)</span></li>
<li>If <span class="math inline">\(z = a + bi\)</span>, <span class="math inline">\(z \bar{z} = a^2 + b^2\)</span> is real and positive.</li>
<li><span class="math inline">\(|z| = \sqrt{z\bar{z}} = \sqrt{a^2 + b^2}\)</span> is unique.</li>
<li><span class="math inline">\(|zw| = |z||w|\)</span></li>
</ol>
<h4 id="theorem-1.3b-schwarz-inequality">Theorem 1.3B: Schwarz Inequality</h4>
<p>If <span class="math inline">\(a_1, ..., a_n\)</span> and <span class="math inline">\(b_1, ..., b_n\)</span> are complex numbers, then:</p>
<p><span class="math display">\[|\sum^n_{j=1} a_j \bar{b_j}|^2 \leq \sum^n_{j=1} |a_j|^2 \sum^{n}_{j=1} |b_j|^2\]</span></p>
<h4 id="property-1.4-properties-of-complex-arithmetic">Property 1.4: Properties of Complex Arithmetic</h4>
<ol type="1">
<li><p>Commutativity:</p>
<p><span class="math display">\[\alpha + \beta = \beta + \alpha, \;\; \alpha \beta = \beta \alpha, \quad \alpha, \beta \in \mathbb{C}\]</span></p></li>
<li><p>Associativity:</p>
<p><span class="math display">\[(\alpha + \beta) + \lambda = \alpha + (\beta + \lambda), \;\; (\alpha\beta)\lambda = \alpha (\beta\lambda), \quad \alpha, \beta, \lambda \in \mathbb{C}\]</span></p></li>
<li><p>Identities:</p>
<p><span class="math display">\[\lambda + 0 = \lambda, \;\; \lambda 1 = \lambda, \quad \forall \lambda \in \mathbb{C}\]</span></p></li>
<li><p>Additive Inverse:</p>
<p>For all <span class="math inline">\(\alpha \in \mathbb{C}\)</span>, there exists a unique <span class="math inline">\(\beta \in \mathbb{C}\)</span> such that <span class="math inline">\(\alpha + \beta = 0\)</span>.</p></li>
<li><p>Multiplicative Inverse:</p>
<p>For all <span class="math inline">\(\alpha \in \mathbb{C}, \alpha \neq 0\)</span>, there exists a unique <span class="math inline">\(\beta \in \mathbb{C}\)</span> such that <span class="math inline">\(\alpha\beta = 1\)</span>.</p></li>
<li><p>Distributive Property:</p>
<p><span class="math display">\[\lambda (\alpha + \beta) = \lambda \alpha + \lambda \beta, \quad \forall \lambda, \alpha, \beta \in \mathbb{C}\]</span></p></li>
</ol>
<h4 id="definition-1.5--alpha-subtraction-frac1alpha-division">Definition 1.5: <span class="math inline">\(-\alpha\)</span>, Subtraction, <span class="math inline">\(\frac{1}{\alpha}\)</span>, Division</h4>
<p>Let <span class="math inline">\(\alpha, \beta \in \mathbb{C}\)</span>:</p>
<ol type="1">
<li>Let <span class="math inline">\(-\alpha\)</span> denote the additive inverse of <span class="math inline">\(\alpha\)</span>. Thus, <span class="math inline">\(-\alpha\)</span> is the unique complex number s.t: <span class="math display">\[\alpha + (- \alpha) = 0\]</span></li>
<li><strong>Subtraction</strong> on <span class="math inline">\(\mathbb{C}\)</span> is defined by: <span class="math display">\[\beta - \alpha = \beta + (-\alpha)\]</span></li>
<li>For <span class="math inline">\(\alpha \neq 0\)</span>, let <span class="math inline">\(\frac{1}{\alpha}\)</span> denote the multiplicative inverse of <span class="math inline">\(\alpha\)</span>. Thus <span class="math inline">\(\frac{1}{\alpha}\)</span> is the unique complex number s.t: <span class="math display">\[\alpha (\frac{1}{\alpha}) = 1\]</span></li>
<li><strong>Division</strong> on <span class="math inline">\(\mathbb{C}\)</span> is defined by: <span class="math display">\[\frac{\beta}{\alpha} = \beta\frac{1}{\alpha}\]</span></li>
</ol>
<h4 id="definition-1.7-mathbbf">Definition 1.7: <span class="math inline">\(\mathbb{F}\)</span></h4>
<p><span class="math inline">\(\mathbb{F}\)</span> stands for either <span class="math inline">\(\mathbb{R}, \mathbb{C}\)</span>. Elements of <span class="math inline">\(\mathbb{F}\)</span> are called <strong>scalars</strong> which is a fancy word for number.</p>
<h4 id="definition-1.8-list-length">Definition 1.8: List, Length</h4>
<p>Suppose <span class="math inline">\(n\)</span> is a nonnegative integer. A <strong>list</strong> of <strong>length</strong> <span class="math inline">\(n\)</span> (<span class="math inline">\(n-tuple\)</span>) is an ordered collection of <span class="math inline">\(n\)</span> elements (can be numbers, other lists or more abstract entities) separated by commas and surrounded by parentheses. A list of length <span class="math inline">\(n\)</span> looks like:</p>
<p><span class="math display">\[(x_1, ..., x_n)\]</span></p>
<p>Two lists are <strong>equal</strong>, if and only if they have the same length and the same elements in the same order.</p>
<p>Each list has a finite length that is a nonnegative integer. Thus an object with <strong>infinite length is not a list</strong>.</p>
<p>A list of length 0 is denoted as <span class="math inline">\(()\)</span>.</p>
<h4 id="definition-1.10-mathbbfn">Definition 1.10: <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p><span class="math inline">\(\mathbb{F}^n\)</span> is the set of all lists of length <span class="math inline">\(n\)</span> of elements of <span class="math inline">\(\mathbb{F}\)</span>:</p>
<p><span class="math display">\[\mathbb{F}^{n} = \{(x_1, ..., x_n): x_j \in \mathbb{F}, \; \forall j=1, ..., n\}\]</span></p>
<p>For <span class="math inline">\((x_1, ..., x_n) \in \mathbb{F}^n\)</span> and <span class="math inline">\(j \in \{1, ..., n\}\)</span>, we say that <span class="math inline">\(x_j\)</span> is the <span class="math inline">\(j\)</span>th <strong>coordinate</strong> of <span class="math inline">\((x_1, ..., x_n)\)</span>.</p>
<h4 id="definition-1.12-addition-in-mathbbfn">Definition 1.12: Addition in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p><strong>Addition</strong> in <span class="math inline">\(\mathbb{F}^n\)</span> is defined by adding corresponding coordinates:</p>
<p><span class="math display">\[(x_1, ...., x_n) + (y_1, ...., y_n) = (x_1 + y_1, ...., x_n + y_n)\]</span></p>
<h4 id="definition-1.13-commutativity-of-addition-in-mathbbfn">Definition 1.13: Commutativity of Addition in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p>If <span class="math inline">\(x, y \in \mathbb{F}^n\)</span>, then <span class="math inline">\(x + y = y + x\)</span></p>
<p><strong>If a single letter is used to denote an element of <span class="math inline">\(\mathbb{F}^n\)</span>, then the same letter with appropriate subscripts is often used when coordinates must be displayed.</strong></p>
<h4 id="definition-1.14-0">Definition 1.14: 0</h4>
<p>Let <span class="math inline">\(0\)</span> denote the list of length <span class="math inline">\(n\)</span> whose coordinates are all 0:</p>
<p><span class="math display">\[0 = (0, ..., 0)\]</span></p>
<h4 id="definition-1.16-additive-inverse-in-mathbbfn">Definition 1.16: Additive Inverse in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p>For <span class="math inline">\(x \in \mathbb{F}^n\)</span>, the <strong>additive inverse</strong> of <span class="math inline">\(x\)</span>, denoted <span class="math inline">\(-x\)</span>, is the vector <span class="math inline">\(-x \in \mathbb{F}^n\)</span> such that</p>
<p><span class="math display">\[x + (-x) = 0\]</span></p>
<p>In order words, if <span class="math inline">\(x = (x_1, ...., x_n)\)</span>, then <span class="math inline">\(-x = (-x_1, ..., -x_n)\)</span></p>
<h4 id="definition-1.17-scalar-multiplication-in-mathbbfn">Definition 1.17: Scalar Multiplication in <span class="math inline">\(\mathbb{F}^n\)</span></h4>
<p>The <strong>product</strong> of a number <span class="math inline">\(\lambda\)</span> and a vector in <span class="math inline">\(\mathbb{F}^n\)</span> is computed by multiplying each coordinate of the vector by <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[\lambda (x_1, ..., x_n) = (\lambda x_1, ...., \lambda x_n)\]</span></p>
<p>here <span class="math inline">\(\lambda \in \mathbb{F}, \;\ (x_1, ..., x_n) \in \mathbb{F}^n\)</span></p>
<h4 id="field">Field</h4>
<p>A <strong>field</strong> is a set containing at least two distinct elements called <span class="math inline">\(0, 1\)</span>, along with operations of addition and multiplication satisfying all the properties in <strong>Definition 1.3</strong>. Thus, <span class="math inline">\(\mathbb{R}, \mathbb{C}\)</span> are fields.</p>
<h3 id="definition-of-vector-space">Definition of Vector Space</h3>
<h4 id="definition-1.18-addition-scalar-multiplication">Definition 1.18: Addition, Scalar Multiplication</h4>
<ol type="1">
<li>An <strong>addition</strong> on a set <span class="math inline">\(V\)</span> is a function that assigns an element <span class="math inline">\(u + v \in V\)</span> to each pair of elements <span class="math inline">\(u, v \in V\)</span>.</li>
<li>A <strong>scalar multiplication</strong> on a set <span class="math inline">\(V\)</span> is a function that assigns an element <span class="math inline">\(\lambda v \in V\)</span> to each <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and each <span class="math inline">\(v \in V\)</span>.</li>
</ol>
<h4 id="definition-1.19-vector-space">Definition 1.19: Vector Space</h4>
<p>A <strong>vector space</strong> is a set <span class="math inline">\(V\)</span> along with an addition on <span class="math inline">\(V\)</span> and a scalar multiplication on <span class="math inline">\(V\)</span> such that the following properties hold:</p>
<ol type="1">
<li><p><strong>Commutativity</strong>: <span class="math display">\[u + v = v + u, \; \forall u, v \in V\]</span></p></li>
<li><p><strong>Associativity</strong>: <span class="math display">\[(u + v) + w = u + (v + w) \text{ and } (ab) v = a(bv), \;  \forall u, v, w \in V, \; \forall a, b \in \mathbb{F}\]</span></p></li>
<li><p><strong>Additive Identity</strong>:</p>
<p>There exists an element <span class="math inline">\(0 \in V\)</span> such that <span class="math inline">\(v + 0 = v, \; \forall v \in V\)</span></p></li>
<li><p><strong>Additive Inverse</strong>: <span class="math display">\[\forall v \in V, \exists \; w \in V \; s.t \; v + w = 0\]</span></p></li>
<li><p><strong>Multiplicative Identity</strong>: <span class="math display">\[1v = v, \; \forall v \in V\]</span></p></li>
<li><p><strong>Distributive Properties</strong>: <span class="math display">\[a(u + v) = au + av \text{ and } (a + b)v = av + bv, \; \forall a, b \in \mathbb{F}, \; \forall u, v \in \mathbb{F}\]</span></p></li>
</ol>
<h4 id="definition-1.20-vector-point">Definition 1.20: Vector, Point</h4>
<p>Elements of a vector space are called <strong>vectors</strong> or <strong>points</strong>.</p>
<p>Since the scalar multiplication in a vector space depends on <span class="math inline">\(\mathbb{F}\)</span>, thus we need to be precise. We say that <span class="math inline">\(V\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span> (i.e <span class="math inline">\(\mathbb{R}^n\)</span> is a vector space over <span class="math inline">\(\mathbb{R}\)</span>).</p>
<h4 id="definition-1.21-real-vector-space-complex-vector-space">Definition 1.21: Real Vector Space, Complex Vector Space</h4>
<ol type="1">
<li>A vector space over <span class="math inline">\(\mathbb{R}\)</span> is called a <strong>real vector space</strong>.</li>
<li>A vector space over <span class="math inline">\(\mathbb{C}\)</span> is called a <strong>complex vector space</strong>.</li>
</ol>
<h4 id="definition-1.23-mathbbfs">Definition 1.23 <span class="math inline">\(\mathbb{F}^S\)</span></h4>
<ol type="1">
<li>If <span class="math inline">\(S\)</span> is a set, then <span class="math inline">\(\mathbb{F}^S\)</span> denotes the set of functions from <span class="math inline">\(S\)</span> to <span class="math inline">\(\mathbb{F}\)</span>.</li>
<li>For <span class="math inline">\(f, g \in \mathbb{F}^S\)</span>, the <strong>sum</strong> <span class="math inline">\(f + g \in \mathbb{F}^S\)</span> is the function defined by: <span class="math display">\[(f + g) (x) = f(x) + g(x), \; \forall x \in S\]</span></li>
<li>For <span class="math inline">\(\lambda \in \mathbb{F}\)</span> and <span class="math inline">\(f \in \mathbb{F}^S\)</span>, the <strong>product</strong> <span class="math inline">\(\lambda f \in \mathbb{F}^S\)</span> is the function defined by: <span class="math display">\[(\lambda f)(x) = \lambda f(x), \; \forall x \in S\]</span></li>
</ol>
<p>We can think of <span class="math inline">\(\mathbb{F}^n\)</span> as special case of <span class="math inline">\(\mathbb{F}^S\)</span>, because it can be represented as <span class="math inline">\(\mathbb{F}^{\{1, ...., n\}}\)</span> which is the set of functions:</p>
<p><span class="math display">\[\{f: \{1, ..., n\} \rightarrow \mathbb{F}\}\]</span></p>
<p>and <span class="math inline">\(f(i)\)</span> is the <span class="math inline">\(i\)</span>th element of the list (i.e <span class="math inline">\((f(1) ,...., f(n)) \in \mathbb{F}^n\)</span>). Since the sequence of numbers in <span class="math inline">\(\mathbb{F}\)</span> is a function that maps from natural number to <span class="math inline">\(\mathbb{F}\)</span>.</p>
<h4 id="property-1.25-unique-additive-identity">Property 1.25: Unique Additive Identity</h4>
<p>A vector space has a unique additive identity.</p>
<h4 id="property-1.26-unique-additive-inverse">Property 1.26: Unique Additive Inverse</h4>
<p>Every element in a vector space has a unique additive inverse.</p>
<h4 id="definition-1.27--v-w---v">Definition 1.27: <span class="math inline">\(-v, w - v\)</span></h4>
<p>Let <span class="math inline">\(v, w \in V\)</span>, where <span class="math inline">\(V\)</span> is a vector space. Then</p>
<ol type="1">
<li><span class="math inline">\(-v\)</span> denotes the additive inverse of <span class="math inline">\(v\)</span>.</li>
<li><span class="math inline">\(w - v\)</span> is defined to be <span class="math inline">\(w + (-v)\)</span>.</li>
</ol>
<h4 id="property-1.29-the-scalar-0-times-a-vector">Property 1.29: The <strong>scalar</strong> 0 times a vector</h4>
<p><span class="math inline">\(0v = 0, \forall v \in V\)</span>, where <span class="math inline">\(V\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span>.</p>
<h4 id="property-1.29-a-scalar-times-a-vector-0">Property 1.29: A scalar times a <strong>vector</strong> 0</h4>
<p><span class="math inline">\(a0 = 0, \forall a \in \mathbb{F}\)</span>.</p>
<h4 id="property-1.31-the-number--1-times-a-vector">Property 1.31: The number <span class="math inline">\(-1\)</span> times a vector</h4>
<p><span class="math inline">\((-1)v = -v, \forall v \in V\)</span>, where <span class="math inline">\(V\)</span> is a vector space over <span class="math inline">\(\mathbb{F}\)</span></p>
<h3 id="subspaces">Subspaces</h3>
<h4 id="definition-1.32-subspace-linear-subspace">Definition 1.32: Subspace (Linear Subspace)</h4>
<p>A subset <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> is called a <strong>subspace</strong> of <span class="math inline">\(V\)</span> if <span class="math inline">\(U\)</span> is also a vector space (using the same addition adn scalar multiplication as on <span class="math inline">\(V\)</span>).</p>
<h4 id="definition-1.34-conditions-for-a-subspace">Definition 1.34 Conditions for a Subspace</h4>
<p>A subset <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> is a subspace of <span class="math inline">\(V\)</span> if and only if <span class="math inline">\(U\)</span> satisfies the following three conditions:</p>
<ol type="1">
<li>Additive Identity: <span class="math display">\[0 \in U\]</span></li>
<li>Closed under Addition: <span class="math display">\[u, w \in U \implies u + w \in U\]</span></li>
<li>closed under scalar multiplication: <span class="math display">\[a \in \mathbb{F}, u \in U \implies au \in U\]</span></li>
</ol>
<h4 id="definition-1.36-sum-of-subsets">Definition 1.36: Sum of Subsets</h4>
<p>Suppose <span class="math inline">\(U_1, ...., U_m\)</span> are subsets of <span class="math inline">\(V\)</span>. The <strong>sum</strong> of <span class="math inline">\(U_1, ..., U_m\)</span>, denoted <span class="math inline">\(U_1 + ... + U_m\)</span>, is the set of all possible sums of elements of <span class="math inline">\(U_1 ,...., U_m\)</span>:</p>
<p><span class="math display">\[U_1 + .... + U_m = \{u_1 + ... u_m: u_1 \in U_1, ..., u_m \in U_m\}\]</span></p>
<p><strong>The union of subspaces is rarely a subspace which is why we usually work with sums rather than unions.</strong></p>
<h4 id="definition-1.39-sum-of-subspaces-is-the-smallest-containing-subspace">Definition 1.39: Sum of Subspaces is the Smallest Containing Subspace</h4>
<p>Suppose <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U_1 + .... + U_m\)</span> is the smallest subspace of <span class="math inline">\(V\)</span> containing <span class="math inline">\(U_1, ...., U_m\)</span>.</p>
<h4 id="definition-1.40-direct-sum">Definition 1.40: Direct Sum</h4>
<p>Suppose <span class="math inline">\(U_1, ..., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>:</p>
<ol type="1">
<li>The sum <span class="math inline">\(U_1 + ... + U_m\)</span> is called a <strong>direct sum</strong> if each element of the resulting set <span class="math inline">\(U_1 + ... + U_m\)</span> can be written in only one way as a sum <span class="math inline">\(u_1 + ... + u_m\)</span>, where each <span class="math inline">\(u_j\)</span> is in <span class="math inline">\(U_j\)</span>.</li>
<li>If <span class="math inline">\(U_1 + .... + U_m\)</span> is a direct sum, then <span class="math inline">\(U_1 \oplus ... \oplus U_m\)</span> denotes <span class="math inline">\(U_1 + ... + U_m\)</span>, with the <span class="math inline">\(\oplus\)</span> indicating the direct sum.</li>
</ol>
<blockquote>
<p><span class="math display">\[U_1 = \{(x, y, 0) \in \mathbb{F}^3: x, y \in \mathbb{F}\}\]</span> <span class="math display">\[U_2 = \{(0, 0, z) \in \mathbb{F}^3: x, y \in \mathbb{F}\}\]</span> <span class="math display">\[U_3 = \{(0, y, y) \in \mathbb{F}^3: x, y \in \mathbb{F}\}\]</span></p>
<p>Then, <span class="math inline">\(U_1 + U_2 + U_3 = \mathbb{F}^3\)</span> is not a direct sum because the element <span class="math inline">\((0, 0, 0) \in \mathbb{F}^3\)</span>, can be written in two different ways using the sum:</p>
<p><span class="math display">\[(0, 1, 0) + (0, 0, 1) + (0, -1, -1) = (0, 0, 0)\]</span> <span class="math display">\[(0, 0, 0) + (0, 0, 0) + (0, 0, 0) = (0, 0, 0)\]</span></p>
</blockquote>
<h4 id="definition-1.44-condition-for-a-direct-sum">Definition 1.44 Condition for a Direct Sum</h4>
<p>Suppose <span class="math inline">\(U_1, ...., U_m\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U_1 + ... + U_m\)</span> is a direct sum if and only if the only way to write <span class="math inline">\(0\)</span> as a sum <span class="math inline">\(u_1 + ... + u_m\)</span>, where each <span class="math inline">\(u_j\)</span> is in <span class="math inline">\(U_j\)</span>, is by taking each <span class="math inline">\(u_j\)</span> equal to <span class="math inline">\(0\)</span>.</p>
<h4 id="definition-1.45-direct-sum-of-two-subspaces">Definition 1.45 Direct Sum of Two Subspaces</h4>
<p>Suppose <span class="math inline">\(U, W\)</span> are subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(U + W\)</span> is a direct sum if and only if <span class="math inline">\(U \cap W = \{0\}\)</span>. <strong>The result only limit to two subspaces.</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://swag1ong.github.io/2022/01/01/real-analysis-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/others/favicon.jpeg">
      <meta itemprop="name" content="Zhu, Zhaoyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GoGoGogo!">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/01/real-analysis-3/" class="post-title-link" itemprop="url">Real Analysis (3)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-01-01 10:33:24" itemprop="dateCreated datePublished" datetime="2022-01-01T10:33:24+08:00">2022-01-01</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-01-17 21:16:22" itemprop="dateModified" datetime="2022-01-17T21:16:22+08:00">2022-01-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Background/" itemprop="url" rel="index"><span itemprop="name">Background</span></a>
        </span>
    </span>

  
    <span id="/2022/01/01/real-analysis-3/" class="post-meta-item leancloud_visitors" data-flag-title="Real Analysis (3)" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>13 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="real-analysis-3">Real Analysis (3)</h1>
<h2 id="basic-topology-of-mathbbr">Basic Topology of <span class="math inline">\(\mathbb{R}\)</span></h2>
<h3 id="open-and-closed-sets">Open and Closed Sets</h3>
<h4 id="definition-3.2.1-open">Definition 3.2.1: Open</h4>
<p>A set <span class="math inline">\(O \subseteq \mathbb{R}\)</span> is <strong>open</strong> if for all points <span class="math inline">\(a \in O\)</span> there exists an <span class="math inline">\(\epsilon-neighborhood V_{\epsilon} (a) \subseteq O\)</span>.</p>
<blockquote>
<p><span class="math inline">\(\mathbb{R}\)</span> is open <span class="math inline">\(\emptyset\)</span> is open</p>
</blockquote>
<h4 id="theorem-3.2.3">Theorem 3.2.3</h4>
<ol type="1">
<li>The union of an arbitrary collection of open sets is open.</li>
<li>The intersection of a finite collection of open sets is open.</li>
</ol>
<h4 id="definition-3.2.4-limit-point">Definition 3.2.4: Limit Point</h4>
<p>A point <span class="math inline">\(x\)</span> is a <strong>limit point</strong> of a set <span class="math inline">\(A\)</span> if every <span class="math inline">\(\epsilon-neighborhood V_{\epsilon} (x)\)</span> of <span class="math inline">\(x\)</span> intersects the set <span class="math inline">\(A\)</span> at some point other than <span class="math inline">\(x\)</span>. Limit points may not be in <span class="math inline">\(A\)</span>, consider the end points of open sets.</p>
<h4 id="theorem-3.2.5">Theorem 3.2.5</h4>
<p>A point <span class="math inline">\(x\)</span> is a <strong>limit point</strong> of a set <span class="math inline">\(A\)</span> if and only if <span class="math inline">\(x = \lim_{n \rightarrow \infty} a_n\)</span> for some sequence <span class="math inline">\((a_n)\)</span> contained in <span class="math inline">\(A\)</span> satisfying <span class="math inline">\(a_n \neq x, \; \forall n \in \mathbb{N}\)</span></p>
<h4 id="definition-3.2.6-isolated-point">Definition 3.2.6: Isolated Point</h4>
<p>A point <span class="math inline">\(a \in A\)</span> is an <strong>isolated point</strong> of <span class="math inline">\(A\)</span> if it is not a limit point of <span class="math inline">\(A\)</span>. Isolated point is always in <span class="math inline">\(A\)</span>.</p>
<h4 id="definition-3.2.7-closed-set">Definition 3.2.7: Closed Set</h4>
<p>A set <span class="math inline">\(F \subseteq \mathbb{R}\)</span> is <strong>closed</strong> if it contains all its limit points. Topologically speaking, a closed set is one where convergent sequences within the set have limits that are also in the set.</p>
<h4 id="theorem-3.2.8">Theorem 3.2.8</h4>
<p>A set <span class="math inline">\(F \subseteq \mathbb{R}\)</span> is <strong>closed</strong> if and only if every Cauchy sequence contained in <span class="math inline">\(\mathbb{F}\)</span> has a limit that is also an element of <span class="math inline">\(F\)</span></p>
<h4 id="theorem-3.2.10-density-of-mathbbq-in-mathbbr">Theorem 3.2.10: Density of <span class="math inline">\(\mathbb{Q}\)</span> in <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>For every <span class="math inline">\(y \in \mathbb{R}\)</span>, there exists a sequence of rational numbers that converges to <span class="math inline">\(y\)</span>.</p>
<h4 id="definition-3.2.11-closure">Definition 3.2.11: Closure</h4>
<p>Given a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, let <span class="math inline">\(L\)</span> be the set of all limit points of <span class="math inline">\(A\)</span>. The <strong>closure</strong> of <span class="math inline">\(A\)</span> is defined to be <span class="math inline">\(\bar{A} = A \cup L\)</span>.</p>
<p>That is, if <span class="math inline">\(A\)</span> is an open interval <span class="math inline">\((a, b)\)</span>, then <span class="math inline">\(\bar{A} = [a, b]\)</span>. If <span class="math inline">\(A\)</span> is a closed interval, then <span class="math inline">\(\{\bar{A} = A\}\)</span>. <span class="math inline">\(\bar{A}\)</span> is always a closed set.</p>
<h4 id="theorem-3.2.12">Theorem 3.2.12</h4>
<p>For any <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, the closure <span class="math inline">\(\bar{A}\)</span> is a closed set and is the smallest closed set containing <span class="math inline">\(A\)</span>.</p>
<h4 id="complement">Complement</h4>
<p>In general, if a set is not open that does not imply it must be closed. Many sets such as half-open interval <span class="math inline">\((c,d]\)</span> are neither open nor closed. <span class="math inline">\(\emptyset, \mathbb{R}\)</span> are both open and closed. The complement of a set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is defined to be the set:</p>
<p><span class="math display">\[A^c = \{x \in \mathbb{R}: x \notin A\}\]</span></p>
<h4 id="theorem-3.2.13">Theorem 3.2.13</h4>
<p>A set <span class="math inline">\(O\)</span> is open if and only if <span class="math inline">\(O^c\)</span> is closed. Likewise, a set <span class="math inline">\(F\)</span> is closed if and only if <span class="math inline">\(F^c\)</span> is open.</p>
<h4 id="theorem-3.2.14">Theorem 3.2.14</h4>
<ol type="1">
<li>The union of a finite collection of closed sets is closed.</li>
<li>The intersection of an arbitrary collection of closed sets is closed.</li>
</ol>
<h3 id="compact-sets">Compact Sets</h3>
<h4 id="definition-3.3.1-compactness">Definition 3.3.1: Compactness</h4>
<p>A set <span class="math inline">\(K \subseteq \mathbb{R}\)</span> is <strong>compact</strong> if every sequence in <span class="math inline">\(K\)</span> has a subsequence that converges to a limit that is also in <span class="math inline">\(K\)</span>.</p>
<h4 id="theorem-3.3.3-bounded-sets">Theorem 3.3.3 Bounded Sets</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is <strong>bounded</strong> if there exists <span class="math inline">\(M &gt; 0\)</span> such that <span class="math inline">\(|a| \leq M, \;\forall a \in A\)</span></p>
<h4 id="theorem-3.3.4-characterization-of-compactness-in-mathbbr">Theorem 3.3.4: Characterization of Compactness in <span class="math inline">\(\mathbb{R}\)</span></h4>
<p>A set <span class="math inline">\(K \subseteq \mathbb{R}\)</span> is compact if and only if it is closed and bounded.</p>
<p>We can think of compact sets as generalizations of closed intervals. Whenever a fact involving closed intervals is true, it is often the case that the same results holds when we replace closed interval with compact set.</p>
<h4 id="theorem-3.3.5-nested-compact-set-property">Theorem 3.3.5: Nested Compact Set Property</h4>
<p>If <span class="math inline">\(K_1 \subseteq K_2 \subseteq K_3 \subseteq ..\)</span> is a nested sequence of nonempty compact sets, then the intersection <span class="math inline">\(bigcap^{\infty}_{n=1} K_n\)</span> is nonempty.</p>
<h3 id="perfect-sets-and-connected-sets">Perfect Sets and Connected Sets</h3>
<h4 id="definition-3.4.1">Definition 3.4.1</h4>
<p>A set <span class="math inline">\(P \subseteq \mathbb{R}\)</span> is <strong>perfect</strong> if it is closed and contains no isolated points (eg. closed intervals on real numbers)</p>
<h4 id="theorem-3.4.3">Theorem 3.4.3</h4>
<p>A nonempty perfect set is uncountable.</p>
<h4 id="definition-3.5.1">Definition 3.5.1</h4>
<p>A set <span class="math inline">\(A \subseteq \mathbb{R}\)</span> is called an <span class="math inline">\(F_\sigma\)</span> set if it can be written as the countable union of closed sets. A set <span class="math inline">\(B \subseteq \mathbb{R}\)</span> is called a <span class="math inline">\(G_\delta\)</span> set if it can be written as the countable intersection of open sets.</p>
<h4 id="theorem-3.5.2">Theorem 3.5.2</h4>
<p>If <span class="math inline">\(\{G_1, ...\}\)</span> is a countable collection of dense, open sets, then the intersection <span class="math inline">\(\bigcap^{\infty}_{n=1} G_n\)</span> is not empty.</p>
<h2 id="functional-limits-and-continuity">Functional Limits and Continuity</h2>
<h3 id="functional-limits">Functional Limits</h3>
<h4 id="definition-4.2.1-functional-limit">Definition 4.2.1: Functional Limit</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, and let <span class="math inline">\(c\)</span> be a limit point of the domain <span class="math inline">\(A\)</span>. We say that <span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span>, provided that, for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that whenever <span class="math inline">\(0 &lt; | x - c | &lt; \delta\)</span> and <span class="math inline">\(x \in A\)</span> it follows that <span class="math inline">\(| f(x) - L | &lt; \epsilon\)</span>. In other words, Let <span class="math inline">\(c\)</span> be a limit point of the domain of <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>. We say <span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span> provided that, for every <span class="math inline">\(V_{\epsilon} (L)\)</span>, there exists a <span class="math inline">\(V_{\delta} (c)\)</span> with the property that for all <span class="math inline">\(x \in V_{\delta} (c)\)</span> different from <span class="math inline">\(c\)</span>, it follows that <span class="math inline">\(f(x ) \in V_{\epsilon} (L)\)</span>.</p>
<h4 id="theorem-4.2.3-sequential-criterion-for-functional-limits">Theorem 4.2.3: Sequential Criterion for Functional Limits</h4>
<p>Given a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and a limit point <span class="math inline">\(c\)</span> of <span class="math inline">\(A\)</span>, the following two statements are equivalent:</p>
<ol type="1">
<li><span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span></li>
<li>For all sequences <span class="math inline">\((x_n) \subseteq A\)</span> satisfying <span class="math inline">\(x_n \neq c\)</span> and <span class="math inline">\((x_n) \rightarrow c\)</span>, it follows that <span class="math inline">\(f(x_n) \rightarrow L\)</span>.</li>
</ol>
<h4 id="corollary-4.2.4-algebraic-limit-theorem-for-functional-limits">Corollary 4.2.4: Algebraic Limit Theorem for Functional Limits</h4>
<p>Let <span class="math inline">\(f, g\)</span> be functions defined on a domain <span class="math inline">\(A \subseteq \mathbb{R}\)</span>, and assume <span class="math inline">\(\lim_{x \rightarrow c} f(x) = L\)</span> and <span class="math inline">\(\lim_{x \rightarrow c} g(x) = M\)</span>, for some limit point <span class="math inline">\(c\)</span> of <span class="math inline">\(A\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\(\lim_{x \rightarrow c} kf(x) = kL\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow c} [f(x) + g(x)] = L + M\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow c} f(x)g(x) = LM\)</span></li>
<li><span class="math inline">\(\lim_{x \rightarrow c} \frac{f(x)}{g(x)} = \frac{L}{M}\)</span>, given <span class="math inline">\(M \neq 0\)</span></li>
</ol>
<h4 id="corollary-4.2.5-divergence-criterion-for-functional-limits">Corollary 4.2.5: Divergence Criterion for Functional Limits</h4>
<p>Let <span class="math inline">\(f\)</span> be a function defined on <span class="math inline">\(A\)</span>, and let <span class="math inline">\(c\)</span> be a limit point of <span class="math inline">\(A\)</span>. If there exist two sequences <span class="math inline">\((x_n), (y_n)\)</span> in <span class="math inline">\(A\)</span> with <span class="math inline">\(x_n \neq c\)</span> and <span class="math inline">\(y_n \neq c\)</span> and</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} x_n = \lim_{n \rightarrow \infty} y_n = c\]</span></p>
<p>but</p>
<p><span class="math display">\[\lim_{n \rightarrow \infty} f(x_n) \neq \lim_{n \rightarrow \infty} f(y_n) \]</span></p>
<p>then, we can conclude that the functional limit <span class="math inline">\(\lim_{n \rightarrow c} f(x)\)</span> <strong>does not exist</strong>.</p>
<h3 id="continues-functions">Continues Functions</h3>
<h4 id="definition-4.3.1-continuity">Definition 4.3.1: Continuity</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is <strong>continues</strong> at a point <span class="math inline">\(c \in A\)</span> if for all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t whenever <span class="math inline">\(|x - c| &lt; \delta\)</span> it follows that <span class="math inline">\(|f(x) - f(c)| &lt; \epsilon\)</span>.</p>
<p>If <span class="math inline">\(c\)</span> is a <strong>limit point</strong> of <span class="math inline">\(A\)</span>, we can reduce the definition to say that, <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c \in A\)</span> if</p>
<p><span class="math display">\[\lim_{x \rightarrow c} f(x) = f(c)\]</span></p>
<p>If <span class="math inline">\(f\)</span> is <strong>continues at every point</strong> in the domain <span class="math inline">\(A\)</span>, then we say that <span class="math inline">\(f\)</span> is continues on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-4.3.2-characterizations-of-continuity">Theorem 4.3.2: Characterizations of Continuity</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and let <span class="math inline">\(c \in A\)</span>. The function <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c\)</span> if and only if any one of the following three conditions is met:</p>
<ol type="1">
<li>For all <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(|x - c| &lt; \delta\)</span> implies <span class="math inline">\(|f(x) - f(c)| &lt; \epsilon\)</span>.</li>
<li>For all <span class="math inline">\(V_{\epsilon} (f(c))\)</span>, there exists a <span class="math inline">\(V_{\delta} (c)\)</span> with the property that <span class="math inline">\(x \in V \implies f(x) \in V_{\epsilon} (f(c))\)</span>.</li>
<li>For all <span class="math inline">\((x_n) \rightarrow c\)</span>, it follows that <span class="math inline">\(f(x) \rightarrow f(c)\)</span>.</li>
<li>If <span class="math inline">\(c\)</span> is a limit point of <span class="math inline">\(A\)</span>, then the above conditions equivalent to <span class="math display">\[\lim_{x \rightarrow c} f(x) = f(c)\]</span></li>
</ol>
<h4 id="corollary-4.3.3-criterion-for-discontinuity">Corollary 4.3.3: Criterion for Discontinuity</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, and let <span class="math inline">\(c \in A\)</span> be a limit point of <span class="math inline">\(A\)</span>. If there exists a sequence <span class="math inline">\((x_n) \subseteq A\)</span> where <span class="math inline">\((x_n) \rightarrow c\)</span>, but such that <span class="math inline">\(f(x_n)\)</span> does not converge to <span class="math inline">\(f(c)\)</span>, we may conclude that <span class="math inline">\(f\)</span> is not continues at <span class="math inline">\(c\)</span>.</p>
<h4 id="theorem-4.3.4-algebraic-continuity-theorem">Theorem 4.3.4: Algebraic Continuity Theorem</h4>
<p>Assume <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> are continuous at a point <span class="math inline">\(c \in A\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\(kf(x)\)</span> is continuous at <span class="math inline">\(c\)</span> for all <span class="math inline">\(k \in \mathbb{R}\)</span>.</li>
<li><span class="math inline">\(f(x) + g(x)\)</span> is continuous at <span class="math inline">\(c\)</span>.</li>
<li><span class="math inline">\(f(x) g(x)\)</span> is continuous at <span class="math inline">\(c\)</span>.</li>
<li><span class="math inline">\(\frac{f(x)}{g(x)}\)</span> is continuous at c, provided the quotient is defined.</li>
</ol>
<h4 id="theorem-4.3.9-composition-of-continuous-functions">Theorem 4.3.9: Composition of Continuous Functions</h4>
<p>Given <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(b \rightarrow \mathbb{R}\)</span>, assume that the range <span class="math inline">\(f(A) = \{f(x): x \in A\}\)</span> is contained in the domain <span class="math inline">\(B\)</span> so that the composition <span class="math inline">\(g \circ f(x) = g(f(x))\)</span> is defined on <span class="math inline">\(A\)</span>.</p>
<p>If <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(c \in A\)</span>, and if <span class="math inline">\(g\)</span> is continuous at <span class="math inline">\(f(c) \in B\)</span>, then <span class="math inline">\(g \circ f\)</span> is continuous at <span class="math inline">\(c\)</span>.</p>
<h3 id="continuous-functions-on-compact-sets">Continuous Functions on Compact Sets</h3>
<p>Given a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and a subset <span class="math inline">\(B \subseteq A\)</span>, the notation <span class="math inline">\(f(B)\)</span> refers to the range of <span class="math inline">\(f\)</span> over the set <span class="math inline">\(B\)</span>, that is,</p>
<p><span class="math display">\[f(B) = \{f(x): x \in B\}\]</span></p>
<h4 id="theorem-4.4.1-preservation-of-compact-sets">Theorem 4.4.1: Preservation of Compact Sets</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> be continuous on <span class="math inline">\(A\)</span>, if <span class="math inline">\(K \subseteq A\)</span> is compact, then <span class="math inline">\(f(K)\)</span> is compact as well.</p>
<h4 id="theorem-4.4.2-extreme-value-theorem">Theorem 4.4.2: Extreme Value Theorem</h4>
<p>If <span class="math inline">\(f: K \rightarrow \mathbb{R}\)</span> is continuous on a compact set <span class="math inline">\(K \subseteq \mathbb{R}\)</span>, then <span class="math inline">\(f\)</span> attains a maximum and minimum value. In other words, there exist <span class="math inline">\(x_0, x_1 \in K\)</span> such that <span class="math inline">\(f(x_0) \leq f(x) \leq f(x_1)\)</span> for all <span class="math inline">\(x \in K\)</span>.</p>
<h4 id="definition-4.4.4-uniform-continuity-stronger-than-continuity">Definition 4.4.4: Uniform Continuity (stronger than continuity)</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is <strong>uniformly continuous</strong> on <span class="math inline">\(A\)</span> if for every <span class="math inline">\(\epsilon &gt; 0\)</span> there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that for all <span class="math inline">\(x, y \in A\)</span>, <span class="math inline">\(|x - y| &lt; \delta \implies |f(x) - f(y)| &lt; \epsilon\)</span>.</p>
<p><strong>The difference between saying "f is continuous on A" and "f is uniformly continuous on A" is that, for the first definition, given <span class="math inline">\(\epsilon &gt; 0\)</span> and <span class="math inline">\(c \in A\)</span>, we can find a <span class="math inline">\(\delta &gt; 0\)</span> s.t the conditions are satisfied. However, for a function to be uniformly continuous, given <span class="math inline">\(\epsilon &gt; 0\)</span>, we need to find a <span class="math inline">\(\delta &gt; 0\)</span> that works for all <span class="math inline">\(c \in A\)</span>. Thus, uniform continuity is stronger.</strong></p>
<h4 id="theorem-4.4.5-sequential-criterion-for-absence-of-uniform-continuity">Theorem 4.4.5: Sequential Criterion for Absence of Uniform Continuity</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> fails to be uniformly continuous on <span class="math inline">\(A\)</span> if and only if there exists a particular <span class="math inline">\(\epsilon_0 &gt; 0\)</span> and two sequences <span class="math inline">\((x_n), (y_n)\)</span> in <span class="math inline">\(A\)</span> satisfying:</p>
<p><span class="math display">\[|x_n - y_n| \rightarrow 0\]</span></p>
<p>but</p>
<p><span class="math display">\[|f(x_n) - f(y_n)| \geq \epsilon_0\]</span></p>
<h4 id="theorem-4.4.7-uniform-continuity-on-compact-sets">Theorem 4.4.7: Uniform Continuity on Compact Sets</h4>
<p>A function that is continuous on a compact set <span class="math inline">\(K\)</span> is uniformly continuous on <span class="math inline">\(K\)</span>.</p>
<h4 id="theorem-4.5.1-intermediate-value-theorem">Theorem 4.5.1: Intermediate Value Theorem</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous. If <span class="math inline">\(L\)</span> is a real number satisfying <span class="math inline">\(f(a) &lt; L &lt; f(b)\)</span> or <span class="math inline">\(f(a) &gt; L &gt; f(b)\)</span>, then there exists a point <span class="math inline">\(c \subseteq (a, b)\)</span> where <span class="math inline">\(f(c) = L\)</span>.</p>
<h4 id="definition-4.5.3-intermediate-value-property">Definition 4.5.3: Intermediate Value Property</h4>
<p>A function <span class="math inline">\(f\)</span> has the <strong>intermediate value property</strong> on an interval <span class="math inline">\([a, b]\)</span> if for all <span class="math inline">\(x &lt; y\)</span> in <span class="math inline">\([a, b]\)</span> and all <span class="math inline">\(L\)</span> between <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(f(y)\)</span>, it is always possible to find a point <span class="math inline">\(c \in (x, y)\)</span> where <span class="math inline">\(f(c) = L\)</span>.</p>
<p>Another way to summarize the intermediate value theorem is to day that every continuous function on <span class="math inline">\([a, b]\)</span> has the intermediate value property.</p>
<h3 id="sets-of-discontinuity">Sets of Discontinuity</h3>
<h4 id="definition-4.6.1-monotonic-function">Definition 4.6.1: Monotonic Function</h4>
<p>A function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> is <strong>increasing</strong> on <span class="math inline">\(A\)</span> if <span class="math inline">\(f(x) \leq f(y)\)</span> whenever <span class="math inline">\(x &lt; y\)</span> and <strong>decreasing</strong> if <span class="math inline">\(f(x) \geq f(y)\)</span> whenever <span class="math inline">\(x &lt; y\)</span> in <span class="math inline">\(A\)</span>. A <strong>monotone function</strong> is one that is either increasing or decreasing.</p>
<h4 id="definition-4.6.2-right-hand-limit">Definition 4.6.2 Right Hand Limit</h4>
<p>Given a limit point <span class="math inline">\(c\)</span> of a set <span class="math inline">\(A\)</span> and a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, we write:</p>
<p><span class="math display">\[\lim_{x \rightarrow c^+} f(x) = L\]</span></p>
<p>if for all <span class="math inline">\(\epsilon &gt; 0\)</span> there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(|f(x) - L| &lt; \epsilon\)</span> whenever <span class="math inline">\(0 &lt; x - c &lt; \delta\)</span>.</p>
<h4 id="definition-4.6.3-left-hand-limit">Definition 4.6.3 Left Hand Limit</h4>
<p>Given a limit point <span class="math inline">\(c\)</span> of a set <span class="math inline">\(A\)</span> and a function <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span>, we write:</p>
<p><span class="math display">\[\lim_{x \rightarrow c^-} f(x) = L\]</span></p>
<p>if for all <span class="math inline">\(\epsilon &gt; 0\)</span> there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t <span class="math inline">\(|f(x) - L| &lt; \epsilon\)</span> whenever <span class="math inline">\(-\delta &lt; x - c &lt; 0\)</span>.</p>
<h4 id="theorem-4.6.4">Theorem 4.6.4</h4>
<p>Given <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and a limit point <span class="math inline">\(c\)</span> of <span class="math inline">\(A\)</span>, <span class="math inline">\(lim_{x \rightarrow c} f(x) = L\)</span> if and only if</p>
<p><span class="math display">\[\lim_{x \rightarrow c^-} f(x) = L\]</span></p>
<p>and</p>
<p><span class="math display">\[\lim{x \rightarrow c^+} f(x) = L\]</span></p>
<h4 id="definition-4.6.5-alpha-continuous">Definition 4.6.5: <span class="math inline">\(\alpha\)</span>-continuous</h4>
<p>Let <span class="math inline">\(f\)</span> be defined on <span class="math inline">\(\mathbb{R}\)</span>, and let <span class="math inline">\(\alpha &gt; 0\)</span>. The function <span class="math inline">\(f\)</span> is <span class="math inline">\(\alpha\)</span>-continuous at <span class="math inline">\(x \in \mathbb{R}\)</span> if there exists a <span class="math inline">\(\delta &gt; 0\)</span> s.t for all <span class="math inline">\(y, z \in (x - \delta, x + \delta)\)</span> it follows that <span class="math inline">\(f(y) - f(z)| &lt; \alpha\)</span>.</p>
<h2 id="derivatives">Derivatives</h2>
<h3 id="derivatives-and-the-intermediate-value-property">Derivatives and the Intermediate Value Property</h3>
<h4 id="definition-5.2.1-differentiability">Definition 5.2.1: Differentiability</h4>
<p>Let <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> be a function defined on an interval <span class="math inline">\(A\)</span>. Given <span class="math inline">\(c \in A\)</span>, the <strong>derivative</strong> of <span class="math inline">\(g\)</span> at <span class="math inline">\(c\)</span> is defined by:</p>
<p><span class="math display">\[g^{\prime} (c) = \lim_{x \rightarrow c} \frac{g(x) - g(c)}{x - c}\]</span></p>
<p>provided this limit exists. In this case, we say <span class="math inline">\(g\)</span> is differentiable at <span class="math inline">\(c\)</span>. If <span class="math inline">\(g^{\prime}\)</span> exists for all points <span class="math inline">\(c \in A\)</span>, we say that <span class="math inline">\(g\)</span> is differentiable on <span class="math inline">\(A\)</span>.</p>
<h4 id="theorem-5.2.3">Theorem 5.2.3</h4>
<p>If <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> is differentiable at a point <span class="math inline">\(c \in A\)</span>, then <span class="math inline">\(g\)</span> is continuous at <span class="math inline">\(c\)</span> as well.</p>
<h4 id="theorem-5.2.4-algebraic-differentiability-theorem">Theorem 5.2.4: Algebraic Differentiability Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be functions defined on an interval <span class="math inline">\(A\)</span>, and assume both are differentiable at some point <span class="math inline">\(c \in A\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\((f + g)^{\prime} (c) = f^{\prime} (c) + g^{\prime} (c)\)</span></li>
<li><span class="math inline">\((kf)^{\prime} (c) = kf^{\prime} (c), \forall k \in \mathbb{R}\)</span></li>
<li><span class="math inline">\((fg)^{\prime} (c) = f^{\prime} (c) g(c) + f(c) g^{\prime} (c)\)</span></li>
<li><span class="math inline">\((\frac{f}{g})^{\prime} (c) = \frac{g(c)f^{\prime}(c) - f(c)g^{\prime}(c)}{[g(c)]^2}, \;\; g(c) \neq 0\)</span></li>
</ol>
<h4 id="theorem-5.2.5-chain-rule">Theorem 5.2.5: Chain Rule</h4>
<p>Let <span class="math inline">\(f: A \rightarrow \mathbb{R}\)</span> and <span class="math inline">\(g: B \rightarrow \mathbb{R}\)</span> satisfy <span class="math inline">\(f(A) \subseteq B\)</span> so that the composition <span class="math inline">\((g \circ f)^{\prime}\)</span> is defined. If <span class="math inline">\(f\)</span> is differentiable at <span class="math inline">\(c \in A\)</span> and if <span class="math inline">\(g\)</span> is differentiable at <span class="math inline">\(f(c) \in B\)</span>, then <span class="math inline">\(g \circ f\)</span> is differentiable at <span class="math inline">\(c\)</span> with:</p>
<p><span class="math display">\[(g\circ f)^{\prime}(c) = g^{\prime} (f(c)) \cdot f^{\prime} (c)\]</span></p>
<h4 id="theorem-5.2.6-interior-extremum-theorem">Theorem 5.2.6: Interior Extremum Theorem</h4>
<p>Let <span class="math inline">\(f\)</span> be differentiable on an open interval <span class="math inline">\((a, b)\)</span>. If <span class="math inline">\(f\)</span> attains a maximum value at some point <span class="math inline">\(c \in (a, b)\)</span> (i.e <span class="math inline">\(f(c) \geq f(x) \; \forall x \in (a, b)\)</span>), then <span class="math inline">\(f^{\prime}(c) = 0\)</span>. The same is true if <span class="math inline">\(f(c)\)</span> is a minimum value.</p>
<h4 id="theorem-5.2.7-darbouxs-theorem">Theorem 5.2.7: Darboux's Theorem</h4>
<p>If <span class="math inline">\(f\)</span> is differentiable on an interval <span class="math inline">\([a, b]\)</span>, and if <span class="math inline">\(\alpha\)</span> satisfies <span class="math inline">\(f^{\prime}(a) &lt; \alpha &lt; f^{\prime} (b)\)</span> or <span class="math inline">\(f^{\prime} &gt; \alpha &gt; f^{\prime} (b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where <span class="math inline">\(f^{\prime} (c) = \alpha\)</span>.</p>
<h3 id="mean-value-theorem">Mean Value Theorem</h3>
<h4 id="theorem-5.3.1-rolles-theorem">Theorem 5.3.1: Rolle's Theorem</h4>
<p>Let <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> be continuous on <span class="math inline">\([a, b]\)</span> and differentiable on <span class="math inline">\((a, b)\)</span>. If <span class="math inline">\(f(a) = f(b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where <span class="math inline">\(f^{\prime} (c) = 0\)</span>.</p>
<h4 id="theorem-5.3.2-mean-value-theorem">Theorem 5.3.2: Mean Value Theorem</h4>
<p>If <span class="math inline">\(f: [a, b] \rightarrow \mathbb{R}\)</span> is continuous on <span class="math inline">\([a, b]\)</span> and differentiable on <span class="math inline">\((a, b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where</p>
<p><span class="math display">\[f^{\prime} (c) = \frac{f(b) - f(a)}{b - a}\]</span></p>
<h4 id="corollary-5.3.3">Corollary 5.3.3</h4>
<p>If <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> is differentiable on an interval <span class="math inline">\(A\)</span> and satisfies <span class="math inline">\(g^{\prime}(x) = 0, \;\forall x \in A\)</span>, then <span class="math inline">\(g(x) = k\)</span> for some constant <span class="math inline">\(k \in \mathbb{R}\)</span>.</p>
<h4 id="corollary-5.3.4">Corollary 5.3.4</h4>
<p>If <span class="math inline">\(f, g\)</span> are differentiable functions on an interval <span class="math inline">\(A\)</span> and satisfy <span class="math inline">\(f^{\prime} (x) = g^{\prime} (x), \; \forall x \in A\)</span>, then <span class="math inline">\(f(x) = g(x) + k\)</span> for some constant <span class="math inline">\(k \in \mathbb{R}\)</span>.</p>
<h4 id="theorem-5.3.5-generalized-mean-value-theorem">Theorem 5.3.5: Generalized Mean Value Theorem</h4>
<p>If <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are continuous on the closed interval <span class="math inline">\([a, b]\)</span> and differentiable on the open interval <span class="math inline">\((a, b)\)</span>, then there exists a point <span class="math inline">\(c \in (a, b)\)</span> where</p>
<p><span class="math display">\[[f(b) - f(a)]g^{\prime} (c) = [g(b) - g(a)] f^{\prime} (c)\]</span></p>
<p>If <span class="math inline">\(g^{\prime}\)</span> is never zero on <span class="math inline">\((a, b)\)</span>, then the conclusion can be stated as:</p>
<p><span class="math display">\[\frac{f^{\prime}(c)}{g^{\prime}(c)} = \frac{f(b) - f(a)}{g(b) - g(a)}\]</span></p>
<h4 id="theorem-5.3.6-lhospitals-rule-00-case">Theorem 5.3.6: L’Hospital’s Rule: 0/0 case</h4>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be continuous on an interval containing <span class="math inline">\(a\)</span>, and assume <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are differentiable on this interval with the possible exception of the point <span class="math inline">\(a\)</span>. If <span class="math inline">\(f(a) = g(a) = 0\)</span> and <span class="math inline">\(g^{\prime} (x) \neq 0, \; \forall x \neq a\)</span>, then:</p>
<p><span class="math display">\[\lim_{x \rightarrow a} \frac{f^{\prime} (x)}{g^{\prime} (x)} = L \implies \lim_{x \rightarrow a} \frac{f (x)}{g (x)} = L\]</span></p>
<h4 id="definition-5.3.7">Definition 5.3.7</h4>
<p>Given <span class="math inline">\(g: A \rightarrow \mathbb{R}\)</span> and a limit point <span class="math inline">\(c \in A\)</span>, we say that <span class="math inline">\(\lim_{x \rightarrow c} g(x) = \infty\)</span> if, for every <span class="math inline">\(M &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that whenever <span class="math inline">\(0 &lt; | x - c | &lt; \delta\)</span> it follows that <span class="math inline">\(g(x) \geq M\)</span>. We can define <span class="math inline">\(\lim_{x \rightarrow c} g(x) = -\infty\)</span> in a similar way.</p>
<h4 id="theorem-5.3.8-lhospitals-rule-inftyinfty-case">Theorem 5.3.8: L’Hospital’s Rule: <span class="math inline">\(\infty/\infty\)</span> case</h4>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be differentiable on <span class="math inline">\((a, b)\)</span>. If <span class="math inline">\(\lim_{x \rightarrow a} g(x) = \infty\)</span> or <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(g^{\prime} (x) \neq 0, \; \forall x \neq a\)</span>, then:</p>
<p><span class="math display">\[\lim_{x \rightarrow a} \frac{f^{\prime} (x)}{g^{\prime} (x)} = L \implies \lim_{x \rightarrow a} \frac{f (x)}{g (x)} = L\]</span></p>
<p>Moreover, these functions have derivatives of all orders.</p>
<h4 id="theorem">Theorem</h4>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>
<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2021 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhu, Zhaoyang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">743k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">11:16</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.3" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{&quot;enable&quot;:true,&quot;app_id&quot;:&quot;gPOc95wWW2Hwp2pkVSAAz28m-MdYXbMMI&quot;,&quot;app_key&quot;:&quot;7Sf65xCHXfEEdBvu29UHSYdV&quot;,&quot;server_url&quot;:&quot;https:&#x2F;&#x2F;swag1ong.github.io&quot;,&quot;security&quot;:true}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{&quot;enable&quot;:true,&quot;repo&quot;:&quot;swag1ong&#x2F;swag1ong.github.io&quot;,&quot;issue_term&quot;:&quot;pathname&quot;,&quot;theme&quot;:&quot;github-light&quot;,&quot;pathname&quot;:&quot;pathname&quot;}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
